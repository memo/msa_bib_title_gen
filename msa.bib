@inproceedings{Akten2016,
abstract = {Recurrent Neural Networks (RNN), particularly Long Short Term Memory (LSTM) RNNs, are a popular and very successful method for learning and generating sequences. However, current generative RNN techniques do not allow real-time interactive control of the sequence generation process, thus aren't well suited for live creative expression. We propose a method of real-time continuous control and ‘steering' of sequence generation using an ensemble of RNNs and dynamically altering the mixture weights of the models. We demonstrate the method using character based LSTM networks and a gestural interface allowing users to ‘conduct' the generation of text.},
author = {Akten, Memo and Grierson, Mick},
booktitle = {NIPS 2016, Recurrent Neural Networks Symposium, Poster presentation},
file = {:home/memo/Mendeley/data/Akten, Grierson - 2016 - Real-time interactive sequence generation and control with Recurrent Neural Network ensembles.pdf:pdf},
title = {{Real-time interactive sequence generation and control with Recurrent Neural Network ensembles}},
year = {2016}
}
@inproceedings{Akten2016a,
abstract = {We investigate a human-machine collaborative drawing environment in which an autonomous agent sketches images while optionally allowing a user to directly influence the agent's trajectory. We combine Monte Carlo Tree Search with image classifiers and test both shallow models (e.g. multinomial logistic regression) and deep Convolutional Neural Networks (e.g. LeNet, Inception v3). We found that using the shallow model, the agent produces a limited variety of images, which are noticably recogonisable by humans. However, using the deeper models, the agent produces a more diverse range of images, and while the agent remains very confident (99.99{\%}) in having achieved its objective, to humans they mostly resemble unrecognisable ‘random' noise. We relate this to recent research which also discovered that ‘deep neural networks are easily fooled' [30] and we discuss possible solutions and future directions for the research.},
author = {Akten, Memo and Grierson, Mick},
booktitle = {NIPS 2016, Constructive Machine Learning Workshop},
file = {:home/memo/Mendeley/data/Akten, Grierson - 2016 - Collaborative creativity with Monte-Carlo Tree Search and Convolutional Neural Networks Memo.pdf:pdf},
title = {{Collaborative creativity with Monte-Carlo Tree Search and Convolutional Neural Networks Memo}},
year = {2016}
}
@inproceedings{Berio,
abstract = {The purpose of this study is to explore the feasibility and potential benefits of using a physiological plausible model of handwriting as a feature representation for sequence generation with recurrent mixture density networks. We build on recent results in handwriting prediction developed by Graves (2013), and we focus on generating sequences that possess the statistical and dynamic qualities of handwriting and calligraphic art forms. Rather than model raw sequence data, we first preprocess and reconstruct the input training data with a concise representation given by a motor plan (in the form of a coarse sequence of ‘ballistic' targets) and corresponding dynamic parameters (which define the velocity and curvature of the pen-tip trajectory). This representation provides a number of advantages, such as enabling the system to learn from very few examples by introducing artificial variability in the training data, and mixing of visual and dynamic qualities learned from different datasets},
author = {Berio, Daniel and Akten, Memo and Leymarie, Frederic Fol and Grierson, Mick and {R{\'{e}}jean Plamondon}},
file = {:home/memo/Mendeley/data/Berio et al. - Unknown - SEQUENCE GENERATION WITH A PHYSIOLOGICALLY PLAUSIBLE MODEL OF HANDWRITING AND RECURRENT MIXTURE DENSITY NETWORK.pdf:pdf},
title = {{SEQUENCE GENERATION WITH A PHYSIOLOGICALLY PLAUSIBLE MODEL OF HANDWRITING AND RECURRENT MIXTURE DENSITY NETWORKS}}
}
@article{Yosinski2015a,
abstract = {We can better understand deep neural networks by identifying which features each of their neurons have learned to detect. To do so, researchers have created Deep Visualization techniques including activation maximization, which synthetically generates inputs (e.g. images) that maximally activate each neuron. A limitation of current techniques is that they assume each neuron detects only one type of feature, but we know that neurons can be multifaceted, in that they fire in response to many different types of features: for example, a grocery store class neuron must activate either for rows of produce or for a storefront. Previous activation maximization techniques constructed images without regard for the multiple different facets of a neuron, creating inappropriate mixes of colors, parts of objects, scales, orientations, etc. Here, we introduce an algorithm that explicitly uncovers the multiple facets of each neuron by producing a synthetic visualization of each of the types of images that activate a neuron. We also introduce regularization methods that produce state-of-the-art results in terms of the interpretability of images obtained by activation maximization. By separately synthesizing each type of image a neuron fires in response to, the visualizations have more appropriate colors and coherent global structure. Multifaceted feature visualization thus provides a clearer and more comprehensive description of the role of each neuron.},
archivePrefix = {arXiv},
arxivId = {1602.03616},
author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
eprint = {1602.03616},
file = {:home/memo/Mendeley/data/Yosinski, Clune, Edu - 2015 - Multifaceted Feature Visualization Uncovering the Different Types of Features Learned By Each Neuron in D.pdf:pdf},
journal = {Arxiv},
pages = {23},
title = {{Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks}},
url = {http://arxiv.org/abs/1602.03616},
year = {2016}
}
@article{Dosovitskiy,
abstract = {Image-generating machine learning models are typically trained with loss functions based on distance in the image space. This often leads to over-smoothed results. We propose a class of loss functions, which we call deep perceptual similarity metrics (DeePSiM), that mitigate this problem. Instead of computing distances in the image space, we compute distances between image features extracted by deep neural networks. This metric better reflects perceptually similarity of images and thus leads to better results. We show three applications: autoencoder training, a modification of a variational autoencoder, and inversion of deep convolutional networks. In all cases, the generated images look sharp and resemble natural images.},
author = {Dosovitskiy, Alexey and Brox, Thomas},
file = {:home/memo/Mendeley/data/Dosovitskiy, Brox - 2016 - Generating Images with Perceptual Similarity Metrics based on Deep Networks.pdf:pdf},
journal = {arXiv preprint arXiv: 1602.02644},
title = {{Generating Images with Perceptual Similarity Metrics based on Deep Networks}},
url = {http://arxiv.org/abs/1602.02644},
year = {2016}
}
@article{Neil2016,
abstract = {Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. However, current RNN models are ill-suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artificial sensors that generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range that produces updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes at runtime.},
archivePrefix = {arXiv},
arxivId = {1610.09513},
author = {Neil, Daniel and Pfeiffer, Michael and Liu, Shih-chii},
eprint = {1610.09513},
file = {:home/memo/Mendeley/data/Neil, Pfeiffer, Liu - 2016 - Phased LSTM Accelerating Recurrent Network Training for Long or Event-based Sequences.pdf:pdf},
number = {Nips},
title = {{Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences}},
url = {http://arxiv.org/abs/1610.09513},
year = {2016}
}
@article{Domingos2012,
abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the “folk knowledge” that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Domingos, Pedro},
doi = {10.1145/2347736.2347755},
eprint = {9605103},
file = {:home/memo/Mendeley/data/Domingos - 2012 - A few useful things to know about machine learning.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
number = {10},
pages = {78},
pmid = {1000183096},
primaryClass = {cs},
title = {{A few useful things to know about machine learning}},
volume = {55},
year = {2012}
}
@article{Thickstun2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.09827v1},
author = {Thickstun, John and Harchaoui, Zaid and Kakade, Sham},
eprint = {arXiv:1611.09827v1},
file = {:home/memo/Mendeley/data/Thickstun, Harchaoui, Kakade - 2016 - Learning Features of Music from Scratch.pdf:pdf},
title = {{Learning Features of Music from Scratch}},
year = {2016}
}
@article{Williams1996,
abstract = {Neural network outputs are interpreted as parameters of statistical$\backslash$ndistributions. This allows us to fit conditional distributions in$\backslash$nwhich the parameters depend on the inputs to the network. We exploit$\backslash$nthis in modeling multivariate data, including the univariate case,$\backslash$nin which there may be input-dependent (e.g., time-dependent) correlations$\backslash$nbetween output components. This provides a novel way of modeling$\backslash$nconditional correlation that extends existing techniques for determining$\backslash$ninput-dependent (local) error bars.},
author = {Williams, Peter M},
doi = {10.1162/neco.1996.8.4.843},
file = {:home/memo/Mendeley/data/Williams - 1996 - Using Neural Networks to Model Conditional Multivariate Densities.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {4},
pages = {843--854},
title = {{Using Neural Networks to Model Conditional Multivariate Densities}},
volume = {8},
year = {1996}
}
@article{Friston2006,
abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure. ?? 2006.},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.4122v2},
author = {Friston, Karl and Kilner, James and Harrison, Lee},
doi = {10.1016/j.jphysparis.2006.10.001},
eprint = {arXiv:1401.4122v2},
file = {:home/memo/Mendeley/data/Friston, Kilner, Harrison - 2006 - A free energy principle for the brain.pdf:pdf},
isbn = {0928-4257},
issn = {09284257},
journal = {Journal of Physiology Paris},
keywords = {Action,Attention,Free energy,Hierarchical,Inference,Learning,Perception,Selection,Variational Bayes},
number = {1-3},
pages = {70--87},
pmid = {17097864},
title = {{A free energy principle for the brain}},
volume = {100},
year = {2006}
}
@article{Yosinski2014,
abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
archivePrefix = {arXiv},
arxivId = {1411.1792},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
eprint = {1411.1792},
file = {:home/memo/Mendeley/data/Yosinski et al. - 2014 - How transferable are features in deep neural networks.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 27 (Proceedings of NIPS)},
pages = {1--9},
title = {{How transferable are features in deep neural networks?}},
url = {http://arxiv.org/abs/1411.1792},
volume = {27},
year = {2014}
}
@article{Friston2009,
abstract = {This article reviews a free-energy formulation that advances Helmholtz's agenda to find principles of brain function based on conservation laws and neuronal energy. It rests on advances in statistical physics, theoretical biology and machine learning to explain a remarkable range of facts about brain structure and function. We could have just scratched the surface of what this formulation offers; for example, it is becoming clear that the Bayesian brain is just one facet of the free-energy principle and that perception is an inevitable consequence of active exchange with the environment. Furthermore, one can see easily how constructs like memory, attention, value, reinforcement and salience might disclose their simple relationships within this framework. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Friston, Karl},
doi = {10.1016/j.tics.2009.04.005},
file = {:home/memo/Mendeley/data/Friston - 2009 - The free-energy principle a rough guide to the brain.pdf:pdf},
isbn = {1364-6613 (Print)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {7},
pages = {293--301},
pmid = {19559644},
title = {{The free-energy principle: a rough guide to the brain?}},
volume = {13},
year = {2009}
}
@article{Donahue2014,
abstract = {We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.},
archivePrefix = {arXiv},
arxivId = {1310.1531},
author = {Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
eprint = {1310.1531},
file = {:home/memo/Mendeley/data/Donahue et al. - 2014 - DeCAF A Deep Convolutional Activation Feature for Generic Visual Recognition.pdf:pdf},
isbn = {9781634393973},
journal = {Icml},
pages = {647--655},
title = {{DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition}},
url = {http://arxiv.org/abs/1310.1531},
volume = {32},
year = {2014}
}
@article{Wu2016a,
abstract = {We study, for the first time, automated inference on criminality based solely on still face images. Via supervised machine learning, we build four classifiers (logistic regression, KNN, SVM, CNN) using facial images of 1856 real persons controlled for race, gender, age and facial expressions, nearly half of whom were convicted criminals, for discriminating between criminals and non-criminals. All four classifiers perform consistently well and produce evidence for the validity of automated face-induced inference on criminality, despite the historical controversy surrounding the topic. Also, we find some discriminating structural features for predicting criminality, such as lip curvature, eye inner corner distance, and the so-called nose-mouth angle. Above all, the most important discovery of this research is that criminal and non-criminal face images populate two quite distinctive manifolds. The variation among criminal faces is significantly greater than that of the non-criminal faces. The two manifolds consisting of criminal and non-criminal faces appear to be concentric, with the non-criminal manifold lying in the kernel with a smaller span, exhibiting a law of normality for faces of non-criminals. In other words, the faces of general law-biding public have a greater degree of resemblance compared with the faces of criminals, or criminals have a higher degree of dissimilarity in facial appearance than normal people.},
archivePrefix = {arXiv},
arxivId = {1611.04135},
author = {Wu, Xiaolin and Zhang, Xi},
eprint = {1611.04135},
file = {:home/memo/Mendeley/data/Wu, Zhang - 2016 - Automated Inference on Criminality using Face Images.pdf:pdf},
title = {{Automated Inference on Criminality using Face Images}},
url = {http://arxiv.org/abs/1611.04135},
year = {2016}
}
@article{Clevert2015,
abstract = {We introduce the "exponential linear unit" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10{\%} classification error for a single crop, single model network.},
archivePrefix = {arXiv},
arxivId = {1511.07289},
author = {Clevert, Djork-Arn{\'{e}} and Unterthiner, Thomas and Hochreiter, Sepp},
eprint = {1511.07289},
file = {:home/memo/Mendeley/data/Clevert, Unterthiner, Hochreiter - 2015 - Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs).pdf:pdf},
journal = {Under review of ICLR2016， 提出了ELU},
number = {1997},
pages = {1--13},
title = {{Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)}},
url = {http://arxiv.org/pdf/1511.07289.pdf{\%}5Cnhttp://arxiv.org/abs/1511.07289{\%}5Cnhttp://arxiv.org/abs/1511.07289},
year = {2015}
}
@article{Lipton2015,
abstract = {Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, music generation, and video game playing all require that a model generate sequences of outputs. In other domains, such as time series prediction, video analysis, and music information retrieval, a model must learn from sequences of inputs. Significantly more interactive tasks, such as natural language translation, engaging in dialogue, and robotic control, often demand both. Recurrent neural networks (RNNs) are a powerful family of connectionist models that capture time dynamics via cycles in the graph. Unlike feedforward neural networks, recurrent networks can process examples one at a time, retaining a state, or memory, that reflects an arbitrarily long context window. While these networks have long been difficult to train and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled large-scale learning with recurrent nets. Over the past few years, systems based on state of the art long short-term memory (LSTM) and bidirectional recurrent neural network (BRNN) architectures have demonstrated record-setting performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this review of the literature we synthesize the body of research that over the past three decades has yielded and reduced to practice these powerful models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a mostly self-contained explication of state of the art systems, together with a historical perspective and ample references to the primary research.},
archivePrefix = {arXiv},
arxivId = {1506.00019v2},
author = {Lipton, Zachary C and Berkowitz, John and Elkan, Charles and {Zachary C. Lipton} and Lipton, Zachary C and {Zachary C. Lipton} and Berkowitz, John and Elkan, Charles},
doi = {10.1145/2647868.2654889},
eprint = {1506.00019v2},
file = {:home/memo/Mendeley/data/Lipton, Berkowitz, Elkan - 2015 - A Critical Review of Recurrent Neural Networks for Sequence Learning arXiv 1506 . 00019v4 cs . LG 1.pdf:pdf},
isbn = {9781450330633},
issn = {9781450330633},
journal = {arXiv preprint},
pages = {1--35},
pmid = {18267787},
title = {{A Critical Review of Recurrent Neural Networks for Sequence Learning}},
url = {http://arxiv.org/abs/1506.00019v2},
year = {2015}
}
@article{Deutsch2014,
abstract = {We present a theory of information expressed solely in terms of which transformations of physical systems are possible and which are impossible – i.e. in constructor-theoretic terms. Although it includes conjectured laws of physics that are directly about information, independently of the details of particular physical instantiations, it does not regard information as an a priori mathematical or logical concept, but as something whose nature and properties are determined by the laws of physics alone. It does not suffer from the circularity at the foundations of existing information theory (namely that information and distinguishability are each defined in terms of the other). It explains the relationship between classical and quantum information, and reveals the single, constructor-theoretic property underlying the most distinctive phenomena associated with the latter, including the lack of in- principle distinguishability of some states, the impossibility of cloning, the existence of pairs of variables that cannot simultaneously have sharp values, the fact that measurement processes can be both deterministic and unpredictable, the irreducible perturbation caused by measurement, and entanglement (locally inaccessible information)},
author = {Deutsch, David and Marletto, Chiara},
journal = {arXiv.org},
keywords = {Information,quantum information},
pages = {1--29},
title = {{Constructor Theory of Information}},
url = {http://www.scientificamerican.com/article/a-meta-law-to-rule-them-all-physicists-devise-a-theory-of-everything/?{\&}WT.mc{\_}id=SA{\_}DD{\_}20140527},
volume = {May},
year = {2014}
}
@article{Gabora2013,
abstract = {This paper summarizes efforts to computationally model two transitions in the evolution of human creativity: its origins about two million years ago, and the 'big bang' of creativity about 50,000 years ago. Using a computational model of cultural evolution in which neural network based agents evolve ideas for actions through invention and imitation, we tested the hypothesis that human creativity began with onset of the capacity for recursive recall. We compared runs in which agents were limited to single-step actions to runs in which they used recursive recall to chain simple actions into complex ones. Chaining resulted in higher diversity, open-ended novelty, no ceiling on the mean fitness of actions, and greater ability to make use of learning. Using a computational model of portrait painting, we tested the hypothesis that the explosion of creativity in the Middle/Upper Paleolithic was due to onset of con-textual focus: the capacity to shift between associative and analytic thought. This resulted in faster convergence on portraits that resembled the sitter, employed painterly techniques, and were rated as preferable. We conclude that recursive recall and contextual focus provide a computationally plausible explanation of how humans evolved the means to transform this planet.},
author = {Gabora, Liane and DiPaola, Steve},
journal = {International Conference on Computational Creativity},
keywords = {80/20,ALife,ANN,Agent,EVOC,HSV color space,artificial society,chaining,genetic algorithms,genetic programming,images,portraits},
pages = {203--210},
title = {{How Did Humans Become So Creative? A Computational Approach}},
url = {http://arxiv.org/abs/1308.5032},
year = {2013}
}
@article{Li2016a,
archivePrefix = {arXiv},
arxivId = {arXiv:1509.03044v2},
author = {Li, Xiujun and Li, Lihong and Gao, Jianfeng and He, Xiaodong and Chen, Jianshu and Deng, Li and He, Ji},
eprint = {arXiv:1509.03044v2},
file = {:home/memo/Mendeley/data/Li et al. - 2016 - Reinforcement Learning with Unsupervised Auxiliary Tasks.pdf:pdf},
pages = {1--11},
title = {{Reinforcement Learning with Unsupervised Auxiliary Tasks}},
year = {2016}
}
@article{Conference2014,
author = {Conference, Ieee International and Processing, Signal},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Conference, Processing - 2014 - END-TO-END LEARNING FOR MUSIC AUDIO Sander Dieleman , Benjamin Schrauwen Electronics and information sys.pdf:pdf},
isbn = {9781479928934},
journal = {Icassp},
pages = {7014--7018},
title = {{END-TO-END LEARNING FOR MUSIC AUDIO Sander Dieleman , Benjamin Schrauwen Electronics and information systems department}},
year = {2014}
}
@article{Deutsch2012,
abstract = {Constructor theory seeks to express all fundamental scientific theories in terms of a dichotomy between possible and impossible physical transformations - those that can be caused to happen and those that cannot. This is a departure from the prevailing conception of fundamental physics which is to predict what will happen from initial conditions and laws of motion. Several converging motivations for expecting constructor theory to be a fundamental branch of physics are discussed. Some principles of the theory are suggested and its potential for solving various problems and achieving various unifications is explored. These include providing a theory of information underlying classical and quantum information; generalising the theory of computation to include all physical transformations; unifying formal statements of conservation laws with the stronger operational ones (such as the ruling-out of perpetual motion machines); expressing the principles of testability and of the computability of nature (currently deemed methodological and metaphysical respectively) as laws of physics; allowing exact statements of emergent laws (such as the second law of thermodynamics); and expressing certain apparently anthropocentric attributes such as knowledge in physical terms.},
archivePrefix = {arXiv},
arxivId = {1210.7439},
author = {Deutsch, David},
doi = {10.1007/s11229-013-0279-z},
eprint = {1210.7439},
file = {:home/memo/Mendeley/data/Deutsch - 2013 - Constructor theory.pdf:pdf},
issn = {15730964},
journal = {Synthese},
keywords = {Constructor theory,Physics of computation,Von Neumann machines},
number = {18},
pages = {4331--4359},
title = {{Constructor theory}},
volume = {190},
year = {2013}
}
@article{Jungang-daero,
author = {Jungang-daero, Techno and Korea, South and Korea, South},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jungang-daero, Korea, Korea - Unknown - RNNDROP A NOVEL DROPOUT FOR RNNS IN ASR Daegu Gyeongbuk Institute of Science and Technology ( D.pdf:pdf},
isbn = {9781479972913},
title = {{RNNDROP : A NOVEL DROPOUT FOR RNNS IN ASR Daegu Gyeongbuk Institute of Science and Technology ( DGIST ) Samsung Advanced Institute of Technology , Samsung Electronics}}
}
@misc{Miller,
author = {Stanford},
file = {:home/memo/Mendeley/data/Stanford - Unknown - Mathematics Reference for Quantum Mechanics.pdf:pdf},
pages = {1--9},
title = {{Mathematics Reference for Quantum Mechanics}},
url = {https://lagunita.stanford.edu/courses/Engineering/QMSE01./Autumn2015/228d39d015724f76b940598ced0847da/}
}
@article{Gal,
abstract = {A long strand of empirical research has claimed that dropout cannot be applied between the recurrent connections of a recurrent neural network (RNN). The reasoning has been that the noise hinders the network's ability to model sequences, and instead should be applied to the RNN's inputs and outputs alone. But dropout is a vital tool for regularisation, and without dropout in recurrent layers our models overfit quickly. In this paper we show that a recently developed theoretical framework, casting dropout as approximate Bayesian inference, can give us mathematically grounded tools to apply dropout within the recurrent layers. We apply our new dropout technique in long short-term memory (LSTM) networks and show that the new approach significantly outperforms existing techniques.},
archivePrefix = {arXiv},
arxivId = {1512.05287},
author = {Gal, Yarin},
eprint = {1512.05287},
file = {:home/memo/Mendeley/data/Gal - Unknown - Recurrent Neural Networks.pdf:pdf},
isbn = {9789537619084},
issn = {0302-9743},
journal = {arXiv:1512.05287},
title = {{A Theoretically Grounded Application of Dropout in Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1512.05287},
year = {2015}
}
@article{Semeniuta,
abstract = {This paper presents a novel approach to recurrent neural network (RNN) regularization. Differently from the widely adopted dropout method, which is applied to forward connections of feed-forward architectures or RNNs, we propose to drop neurons directly in recurrent connections in a way that does not cause loss of long-term memory. Our approach is as easy to implement and apply as the regular feed-forward dropout and we demonstrate its effectiveness for the most popular recurrent networks: vanilla RNNs, Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks. Our experiments on three NLP benchmarks show consistent improvements even when combined with conventional feed-forward dropout.},
archivePrefix = {arXiv},
arxivId = {1603.05118},
author = {Semeniuta, Stanislau and Severyn, Aliaksei and Barth, Erhardt},
eprint = {1603.05118},
file = {:home/memo/Mendeley/data/Semeniuta, Severyn, Barth - 2016 - Recurrent Dropout without Memory Loss.pdf:pdf},
journal = {Arxiv},
title = {{Recurrent Dropout without Memory Loss}},
url = {http://arxiv.org/abs/1603.05118},
year = {2016}
}
@misc{Schlosshauer,
abstract = {Environment-induced decoherence and superselection have been a subject of intensive research over the past two decades, yet their implications for the foundational problems of quantum mechanics, most notably the quantum measurement problem, have remained a matter of great controversy. This paper is intended to clarify key features of the decoherence program, including its more recent results, and to investigate their application and consequences in the context of the main interpretive approaches of quantum mechanics.},
archivePrefix = {arXiv},
arxivId = {quant-ph/0312059},
author = {Schlosshauer, Maximilian},
booktitle = {Reviews of Modern Physics},
doi = {10.1103/RevModPhys.76.1267},
eprint = {0312059},
file = {:home/memo/Mendeley/data/Schlosshauer - 2004 - Decoherence, the measurement problem, and interpretations of quantum mechanics.pdf:pdf},
isbn = {0034-6861},
issn = {00346861},
number = {4},
pages = {1267--1305},
primaryClass = {quant-ph},
title = {{Decoherence, the measurement problem, and interpretations of quantum mechanics}},
volume = {76},
year = {2004}
}
@article{Valentini2010,
abstract = {We show that inflationary cosmology may be used to test the statistical predictions of quantum theory at very short distances and at very early times. Hidden-variables theories, such as the pilot-wave theory of de Broglie and Bohm, allow the existence of vacuum states with non-standard field fluctuations ('quantum nonequilibrium'). We show that inflationary expansion can transfer microscopic nonequilibrium to macroscopic scales, resulting in anomalous power spectra for the cosmic microwave background. The conclusions depend only weakly on the details of the de Broglie-Bohm dynamics. We discuss, in particular, the nonequilibrium breaking of scale invariance for the primordial (scalar) power spectrum. We also show how nonequilibrium can generate primordial perturbations with non-random phases and inter-mode correlations (primordial non-Gaussianity). We address the possibility of a low-power anomaly at large angular scales, and show how it might arise from a nonequilibrium suppression of quantum noise. Recent observations are used to set an approximate bound on violations of quantum theory in the early universe.},
archivePrefix = {arXiv},
arxivId = {0805.0163},
author = {Valentini, Antony},
doi = {10.1103/PhysRevD.82.063513},
eprint = {0805.0163},
file = {:home/memo/Mendeley/data/Valentini - 2010 - Inflationary cosmology as a probe of primordial quantum mechanics.pdf:pdf},
issn = {15507998},
journal = {Physical Review D - Particles, Fields, Gravitation and Cosmology},
number = {6},
pages = {1--44},
title = {{Inflationary cosmology as a probe of primordial quantum mechanics}},
volume = {82},
year = {2010}
}
@article{SamuelReich2013,
author = {{Samuel Reich}, Eugenie},
doi = {doi: 10.1038/nature.2013.13899},
file = {:home/memo/Mendeley/data/Samuel Reich - 2013 - Physicists snatch a peep into quantum paradox.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {measurementproblem},
pages = {1--5},
title = {{Physicists snatch a peep into quantum paradox}},
url = {citeulike-article-id:12802672{\%}5Cnhttp://dx.doi.org/10.1038/nature.2013.13899},
year = {2013}
}
@article{Giovannetti2004,
abstract = {Quantum mechanics, through the Heisenberg uncertainty principle, imposes limits on the precision of measurement. Conventional measurement techniques typically fail to reach these limits. Conventional bounds to the precision of measurements such as the shot noise limit or the standard quantum limit are not as fundamental as the Heisenberg limits and can be beaten using quantum strategies that employ "quantum tricks" such as squeezing and entanglement.},
archivePrefix = {arXiv},
arxivId = {quant-ph/0412078},
author = {Giovannetti, Vittorio and Lloyd, Seth and Maccone, Lorenzo},
doi = {10.1126/science.1104149},
eprint = {0412078},
file = {:home/memo/Mendeley/data/Giovannetti, Lloyd, Maccone - 2004 - Quantum-enhanced measurements beating the standard quantum limit.pdf:pdf},
isbn = {0036-8075},
issn = {1095-9203},
journal = {Science},
number = {5700},
pages = {1330--6},
pmid = {15550661},
primaryClass = {quant-ph},
title = {{Quantum-enhanced measurements: beating the standard quantum limit.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15550661},
volume = {306},
year = {2004}
}
@misc{Monroe,
author = {Monroe, C. and Meekhof, D. M. and King, B. E. and Wineland, D. J.},
file = {:home/memo/Mendeley/data/Monroe et al. - Unknown - A Schrodinger Cat Superposition State of an Atom.pdf:pdf},
title = {{A "Schrodinger Cat" Superposition State of an Atom}}
}
@article{SamuelReich2012,
abstract = {Theorists claim they can prove that wavefunctions are real states.},
archivePrefix = {arXiv},
arxivId = {arXiv:1209.2862v1},
author = {{Samuel Reich}, Eugenie},
doi = {10.1038/485157a},
eprint = {arXiv:1209.2862v1},
file = {:home/memo/Mendeley/data/Samuel Reich - 2012 - A boost for quantum reality.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7397},
pages = {157--158},
pmid = {22575936},
title = {{A boost for quantum reality}},
volume = {485},
year = {2012}
}
@article{Zurek2014,
abstract = {Tracing flows of information in our quantum Universe explains why we see the world as classical.},
archivePrefix = {arXiv},
arxivId = {1412.5206},
author = {Zurek, Wojciech H.},
doi = {10.1063/PT.3.2550},
eprint = {1412.5206},
file = {:home/memo/Mendeley/data/Zurek - 2014 - Quantum Darwinism, classical reality, and the randomness of quantum jumps.pdf:pdf},
isbn = {9780874216561},
issn = {00319228},
journal = {Physics Today},
number = {10},
pages = {44--50},
pmid = {15003161},
title = {{Quantum Darwinism, classical reality, and the randomness of quantum jumps}},
volume = {67},
year = {2014}
}
@article{Goth2011,
abstract = {We devise so many new materials nowadays that it is hard to know which one would define our times. ?? 2013 Reed Business Information Ltd, England.},
author = {Goth, Greg},
doi = {10.1109/MIC.2011.48},
file = {:home/memo/Mendeley/data/Goth - 2011 - THE AGE OF THE QUBIT.pdf:pdf},
isbn = {07398395},
issn = {10897801},
journal = {IEEE Internet Computing},
keywords = {Internet,WikiLeaks,news and trends},
number = {2},
pages = {7--10},
title = {{THE AGE OF THE QUBIT}},
volume = {15},
year = {2011}
}
@article{Lambert2012,
abstract = {Nature Physics 8, 1 (2012). doi:10.1038/nphys2474},
archivePrefix = {arXiv},
arxivId = {1409.0950},
author = {Lambert, Neill and Chen, Yueh-Nan and Cheng, Yuan-Chung and Li, Che-Ming and Chen, Guang-Yin and Nori, Franco},
doi = {10.1038/nphys2474},
eprint = {1409.0950},
file = {:home/memo/Mendeley/data/Lambert et al. - 2012 - Quantum biology.pdf:pdf},
isbn = {1745-2473},
issn = {1745-2473},
journal = {Nature Physics},
number = {1},
pages = {10--18},
publisher = {Nature Publishing Group},
title = {{Quantum biology}},
url = {http://dx.doi.org/10.1038/nphys2474{\%}5Cnpapers2://publication/doi/10.1038/nphys2474{\%}5Cnhttp://www.nature.com/doifinder/10.1038/nphys2474},
volume = {9},
year = {2012}
}
@article{Marquardt2009,
author = {Marquardt, Florian and Girvin, Steven},
doi = {10.1103/Physics.2.40},
file = {:home/memo/Mendeley/data/Marquardt, Girvin - 2009 - Optomechanics.pdf:pdf},
issn = {1943-2879},
journal = {Physics},
keywords = {and the radiation pressure,forces on material objects,observed ex-,of light was first,optics,quantum information,quantum mechanics,radiation can exert,the concept that electromagnetic,was predicted by maxwell},
pages = {40},
title = {{Optomechanics}},
url = {http://link.aps.org/doi/10.1103/Physics.2.40},
volume = {2},
year = {2009}
}
@article{Schrodinger1926,
abstract = {The paper gives an account of the author's work on a new form of quantum theory. {\S}1. The Hamiltonian analogy between mechanics and optics. {\S}2. The analogy is to be extended to include real "physical" or "undulatory" mechanics instead of mere geometrical mechanics. {\S}3. The significance of wave-length; macro-mechanical and micro-mechanical problems. {\S}4. The wave-equation and its application to the hydrogen atom. {\S}5. The intrinsic reason for the appearance of discrete characteristic frequencies. {\S}6. Other problems; intensity of emitted light. {\S}7. The wave-equation derived from a Hamiltonian variation-principle; generalization to an arbitrary conservative system. {\S}8. The wave-function physically means and determines a continuous distribution of electricity in space, the fluctuations of which determine the radiation by the laws of ordinary electrodynamics. {\S}9. Non-conservative systems. Theory of dispersion and scattering and of the "transitions" between the "stationary states." {\S}10. The question of relativity and the action of a magnetic field. Incompleteness of that part of the theory.},
archivePrefix = {arXiv},
arxivId = {1112.5320},
author = {Schr{\"{o}}dinger, E.},
doi = {10.1103/PhysRev.28.1049},
eprint = {1112.5320},
file = {:home/memo/Mendeley/data/Schr{\"{o}}dinger - 1926 - An undulatory theory of the mechanics of atoms and molecules.pdf:pdf},
isbn = {0031-899X},
issn = {0031899X},
journal = {Physical Review},
number = {6},
pages = {1049--1070},
pmid = {21793126},
title = {{An undulatory theory of the mechanics of atoms and molecules}},
volume = {28},
year = {1926}
}
@article{Lansbergen2012,
abstract = {A single-atom transistor has been made by positioning a phosphorus atom between metallic electrodes, also made of phosphorus, on a silicon surface.},
author = {Lansbergen, Gabriel P.},
doi = {10.1038/nnano.2012.23},
file = {:home/memo/Mendeley/data/Lansbergen - 2012 - Nanoelectronics Transistors arrive at the atomic limit.pdf:pdf},
isbn = {1748-3387},
issn = {1748-3387},
journal = {Nature Nanotechnology},
number = {4},
pages = {209--210},
pmid = {22343381},
publisher = {Nature Publishing Group},
title = {{Nanoelectronics: Transistors arrive at the atomic limit}},
url = {http://dx.doi.org/10.1038/nnano.2012.23},
volume = {7},
year = {2012}
}
@article{Mermin2012,
author = {Mermin, N. David},
doi = {10.1063/PT.3.1618},
file = {:home/memo/Mendeley/data/Mermin - 2012 - Commentary Quantum mechanics Fixing the shifty split.pdf:pdf},
isbn = {0031-9228},
issn = {00319228},
journal = {Physics Today},
number = {7},
pages = {8},
title = {{Commentary Quantum mechanics: Fixing the shifty split}},
url = {http://scitation.aip.org/content/aip/magazine/physicstoday/article/65/7/10.1063/PT.3.1618},
volume = {65},
year = {2012}
}
@article{Physics2015,
abstract = {The Hong–Ou–Mandel effect, whereby two identical quantum particles launched into the two input ports of a 'beam-splitter' always bunch together in the same output port, has now been demonstrated for helium-4 atoms. See Letter p.66},
author = {Physics, Quant U M},
file = {:home/memo/Mendeley/data/Physics - 2015 - Two-atom bunching.pdf:pdf},
issn = {0028-0836},
journal = {News {\&} Views},
pages = {4--5},
title = {{Two-atom bunching}},
year = {2015}
}
@article{Wang2016,
author = {Wang, S and Song, J and Lien, J and Poupyrev, I},
file = {:home/memo/Mendeley/data/Wang et al. - 2016 - Interacting with soli Exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum.pdf:pdf},
isbn = {9781450341899},
journal = {Proceedings of the 29th},
pages = {851--860},
title = {{Interacting with soli: Exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum}},
url = {http://dl.acm.org/citation.cfm?id=2984565},
year = {2016}
}
@article{Lo2009,
abstract = {51 pages, 14 figures. This is a shortened version of an invited review article for the Encyclopedia of Complexity and System Science (to be published by Springer). This submission is with permission of Springer},
archivePrefix = {arXiv},
arxivId = {arXiv:0803.2507v4},
author = {Lo, Hoi-kwong and Zhao, Yi-Bo},
doi = {10.1007/s10701-010-9408-4},
eprint = {arXiv:0803.2507v4},
file = {:home/memo/Mendeley/data/Lo, Zhao - 2009 - Quantum Cryptography.pdf:pdf},
isbn = {9781424445721},
issn = {1540-7993},
journal = {Encyclopedia of Complexity and Systems Science},
pages = {7265--7289},
pmid = {25378231},
title = {{Quantum Cryptography}},
url = {http://uk.arxiv.org/abs/0803.2507v4},
volume = {8},
year = {2009}
}
@article{Plaga1995,
abstract = {The many-worlds interpretation of quantum mechanics predicts the formation of distinct parallel worlds as a result of a quantum mechanical measurement. Communication among these parallel worlds would experimentally rule out alternatives to this interpretation. A procedure for ``interworld'' exchange of information and energy, using only state of the art quantum optical equipment, is described. A single ion is isolated from its environment in an ion trap. Then a quantum mechanical measurement with two discrete outcomes is performed on another system, resulting in the formation of two parallel worlds. Depending on the outcome of this measurement the ion is excited from only one of the parallel worlds before the ion decoheres through its interaction with the environment. A detection of this excitation in the other parallel world is direct evidence for the many-worlds interpretation. This method could have important practical applications in physics and beyond.},
archivePrefix = {arXiv},
arxivId = {arXiv:quant-ph/9510007v3},
author = {Plaga, R.},
doi = {10.1007/BF02550677},
eprint = {9510007v3},
file = {:home/memo/Mendeley/data/Plaga - 1995 - Proposal for an experimental test of the many-worlds interpretation of quantum mechanics.pdf:pdf},
journal = {arXiv.org},
pages = {1--17},
primaryClass = {arXiv:quant-ph},
title = {{Proposal for an experimental test of the many-worlds interpretation of quantum mechanics}},
url = {http://arxiv.org/abs/quant-ph/9510007{\%}5Cnhttp://dx.doi.org/10.1007/BF02550677{\%}5Cnhttp://arxiv.org/abs/quant-ph/9510007v3},
year = {1995}
}
@article{Planck1901,
abstract = {[Transcriber's Note: Where an equation is numbered and NOT part of an image, I have used a pound ({\{}{\#}{\}}) sign to indicate a numbered equation. Due to the formatting, I would not want some to think that a numerial factor was being used in the equation. JP]$\backslash$n},
author = {Planck, M},
doi = {10.1002/andp.19013090310},
file = {:home/memo/Mendeley/data/Planck - 1901 - On the law of the energy distribution in the normal spectrum.pdf:pdf},
isbn = {1521-3889},
issn = {1521-3889},
journal = {Ann. Phys},
pages = {1--11},
title = {{On the law of the energy distribution in the normal spectrum}},
url = {http://www.ffn.ub.es/luisnavarro/nuevo{\_}maletin/Planck (1901), Energy distribution.pdf},
volume = {4},
year = {1901}
}
@article{DeBroglie1929,
abstract = {... This new mechanics has since been developed, thanks mainly Page 9. 252 1929 L.DE BROGLIE to the fine work done by Schr{\"{o}}dinger . It is based on wave propagation equations and strictly defines the evolution in time of the wave associated with a corpuscle. ...},
author = {{De Broglie}, Louis},
file = {:home/memo/Mendeley/data/De Broglie - 1929 - The wave nature of the electron.pdf:pdf},
journal = {Nobel lectures, Physics 1922-1941},
pages = {244--256},
title = {{The wave nature of the electron}},
url = {http://www.nobelprize.org/nobel{\_}prizes/physics/laureates/1929/},
year = {1929}
}
@article{DeWitt1970,
abstract = {Everett, Wheeler, Graham},
archivePrefix = {arXiv},
arxivId = {quant-ph/0412148},
author = {DeWitt, Bryce S.},
doi = {10.1063/1.3022331},
eprint = {0412148},
file = {:home/memo/Mendeley/data/Unknown - Unknown - Quantum mechanics and reality.pdf:pdf},
isbn = {9781608761159},
issn = {19450699},
journal = {Physics Today},
number = {9},
pages = {30--35},
primaryClass = {quant-ph},
title = {{Quantum mechanics and reality}},
volume = {23},
year = {1970}
}
@article{Hornberger2012,
abstract = {Recent progress and future prospects of matter-wave interferometry with complex organic molecules and inorganic clusters are reviewed. Three variants of a near-field interference effect, based on diffraction by material nanostructures, at optical phase gratings, and at ionizing laser fields are considered. The theoretical concepts underlying these experiments and the experimental challenges are discussed. This includes optimizing interferometer designs as well as understanding the role of decoherence. The high sensitivity of matter-wave interference experiments to external perturbations is demonstrated to be useful for accurately measuring internal properties of delocalized nanoparticles. The prospects for probing the quantum superposition principle are investigated in the limit of high particle mass and complexity.},
archivePrefix = {arXiv},
arxivId = {1109.5937},
author = {Hornberger, Klaus and Gerlich, Stefan and Haslinger, Philipp and Nimmrichter, Stefan and Arndt, Markus},
doi = {10.1103/RevModPhys.84.157},
eprint = {1109.5937},
file = {:home/memo/Mendeley/data/Hornberger et al. - 2012 - Colloquium Quantum interference of clusters and molecules.pdf:pdf},
isbn = {0034-6861$\backslash$n1539-0756},
issn = {00346861},
journal = {Reviews of Modern Physics},
number = {1},
pages = {157--173},
title = {{Colloquium: Quantum interference of clusters and molecules}},
volume = {84},
year = {2012}
}
@article{Bohr1913,
author = {Bohr, Niels Henrik David},
file = {:home/memo/Mendeley/data/Bohr - 1913 - On the constitution of atoms and molecules, 1.pdf:pdf},
issn = {00280836},
journal = {Philos. Mag.},
number = {April},
pages = {1},
title = {{On the constitution of atoms and molecules, 1}},
volume = {26},
year = {1913}
}
@article{Plesiewicz1986,
author = {Plesiewicz, W},
doi = {10.1103/PhysRevLett.3.32},
file = {:home/memo/Mendeley/data/Plesiewicz - 1986 - Physical review.pdf:pdf},
isbn = {0031-9007},
issn = {0031-9007},
journal = {Physical Review Letters},
number = {January},
pages = {2419--2422},
pmid = {9962131},
title = {{Physical review}},
volume = {56},
year = {1986}
}
@article{Haar1967,
author = {Haar, D T E R},
file = {:home/memo/Mendeley/data/Haar - 1967 - The Old Quantum Theory.pdf:pdf},
title = {{The Old Quantum Theory}},
year = {1967}
}
@article{Compton1923,
abstract = {A quantum theory of the scattering of X-rays and {\$}\backslashgamma{\$}-rays by light elements.{\^{a}}€”The hypothesis is suggested that when an X-ray quantum is scattered it spends all of its energy and momentum upon some particular electron. This electron in turn scatters the ray in some definite direction. The change in momentum of the X-ray quantum due to the change in its direction of propagation results in a recoil of the scattering electron. The energy in the scattered quantum is thus less than the energy in the primary quantum by the kinetic energy of recoil of the scattering electron. The corresponding increase in the wave-length of the scattered beam is {\$}\backslashlambda{\$}{\$}\backslashtheta{\$}-{\$}\backslashlambda{\$}0=(2h/mc) sin2 1/2{\$}\backslashtheta{\$}=0.0484 sin2 1/2{\$}\backslashtheta{\$}, where h is the Planck constant, m is the mass of the scattering electron, c is the velocity of light, and {\$}\backslashtheta{\$} is the angle between the incident and the scattered ray. Hence the increase is independent of the wave-length. The distribution of the scattered radiation is found, by an indirect and not quite rigid method, to be concentrated in the forward direction according to a definite law (Eq. 27). The total energy removed from the primary beam comes out less than that given by the classical Thomson theory in the ratio 1/(1+2{\$}\backslashalpha{\$}), where {\$}\backslashalpha{\$}=h/mc{\$}\backslashlambda{\$}0=0.0242/{\$}\backslashlambda{\$}0. Of this energy a fraction (1+{\$}\backslashalpha{\$})/(1+2{\$}\backslashalpha{\$}) reappears as scattered radiation, while the remainder is truly absorbed and transformed into kinetic energy of recoil of the scattering electrons. Hence, if {\$}\backslashsigma{\$}0 is the scattering absorption coefficient according to the classical theory, the coefficient according to this theory is {\$}\backslashsigma{\$}={\$}\backslashsigma{\$}0/(1+2{\$}\backslashalpha{\$})={\$}\backslashsigma{\$}s+{\$}\backslashsigma{\$}a, where {\$}\backslashsigma{\$}s is the true scattering coefficient [(1+{\$}\backslashalpha{\$}){\$}\backslashsigma{\$}/(1+2{\$}\backslashalpha{\$})2], and {\$}\backslashsigma{\$}a is the coefficient of absorption due to scattering [{\$}\backslashalpha{\$}{\$}\backslashsigma{\$}/(1+2{\$}\backslashalpha{\$})2]. Unpublished experimental results are given which show that for graphite and the Mo-K radiation the scattered radiation is longer than the primary, the observed difference ({\$}\backslashlambda{\$}{\$}\backslashpi{\$}/2-{\$}\backslashlambda{\$}0=.022) being close to the computed value.024. In the case of scattered {\$}\backslashgamma{\$}-rays, the wave-length has been found to vary with {\$}\backslashtheta{\$} in agreement with the theory, increasing from.022 A (primary) to.068 A ({\$}\backslashtheta{\$}=135{\^{a}}ˆ˜). Also the velocity of secondary {\$}\backslashbeta{\$}-rays excited in light elements by {\$}\backslashgamma{\$}-rays agrees with the suggestion that they are recoil electrons. As for the predicted variation of absorption with {\$}\backslashlambda{\$}, Hewlett's results for carbon for wave-lengths below 0.5 A are in excellent agreement with this theory; also the predicted concentration in the forward direction is shown to be in agreement with the experimental results, both for X-rays and {\$}\backslashgamma{\$}-rays. This remarkable agreement between experiment and theory indicates clearly that scattering is a quantum phenomenon and can be explained without introducing any new hypothesis as to the size of the electron or any new constants; also that a radiation quantum carries with it momentum as well as energy. The restriction to light elements is due to the assumption that the constraining forces acting on the scattering electrons are negligible, which is probably legitimate only for the lighter elements. Spectrum of K-rays from Mo scattered by graphite, as compared with the spectrum of the primary rays, is given in Fig. 4, showing the change of wave-length. Radiation from a moving isotropic radiator.{\^{a}}€”It is found that in a direction {\$}\backslashtheta{\$} with the velocity, I{\$}\backslashtheta{\$}/I{\^{a}}€²=(1-{\$}\backslashbeta{\$})2/(1-{\$}\backslashbeta{\$} cos {\$}\backslashtheta{\$})4=({\$}\backslashnu{\$}{\$}\backslashtheta{\$}/{\$}\backslashnu{\$}{\^{a}}€²)4. For the total radiation from a black body in motion to an observer at rest, I/I{\^{a}}€²=(T/T{\^{a}}€²)4=({\$}\backslashnu{\$}m/{\$}\backslashnu{\$}m{\^{a}}€²)4, where the primed quantities refer to the body at rest.},
author = {Compton, Arthur H},
file = {:home/memo/Mendeley/data/Compton - 1923 - A QUANTUM THEORY OF THE SCATTERING OF X-RAYS BY LIGHT ELEMENTS.pdf:pdf},
keywords = {doi:10.1103/PhysRev.21.483 url:http://dx.doi.org/1},
title = {{A QUANTUM THEORY OF THE SCATTERING OF X-RAYS BY LIGHT ELEMENTS}},
year = {1923}
}
@misc{Aspect1981,
author = {Aspect, Alain and Grangier, Philippe and Roger, Gerard},
file = {:home/memo/Mendeley/data/Aspect, Grangier, Roger - 1981 - Experimental Tests of Realistic Local Theories via Bell's Theorem.pdf:pdf},
title = {{Experimental Tests of Realistic Local Theories via Bell's Theorem}},
year = {1981}
}
@article{Aspect2004,
abstract = {In the first part of this presentation (sections 2 to 6), I show that Bell's Inequalities provide a quantitative criterion to test "reasonable" Supplementary Parameters Theories versus Quantum Mechanics. Following Bell, I first explain the motivations for considering supplementary parameters theories: the argument is based on an analysis of the famous Einstein-Podolsky-Rosen (EPR) Gedankenexperiment . Introducing a reasonable Locality Condition, we will then derive Bell's theorem, which states: (i) that Local Supplementary Parameters Theories are constrained by Bell's Inequalities; (ii) that certain predictions of Quantum Mechanics violate Bell's Inequalities, and therefore that Quantum Mechanics is incompatible with Local Supplementary Parameters Theories. I then point out that a fundamental assumption for this conflict is the Locality assumption, and I show that in a more sophisticated version of the E.P.R. thought experiment ("timing experiment"), the Locality Condition may be considered a consequence of Einstein's Causality, preventing faster-than-light interactions. The purpose of this first part is to convince the reader that the formalism leading to Bell's Inequalities is very general and reasonable. What is surprising is that such a reasonable formalism conflicts with Quantum Mechanics. In fact, situations exhibiting a conflict are very rare, and Quantum Optics is the domain where the most significant tests of this conflict have been carried out, as presented in sections 7 to 11.},
archivePrefix = {arXiv},
arxivId = {quant-ph/0402001},
author = {Aspect, Alain},
doi = {10.1007/978-3-662-05032-3_9},
eprint = {0402001},
file = {:home/memo/Mendeley/data/Aspect - 2004 - Bell's Theorem The Naive View of an Experimentalist.pdf:pdf},
isbn = {3-540-42756-2},
journal = {arXiv},
number = {December 2000},
primaryClass = {quant-ph},
title = {{Bell's Theorem : The Naive View of an Experimentalist}},
url = {http://arxiv.org/abs/quant-ph/0402001},
year = {2004}
}
@article{Adler,
archivePrefix = {arXiv},
arxivId = {0912.2211},
author = {Adler, Stephen L and Bassi, Angelo},
eprint = {0912.2211},
file = {:home/memo/Mendeley/data/Adler, Bassi - Unknown - Quantum Theory Exact or Approximate.pdf:pdf},
title = {{Quantum Theory : Exact or Approximate ?}}
}
@article{Wilde2013,
abstract = {The aim of this book is to develop "from the ground up" many of the major, exciting, pre- and post-millenium developments in the general area of study known as quantum Shannon theory. As such, we spend a significant amount of time on quantum mechanics for quantum information theory (Part II), we give a careful study of the important unit protocols of teleportation, super-dense coding, and entanglement distribution (Part III), and we develop many of the tools necessary for understanding information transmission or compression (Part IV). Parts V and VI are the culmination of this book, where all of the tools developed come into play for understanding many of the important results in quantum Shannon theory.},
archivePrefix = {arXiv},
arxivId = {1106.1445},
author = {Wilde, Mark M.},
doi = {10.1017/CBO9781139525343},
eprint = {1106.1445},
file = {:home/memo/Mendeley/data/Wilde - 2013 - From Classical to Quantum Shannon Theory.pdf:pdf},
isbn = {9781107034259},
journal = {Cambridge University Press},
pages = {642},
title = {{From Classical to Quantum Shannon Theory}},
url = {http://arxiv.org/abs/1106.1445},
year = {2013}
}
@article{Barnett2015,
author = {Barnett, Stephen M.},
file = {:home/memo/Mendeley/data/Barnett - 2015 - Introduction to Quantum Information Science.pdf:pdf},
title = {{Introduction to Quantum Information Science}},
year = {2015}
}
@article{Theocharous2003,
abstract = {Recent research has demonstrated that useful POMDP solutions do not require consideration of the entire belief space. We extend this idea with the notion of temporal abstraction. We present and explore a new rein- forcement learning algorithm over grid-points in belief space, which uses macro-actions and Monte Carlo updates of the Q-values. We apply the algorithm to a large scale robot navigation task and demonstrate that with temporal abstraction we can consider an even smaller part of the belief space, we can learn POMDP policies faster, and we can do information gathering more efficiently.},
author = {Theocharous, Georgio and Kaelbling, Leslie Pack},
file = {:home/memo/Mendeley/data/Theocharous, Kaelbling - 2003 - Approximate Planning in POMDPs with Macro-Actions.pdf:pdf},
journal = {Advances in Neural Processing Information Systems},
pages = {775--782},
title = {{Approximate Planning in POMDPs with Macro-Actions}},
url = {http://papers.nips.cc/paper/2485-approximate-planning-in-pomdps-with-macro-actions},
volume = {17},
year = {2003}
}
@article{Cherti2017,
author = {Cherti, Mehdi and Kegl, Balazs and Kazakci, Akin},
file = {:home/memo/Mendeley/data/Cherti, Kegl, Kazakci - 2017 - Out-of-class novelty generation an experimental foundation.pdf:pdf},
pages = {1--13},
title = {{Out-of-class novelty generation: an experimental foundation}},
year = {2017}
}
@article{Fiebrink2016,
archivePrefix = {arXiv},
arxivId = {1611.00379},
author = {Fiebrink, Rebecca and Caramiaux, Baptiste},
eprint = {1611.00379},
journal = {Handbook of algorithmic Music},
title = {{The Machine Learning Algorithm as Creative Musical Tool}},
year = {2016}
}
@book{spalter1998computer,
author = {Spalter, Anne Morgan},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
title = {{The computer in the visual arts}},
year = {1998}
}
@article{kempka2016vizdoom,
abstract = {The recent advances in deep neural networks have led to effective vision-based reinforcement learning methods that have been employed to obtain human-level controllers in Atari 2600 games from pixel data. Atari 2600 games, however, do not resemble real-world tasks since they involve non-realistic 2D environments and the third-person perspective. Here, we propose a novel test-bed platform for reinforcement learning research from raw visual information which employs the first-person perspective in a semi-realistic 3D world. The software, called ViZDoom, is based on the classical first-person shooter video game, Doom. It allows developing bots that play the game using the screen buffer. ViZDoom is lightweight, fast, and highly customizable via a convenient mechanism of user scenarios. In the experimental part, we test the environment by trying to learn bots for two scenarios: a basic move-and-shoot task and a more complex maze-navigation problem. Using convolutional deep neural networks with Q-learning and experience replay, for both scenarios, we were able to train competent bots, which exhibit human-like behaviors. The results confirm the utility of ViZDoom as an AI research platform and imply that visual reinforcement learning in 3D realistic first-person perspective environments is feasible.},
author = {Kempka, Micha{\l} and Wydmuch, Marek and Runc, Grzegorz and Toczek, Jakub and Ja{\'{s}}kowski, Wojciech},
journal = {arXiv:1605.02097v1 [cs.LG]},
keywords = {deep reinforcement learning,first-person perspective games,fps,neural networks,video games,visual learning,visual-based reinforcement learning},
title = {{ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement Learning}},
year = {2016}
}
@incollection{wiggins2006preliminary,
abstract = {I summarise and attempt to clarify some concepts presented in and arising from Margaret Boden's (1990) descriptive hierarchy of creativity, by beginning to formalise the ideas she proposes. The aim is to move towards a model which allows detailed comparison, and hence better understanding, of systems which exhibit behaviour which would be called "creative" in humans. The work paves the way for the description of naturalistic, multi-agent creative AI systems, which create in a societal context. I demonstrate some simple reasoning about creative behaviour based on the new framework, to show how it might be useful for the analysis and study of creative systems. In particular, I identify some crucial properties of creative systems, in terms of the framework components, some of which may usefully be proven a priori of a given system. I suggest that Boden's descriptive framework, once elaborated in detail, is more uniform and more powerful than it first appears. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Wiggins, Geraint A},
booktitle = {Knowledge-Based Systems},
doi = {10.1016/j.knosys.2006.04.009},
issn = {09507051},
number = {7},
pages = {449--458},
publisher = {Elsevier},
title = {{A preliminary framework for description, analysis and comparison of creative systems}},
volume = {19},
year = {2006}
}
@article{pease2001evaluating,
author = {Pease, Alison and Winterstein, Daniel and Colton, Simon and Pease, Alison and Winterstein, Daniel and Colton, Simon},
journal = {Workshop on Creative Systems, 4th International Conference on Case Based Reasoning},
keywords = {all rights reserved,concept spaces,copyright c 2001 by,evaluating novelty,evaluating quality,machine creativity,measures of creativity,the university of edinburgh},
number = {November},
pages = {129--137},
title = {{Division of Informatics , University of Edinburgh Centre for Intelligent Systems and their Applications by Evaluating Machine Creativity}},
year = {2001}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28{\%} relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
journal = {arXiv preprint arXiv:1512.03385},
keywords = {deep learning,denoising auto-encoder,image denoising},
title = {{Deep Residual Learning for Image Recognition}},
year = {2015}
}
@article{Kalchbrenner2015,
abstract = {This paper introduces Grid Long Short-Term Memory, a network of LSTM cells arranged in a multidimensional grid that can be applied to vectors, sequences or higher dimensional data such as images. The network differs from existing deep LSTM architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data. It therefore provides a unified way of using LSTM for both deep and sequential computation. We apply the model to algorithmic tasks such as integer addition and determining the parity of random binary vectors. It is able to solve these problems for 15-digit integers and 250-bit vectors respectively. We then give results for three empirical tasks. We find that 2D Grid LSTM achieves 1.47 bits per character on the Wikipedia character prediction benchmark, which is state-of-the-art among neural approaches. We also observe that a two-dimensional translation model based on Grid LSTM outperforms a phrase-based reference system on a Chinese-to-English translation task, and that 3D Grid LSTM yields a near state-of-the-art error rate of 0.32{\%} on MNIST.},
archivePrefix = {arXiv},
arxivId = {1507.01526},
author = {Kalchbrenner, Nal and Danihelka, Ivo and Graves, Alex},
eprint = {1507.01526},
journal = {arXiv preprint arXiv:1507.01526},
pages = {14},
title = {{Grid Long Short-Term Memory}},
url = {http://arxiv.org/abs/1507.01526},
year = {2015}
}
@article{Tresset2014,
author = {Tresset, Patrick and Deussen, Oliver},
number = {April},
title = {{Artistically Skilled Embodied Agents}},
year = {2014}
}
@article{Prechelt2012,
abstract = {Validation can be used to detect when overrtting starts dur-ing supervised training of a neural network; training is then stopped before convergence to avoid the overrtting early stopping". The ex-act criterion used for validation-based early stopping, however, is usually chosen in an ad-hoc fashion or training is stopped interactively. This trick describes how to select a stopping criterion in a systematic fashion; it is a trick for either speeding learning procedures or improving gener-alization, whichever is more important in the particular situation. An empirical investigation on multi-layer perceptrons shows that there ex-ists a tradeoo between training time and generalization: From the given mix of 1296 training runs using diierent 12 problems and 24 diierent network architectures I conclude slower stopping criteria allow for small improvements in generalization here: about 4 on average, but cost much more training time here: about factor 4 longer on average.},
author = {Prechelt, Lutz},
doi = {10.1007/978-3-642-35289-8-5},
isbn = {9783642352881},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {53--67},
title = {{Early stopping - But when?}},
volume = {7700 LECTU},
year = {2012}
}
@misc{Seigelmann1995,
abstract = {This paper deals with finite size networks which consist of inter-connections of synchronously evolving processors. Each processor updates its state by applying a "sigmoidal" function to a linear combination of the previous states of all units. We proves that one may simulate all Turing machines by such nets. In particular, one can simulate any mlti-stack Turing machine in real time, and there is a net made up of 886 processors which computes a universal partial-recursive function.},
author = {Seigelmann, Hava T. and Sontag, Eduardo D.},
booktitle = {Journal of Computer and System Sciences},
pages = {132--150},
title = {{On the Computational Power of Neural Nets}},
volume = {50},
year = {1995}
}
@article{Wehrhahn1979,
author = {Wehrhahn, C},
file = {:home/memo/Mendeley/data/Wehrhahn - 1979 - Biological Cybernetics.pdf:pdf},
number = {1995},
pages = {239--241},
pmid = {1000253956},
title = {{Biological Cybernetics}},
volume = {241},
year = {1979}
}
@article{pascanu2013construct,
abstract = {In this paper, we propose a novel way to extend a recurrent neural network (RNN) to a deep RNN. We start by arguing that the concept of the depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, we define three points which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. This can be considered in addition to stacking multiple recurrent layers proposed earlier by Schmidhuber (1992). Based on this observation, we propose two novel architectures of a deep RNN and provide an alternative interpretation of these deep RNN's using a novel framework based on neural operators. The proposed deep RNN's are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNN's benefit from the depth and outperform the conventional, shallow RNN.},
author = {Pascanu, Razvan and G{\"{u}}l{\c{c}}ehre, {\c{C}}aglar and Cho, Kyunghyun and Bengio, Yoshua and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
file = {:home/memo/Mendeley/data/Pascanu et al. - 2013 - How to Construct Deep Recurrent Neural Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1312.6026},
title = {{How to Construct Deep Recurrent Neural Networks}},
year = {2013}
}
@article{Morley2002,
abstract = {This article reports an analysis of an asynchronous web-mediated discussion in a university philosophy class. The aim was to  nd out what kinds of interaction took place and what created potential for learning, using dialogue theory based on Bakhtin, Rommetveit and Lotman. It is argued that the high degree of interactivity and dialogicality, where the students not only presented their own ideas but engaged with one another through extended written responses, was a result of the quality of the assignment, the role of the teacher and the symmetry of the participants. The analysis shows that the discussion entries combined dialogic and univocal functions, both of which contributed to a high learning potential as well as the multi-voicedness of the learning experience.},
author = {Morley, Louise and Leonard, Diana and David, Miriam},
doi = {10.1080/0307507022000},
file = {:home/memo/Mendeley/data/Morley, Leonard, David - 2002 - Variations in Vivas quality and equality in British PhD assessments.pdf:pdf},
isbn = {0307507022000},
issn = {0307-5079},
journal = {Studies in Higher Education},
number = {3},
pages = {263--273},
pmid = {18063329},
title = {{Variations in Vivas: quality and equality in British PhD assessments}},
url = {http://library.mtroyal.ca:2090/pqdweb?index=34{\&}did=646908511{\&}SrchMode=1{\&}sid=2{\&}Fmt=2{\&}VInst=PROD{\&}VType=PQD{\&}RQT=309{\&}VName=PQD{\&}TS=1257911574{\&}clientId=1751},
volume = {27},
year = {2002}
}
@article{Rish2000,
abstract = {This tutorial contains basic concepts and mathematics for Bayesian Network, its inferencing and learning approaches and related inherent algorithms. It also describes the parameter and graph learning mechanisms. Its a very good tutorial to get insight of some complex topics with nice illustrations and explanation like Markov Blanket, d-separation, three rules of independence, variables and parameters and their numbering, how to reduce the number of parameters of a bayesian network.},
author = {Rish, Irina and Singh, M},
file = {:home/memo/Mendeley/data/Rish, Singh - 2000 - A tutorial on inference and learning in Bayesian networks.pdf:pdf},
journal = {IBM Watson Research Center},
keywords = {Conditional Independence,D-Separation,Graph Learning.,IC,Markov Blanket,PC,Parameter Learning,Parameters,Random Variables},
title = {{A tutorial on inference and learning in Bayesian networks}},
url = {http://www.ee.columbia.edu/{~}vittorio/Lecture12.pdf},
year = {2000}
}
@article{Murphy2012,
author = {Murphy, Kevin P},
file = {:home/memo/Mendeley/data/Murphy - 2012 - Tutorial on Probabilistic Graphical Models ML Summer School UC Santa Cruz.pdf:pdf},
number = {July},
title = {{Tutorial on Probabilistic Graphical Models ML Summer School UC Santa Cruz}},
year = {2012}
}
@article{Rusu2016,
abstract = {Applying end-to-end learning to solve complex, interactive, pixel-driven control tasks on a robot is an unsolved problem. Deep Reinforcement Learning algorithms are too slow to achieve performance on a real robot, but their potential has been demonstrated in simulated environments. We propose using progressive networks to bridge the reality gap and transfer learned policies from simulation to the real world. The progressive net approach is a general framework that enables reuse of everything from low-level visual features to high-level policies for transfer to new tasks, enabling a compositional, yet simple, approach to building complex skills. We present an early demonstration of this approach with a number of experiments in the domain of robot manipulation that focus on bridging the reality gap. Unlike other proposed approaches, our real-world experiments demonstrate successful task learning from raw visual input on a fully actuated robot manipulator. Moreover, rather than relying on model-based trajectory optimisation, the task learning is accomplished using only deep reinforcement learning and sparse rewards.},
archivePrefix = {arXiv},
arxivId = {1610.04286},
author = {Rusu, Andrei A. and Vecerik, Matej and Roth{\"{o}}rl, Thomas and Heess, Nicolas and Pascanu, Razvan and Hadsell, Raia},
eprint = {1610.04286},
file = {:home/memo/Mendeley/data/Rusu et al. - 2016 - Sim-to-Real Robot Learning from Pixels with Progressive Nets.pdf:pdf},
title = {{Sim-to-Real Robot Learning from Pixels with Progressive Nets}},
url = {http://arxiv.org/abs/1610.04286},
year = {2016}
}
@article{Hadjeres2016,
abstract = {Modeling polyphonic music is a particularly challenging task because of the intricate interplay between melody and harmony. A good model should satisfy three requirements: statistical accuracy (capturing faithfully the statistics of correlations at various ranges, horizontally and vertically), flexibility (coping with arbitrary user constraints), and generalization capacity (inventing new material, while staying in the style of the training corpus). Models proposed so far fail on at least one of these requirements. We propose a statistical model of polyphonic music, based on the maximum entropy principle. This model is able to learn and reproduce pairwise statistics between neighboring note events in a given corpus. The model is also able to invent new chords and to harmonize unknown melodies. We evaluate the invention capacity of the model by assessing the amount of cited, re-discovered, and invented chords on a corpus of Bach chorales. We discuss how the model enables the user to specify and enforce user-defined constraints, which makes it useful for style-based, interactive music generation.},
archivePrefix = {arXiv},
arxivId = {1609.05152},
author = {Hadjeres, Ga{\"{e}}tan and Sakellariou, Jason and Pachet, Fran{\c{c}}ois},
eprint = {1609.05152},
file = {:home/memo/Mendeley/data/Hadjeres, Sakellariou, Pachet - 2016 - Style Imitation and Chord Invention in Polyphonic Music with Exponential Families.pdf:pdf},
title = {{Style Imitation and Chord Invention in Polyphonic Music with Exponential Families}},
url = {http://arxiv.org/abs/1609.05152},
year = {2016}
}
@article{Ha2016,
abstract = {This work explores hypernetworks: an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve state-of-art results on a variety of language modeling tasks with Character-Level Penn Treebank and Hutter Prize Wikipedia datasets, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.},
author = {Ha, David and Dai, Andrew and Le, Quoc V.},
file = {:home/memo/Mendeley/data/Ha, Dai, Le - 2016 - HyperNetworks.pdf:pdf},
journal = {arXiv preprint arXiv:1609.09106},
title = {{HyperNetworks}},
year = {2016}
}
@article{Oudeyer2009,
abstract = {Intrinsic motivation, centrally involved in spontaneous exploration and curiosity, is a crucial concept in developmental psychology. It has been argued to be a crucial mechanism for open-ended cognitive development in humans, and as such has gathered a growing interest from developmental roboticists in the recent years. The goal of this paper is threefold. First, it provides a synthesis of the different approaches of intrinsic motivation in psychology. Second, by interpreting these approaches in a computational reinforcement learning framework, we argue that they are not operational and even sometimes inconsistent. Third, we set the ground for a systematic operational study of intrinsic motivation by presenting a formal typology of possible computational approaches. This typology is partly based on existing computational models, but also presents new ways of conceptualizing intrinsic motivation. We argue that this kind of computational typology might be useful for opening new avenues for research both in psychology and developmental robotics.},
author = {Oudeyer, Pierre Yves and Kaplan, Frederic},
doi = {10.3389/neuro.12.006.2007},
file = {:home/memo/Mendeley/data/Oudeyer, Kaplan - 2009 - What is intrinsic motivation A typology of computational approaches.pdf:pdf},
isbn = {1662-5218 (Electronic)$\backslash$r1662-5218 (Linking)},
issn = {16625218},
journal = {Frontiers in Neurorobotics},
keywords = {Artificial intelligence,Cognitive development,Computational modeling,Curiosity,Developmental robotics,Exploration,Intrinsic motivation,Reinforcement learning,Reward},
number = {NOV},
pages = {1--14},
pmid = {18958277},
title = {{What is intrinsic motivation? A typology of computational approaches}},
volume = {3},
year = {2009}
}
@article{MacKay1951a,
author = {MacKay, David M},
journal = {Bulletin of the British Society for the History of Science},
number = {S5},
pages = {164--165},
publisher = {Cambridge Univ Press},
title = {{Mind-like behaviour in artefacts}},
volume = {1},
year = {1951}
}
@inproceedings{Talton2012,
abstract = {Design patterns have proven useful in many creative fields, providing content creators with archetypal, reusable guidelines to leverage in projects. Creating such patterns, however, is a time-consuming, manual process, typically relegated to a few experts in any given domain. In this paper, we describe an algorithmic method for learning design patterns directly from data using techniques from natural language processing and structured concept learning. Given a set of labeled, hierarchical designs as input, we induce a probabilistic formal grammar over these exemplars. Once learned, this grammar encodes a set of generative rules for the class of designs, which can be sampled to synthesize novel artifacts. We demonstrate the method on geometric models and Web pages, and discuss how the learned patterns can drive new interaction mechanisms for content creators. Copyright 2012 ACM.},
author = {Talton, Jerry and Yang, Lingfeng and Kumar, Ranjitha and Lim, Maxine and Goodman, Noah and M{\v{e}}ch, Radom{\'{i}}r Radom$\backslash$'$\backslash$ir},
booktitle = {Proceedings of the 25th annual ACM symposium on User interface software and technology},
doi = {10.1145/2380116.2380127},
file = {:home/memo/Mendeley/data/Talton et al. - 2012 - Learning design patterns with bayesian grammar induction.pdf:pdf},
isbn = {9781450315807},
organization = {ACM},
pages = {63--74},
title = {{Learning design patterns with bayesian grammar induction}},
url = {http://dl.acm.org/citation.cfm?doid=2380116.2380127},
year = {2012}
}
@article{Graves2013,
abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
author = {Graves, Alex},
file = {:home/memo/Mendeley/data/Graves - 2013 - Generating sequences with Recurrent Neural Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1308.0850},
title = {{Generating sequences with Recurrent Neural Networks}},
year = {2013}
}
@inproceedings{berio2015cae,
author = {Berio, Daniel and Leymarie, Frederic Fol},
booktitle = {Computational Aesthetics},
editor = {Rosin, Paul},
file = {:home/memo/Mendeley/data/Berio, Leymarie - 2015 - Computational Models for the Analysis and Synthesis of Graffiti Tag Strokes.pdf:pdf},
publisher = {Eurographics Association},
title = {{Computational Models for the Analysis and Synthesis of Graffiti Tag Strokes}},
year = {2015}
}
@article{Aparajeya2015,
author = {Aparajeya, Prashant and Leymarie, Frederic Fol},
file = {:home/memo/Mendeley/data/Aparajeya, Leymarie - 2015 - Point-based medialness for 2D shape description and identification.pdf:pdf},
journal = {Multimedia Tools and Applications},
pages = {1--33},
publisher = {Springer},
title = {{Point-based medialness for 2D shape description and identification}},
year = {2015}
}
@inproceedings{Lake2013,
abstract = {People can learn a new visual class from just one example, yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems. Here we present a Hierarchical Bayesian model based on compositionality and causality that can learn a wide range of natural (although simple) visual concepts, generalizing in human-like ways from just one image. We evaluated performance on a challenging one-shot classification task, where our model achieved a human-level error rate while substantially outperforming two deep learning models. We also tested the model on another conceptual task, generating new examples, by using a “visual Turing test” to show that our model produces human-like performance.},
author = {Lake, Brenden M and Salakhutdinov, Ruslan R and Tenenbaum, Joshua B},
booktitle = {Advances in neural information processing systems},
file = {:home/memo/Mendeley/data/Lake, Salakhutdinov, Tenenbaum - 2013 - One-shot learning by inverting a compositional causal process.pdf:pdf},
issn = {10495258},
pages = {2526--2534},
title = {{One-shot learning by inverting a compositional causal process}},
year = {2013}
}
@article{Hochreiter1997,
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
file = {:home/memo/Mendeley/data/Hochreiter, Schmidhuber - 1997 - Long Short-Term Memory.pdf:pdf},
journal = {Neural Computation},
keywords = {Algorithms,Learning,Memory,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Psychological,Short-Term,Time Factors},
number = {8},
pages = {1735--1780},
publisher = {MIT Press},
title = {{Long Short-Term Memory}},
volume = {9},
year = {1997}
}
@article{Bishop1994,
abstract = {Minimization of a sum-of-squares or cross-entropy error function leads to network outputs which approximate the conditional averages of the target data, conditioned on the input vector. For classifications problems, with a suitably chosen target coding scheme, these averages represent the posterior probabilities of class membership, and so can be regarded as optimal. For problems involving the prediction of continuous variables, however, the conditional averages provide only a very limited description of the properties of the target variables. This is particularly true for problems in which the mapping to be learned is multi-valued, as often arises in the solution of inverse problems, since the average of several correct target values is not necessarily itself a correct value. In order to obtain a complete description of the data, for the purposes of predicting the outputs corresponding to new input vectors, we must model the conditional probability distribution of the target data, again conditioned on the input vector. In this paper we introduce a new class of network models obtained by combining a conventional neural network with a mixture density model. The complete system is called a Mixture Density Network, and can in principle represent arbitrary conditional probability distributions in the same way that a conventional neural network can represent arbitrary functions. We demonstrate the effectiveness of Mixture Density Networks using both a toy problem and a problem involving robot inverse kinematics.},
author = {Bishop, Christopher M},
file = {:home/memo/Mendeley/data/Bishop - 1994 - Mixture density networks.pdf:pdf},
journal = {Group},
keywords = {mathematical computing sciences not elsewhere clas,neural computing},
publisher = {Aston University},
title = {{Mixture density networks}},
url = {http://eprints.aston.ac.uk/373/},
year = {1994}
}
@article{Gatys2015,
abstract = {In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.},
archivePrefix = {arXiv},
arxivId = {1508.06576},
author = {Gatys, Leon a. and Ecker, Alexander S. and Bethge, Matthias},
eprint = {1508.06576},
file = {:home/memo/Mendeley/data/Gatys, Ecker, Bethge - 2015 - A Neural Algorithm of Artistic Style.pdf:pdf},
journal = {arXiv preprint arXiv:1508.06576},
title = {{A Neural Algorithm of Artistic Style}},
year = {2015}
}
@article{Kov??cs1998,
abstract = {We describe a region-based shape representation that might be particularly useful from a biological perspective because it promotes the localization of objects, and object parts relative to each other. The proposed medial-point representation is similar to medial-axis type representations, but it is more compact. The medial points are those points along the medial axis that are equidistant from the longest segments of the boundary, therefore they represent the largest amount of edge information. The main advantage is that the original image can be reduced to a small number of points. We also provide psychophysical correlates of the representation for shapes with increasing complexity. Using a reverse mapping technique, we find that variations of contrast sensitivity within figures are defined by the shape of the bounding contour, and the peaks in the sensitivity maps correspond to the medial points of the proposed representation.},
author = {Kov{\'{a}}cs, Ilona and Feh{\'{e}}r, {\'{A}}kos and Julesz, Bela and Kov??cs, Ilona and Feh??r, ??kos and Julesz, Bela},
doi = {10.1016/S0042-6989(97)00321-0},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kov{\'{a}}cs et al. - 1998 - Medial-point description of shape A representation for action coding and its psychophysical correlates.pdf:pdf},
isbn = {0042-6989},
issn = {00426989},
journal = {Vision Research},
keywords = {Contrast sensitivity,Medial-axis,Perceptual organization,Shape,Spatial interaction},
number = {15-16},
pages = {2323--2333},
pmid = {9798002},
publisher = {Elsevier},
title = {{Medial-point description of shape: A representation for action coding and its psychophysical correlates}},
volume = {38},
year = {1998}
}
@inproceedings{cohen1982make,
author = {Cohen, Harold},
booktitle = {talk given to the Science Colloquium, National Bureau of Standards, Washington DC},
file = {:home/memo/Mendeley/data/Cohen - 1982 - How to make a drawing.pdf:pdf},
pages = {1--15},
title = {{How to make a drawing}},
url = {http://haroldcohen.com/aaron/publications/how2make.pdf},
volume = {17},
year = {1982}
}
@article{Stulp2015,
author = {Stulp, Freek and Sigaud, Olivier},
file = {:home/memo/Mendeley/data/Stulp, Sigaud - 2015 - Many regression algorithms, one unified model A review.pdf:pdf},
journal = {Neural Networks},
pages = {60--79},
publisher = {Elsevier},
title = {{Many regression algorithms, one unified model: A review}},
volume = {69},
year = {2015}
}
@article{Corneli2014,
abstract = {Drawing on well-known examples of serendipity in scientific discovery, we develop a set of criteria that can be applied to model and evaluate serendipity in computational settings. We use design patterns, and the growth of a pattern language, as a way to describe the processes of discovery and invention that comprise serendipitous encounters. We show how several earlier patterns of serendipity can be applied in a Writers Workshop for computational systems, and include related recommendations for practitioners.},
archivePrefix = {arXiv},
arxivId = {1411.0440},
author = {Corneli, Joseph and Pease, Alison and Colton, Simon and Jordanous, Anna and Guckelsberger, Christian},
eprint = {1411.0440},
file = {:home/memo/Mendeley/data/Corneli et al. - 2014 - Modelling serendipity in a computational context.pdf:pdf},
journal = {arXiv preprint arXiv:1411.0440},
keywords = {design patterns,intelligent machinery,serendipity,writers},
number = {2013},
pages = {1--32},
title = {{Modelling serendipity in a computational context}},
url = {http://arxiv.org/abs/1411.0440},
volume = {611553},
year = {2014}
}
@inproceedings{Lake2011,
author = {Lake, Brenden M and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua B},
booktitle = {Proceedings of the 33rd Annual Conference of the Cognitive Science Society},
file = {:home/memo/Mendeley/data/Lake et al. - 2011 - One shot learning of simple visual concepts.pdf:pdf},
keywords = {a,bayesian,boxed in red,can you find the,category learning,figure 1,from the example,modeling,neural networks,on the left is,others in the array,shot learning,test yourself on one,transfer learning},
pages = {2},
title = {{One shot learning of simple visual concepts}},
volume = {172},
year = {2011}
}
@article{Schomaker1992,
author = {Schomaker, Lambert and Schomaker, R B},
file = {:home/memo/Mendeley/data/Schomaker, Schomaker - 1992 - A neural oscillator-network model of temporal pattern generation.pdf:pdf},
journal = {Human movement science},
number = {1},
pages = {181--192},
publisher = {Elsevier},
title = {{A neural oscillator-network model of temporal pattern generation}},
volume = {11},
year = {1992}
}
@article{Tenenbaum2000,
abstract = {Perceptual systems routinely separate "content" from "style," classifying familiar words spoken in an unfamiliar accent, identifying a font or handwriting style across letters, or recognizing a familiar face or object seen under unfamiliar viewing conditions. Yet a general and tractable computational model of this ability to untangle the underlying factors of perceptual observations remains elusive (Hofstadter, 1985). Existing factor models (Mardia, Kent, {\&} Bibby, 1979; Hinton {\&} Zemel, 1994; Ghahramani, 1995; Bell {\&} Sejnowski, 1995; Hinton, Dayan, Frey, {\&} Neal, 1995; Dayan, Hinton, Neal, {\&} Zemel, 1995; Hinton {\&} Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually meaningful factors such as phoneme and speaker accent or letter and font, or do not allow efficient learning algorithms. We present a general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization. We report promising results on three different tasks in three different perceptual domains: spoken vowel classification with a benchmark multi-speaker database, extrapolation of fonts to unseen letters, and translation of faces to novel illuminants.},
author = {Tenenbaum, Joshua B and Freeman, William T},
doi = {10.1162/089976600300015349},
file = {:home/memo/Mendeley/data/Tenenbaum, Freeman - 2000 - Separating style and content with bilinear models.pdf:pdf},
isbn = {0899-7667 (Print)$\backslash$r0899-7667 (Linking)},
issn = {0899-7667},
journal = {Neural computation},
number = {6},
pages = {1247--1283},
pmid = {10935711},
publisher = {MIT Press},
title = {{Separating style and content with bilinear models}},
volume = {12},
year = {2000}
}
@misc{freyd1987,
author = {Freyd, J J},
booktitle = {Psychological review},
isbn = {0033-295X{\$}\backslash{\$}r1939-1471},
issn = {0033-295X},
number = {4},
pages = {427--438},
pmid = {3317470},
title = {{Dynamic mental representations.}},
volume = {94},
year = {1987}
}
@article{Feldman2013,
author = {Feldman, Jacob},
journal = {Handbook of perceptual organization},
title = {{Bayesian models of perceptual organization}},
year = {2013}
}
@inproceedings{Mehra2009,
author = {Mehra, Ravish and Zhou, Qingnan and Long, Jeremy and Sheffer, Alla and Gooch, Amy and Mitra, Niloy J},
booktitle = {ACM Transactions on Graphics (TOG)},
number = {5},
organization = {ACM},
pages = {137},
title = {{Abstraction of man-made shapes}},
volume = {28},
year = {2009}
}
@article{Viviani1989,
author = {Viviani, Paolo and Stucchi, Natale},
journal = {Perception {\&} Psychophysics},
number = {3},
pages = {266--274},
publisher = {Springer},
title = {{The effect of movement velocity on form perception: Geometric illusions in dynamic displays}},
volume = {46},
year = {1989}
}
@book{McCorduck1991AARON,
author = {McCorduck, Pamela},
publisher = {Freeman},
title = {{AARON's Code}},
year = {1991}
}
@article{vanDoorn1993Handwriting,
author = {van Doorn, Robert R A and Keuss, Paul J G},
doi = {http://dx.doi.org/10.1016/0001-6918(93)90016-K},
issn = {0001-6918},
journal = {Acta Psychologica},
number = {1–3},
pages = {275--290},
title = {{Does the production of letter strokes in handwriting benefit from vision?}},
url = {http://www.sciencedirect.com/science/article/pii/000169189390016K},
volume = {82},
year = {1993}
}
@article{Talton2009,
author = {Talton, Jerry O and Gibson, Daniel and Yang, Lingfeng and Hanrahan, Pat and Koltun, Vladlen},
journal = {ACM Transactions on Graphics-TOG},
number = {5},
pages = {167},
title = {{Exploratory modeling with collaborative design spaces}},
volume = {28},
year = {2009}
}
@book{Lashley1951,
author = {Lashley, Karl Spencer},
publisher = {Bobbs-Merrill},
title = {{The problem of serial order in behavior}},
year = {1951}
}
@article{almeraj2009automatically,
author = {AlMeraj, Zainab and Wyvill, Brian and Isenberg, Tobias and Gooch, Amy A and Guy, Richard},
journal = {Computers {\&} Graphics},
number = {4},
pages = {496--508},
publisher = {Elsevier},
title = {{Automatically mimicking unique hand-drawn pencil lines}},
volume = {33},
year = {2009}
}
@article{lacquaniti1983law,
author = {Lacquaniti, Francesco and Terzuolo, Carlo and Viviani, Paolo},
journal = {Acta psychologica},
number = {1},
pages = {115--130},
publisher = {Elsevier},
title = {{The law relating the kinematic and figural aspects of drawing movements}},
volume = {54},
year = {1983}
}
@article{Teulings1986,
author = {Teulings, Hans-Leo and Mullins, Patricia A and Stelmach, George E},
journal = {Advances in Psychology},
pages = {21--32},
publisher = {Elsevier},
title = {{The elementary units of programming in handwriting}},
volume = {37},
year = {1986}
}
@article{Ijspeert2013,
author = {Ijspeert, Auke Jan and Nakanishi, Jun and Hoffmann, Heiko and Pastor, Peter and Schaal, Stefan},
journal = {Neural computation},
number = {2},
pages = {328--373},
publisher = {MIT Press},
title = {{Dynamical movement primitives: learning attractor models for motor behaviors}},
volume = {25},
year = {2013}
}
@book{xu2009computational,
author = {Xu, Songhua and Lau, Francis C M and Pan, Yunhe},
publisher = {Springer},
title = {{A Computational Approach to Digital Chinese Painting and Calligraphy}},
year = {2009}
}
@article{Cross1983,
author = {Cross, George R and Jain, Anil K},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {1},
pages = {25--39},
publisher = {IEEE},
title = {{Markov random field texture models}},
year = {1983}
}
@article{Talton2011,
author = {Talton, Jerry O and Lou, Yu and Lesser, Steve and Duke, Jared and M{\v{e}}ch, Radom$\backslash$'$\backslash$ir and Koltun, Vladlen},
journal = {ACM Transactions on Graphics (TOG)},
number = {2},
pages = {11},
publisher = {ACM},
title = {{Metropolis procedural modeling}},
volume = {30},
year = {2011}
}
@article{rothGraff,
author = {Roth, Evan},
title = {{Graffiti Analysis}},
year = {2004}
}
@article{Hogan2009,
author = {Hogan, Neville and Sternad, Dagmar},
journal = {Journal of motor behavior},
number = {6},
pages = {529--534},
publisher = {Taylor {\&} Francis},
title = {{Sensitivity of smoothness measures to movement duration, amplitude, and arrests}},
volume = {41},
year = {2009}
}
@article{Bizzi1991,
author = {Bizzi, Emilio and Mussa-Ivaldi, Ferdinando A and Giszter, Simon},
journal = {Science},
number = {5017},
pages = {287--291},
publisher = {American Association for the Advancement of Science},
title = {{Computations underlying the execution of movement: a biological perspective}},
volume = {253},
year = {1991}
}
@inproceedings{Fu2011,
author = {Fu, Hongbo and Zhou, Shizhe and Liu, Ligang and Mitra, Niloy J},
booktitle = {ACM Transactions on Graphics (TOG)},
number = {6},
organization = {ACM},
pages = {133},
title = {{Animated construction of line drawings}},
volume = {30},
year = {2011}
}
@incollection{DBLP:books/daglib/p/DiVerdi13,
author = {DiVerdi, Stephen},
booktitle = {Image and Video-Based Artistic Stylisation},
pages = {23--44},
title = {{A Brush Stroke Synthesis Toolbox}},
year = {2013}
}
@incollection{Colton2012,
author = {Colton, Simon},
booktitle = {Computers and creativity},
pages = {3--38},
publisher = {Springer},
title = {{The painting fool: Stories from building an automated painter}},
year = {2012}
}
@article{Mussa-Ivaldi2000,
author = {Mussa--Ivaldi, Ferdinando A and Bizzi, Emilio},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
number = {1404},
pages = {1755--1769},
title = {{Motor learning through the combination of primitives}},
volume = {355},
year = {2000}
}
@article{Calinon06SMC,
author = {Calinon, Sylvain and Others},
journal = {IEEE Trans. SMC (B)},
number = {2},
pages = {286--298},
title = {{On learning, representing, and generalizing a task in a humanoid robot}},
volume = {37},
year = {2007}
}
@article{Viviani83therelation,
author = {Viviani, P and Mccollum, G},
journal = {Neuroscience},
pages = {211218},
title = {{The relation between linear extent and velocity in drawing movements}},
year = {1983}
}
@article{Xu2005calligraphy,
author = {Xu, Songhua and Lau, Francis and Cheung, William K and Pan, Yunhe},
journal = {Intelligent Systems, IEEE},
number = {3},
pages = {32--39},
publisher = {IEEE},
title = {{Automatic generation of artistic Chinese calligraphy}},
volume = {20},
year = {2005}
}
@article{plamondon2006multi,
author = {Plamondon, R{\'{e}}jean and Djioua, Moussa},
journal = {Human Movement Science},
number = {4},
pages = {586--607},
publisher = {Elsevier},
title = {{A multi-level representation paradigm for handwriting stroke generation}},
volume = {25},
year = {2006}
}
@inproceedings{OReilly2008,
author = {O'Reilly, Christian and Plamondon, R{\'{e}}jean},
booktitle = {Proceedings of the 11th International Conference on Frontier in Handwriting Recognition, to appear},
organization = {Citeseer},
title = {{Automatic extraction of sigma-lognormal parameters on signatures}},
year = {2008}
}
@article{xu2005synthesis,
author = {XU, Song-Hua and PAN, Yun-He and ZHUANG, Yue-Ting and {FRANCIS CM}, Lau},
journal = {ACTA AUTOMATICA SINICA},
title = {{Synthesis Reasoning and Its Application in Chinese Calligraphy Generation1, 2)}},
year = {2005}
}
@inproceedings{Ma2014,
author = {Ma, Chongyang and Huang, Haibin and Sheffer, Alla and Kalogerakis, Evangelos and Wang, Rui},
booktitle = {Computer Graphics Forum},
number = {2},
organization = {Wiley Online Library},
pages = {175--184},
title = {{Analogy-driven 3D style transfer}},
volume = {33},
year = {2014}
}
@article{Wada1994,
author = {Wada, Yasuhiro and Koike, Yasuharu and Vatikiotis-Bateson, Eric and Kawato, Mitsuo},
journal = {Advances in Neural Information Processing Systems},
pages = {727},
publisher = {MORGAN KAUFMANN PUBLISHERS},
title = {{A computational model for cursive handwriting based on the minimization principle}},
year = {1994}
}
@article{Lake2015,
author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
journal = {Science},
number = {6266},
pages = {1332--1338},
publisher = {American Association for the Advancement of Science},
title = {{Human-level concept learning through probabilistic program induction}},
volume = {350},
year = {2015}
}
@article{Slim2013,
author = {Slim, Mohamed Aymen and Abdelkarim, A and Benrejeb, Mohamed},
journal = {Int. J. Comput. Inf. Syst. Ind. Manag. Appl},
pages = {297--307},
title = {{Handwriting process modelling by artificial neural networks}},
volume = {5},
year = {2013}
}
@article{attneave1954some,
author = {Attneave, Fred},
journal = {Psychological review},
number = {3},
pages = {183},
publisher = {American Psychological Association},
title = {{Some informational aspects of visual perception.}},
volume = {61},
year = {1954}
}
@article{Tanaka2004,
author = {Tanaka, Hirokazu and Tai, Meihua and Qian, Ning},
journal = {Neural computation},
number = {10},
pages = {2021--2040},
publisher = {MIT Press},
title = {{Different predictions by the minimum variance and minimum torque-change models on the skewness of movement velocity profiles}},
volume = {16},
year = {2004}
}
@inproceedings{Dolinsky2007,
author = {Dolinsk$\backslash$`y, J{\'{a}}n and Takagi, Hideyuki},
booktitle = {Computational Cybernetics, 2007. ICCC 2007. IEEE International Conference on},
organization = {IEEE},
pages = {101--106},
title = {{Synthesizing handwritten characters using naturalness learning}},
year = {2007}
}
@article{knoblich2002,
author = {Knoblich, Gunther and Seigerschmidt, Eva and Flach, R{\"{u}}diger and Prinz, Wolfgang},
doi = {10.1080/02724980143000631},
isbn = {0272-4987 (Print){\$}\backslash{\$}r0272-4987},
issn = {0272-4987},
journal = {The Quarterly journal of experimental psychology. A, Human experimental psychology},
number = {3},
pages = {1027--1046},
pmid = {12188508},
title = {{Authorship effects in the prediction of handwriting strokes: evidence for action simulation during action perception.}},
volume = {55},
year = {2002}
}
@article{Southall1985,
author = {Southall, Richard},
publisher = {Stanford University},
title = {{Designing new typefaces with Metafont}},
year = {1985}
}
@article{Kokula1994,
author = {Kokula, Michael},
journal = {Electronic Publishing},
number = {4},
pages = {217--229},
title = {{Automatic generation of script font ligatures based on curve smoothness optimization}},
volume = {7},
year = {1994}
}
@incollection{Browne1998,
author = {Browne, Cameron},
booktitle = {Electronic Publishing, Artistic Imaging, and Digital Typography},
pages = {23--43},
publisher = {Springer},
title = {{Font decoration by automatic mesh fitting}},
year = {1998}
}
@article{Viviani1995,
author = {Viviani, Paolo and Flash, Tamar},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {1},
pages = {32},
publisher = {American Psychological Association},
title = {{Minimum-jerk, two-thirds power law, and isochrony: converging approaches to movement planning.}},
volume = {21},
year = {1995}
}
@article{Feldman2006,
author = {Feldman, Jacob and Singh, Manish},
journal = {Proceedings of the National Academy of Sciences},
number = {47},
pages = {18014--18019},
publisher = {National Acad Sciences},
title = {{Bayesian estimation of the shape skeleton}},
volume = {103},
year = {2006}
}
@article{genna2013sviluppo,
author = {Genna, Mariangela},
publisher = {Universit{\{}{\`{a}}{\}} degli studi di Trieste},
title = {{Sviluppo di strumenti per l'analisi della scrittura e applicazioni}},
year = {2013}
}
@article{blum1967transformation,
author = {Blum, H and Others},
journal = {Models for the perception of speech and visual form},
number = {5},
pages = {362--380},
title = {{A transformation for extracting new descriptors of shape}},
volume = {19},
year = {1967}
}
@article{morasso1982trajectory,
author = {Morasso, P and {Mussa Ivaldi}, F A},
journal = {Biological cybernetics},
number = {2},
pages = {131--142},
publisher = {Springer},
title = {{Trajectory formation and handwriting: a computational model}},
volume = {45},
year = {1982}
}
@article{flash1985coordination,
author = {Flash, Tamar and Hogan, Neville},
journal = {Journal of Neuroscience},
number = {7},
pages = {1688--1703},
title = {{The coordination of arm movements}},
volume = {5},
year = {1985}
}
@book{leyton2006structure,
author = {Leyton, M},
publisher = {Springer},
title = {{The structure of paintings}},
year = {2006}
}
@inproceedings{Schubert2013,
author = {Schubert, Alexander and Mombaur, Katja},
booktitle = {Proceedings of the Fourth International Conference on Computational Creativity},
title = {{The role of motion dynamics in abstract painting}},
volume = {2013},
year = {2013}
}
@incollection{Watt1988,
author = {Watt, William C},
booktitle = {The alphabet and the brain},
pages = {122--152},
publisher = {Springer},
title = {{Canons of alphabetic change}},
year = {1988}
}
@book{Solso2003,
author = {Solso, Robert L},
publisher = {MIT Press},
title = {{The Psychology of Art and the Evolution of the Conscious Brain}},
year = {2003}
}
@article{Phang2015,
author = {Phang, S K and Others},
journal = {Mechatronics},
title = {{Systems design {\&} implementation with jerk-optimized trajectory generation for {\{}UAV{\}} calligraphy}},
volume = {30},
year = {2015}
}
@article{Viviani1991,
author = {Viviani, Paolo and Schneider, Roland},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {1},
pages = {198},
publisher = {American Psychological Association},
title = {{A developmental study of the relationship between geometry and kinematics in drawing movements.}},
volume = {17},
year = {1991}
}
@inproceedings{Wang2009,
author = {Wang, Rong-Jyue and Zhang, Jun-Wei and Xu, Jia-Ming and Liu, Hsin-Yu},
booktitle = {Fuzzy Systems, 2009. FUZZ-IEEE 2009. IEEE International Conference on},
organization = {IEEE},
pages = {1995--2000},
title = {{The multiple-function intelligent robotic arms}},
year = {2009}
}
@article{Fitts1967,
author = {Fitts, Paul Morris and Posner, Michael I},
publisher = {Brooks/Cole},
title = {{Human performance.}},
year = {1967}
}
@article{xu2009,
author = {Xu, Songhua and Jiang, Hao and Jin, Tao and Lau, Francis C M and Pan, Yunhe},
journal = {IEEE Intelligent Systems},
number = {2},
pages = {44--53},
publisher = {IEEE, Computer Society. The Journal's web site is located at http://computer. org/intelligent/},
title = {{Automatic generation of Chinese calligraphic writings with style imitation}},
volume = {24},
year = {2009}
}
@article{Rohrer2006,
author = {Rohrer, Brandon and Hogan, Neville},
journal = {Biological cybernetics},
number = {5},
pages = {409--414},
title = {{Avoiding spurious submovement decompositions {\{}II{\}}}},
volume = {94},
year = {2006}
}
@article{demers1993non,
author = {DeMers, D and Cottrell, G and Others},
journal = {Advances in neural information processing systems},
pages = {580},
publisher = {MORGAN KAUFMANN PUBLISHERS},
title = {{Non-linear dimensionality reduction}},
year = {1993}
}
@phdthesis{FlashThesis1983,
author = {Flash, Tamar},
school = {Massachusetts Institute of Technology},
title = {{Organizing principles underlying the formation of arm trajectories}},
year = {1983}
}
@article{Geyer2011,
author = {Geyer, Charles},
journal = {Handbook of Markov Chain Monte Carlo},
pages = {3--48},
title = {{Introduction to Markov Chain Monte Carlo}},
year = {2011}
}
@article{Cox1982,
author = {Cox, C H and Coueignoux, Philippe and Blesser, B and Eden, M},
journal = {Pattern Recognition},
number = {1},
pages = {11--22},
publisher = {Elsevier},
title = {{Skeletons: A link between theoretical and physical letter descriptions}},
volume = {15},
year = {1982}
}
@article{Bernstein1967,
author = {Bernstein, Nikolaj A},
publisher = {Pergamon Press Ltd.},
title = {{The co-ordination and regulation of movements}},
year = {1967}
}
@article{Ai2007,
author = {Ai, Tinghua},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
number = {2},
pages = {93--103},
publisher = {Elsevier},
title = {{The drainage network extraction from contour lines for contour line generalization}},
volume = {62},
year = {2007}
}
@article{hofstadter1982metamagical,
author = {Hofstadter, D},
journal = {Scientific American},
number = {4},
pages = {14--21},
title = {{Metamagical themas: variations on a theme as the essence of imagination}},
volume = {247},
year = {1982}
}
@inproceedings{Li2014calligraphy,
author = {Li, Jun and Others},
booktitle = {IEEE Proc. CASE},
pages = {221--226},
title = {{Teaching a calligraphy robot via a touch screen}},
year = {2014}
}
@inproceedings{lambert2013emergence,
author = {Lambert, Nicholas and Latham, William and {Fol Leymarie}, Frederic},
booktitle = {ACM SIGGRAPH 2013 Art Gallery},
organization = {ACM},
pages = {367--375},
title = {{The emergence and growth of evolutionary art: 1980--1993}},
year = {2013}
}
@inproceedings{Hood2015,
author = {Hood, Deanna and Lemaignan, S{\'{e}}verin and Dillenbourg, Pierre},
booktitle = {Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction},
organization = {ACM},
pages = {83--90},
title = {{When children teach a robot to write: An autonomous teachable humanoid which uses simulated handwriting}},
year = {2015}
}
@article{yu2005realistic,
author = {Yu, Jinhui and Peng, Qunsheng},
journal = {Computers {\&} Graphics},
number = {1},
pages = {145--153},
publisher = {Elsevier},
title = {{Realistic synthesis of cao shu of Chinese calligraphy}},
volume = {29},
year = {2005}
}
@article{bullock1993neural,
author = {Bullock, Daniel and Grossberg, Stephen and Mannes, Christian},
journal = {Biological Cybernetics},
number = {1},
pages = {15--28},
publisher = {Springer},
title = {{A neural network model for cursive script production}},
volume = {70},
year = {1993}
}
@article{Liegeois1977,
author = {Liegeois, A},
journal = {IEEE Trans. SMC},
number = {12},
pages = {868--871},
title = {{Automatic supervisory control of the config. {\&} behavior of multibody mechanisms}},
volume = {7},
year = {1977}
}
@inproceedings{Xie2015,
author = {Xie, Ning and Zhao, Tingting and Tian, Feng and Zhang, Xiaohua and Sugiyama, Masashi},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
organization = {AAAI Press},
pages = {2531--2537},
title = {{Stroke-based stylization learning and rendering with inverse reinforcement learning}},
year = {2015}
}
@incollection{Caligiuri2012,
author = {Caligiuri, Michael P and Mohammed, Linton A},
chapter = {8},
pages = {113--119},
publisher = {CRC Press},
title = {{The neuroscience of handwriting: Applications for forensic document examination}},
year = {2012}
}
@article{Polyakov2009,
author = {Polyakov, Felix and Drori, Rotem and Ben-Shaul, Yoram and Abeles, Moshe and Flash, Tamar},
journal = {PLoS Comput Biol},
number = {7},
pages = {e1000427----e1000427},
title = {{A compact representation of drawing movements with sequences of parabolic primitives}},
volume = {5},
year = {2009}
}
@inproceedings{Kwok2006,
author = {Kwok, Ka Wai and Others},
booktitle = {IEEE Int'l Conf. Automation Sci. {\&} Engineering},
pages = {466--471},
title = {{Evolutionary replication of calligraphic characters by a robot drawing platform}},
year = {2006}
}
@inproceedings{Calinon2014,
author = {Calinon, Sylvain and Bruno, Danilo and Caldwell, Darwin G},
booktitle = {Robotics and Automation (ICRA), 2014 IEEE International Conference on},
organization = {IEEE},
pages = {3339--3344},
title = {{A task-parameterized probabilistic model with minimal intervention control}},
year = {2014}
}
@article{viviani1992biological,
author = {Viviani, Paolo and Stucchi, Natale},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {3},
pages = {603},
publisher = {American Psychological Association},
title = {{Biological movements look uniform: evidence of motor-perceptual interactions.}},
volume = {18},
year = {1992}
}
@article{Viviani1980,
author = {Viviani, Paolo and Terzuolo, Carlo},
journal = {Advances in psychology},
pages = {525--533},
publisher = {Elsevier},
title = {{32 Space-Time Invariance in Learned Motor Skills}},
volume = {1},
year = {1980}
}
@article{Grippo1997,
author = {Grippo, Luigi and Lucidi, Stefano},
journal = {Mathematical Programming},
number = {3},
pages = {375--391},
publisher = {Springer},
title = {{A globally convergent version of the Polak-Ribiere conjugate gradient method}},
volume = {78},
year = {1997}
}
@book{klee1961paul,
author = {Klee, Paul},
publisher = {G. Wittenborn},
title = {{Paul Klee: the thinking eye: the notebooks of Paul Klee}},
volume = {15},
year = {1961}
}
@article{kolmogorov1963tables,
author = {Kolmogorov, A N},
journal = {Sankhy{\{}$\backslash$=a{\}}: The Indian Journal of Statistics, Series A},
number = {4},
pages = {369--376},
publisher = {JSTOR},
title = {{On tables of random numbers}},
volume = {25},
year = {1963}
}
@article{orbay2011beautification,
author = {Orbay, Gunay and Kara, Levent Burak},
journal = {Visualization and Computer Graphics, IEEE Transactions on},
number = {5},
pages = {694--708},
publisher = {IEEE},
title = {{Beautification of design sketches using trainable stroke clustering and curve fitting}},
volume = {17},
year = {2011}
}
@book{kao1986graphonomics,
author = {Kao, Henry S R and Hoosain, Rumjahn and {Van Galen}, G P},
publisher = {Elsevier},
title = {{Graphonomics: Contemporary research in handwriting}},
year = {1986}
}
@inproceedings{okabe2005paintbrush,
author = {Okabe, Yuta and Saito, Suguru and Nakajima, Masayuki},
booktitle = {Proceedings of the 3rd international conference on Computer graphics and interactive techniques in Australasia and South East Asia},
organization = {ACM},
pages = {91--98},
title = {{Paintbrush rendering of lines using HMMs}},
year = {2005}
}
@article{Ostry1987,
author = {Ostry, David J and Cooke, James D and Munhall, Kevin G},
journal = {Experimental Brain Research},
number = {1},
pages = {37--46},
publisher = {Springer},
title = {{Velocity curves of human arm and speech movements}},
volume = {68},
year = {1987}
}
@inproceedings{kimia2002role,
author = {Kimia, B and Tamrakar, A},
booktitle = {Biologically Motivated Computer Vision},
organization = {Springer},
pages = {197--207},
title = {{The role of propagation and medial geometry in human vision}},
year = {2002}
}
@article{Bizzi1984,
author = {Bizzi, Emilio and Accornero, Neri and Chapple, William and Hogan, Neville},
journal = {The Journal of Neuroscience},
number = {11},
pages = {2738--2744},
publisher = {Soc Neuroscience},
title = {{Posture control and trajectory formation during arm movement}},
volume = {4},
year = {1984}
}
@article{Harris1998,
author = {Harris, Christopher M and Wolpert, Daniel M},
journal = {Nature},
number = {6695},
pages = {780--784},
publisher = {Nature Publishing Group},
title = {{Signal-dependent noise determines motor planning}},
volume = {394},
year = {1998}
}
@article{Longcamp2009,
author = {Longcamp, Marieke and Hlushchuk, Yevhen and Hari, Riitta},
journal = {Advances in Graphonomics: Proceedings of IGS 2009},
pages = {194--197},
title = {{Neural correlates of the visual perception of handwritten letters}},
year = {2009}
}
@article{Gordon1994,
author = {Gordon, James and Ghilardi, Maria Felice and Cooper, Scott E and Ghez, Claude},
journal = {Experimental Brain Research},
number = {1},
pages = {112--130},
publisher = {Springer},
title = {{Accuracy of planar reaching movements}},
volume = {99},
year = {1994}
}
@article{havemann2013curvature,
author = {Havemann, Sven and Edelsbrunner, Johannes and Wagner, Philipp and Fellner, Dieter},
journal = {Computers {\&} Graphics},
number = {6},
pages = {764--773},
publisher = {Elsevier},
title = {{Curvature-controlled curve editing using piecewise clothoid curves}},
volume = {37},
year = {2013}
}
@incollection{Davis2015,
author = {Davis, Nicholas and Hsiao, Chih-Pin and Popova, Yanna and Magerko, Brian},
booktitle = {Creativity in the Digital Age},
pages = {109--133},
publisher = {Springer},
title = {{An Enactive Model of Creativity for Computational Collaboration and Co-creation}},
year = {2015}
}
@article{tresset2005generative,
author = {Tresset, P and Leymarie, F F},
journal = {Proc. VSMM'05},
publisher = {Citeseer},
title = {{Generative portrait sketching}},
year = {2005}
}
@article{moustapha2001arabic,
author = {Moustapha, Hoda and Krishnamurti, Ramesh},
journal = {Mathematics and design},
title = {{Arabic calligraphy: A computational Exploration}},
year = {2001}
}
@article{Summers2009,
author = {Summers, Jeffery J and Anson, J Greg},
journal = {Human Movement Science},
number = {5},
pages = {566--577},
publisher = {Elsevier},
title = {{Current status of the motor program: Revisited}},
volume = {28},
year = {2009}
}
@inproceedings{hertzmann2002curve,
author = {Hertzmann, Aaron and Oliver, Nuria and Curless, Brian and Seitz, Steven M},
booktitle = {Rendering Techniques},
pages = {233--246},
title = {{Curve Analogies.}},
year = {2002}
}
@article{jeannerod1995mental,
author = {Jeannerod, Marc},
journal = {Neuropsychologia},
number = {11},
pages = {1419--1432},
publisher = {Elsevier},
title = {{Mental imagery in the motor context}},
volume = {33},
year = {1995}
}
@inproceedings{djioua2008new,
author = {Djioua, Moussa and Plamondon, R{\'{e}}jean},
booktitle = {International Conference on Frontiers in Handwriting Recognition, Montreal},
pages = {112--117},
title = {{A new methodology to improve myoelectric signal processing using handwriting}},
year = {2008}
}
@book{Leavitt1976,
author = {Leavitt, Ruth},
publisher = {Crown},
title = {{Artist and computer}},
year = {1976}
}
@article{james2006,
author = {James, Karin H and Gauthier, Isabel},
doi = {10.1016/j.neuropsychologia.2006.06.026},
isbn = {0028-3932},
issn = {00283932},
journal = {Neuropsychologia},
number = {14},
pages = {2937--2949},
pmid = {16920164},
title = {{Letter processing automatically recruits a sensory-motor brain network}},
volume = {44},
year = {2006}
}
@article{freedberg2007motion,
author = {Freedberg, David and Gallese, Vittorio},
journal = {Trends in cognitive sciences},
number = {5},
pages = {197--203},
publisher = {Elsevier},
title = {{Motion, emotion and empathy in esthetic experience}},
volume = {11},
year = {2007}
}
@inproceedings{deussen2012feedback,
author = {Deussen, Oliver and Others},
booktitle = {Proc. of 8th Symp. on Comp. Aesthetics in Graphics, Visualization, and Imaging},
pages = {25--33},
title = {{Feedback-guided stroke placement for a painting machine}},
year = {2012}
}
@incollection{Shi2012,
author = {Shi, Cao and Xiao, Jianguo and Jia, Wenhua and Xu, Canhui},
booktitle = {Natural Language Processing and Chinese Computing},
pages = {23--33},
publisher = {Springer},
title = {{Automatic generation of Chinese character based on human vision and prior knowledge of calligraphy}},
year = {2012}
}
@article{McCrae2009Clothoids,
author = {McCrae, James and Singh, Karan},
doi = {10.1016/j.cag.2009.05.006},
isbn = {978-3-905674-07-1},
issn = {00978493},
journal = {Computers and Graphics (Pergamon)},
number = {4},
pages = {452--461},
publisher = {Elsevier},
title = {{Sketching piecewise clothoid curves}},
url = {http://dx.doi.org/10.1016/j.cag.2009.05.006},
volume = {33},
year = {2009}
}
@article{Viviani1982,
author = {Viviani, P and Terzuolo, C},
journal = {Neuroscience},
number = {2},
pages = {431--437},
publisher = {Elsevier},
title = {{Trajectory determines movement dynamics}},
volume = {7},
year = {1982}
}
@misc{wikiWildStyle,
title = {{WIKIPEDIA: Wildstyle}},
url = {https://en.wikipedia.org/wiki/Wildstyle}
}
@article{plamondon2013Lognormality,
author = {Plamondon, Rejean and O'Reilly, Christian and Remi, Celine and Duval, Theresa},
issn = {1664-1078},
journal = {Frontiers in Psychology},
number = {945},
title = {{The Lognormal Handwriter: Learning, Performing and Declining.}},
volume = {4},
year = {2013}
}
@article{Arbib1992,
author = {Arbib, Michael A},
journal = {The Encyclopedia of Artificial Intelligence},
pages = {1427--1443},
publisher = {Wiley Interscience},
title = {{Schema theory}},
volume = {2},
year = {1992}
}
@misc{graffitizer2,
author = {Berio, Daniel},
howpublished = {$\backslash$url{\{}http://www.enist.org/wp/graffitizer/{\}}},
title = {{Graffitizer 2}},
year = {2013}
}
@inproceedings{konieczny2009airbrush,
author = {Konieczny, Jonathan and Meyer, Gary},
booktitle = {Proceedings of the 7th International Symposium on Non-Photorealistic Animation and Rendering},
organization = {ACM},
pages = {61--69},
title = {{Airbrush simulation for artwork and computer modeling}},
year = {2009}
}
@incollection{Schaal2006,
author = {Schaal, Stefan},
booktitle = {Adaptive Motion of Animals and Machines},
pages = {261--280},
publisher = {Springer},
title = {{Dynamic movement primitives-a framework for motor control in humans and humanoid robotics}},
year = {2006}
}
@article{Flash1987,
author = {Flash, Tamar},
journal = {Biological cybernetics},
number = {4-5},
pages = {257--274},
publisher = {Springer},
title = {{The control of hand equilibrium trajectories in multi-joint arm movements}},
volume = {57},
year = {1987}
}
@article{Biernacki2003,
author = {Biernacki, Christophe and Others},
journal = {Comp. Stats. {\&} Data Analysis},
number = {3},
pages = {561--575},
title = {{Choosing starting values for the EM algorithm for getting the highest likelihood in multivariate {\{}G{\}}aussian mixture models}},
volume = {41},
year = {2003}
}
@article{Stamm1998,
author = {Stamm, Beat},
journal = {Electronic Publishing, Artistic Imaging, and Digital Typography},
pages = {77--92},
publisher = {Springer},
title = {{Visual TrueType: A graphical method for authoring font intelligence}},
year = {1998}
}
@article{Rosenbaum1995,
author = {Rosenbaum, David A and Loukopoulos, Loukia D and Meulenbroek, Ruud G J and Vaughan, Jonathan and Engelbrecht, Sascha E},
journal = {Psychological review},
number = {1},
pages = {28},
publisher = {American Psychological Association},
title = {{Planning reaches by evaluating stored postures.}},
volume = {102},
year = {1995}
}
@article{koenderink2012geometry,
author = {Koenderink, Jan J},
journal = {Journal of Physiology-Paris},
number = {5},
pages = {173--182},
publisher = {Elsevier},
title = {{Geometry of imaginary spaces}},
volume = {106},
year = {2012}
}
@article{Wang2005,
author = {Wang, Jue and Wu, Chenyu and Xu, Ying-Qing and Shum, Heung-Yeung},
journal = {International Journal of Document Analysis and Recognition (IJDAR)},
number = {4},
pages = {219--227},
publisher = {Springer},
title = {{Combining shape and physical modelsfor online cursive handwriting synthesis}},
volume = {7},
year = {2005}
}
@incollection{Zhang2009,
author = {Zhang, Xiafen and Liu, Guangzhong},
booktitle = {Advances in Multimedia Information Processing-PCM 2009},
pages = {167--178},
publisher = {Springer},
title = {{Chinese calligraphy character image synthesis based on retrieval}},
year = {2009}
}
@article{Feldman1966,
author = {Feldman, A G},
journal = {Biofizika},
pages = {498--508},
title = {{Functional Tuning of the Nervous System with Control of Movement of Maintenance of a Steady Posture of Movement or Maintenance of a Steady Posture-II. Controllable Parameters of the Muscles}},
volume = {11},
year = {1966}
}
@inproceedings{Wang2013,
author = {Wang, Xiaoqing and Liang, Xiaohui and Sun, Linjia and Liu, Min},
booktitle = {Document Analysis and Recognition (ICDAR), 2013 12th International Conference on},
organization = {IEEE},
pages = {1155--1159},
title = {{Triangular Mesh Based Stroke Segmentation for Chinese Calligraphy}},
year = {2013}
}
@article{Dempster77,
author = {Dempster, A P and Others},
journal = {J. Royal Statistical Society B},
number = {1},
pages = {1--38},
title = {{Maximum Likelihood from Incomplete Data via the {\{}EM{\}} Algorithm}},
volume = {39},
year = {1977}
}
@book{arnheim1954art,
author = {Arnheim, Rudolf},
publisher = {Univ of California Press},
title = {{Art and visual perception: A psychology of the creative eye}},
year = {1954}
}
@phdthesis{gips1974shape,
author = {Gips, J},
school = {Stanford University},
title = {{Shape grammars and their uses}},
year = {1974}
}
@article{Lu2014,
author = {Lu, Jingwan and Barnes, Connelly and Wan, Connie and Asente, Paul and Mech, Radomir and Finkelstein, Adam},
journal = {ACM Transactions on Graphics (TOG)},
number = {4},
pages = {90},
publisher = {ACM},
title = {{Decobrush: Drawing structured decorative patterns by example}},
volume = {33},
year = {2014}
}
@inproceedings{Nguyen2010,
author = {Nguyen, Vu and Blumenstein, Michael},
booktitle = {Proceedings of the 9th IAPR International Workshop on Document Analysis Systems},
organization = {ACM},
pages = {463--470},
title = {{Techniques for static handwriting trajectory recovery: a survey}},
year = {2010}
}
@article{bertolazzi2013fast,
author = {Bertolazzi, Enrico and Frego, Marco},
journal = {arXiv preprint arXiv:1305.6644},
title = {{Fast and accurate {\$}{\{}G{\}}{\^{}}{\{}1{\}}{\$} fitting of clothoid curves}},
year = {2013}
}
@article{djioua2009studying,
author = {Djioua, M and Plamondon, R},
journal = {Human movement science},
number = {5},
pages = {588--601},
publisher = {Elsevier},
title = {{Studying the variability of handwriting patterns using the Kinematic Theory}},
volume = {28},
year = {2009}
}
@incollection{Rasmussen2004,
author = {Rasmussen, Carl Edward},
booktitle = {Advanced lectures on machine learning},
pages = {63--71},
publisher = {Springer},
title = {{Gaussian processes in machine learning}},
year = {2004}
}
@article{Koch2015,
author = {Koch, Christof},
journal = {Scientific American Mind},
number = {6},
pages = {24--27},
publisher = {Nature Publishing Group},
title = {{Do Androids Dream?}},
volume = {26},
year = {2015}
}
@article{Wolpert2011,
author = {Wolpert, Daniel M and Diedrichsen, J{\"{o}}rn and Flanagan, J Randall},
journal = {Nature Reviews Neuroscience},
number = {12},
pages = {739--751},
publisher = {Nature Publishing Group},
title = {{Principles of sensorimotor learning}},
volume = {12},
year = {2011}
}
@inproceedings{yang2009animating,
author = {Yang, Lijie and Li, Xiaoshan},
booktitle = {Computer and Information Science, 2009. ICIS 2009. Eighth IEEE/ACIS International Conference on},
organization = {IEEE},
pages = {683--688},
title = {{Animating the brush-writing process of Chinese calligraphy characters}},
year = {2009}
}
@article{Sbriscia-Fioretti2013,
author = {Sbriscia-Fioretti, Beatrice and Berchio, Cristina and Freedberg, David and Gallese, Vittorio and Umilt{\`{a}}, Maria Alessandra},
journal = {PloS one},
number = {10},
pages = {e75241},
publisher = {Public Library of Science},
title = {{ERP Modulation during observation of abstract paintings by Franz Kline}},
volume = {8},
year = {2013}
}
@article{Vatti1992,
author = {Vatti, Bala R},
journal = {Communications of the ACM},
number = {7},
pages = {56--63},
publisher = {ACM},
title = {{A generic solution to polygon clipping}},
volume = {35},
year = {1992}
}
@inproceedings{mackenzie1992extending,
author = {MacKenzie, I Scott and Buxton, William},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
organization = {ACM},
pages = {219--226},
title = {{Extending Fitts' law to two-dimensional tasks}},
year = {1992}
}
@article{Hoff1994,
author = {Hoff, Bruce},
journal = {Biological Cybernetics},
number = {6},
pages = {481--488},
publisher = {Springer},
title = {{A model of duration in normal and perturbed reaching movement}},
volume = {71},
year = {1994}
}
@article{Newell2001,
author = {Newell, Karl M and Vaillancourt, David E},
journal = {Human movement science},
number = {4},
pages = {695--715},
publisher = {Elsevier},
title = {{Dimensional change in motor learning}},
volume = {20},
year = {2001}
}
@inproceedings{Chen2012,
author = {Chen, Zhanghui and Zhou, Baoyao},
booktitle = {Proceedings of the 2012 ACM symposium on Document engineering},
organization = {ACM},
pages = {107--116},
title = {{Effective radical segmentation of offline handwritten Chinese characters towards constructing personal handwritten fonts}},
year = {2012}
}
@inproceedings{gooch2010viewing,
author = {Gooch, Amy A and Long, Jeremy and Ji, Li and Estey, Anthony and Gooch, Bruce S},
booktitle = {Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering},
organization = {ACM},
pages = {165--171},
title = {{Viewing progress in non-photorealistic rendering through Heinlein's lens}},
year = {2010}
}
@article{guberman2012gestalt,
author = {Guberman, S and Maximov, V V and Pashintsev, A},
journal = {Gestalt Theory},
number = {2},
pages = {143},
title = {{Gestalt and Image Understanding}},
volume = {34},
year = {2012}
}
@article{Oztop2013,
author = {Oztop, Erhan and Kawato, Mitsuo and Arbib, Michael A},
journal = {Neuroscience letters},
pages = {43--55},
publisher = {Elsevier},
title = {{Mirror neurons: functions, mechanisms and models}},
volume = {540},
year = {2013}
}
@incollection{Leymarie06Aesthetics,
author = {Leymarie, Frederic Fol},
chapter = {14},
month = {apr},
publisher = {MIT Press},
series = {Aesthetic Computing, Paul Fishwick, ed.},
title = {{Aesthetic Computing and Shape}},
year = {2006}
}
@article{li1998segmentation,
author = {Li, Xiaolin and Parizeau, Marc and Plamondon, R{\'{e}}jean},
journal = {Pattern recognition},
number = {6},
pages = {675--684},
publisher = {Elsevier},
title = {{Segmentation and reconstruction of on-line handwritten scripts}},
volume = {31},
year = {1998}
}
@article{dietrich1986visual,
author = {Dietrich, Frank},
journal = {Leonardo},
number = {2},
pages = {159--169},
publisher = {Pergamon Press},
title = {{Visual intelligence: The first decade of computer art (1965-1975)}},
volume = {19},
year = {1986}
}
@article{Rohrer2004,
author = {Rohrer, Brandon and Fasoli, Susan and Krebs, Hermano Igo and Volpe, Bruce and Frontera, Walter R and Stein, Joel and Hogan, Neville and Others},
journal = {MOTOR CONTROL-CHAMPAIGN-},
pages = {472--483},
publisher = {HUMAN KINETICS},
title = {{Submovements grow larger, fewer, and more blended during stroke recovery}},
volume = {8},
year = {2004}
}
@article{veroAlg1,
author = {Verostko, Roman},
title = {{Algorithms and The Artist}},
url = {http://www.verostko.com/alg-isea94.html}
}
@inproceedings{Murata2013,
author = {Murata, Atsuo and Inoue, Kousuke and Moriwaka, Makoto},
booktitle = {SICE Annual Conference (SICE), 2013 Proceedings of},
organization = {IEEE},
pages = {2412--2417},
title = {{Basic study on extraction of skilled element on the basis of eye-hand coordination and writing pressure in calligraphy}},
year = {2013}
}
@inproceedings{tutenel2009usig,
author = {{Tutenel Tim ad Smelik}, Ruben Micha{\"{e}}l and Bidarra, Rafael and de Kraker, Klaas Jan},
booktitle = {AIIDE},
title = {{Using Semantics to Improve the Design of Game Worlds}},
url = {http://www.aaai.org/ocs/index.php/AIIDE/AIIDE09/paper/viewFile/805/1083},
year = {2009}
}
@inproceedings{burton1995thoughtful,
author = {Burton, Ed},
booktitle = {Computer Graphics Forum},
number = {3},
organization = {Wiley Online Library},
pages = {159--170},
title = {{Thoughtful drawings: A computational model of the cognitive nature of children's drawing}},
volume = {14},
year = {1995}
}
@misc{orliaguet1997,
author = {Orliaguet, Jean Pierre and Bo{\"{e}}, Louis Jean},
title = {{Visual perception of motor anticipation in cursive handwriting}},
year = {1997}
}
@inproceedings{leymarie2014point,
author = {Leymarie, Frederic Fol and Aparajeya, Prashant and MacGillivray, Carol},
booktitle = {Proceedings of the 2014 International Workshop on Movement and Computing},
organization = {ACM},
pages = {31},
title = {{Point-based medialness for movement computing}},
year = {2014}
}
@article{Kimia:JPhyiology:2003,
author = {Kimia, Benjamin B},
journal = {Journal of Physiology-Paris},
number = {2{\{}$\backslash$textendash{\}}3},
pages = {155{\{}$\backslash$textendash{\}}190},
title = {{On the Role of Medial Geometry in Human Vision}},
volume = {97},
year = {2003}
}
@article{Teulings1996,
author = {Teulings, Hans-Leo},
journal = {Handbook of perception and action},
pages = {561--613},
publisher = {Academic Press London},
title = {{Handwriting movement control}},
volume = {2},
year = {1996}
}
@inproceedings{kudoh2007painter,
author = {Kudoh, Shunsuke and Ogawara, Koichi and Ruchanurucks, Miti and Ikeuchi, Katsushi},
booktitle = {IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS) Workshop" Art and Robots},
pages = {63--68},
title = {{Painter Robot: Manipulation of Paintbrush by Force and Visual Feedback}},
year = {2007}
}
@book{kimvall2014gword,
address = {Stockholm},
author = {Kimvall, Jacob},
isbn = {9789185639687},
publisher = {Dokument},
title = {{The G-word}},
year = {2014}
}
@article{hsu1994skeletal,
address = {New York, New York, USA},
author = {Hsu, Siu Chi and Lee, Irene H H},
doi = {10.1145/192161.192186},
isbn = {0897916670},
journal = {Proceedings of the 21st annual conference on Computer graphics and interactive techniques - SIGGRAPH '94},
pages = {109--118},
publisher = {ACM Press},
title = {{Drawing and animation using skeletal strokes}},
url = {http://portal.acm.org/citation.cfm?doid=192161.192186},
year = {1994}
}
@article{Xu2012a,
author = {Xu, Kai and Zhang, Hao and Cohen-Or, Daniel and Chen, Baoquan},
journal = {ACM Transactions on Graphics (TOG)},
number = {4},
pages = {57},
publisher = {ACM},
title = {{Fit and diverse: set evolution for inspiring 3D shape galleries}},
volume = {31},
year = {2012}
}
@article{Heald1985Fresnel,
author = {Heald, Mark a.},
doi = {10.1090/S0025-5718-1985-0777277-6},
issn = {0025-5718},
journal = {Mathematics of Computation},
number = {170},
pages = {459},
title = {{Rational approximations for the Fresnel integrals}},
volume = {44},
year = {1985}
}
@inproceedings{Cao2000,
author = {Cao, Ruini and Tan, Chew Lim},
booktitle = {Pattern Recognition, 2000. Proceedings. 15th International Conference on},
organization = {IEEE},
pages = {368--371},
title = {{A model of stroke extraction from Chinese character images}},
volume = {4},
year = {2000}
}
@incollection{Gwilt2014,
author = {Gwilt, Ian},
booktitle = {Augmented Reality Art},
pages = {189--198},
publisher = {Springer},
title = {{Augmented Reality Graffiti and Street Art}},
year = {2014}
}
@article{Zeestraten,
author = {Zeestraten, Martijn J A and Calinon, Sylvain and Caldwell, Darwin G},
title = {{Variable Duration Movement Encoding with Minimal Intervention Control}},
year = {2016}
}
@article{Galantucci2006,
author = {Galantucci, Bruno and Fowler, Carol A and Turvey, Michael T},
journal = {Psychonomic bulletin {\&} review},
number = {3},
pages = {361--377},
publisher = {Springer},
title = {{The motor theory of speech perception reviewed}},
volume = {13},
year = {2006}
}
@article{kimvall2007,
author = {Kimvall, Jacob},
title = {{Bad Graffiti Art Gone Good Street Art}},
url = {http://www.academia.edu/1121025/Bad{\_}Graffiti{\_}Art{\_}Gone{\_}Good{\_}Street{\_}Art},
year = {2007}
}
@article{goldberg1991comparative,
author = {Goldberg, David E and Deb, Kalyanmoy},
journal = {Foundations of genetic algorithms},
pages = {69--93},
title = {{A comparative analysis of selection schemes used in genetic algorithms}},
volume = {1},
year = {1991}
}
@book{hofstadter1996fluid,
author = {Hofstadter, D R},
publisher = {Basic Books},
title = {{Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought}},
year = {1996}
}
@article{Grossberg2000,
author = {Grossberg, Stephen and Paine, Rainer W},
journal = {Neural Networks},
number = {8},
pages = {999--1046},
publisher = {Elsevier},
title = {{A neural model of cortico-cerebellar interactions during attentive imitation and predictive learning of sequential handwriting movements}},
volume = {13},
year = {2000}
}
@phdthesis{Schomaker1991,
author = {Schomaker, L},
school = {Citeseer},
title = {{Simulation and recognition of handwriting movements}},
year = {1991}
}
@article{Zeng1995,
author = {Zeng, Jianchao and Hidehiko, Sanada and Yoshikazu, Tezuka and Xu, Guangyou},
journal = {Journal of Computer Science and Technology},
number = {1},
pages = {23--34},
publisher = {Springer},
title = {{A form-correcting system of Chinese characters using a model of correcting procedures of calligraphists}},
volume = {10},
year = {1995}
}
@article{Gallese1996,
author = {Gallese, Vittorio and Fadiga, Luciano and Fogassi, Leonardo and Rizzolatti, Giacomo},
journal = {Brain},
number = {2},
pages = {593--610},
publisher = {Oxford Univ Press},
title = {{Action recognition in the premotor cortex}},
volume = {119},
year = {1996}
}
@article{Todorov1998,
author = {Todorov, Emanuel and Jordan, Michael I},
journal = {Journal of Neurophysiology},
number = {2},
pages = {696--714},
publisher = {Am Physiological Soc},
title = {{Smoothness maximization along a predefined path accurately predicts the speed profiles of complex arm movements}},
volume = {80},
year = {1998}
}
@article{Umilta2012,
author = {Umilta, M Alessandra and Berchio, Cristina and Sestito, Mariateresa and Freedberg, David and Gallese, Vittorio},
journal = {Frontiers in human neuroscience},
publisher = {Frontiers Media SA},
title = {{Abstract art and cortical motor activation: an EEG study}},
volume = {6},
year = {2012}
}
@article{Calinon2016,
author = {Calinon, Sylvain},
journal = {Intelligent Service Robotics},
number = {1},
pages = {1--29},
publisher = {Springer},
title = {{A tutorial on task-parameterized movement learning and retrieval}},
volume = {9},
year = {2016}
}
@article{knuth1979mathematical,
author = {Knuth, D},
journal = {Bulletin of the American Mathematical Society},
number = {2},
title = {{Mathematical typography}},
volume = {1},
year = {1979}
}
@article{Mueller2007,
author = {M{\"{u}}ller, Meinard},
journal = {Information retrieval for music and motion},
pages = {69--84},
publisher = {Springer},
title = {{Dynamic time warping}},
year = {2007}
}
@article{Bennequin2009,
author = {Bennequin, Daniel and Fuchs, Ronit and Berthoz, Alain and Flash, Tamar},
journal = {PLoS Comput Biol},
number = {7},
pages = {e1000426},
title = {{Movement timing and invariance arise from several geometries}},
volume = {5},
year = {2009}
}
@inproceedings{anquetil1997perceptual,
author = {Anquetil, E and Lorette, Guy},
booktitle = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
organization = {IEEE},
pages = {112--117},
title = {{Perceptual model of handwriting drawing. Application to the handwriting segmentation problem}},
volume = {1},
year = {1997}
}
@article{Walton2009Proof,
author = {Walton, D J and Meek, D S},
doi = {http://dx.doi.org/10.1016/j.cam.2007.12.022},
issn = {0377-0427},
journal = {Journal of Computational and Applied Mathematics},
number = {1},
pages = {86--96},
title = {{interpolation with a single Cornu spiral segment}},
url = {http://www.sciencedirect.com/science/article/pii/S037704270700670X},
volume = {223},
year = {2009}
}
@article{Longstaff1997,
author = {Longstaff, Mitchell G and Heath, Richard A},
journal = {Acta psychologica},
number = {2},
pages = {201--214},
publisher = {Elsevier},
title = {{Space-time invariance in adult handwriting}},
volume = {97},
year = {1997}
}
@book{strogatz2014,
author = {Strogatz, Steven H},
publisher = {Westview press},
title = {{Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering}},
year = {2014}
}
@phdthesis{mcgraw1995letter,
author = {{McGraw Jr}, G E},
school = {Indiana University},
title = {{Letter Spirit (part one): Emergent high-level perception of letters using fluid concepts}},
year = {1995}
}
@book{noordzij2005stroke,
author = {Noordzij, Gerrit},
publisher = {Hyphen},
title = {{The stroke}},
year = {2005}
}
@inproceedings{Choi2003,
author = {Choi, Hyunil and Cho, Sung-Jung and Kim, Jin H},
booktitle = {null},
organization = {IEEE},
pages = {995},
title = {{Generation of handwritten characters with Bayesian network based on-line handwriting recognizers}},
year = {2003}
}
@article{Han2008,
author = {Han, Chin-Chuan and Chou, Chih-Hsun and Wu, Chung-Shiou},
journal = {Machine Vision and Applications},
number = {1},
pages = {43--55},
publisher = {Springer},
title = {{An interactive grading and learning system for Chinese calligraphy}},
volume = {19},
year = {2008}
}
@article{schmidt1975schema,
author = {Schmidt, Richard A},
journal = {Psychological review},
number = {4},
pages = {225},
publisher = {American Psychological Association},
title = {{A schema theory of discrete motor skill learning.}},
volume = {82},
year = {1975}
}
@article{hollerbach1981oscillation,
author = {Hollerbach, John M},
journal = {Biological Cybernetics},
number = {2},
pages = {139--156},
publisher = {Springer},
title = {{An oscillation theory of handwriting}},
volume = {39},
year = {1981}
}
@book{thomas1995illusion,
author = {Thomas, Frank and Johnston, Ollie and Thomas, Frank.},
publisher = {Hyperion New York},
title = {{The illusion of life: Disney animation}},
year = {1995}
}
@book{Prusinkiewicz1990,
author = {Prusinkiewicz, Przemyslaw and Lindenmayer, Aristid},
publisher = {New York: Springer Verlag},
title = {{The algorithmic beauty of plants}},
year = {1990}
}
@article{Rohrer2003,
author = {Rohrer, Brandon and Hogan, Neville},
journal = {Biological cybernetics},
number = {3},
pages = {190--199},
publisher = {Springer},
title = {{Avoiding spurious submovement decompositions: a globally optimal algorithm}},
volume = {89},
year = {2003}
}
@article{rupasov2012neuronal,
author = {Rupasov, Valery I and Lebedev, Mikhail A and Erlichman, Joseph S and Linderman, Michael},
journal = {PloS one},
number = {4},
pages = {e34759},
publisher = {Public Library of Science},
title = {{Neuronal variability during handwriting: lognormal distribution}},
volume = {7},
year = {2012}
}
@article{Mussa-Ivaldi2004,
author = {Mussa-Ivaldi, Ferdinando and Solla, Sara and Others},
journal = {Oceanic Engineering, IEEE Journal of},
number = {3},
pages = {640--650},
publisher = {IEEE},
title = {{Neural primitives for motion control}},
volume = {29},
year = {2004}
}
@article{Alimi2003betafuzzy,
author = {Alimi, Adel M},
journal = {Group},
number = {1},
pages = {23--41},
title = {{Beta Neuro-Fuzzy Systems}},
volume = {1},
year = {2003}
}
@inproceedings{Man2010,
author = {Man, Yongkui and Others},
booktitle = {IEEE Proc. ICIS},
pages = {635--638},
title = {{A kind of calligraphy robot}},
year = {2010}
}
@article{Smyth1989,
author = {Smyth, Mary M},
journal = {Acta psychologica},
number = {3},
pages = {253--265},
publisher = {Elsevier},
title = {{Visual control of movement patterns and the grammar of action}},
volume = {70},
year = {1989}
}
@article{Edelman1987,
author = {Edelman, Shimon and Flash, Tamar},
journal = {Biological cybernetics},
number = {1-2},
pages = {25--36},
publisher = {Springer},
title = {{A model of handwriting}},
volume = {57},
year = {1987}
}
@article{viviani1985segmentation,
author = {Viviani, Paolo and Cenzato, Marco},
journal = {Journal of experimental psychology: Human perception and performance},
number = {6},
pages = {828},
publisher = {American Psychological Association},
title = {{Segmentation and coupling in complex movements.}},
volume = {11},
year = {1985}
}
@article{Bozkurt2014,
author = {Bozkurt, Alican and Duygulu, Pinar and Cetin, A Enis},
journal = {arXiv preprint arXiv:1407.2649},
title = {{Classifying Fonts and Calligraphy Styles Using Complex Wavelet Transform}},
year = {2014}
}
@article{lin2007style,
author = {Lin, Zhouchen and Wan, Liang},
journal = {Pattern Recognition},
number = {7},
pages = {2097--2109},
publisher = {Elsevier},
title = {{Style-preserving English handwriting synthesis}},
volume = {40},
year = {2007}
}
@article{Papert1971,
author = {Papert, Seymour and Solomon, Cynthia},
title = {{Twenty things to do with a computer}},
year = {1971}
}
@book{Ebert:2002:TMP:572337,
address = {San Francisco, CA, USA},
author = {Ebert, David S and Musgrave, F Kenton and Peachey, Darwyn and Perlin, Ken and Worley, Steven},
edition = {3rd},
isbn = {1558608486},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Texturing and Modeling: A Procedural Approach}},
year = {2002}
}
@inproceedings{Gao2012,
author = {Gao, Pengcheng and Wu, Jiangqin and Xia, Yang and Lin, Yuan},
booktitle = {Proceedings of the 12th ACM/IEEE-CS joint conference on Digital Libraries},
organization = {ACM},
pages = {357--358},
title = {{CADAL digital calligraphy system}},
year = {2012}
}
@article{hollerbach1982dynamic,
author = {Hollerbach, John M and Flash, Tamar},
journal = {Biological cybernetics},
number = {1},
pages = {67--77},
publisher = {Springer},
title = {{Dynamic interactions between limb segments during planar arm movement}},
volume = {44},
year = {1982}
}
@article{plamondon2003kinematic,
author = {Plamondon, R and Others},
journal = {Biological Cybernetics},
number = {2},
pages = {126--138},
title = {{A kinematic theory of rapid human movement. {\{}P{\}}art {\{}IV{\}}}},
volume = {89},
year = {2003}
}
@article{CHEN2010,
author = {CHEN, Jie and ZHU, Fu-xi},
journal = {Journal of Image and Graphics},
pages = {26},
title = {{Novel Chinese Calligraphy Style Generation Based on Curve Analogy with FSVM}},
volume = {2},
year = {2010}
}
@incollection{Ostromoukhov1998,
author = {Ostromoukhov, Victor},
booktitle = {Electronic Publishing, Artistic Imaging, and Digital Typography},
pages = {193--223},
publisher = {Springer},
title = {{Mathematical tools for computer-generated ornamental patterns}},
year = {1998}
}
@article{Mahalanobis1936,
author = {Mahalanobis, Prasanta Chandra},
journal = {Proceedings of the National Institute of Sciences (Calcutta)},
pages = {49--55},
title = {{On the generalized distance in statistics}},
volume = {2},
year = {1936}
}
@book{macdonald1966experimental,
author = {MacDonald, John Spencer},
publisher = {Citeseer},
title = {{Experimental studies of handwriting signals}},
year = {1966}
}
@inproceedings{Danna2013,
author = {Danna, J{\'{e}}r{\'{e}}my and Paz-Villagr{\'{a}}n, Vietminh and Gondre, Charles and Aramaki, Mitsuko and Kronland-Martinet, Richard and Ystad, S{\o}lvi and Velay, Jean-Luc},
booktitle = {Recent Progress in Graphonomics: Learn from the Past--Proceedings of the 16th Conference of the International Graphonomics Society},
organization = {Tokyo University of Agriculture and Technology Press Tokyo},
pages = {123--126},
title = {{Handwriting sonification for the diagnosis of dysgraphia}},
year = {2013}
}
@inproceedings{hertzmann2010non,
author = {Hertzmann, Aaron},
booktitle = {Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering},
organization = {ACM},
pages = {147--157},
title = {{Non-photorealistic rendering and the science of art}},
year = {2010}
}
@inproceedings{DeSantis2005,
author = {{De Santis}, A and Others},
booktitle = {12th Conference of the International Graphonomics Society},
title = {{Anthropic inverse kinematics of robot manipulators in handwriting tasks}},
year = {2005}
}
@inproceedings{Stallings1972,
author = {Stallings, William},
booktitle = {Proceedings of the May 16-18, 1972, spring joint computer conference},
organization = {ACM},
pages = {1015--1025},
title = {{Computer description and recognition of printed Chinese characters}},
year = {1972}
}
@article{Rabiner1989,
author = {Rabiner, Lawrence R},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
publisher = {IEEE},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
volume = {77},
year = {1989}
}
@article{morasso1981spatial,
author = {Morasso, Pietro},
journal = {Experimental Brain Research},
number = {2},
pages = {223--227},
title = {{Spatial control of arm movements}},
volume = {42},
year = {1981}
}
@article{keele1968movement,
author = {Keele, Steven W},
journal = {Psychological bulletin},
number = {6p1},
pages = {387},
publisher = {American Psychological Association},
title = {{Movement control in skilled motor performance.}},
volume = {70},
year = {1968}
}
@misc{hektor,
author = {Lehni, Jurg},
howpublished = {$\backslash$url{\{}http://hektor.ch/{\}}},
title = {{Hektor}},
year = {2004}
}
@article{Maoz2009,
author = {Maoz, Uri and Berthoz, Alain and Flash, Tamar},
journal = {Journal of neurophysiology},
number = {2},
pages = {1002--1015},
publisher = {Am Physiological Soc},
title = {{Complex unconstrained three-dimensional hand movement and constant equi-affine speed}},
volume = {101},
year = {2009}
}
@article{Kelso1982,
author = {Kelso, J A S and Saltzman, E L},
journal = {Behavioral and Brain Sciences},
number = {04},
pages = {554--557},
publisher = {Cambridge Univ Press},
title = {{Motor control: Which themes do we orchestrate?}},
volume = {5},
year = {1982}
}
@inproceedings{hofstadter1993letter,
author = {Hofstadter, D and McGraw, G and Others},
booktitle = {Center for},
title = {{Letter spirit: An emergent model of the perception and creation of alphabetic style}},
year = {1993}
}
@article{Uno1989,
author = {Uno, Yoji and Kawato, Mitsuo and Suzuki, Rika},
journal = {Biological cybernetics},
number = {2},
pages = {89--101},
publisher = {Springer},
title = {{Formation and control of optimal trajectory in human multijoint arm movement}},
volume = {61},
year = {1989}
}
@misc{tudelft3dprint,
author = {Kruit and Geraedts, Jeroen and Jo},
title = {{Freeform Manufacturing}},
url = {http://www.io.tudelft.nl/?id=80828},
year = {2013}
}
@article{djioua2010limit,
author = {Djioua, Moussa and Plamondon, R{\'{e}}jean},
doi = {http://dx.doi.org/10.1016/j.humov.2009.02.007},
issn = {0167-9457},
journal = {Human Movement Science},
number = {1},
pages = {48--61},
title = {{The limit profile of a rapid movement velocity}},
url = {http://www.sciencedirect.com/science/article/pii/S0167945709000761},
volume = {29},
year = {2010}
}
@book{shiffman2012nature,
author = {Shiffman, Daniel and Fry, Shannon and Marsh, Zannah},
chapter = {9},
publisher = {D. Shiffman},
title = {{The nature of code}},
year = {2012}
}
@article{Dooijes1983,
author = {Dooijes, Edo Hans},
journal = {Acta Psychologica},
number = {1},
pages = {99--114},
publisher = {Elsevier},
title = {{Analysis of handwriting movements}},
volume = {54},
year = {1983}
}
@article{Jack1894,
author = {Jack, William R},
journal = {Proceedings of the Royal Society of London},
number = {340-346},
pages = {477--481},
publisher = {The Royal Society},
title = {{On the Analysis of Voluntary Muscular Movements by Certain New Instruments.}},
volume = {57},
year = {1894}
}
@article{Lestienne1979,
author = {Lestienne, F},
journal = {Experimental Brain Research},
number = {3},
pages = {407--418},
publisher = {Springer},
title = {{Effects of inertial load and velocity on the braking process of voluntary limb movements}},
volume = {35},
year = {1979}
}
@inproceedings{Ramaiah2014,
author = {Ramaiah, Chetan and Plamondonm, R{\'{e}}jean and Govindaraju, Venu},
booktitle = {Pattern Recognition (ICPR), 2014 22nd International Conference on},
organization = {IEEE},
pages = {250--255},
title = {{A Sigma-Lognormal Model for Handwritten Text CAPTCHA Generation}},
year = {2014}
}
@incollection{togelius2014introduction,
author = {Togelius, Julian and Shaker, Noor and Nelson, Mark J},
booktitle = {Procedural Content Generation in Games: A Textbook and an Overview of Current Research},
editor = {Shaker, Noor and Togelius, Julian and Nelson, Mark J},
publisher = {Springer},
title = {{Introduction}},
year = {2014}
}
@inproceedings{Nair2005,
author = {Nair, Vinod and Hinton, Geoffrey E},
booktitle = {Advances in neural information processing systems},
pages = {515--522},
title = {{Inferring motor programs from images of handwritten digits}},
year = {2005}
}
@article{veroAlg2,
author = {Verostko, Roman},
title = {{The Algorists}},
url = {http://www.verostko.com/algorist.html},
year = {2012}
}
@article{Taub1968,
author = {Taub, EDWARD and Berman, A J},
journal = {The neuropsychology of spatially oriented behavior},
pages = {173--192},
publisher = {Dorsey Press Homewood, Illinois},
title = {{Movement and learning in the absence of sensory feedback}},
volume = {2},
year = {1968}
}
@inproceedings{Nguyen-Tuong2008,
author = {Nguyen-Tuong, Duy and Peters, Jan},
booktitle = {IEEE Proc. LAB-RS},
pages = {59--64},
title = {{Learning robot dynamics for computed torque control using local {\{}G{\}}aussian processes regression}},
year = {2008}
}
@article{Brassel1978,
author = {Brassel, Kurt E and Utano, Jack J},
journal = {ACM SIGGRAPH Computer Graphics},
number = {4},
pages = {67--77},
publisher = {ACM},
title = {{Font variations in vector plotter lettering}},
volume = {11},
year = {1978}
}
@article{dewinter2008perceptual,
author = {{De Winter}, Joeri and Wagemans, Johan},
journal = {Perception {\&} Psychophysics},
number = {1},
pages = {50--64},
publisher = {Springer},
title = {{Perceptual saliency of points along the contour of everyday objects: A large-scale study}},
volume = {70},
year = {2008}
}
@incollection{Mandelbrot1997,
author = {Mandelbrot, Benoit B},
booktitle = {Fractals and scaling in finance},
pages = {252--269},
publisher = {Springer},
title = {{A case against the lognormal distribution}},
year = {1997}
}
@article{djioua2008experimental,
author = {Djioua, Moussa and Mathieu, Pierre and Plamondon, R{\'{e}}jean},
publisher = {{\{}{\'{E}}{\}}cole polytechnique},
title = {{Experimental Observation of the Proportional Effect Hypothesis of the Kinematic Theory: Preliminary Report}},
year = {2008}
}
@article{Gon1962,
author = {van der Gon, J J Denier and Thuring, J Ph and Strackee, J},
journal = {Physics in medicine and Biology},
number = {6},
pages = {407--414},
title = {{A handwriting simulator.}},
year = {1962}
}
@inproceedings{Lian2012,
author = {Lian, Zhouhui and Xiao, Jianguo},
booktitle = {SIGGRAPH Asia 2012 Technical Briefs},
organization = {ACM},
pages = {2},
title = {{Automatic shape morphing for Chinese characters}},
year = {2012}
}
@article{stowers1997graffiti,
author = {Stowers, George C and Goldman, Phil},
journal = {Unpublished essay, Fall},
title = {{Graffiti art: an essay concerning the recognition of some forms of graffiti as art}},
year = {1997}
}
@incollection{sastry2005genetic,
author = {Sastry, Kumara and Goldberg, David and Kendall, Graham},
booktitle = {Search methodologies},
pages = {97--125},
publisher = {Springer},
title = {{Genetic algorithms}},
year = {2005}
}
@article{Rao1993,
author = {Rao, P},
journal = {Sadhana},
number = {1},
pages = {1--15},
publisher = {Springer},
title = {{Shape vectors: an efficient parametric representation for the synthesis and recognition of hand script characters}},
volume = {18},
year = {1993}
}
@article{fujioka2006constructing,
author = {Fujioka, Hiroyuki and Kano, Hiroyuki and Nakata, Hiroaki and Shinoda, Hayato},
journal = {Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on},
number = {4},
pages = {661--670},
publisher = {IEEE},
title = {{Constructing and reconstructing characters, words, and sentences by synthesizing writing motions}},
volume = {36},
year = {2006}
}
@article{Wright1993Handwriting,
author = {Wright, Charles E},
doi = {http://dx.doi.org/10.1016/0001-6918(93)90003-A},
issn = {0001-6918},
journal = {Acta Psychologica},
number = {1–3},
pages = {5--52},
title = {{Evaluating the special role of time in the control of handwriting}},
url = {http://www.sciencedirect.com/science/article/pii/000169189390003A},
volume = {82},
year = {1993}
}
@article{Sosnik2004,
author = {Sosnik, Ronen and Hauptmann, Bjoern and Karni, Avi and Flash, Tamar},
journal = {Experimental Brain Research},
number = {4},
pages = {422--438},
publisher = {Springer},
title = {{When practice leads to co-articulation: the evolution of geometrically defined movement primitives}},
volume = {156},
year = {2004}
}
@inproceedings{Sun2014,
author = {Sun, Yuandong and Qian, Huihuan and Xu, Yangsheng},
booktitle = {Robotics and Automation (ICRA), 2014 IEEE International Conference on},
organization = {IEEE},
pages = {3207--3212},
title = {{A geometric approach to stroke extraction for the Chinese calligraphy robot}},
year = {2014}
}
@article{zhu2008calligraphic,
author = {Zhu, Xinghua and Jin, Lianwen},
journal = {Proceedings of ICFHR2008},
pages = {135--140},
title = {{Calligraphic beautification of handwritten chinese characters: a patternized approach to handwriting transfiguration}},
year = {2008}
}
@inproceedings{Wang2009a,
author = {Wang, Liuping},
booktitle = {American Control Conference, 2009. ACC'09.},
organization = {IEEE},
pages = {25--26},
title = {{Model Predictive Control: Design and implementation using MATLAB (T-3)}},
year = {2009}
}
@incollection{Thomassen1985Time,
author = {Thomassen, ArnoldJ.W.M. and Teulings, Hans-Leo},
booktitle = {Time, Mind, and Behavior},
doi = {10.1007/978-3-642-70491-8_17},
editor = {Michon, JohnA. and Jackson, JanetL.},
isbn = {978-3-642-70493-2},
pages = {253--263},
publisher = {Springer Berlin Heidelberg},
title = {{Time, Size and Shape in Handwriting: Exploring Spatio-temporal Relationships at Different Levels}},
url = {http://dx.doi.org/10.1007/978-3-642-70491-8{\_}17},
year = {1985}
}
@article{babcock1988perception,
author = {Babcock, Mary K and Freyd, Jennifer J},
journal = {The American journal of psychology},
pages = {111--130},
publisher = {JSTOR},
title = {{Perception of dynamic information in static handwritten forms}},
year = {1988}
}
@inproceedings{djioua2008interactive,
author = {Djioua, Moussa and Plamondon, R{\'{e}}jean},
booktitle = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
organization = {IEEE},
pages = {1--4},
title = {{An interactive system for the automatic generation of huge handwriting databases from a few specimens}},
year = {2008}
}
@incollection{Lee1998,
author = {Lee, Do-Hoon and Cho, Hwan-Gue},
booktitle = {Electronic Publishing, Artistic Imaging, and Digital Typography},
pages = {252--264},
publisher = {Springer},
title = {{The beta-velocity model for simulating handwritten Korean scripts}},
year = {1998}
}
@article{lu2012helpinghand,
author = {Lu, Jingwan and Yu, Fisher and Finkelstein, Adam and DiVerdi, Stephen},
journal = {ACM Transactions on Graphics (TOG)},
number = {4},
pages = {46},
publisher = {ACM},
title = {{HelpingHand: example-based stroke stylization}},
volume = {31},
year = {2012}
}
@inproceedings{zhang2005sensor,
author = {Zhang, Kejun and Su, Jianbo},
booktitle = {Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on},
organization = {IEEE},
pages = {3570--3575},
title = {{On Sensor Management of Calligraphic Robot}},
year = {2005}
}
@inproceedings{Kemp2007,
author = {Kemp, Charles and Goodman, Noah D and Tenenbaum, Joshua B},
organization = {Cognitive Science Society},
title = {{Learning causal schemata}},
year = {2007}
}
@article{Shen2013,
author = {Shen, Wei and Bai, Xiang and Yang, XingWei and Latecki, Longin Jan},
journal = {Science China Information Sciences},
number = {4},
pages = {1--14},
publisher = {Springer},
title = {{Skeleton pruning as trade-off between skeleton simplicity and reconstruction error}},
volume = {56},
year = {2013}
}
@phdthesis{Stolcke1994,
author = {Stolcke, Andreas},
school = {University of California, Berkeley},
title = {{Bayesian learning of probabilistic language models}},
year = {1994}
}
@article{longcamp2006,
author = {Longcamp, M and Tanskanen, T and Hari, R},
issn = {10538119},
journal = {NeuroImage},
number = {2},
pages = {681--688},
pmid = {16965922},
title = {{The imprint of action: Motor cortex involvement in visual perception of handwritten letters}},
volume = {33},
year = {2006}
}
@article{Plamondon1998,
author = {Plamondon, R{\'{e}}jean and Guerfali, Wacef},
journal = {Acta psychologica},
number = {1},
pages = {85--96},
publisher = {Elsevier},
title = {{The 2/3 power law: When and why?}},
volume = {100},
year = {1998}
}
@inproceedings{Hogan1982,
author = {Hogan, Neville},
booktitle = {American Control Conference, 1982},
organization = {IEEE},
pages = {522--528},
title = {{Control and coordination of voluntary arm movements}},
year = {1982}
}
@book{varga2006off,
author = {Varga, Tam{\'{a}}s},
publisher = {Citeseer},
title = {{Off-line Cursive Handwriting recognition using synthetic training data}},
year = {2006}
}
@inproceedings{Chen2015,
author = {Chen, Hsin-I and Lin, Tse-Ju and Jian, Xiao-Feng and Shen, I and Chen, Bing-Yu and Others},
booktitle = {Computer Graphics Forum},
number = {7},
organization = {Wiley Online Library},
pages = {235--244},
title = {{Data-driven Handwriting Synthesis in a Conjoined Manner}},
volume = {34},
year = {2015}
}
@inproceedings{djioua2007analysis,
author = {Djioua, M and Plamondon, R},
booktitle = {13th Conference of the International Graphonomics Society. Melbourne, Victoria, Australia},
pages = {19--22},
title = {{Analysis and synthesis of handwriting variability using the sigma-lognormal model}},
year = {2007}
}
@article{Stetson1923,
author = {Stetson, R H and McDill, James A},
journal = {Psychological Monographs},
number = {3},
pages = {18},
publisher = {Psychological Review Company},
title = {{Mechanism of the different types of movement.}},
volume = {32},
year = {1923}
}
@inproceedings{Mashal2013,
author = {Mash'al, Mohamadreza and Sadri, Javad},
booktitle = {Pattern Recognition and Image Analysis (PRIA), 2013 First Iranian Conference on},
organization = {IEEE},
pages = {1--6},
title = {{Persian calligraphy using genetic algorithm}},
year = {2013}
}
@inproceedings{calinon2010learning,
author = {Calinon, Sylvain and Sardellitti, Irene and Caldwell, Darwin G},
booktitle = {Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on},
organization = {IEEE},
pages = {249--254},
title = {{Learning-based control strategy for safe human-robot interaction exploiting task and robot redundancies}},
year = {2010}
}
@article{Wamain2009,
author = {Wamain, Yannick and Kostrubiec, Viviane and Longcamp, Marieke and Tallet, Jessica and Zanone, Pier Giorgio},
journal = {Advances in Graphonomics: Proceedings of IGS 2009},
pages = {202--205},
title = {{Does graphic shapes perception mirror handwriting patterns production?}},
year = {2009}
}
@incollection{togelius_et_al:DFU:2013:4336,
author = {Togelius, Julian and Champandard, Alex J and Lanzi, Pier Luca and Mateas, Michael and Paiva, Ana and Preuss, Mike and Stanley, Kenneth O},
booktitle = {Artificial and Computational Intelligence in Games},
pages = {61--75},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Dagstuhl Follow-Ups},
title = {{Procedural Content Generation: Goals, Challenges and Actionable Steps}},
volume = {6},
year = {2013}
}
@inproceedings{Xie2014Portrait,
author = {Xie, Jun and Hertzmann, Aaron and Li, Wilmot and Winnem{\"{o}}ller, Holger},
booktitle = {Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
pages = {407--417},
publisher = {ACM},
title = {{PortraitSketch: Face Sketching Assistance for Novices}},
year = {2014}
}
@book{Maarse1987,
author = {Maarse, Frans J},
publisher = {Lisse [etc.]: Swets {\&} Zeitlinger},
title = {{The study of handwriting movement: Peripheral models and signal processing techniques}},
year = {1987}
}
@book{leyton2001generative,
author = {Leyton, M},
publisher = {Springer},
title = {{A generative theory of shape}},
volume = {2145},
year = {2001}
}
@inproceedings{Aguilar2008,
author = {Aguilar, Carlos and Lipson, Hod},
booktitle = {Int'l Conf. on Generative Art},
title = {{A robotic system for interpreting images into painted artwork}},
year = {2008}
}
@article{Wright1999,
author = {Wright, Stephen and Nocedal, Jorge},
journal = {Springer Science},
pages = {67--68},
title = {{Numerical optimization}},
volume = {35},
year = {1999}
}
@book{knuth1999digital,
author = {Knuth, Donald Ervin},
title = {{Digital typography}},
volume = {78}
}
@article{Barton2010,
author = {Barton, Jason J S and Sekunova, Alla and Sheldon, Claire and Johnston, Samantha and Iaria, Giuseppe and Scheel, Michael},
journal = {Neuropsychologia},
number = {13},
pages = {3868--3877},
publisher = {Elsevier},
title = {{Reading words, seeing style: the neuropsychology of word, font and handwriting perception}},
volume = {48},
year = {2010}
}
@inproceedings{Leymarie89Shape,
address = {Philadelphia, PA, U.S.A.},
author = {Leymarie, F and Levine, M D},
booktitle = {Proc. of the SPIE Conf. on Intelligent Robots and Computer Vision VIII: Algorithms and Techniques},
editor = {Casasent, D P},
month = {nov},
pages = {536--547},
publisher = {SPIE},
title = {{Shape Features Using Curvature Morphology}},
volume = {SPIE--1192},
year = {1989}
}
@inproceedings{Merrell2009,
author = {Merrell, Paul and Manocha, Dinesh},
booktitle = {2009 SIAM/ACM Joint Conference on Geometric and Physical Modeling},
organization = {ACM},
pages = {101--111},
title = {{Constraint-based model synthesis}},
year = {2009}
}
@article{Flash2007,
author = {Flash, Tamar and Handzel, Amir A},
journal = {Biological cybernetics},
number = {6},
pages = {577--601},
publisher = {Springer},
title = {{Affine differential geometry analysis of human arm movements}},
volume = {96},
year = {2007}
}
@article{todorov2002,
author = {Todorov, Emanuel and Jordan, Michael I},
journal = {Nature neuroscience},
number = {11},
pages = {1226--1235},
publisher = {Nature Publishing Group},
title = {{Optimal feedback control as a theory of motor coordination}},
volume = {5},
year = {2002}
}
@article{Thomassen1991,
author = {Thomassen, Arnold J W M and Meulenbroek, Ruud G J and Tibosch, Hein J C M},
journal = {Human Movement Science},
number = {2},
pages = {271--289},
publisher = {Elsevier},
title = {{Latencies and kinematics reflect graphic production rules}},
volume = {10},
year = {1991}
}
@article{Liberman1985,
author = {Liberman, Alvin M and Mattingly, Ignatius G},
journal = {Cognition},
number = {1},
pages = {1--36},
publisher = {Elsevier},
title = {{The motor theory of speech perception revised}},
volume = {21},
year = {1985}
}
@article{Campbell2014,
author = {Campbell, Neill D F and Kautz, Jan},
journal = {ACM Transactions on Graphics (TOG)},
number = {4},
pages = {91},
publisher = {ACM},
title = {{Learning a manifold of fonts}},
volume = {33},
year = {2014}
}
@article{Lia,
author = {Lia, Wei and Zhoua, Changle},
title = {{Data-driven Enhancement of Chinese Calligraphy Aesthetic Style}}
}
@misc{woodward1999read,
author = {Woodward, Jason Dax},
title = {{How to read graffiti}},
year = {1999}
}
@phdthesis{rehling2001letter,
author = {Rehling, J A},
school = {Indiana University},
title = {{Letter Spirit part two: Modeling Creativity in a Visual Domain}},
year = {2001}
}
@article{Hu2001,
author = {Hu, Changyuan and Hersch, Roger D},
journal = {Computer Graphics and Applications, IEEE},
number = {3},
pages = {70--85},
publisher = {IEEE},
title = {{Parameterizable fonts based on shape components}},
volume = {21},
year = {2001}
}
@inproceedings{haeberli1990paint,
author = {Haeberli, P},
booktitle = {ACM SIGGRAPH Computer Graphics},
number = {4},
organization = {ACM},
pages = {207--214},
title = {{Paint by numbers: Abstract image representations}},
volume = {24},
year = {1990}
}
@article{Xu2012,
author = {Xu, Songhua and Jiang, Hao and Lau, Francis C M and Pan, Yunhe},
journal = {IEEE intelligent systems},
number = {3},
pages = {63--72},
publisher = {IEEE},
title = {{Computationally evaluating and reproducing the beauty of chinese calligraphy}},
year = {2012}
}
@article{Wada1995,
author = {Wada, Yasuhiro and Kawato, Mitsuo},
journal = {Biological Cybernetics},
number = {1},
pages = {3--13},
publisher = {Springer},
title = {{A theory for cursive handwriting based on the minimization principle}},
volume = {73},
year = {1995}
}
@article{kherallah2008line,
author = {Kherallah, Monji and Haddad, Lobna and Alimi, Adel M and Mitiche, Amar},
journal = {Pattern Recognition Letters},
number = {5},
pages = {580--594},
publisher = {Elsevier},
title = {{On-line handwritten digit recognition based on trajectory and velocity modeling}},
volume = {29},
year = {2008}
}
@article{Jameson1996,
author = {Jameson, Kimberly A},
journal = {Acta psychologica},
number = {2},
pages = {169--208},
publisher = {Elsevier},
title = {{Numerical scaling techniques for evaluating generative models of orthographies}},
volume = {92},
year = {1996}
}
@article{Deo1995,
author = {Deo, Arati S and Walker, Ian D},
journal = {Journal of Intelligent and Robotic Systems},
number = {1},
pages = {43--68},
publisher = {Springer},
title = {{Overview of damped least-squares methods for inverse kinematics of robot manipulators}},
volume = {14},
year = {1995}
}
@inproceedings{shinoda2003generation,
author = {Shinoda, Hayato and Others},
booktitle = {IEEE Proc. SICE},
pages = {730--733},
title = {{Generation of cursive characters using minimum jerk model}},
volume = {1},
year = {2003}
}
@inproceedings{Masui1994,
author = {Masui, Sliigeliiro and Terano, Toshiro},
booktitle = {Fuzzy Systems, 1994. IEEE World Congress on Computational Intelligence., Proceedings of the Third IEEE Conference on},
organization = {IEEE},
pages = {1598--1603},
title = {{Calligraphic robot by fuzzy logic}},
year = {1994}
}
@inproceedings{djioua2006interactive,
author = {Djioua, M and O'Reilly, C and Plamondon, R},
booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
organization = {IEEE},
pages = {1124--1127},
title = {{An interactive trajectory synthesizer to study outlier patterns in handwriting recognition and signature verification}},
volume = {1},
year = {2006}
}
@inproceedings{Burns2004,
author = {Burns, Kevin},
booktitle = {Proc. AAAI Fall Symp. Style and Meaning in Language, Music, Art and Design},
pages = {7--14},
title = {{Creature double feature: on style and subject in the art of caricature}},
year = {2004}
}
@inproceedings{Jakubiak2006,
author = {Jakubiak, Elena J and Perry, Ronald N and Frisken, Sarah F},
booktitle = {Proceedings of ACM SIGGRAPH},
title = {{An improved representation for stroke-based fonts}},
volume = {4},
year = {2006}
}
@article{Zelaznik1986,
author = {Zelaznik, Howard N and Schmidt, Richard A and Gielen, Stan C A M},
journal = {Journal of Motor Behavior},
number = {4},
pages = {353--372},
publisher = {Taylor {\&} Francis},
title = {{Kinematic properties of rapid aimed hand movements}},
volume = {18},
year = {1986}
}
@inproceedings{Walton2008Euler,
author = {Walton, D J and Meek, D S},
booktitle = {Computer and Robot Vision, 2008. CRV '08. Canadian Conference on},
doi = {10.1109/CRV.2008.11},
month = {may},
pages = {237--244},
title = {{An Improved Euler Spiral Algorithm for Shape Completion}},
year = {2008}
}
@article{Goldstein1981,
author = {Goldstein, E Bruce},
journal = {Leonardo},
pages = {191--195},
publisher = {JSTOR},
title = {{The ecology of JJ Gibson's perception}},
year = {1981}
}
@article{tresset2013portrait,
author = {Tresset, Patrick and {Fol Leymarie}, Frederic},
journal = {Computers {\&} Graphics},
number = {5},
pages = {348--363},
title = {{Portrait drawing by {\{}P{\}}aul the robot}},
volume = {37},
year = {2013}
}
@article{Bullock2006,
author = {Bullock, R},
journal = {URL:{\$}{\{}{\$}www. dtcenter. org/met/users/docs/write{\_}ups/circle{\_}fit. pdf{\$}{\}}{\$}},
title = {{Least-squares circle fit}},
year = {2006}
}
@article{Zhang2004,
author = {Zhang, Dengsheng and Lu, Guojun},
journal = {Pattern recognition},
number = {1},
pages = {1--19},
publisher = {Elsevier},
title = {{Review of shape representation and description techniques}},
volume = {37},
year = {2004}
}
@article{ullman1976filling,
author = {Ullman, Shimon},
journal = {Biological Cybernetics},
number = {1},
pages = {1--6},
publisher = {Springer},
title = {{Filling-in the gaps: The shape of subjective contours and a model for their generation}},
volume = {25},
year = {1976}
}
@article{boden199818,
author = {Boden, M A},
journal = {Handbook of creativity},
pages = {351},
publisher = {Cambridge University Press},
title = {{18 Computer Models of Creativity}},
year = {1998}
}
@article{Turvey1982,
author = {Turvey, M T and Fitch, Hollis L and Tuller, Betty},
journal = {Human motor behavior: An introduction},
pages = {239--252},
publisher = {Erlbaum Hillsdale, NJ},
title = {{The Bernstein perspective: I. The problems of degrees of freedom and context-conditioned variability}},
year = {1982}
}
@article{Lai1997,
author = {Lai, Pak-Keung and Yeung, Dit-Yan and Pong, Man-Chi},
journal = {Computer Processing of Oriental Languages},
number = {3},
pages = {281--297},
title = {{A heuristic search approach to Chinese glyph generation using hierarchical character composition}},
volume = {10},
year = {1997}
}
@article{Connor2014Euler,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Connor, Dale and Krivodonova, Lilia},
doi = {10.1016/j.cam.2013.11.009},
issn = {0377-0427},
journal = {J. Comput. Appl. Math.},
month = {may},
pages = {320--332},
publisher = {Elsevier Science Publishers B. V.},
title = {{Interpolation of Two-dimensional Curves with Euler Spirals}},
url = {http://dx.doi.org/10.1016/j.cam.2013.11.009},
volume = {261},
year = {2014}
}
@inproceedings{Stava2010,
author = {{\v{S}}t'ava, O and Bene{\v{s}}, B and M{\v{e}}ch, R and Aliaga, Daniel G and Kri{\v{s}}tof, P},
booktitle = {Computer Graphics Forum},
number = {2},
organization = {Wiley Online Library},
pages = {665--674},
title = {{Inverse Procedural Modeling by Automatic Generation of L-systems}},
volume = {29},
year = {2010}
}
@inproceedings{Cheng2004,
author = {Cheng, Jian and Tong, Ruofeng and Tang, Ming and Dong, Jinxing},
booktitle = {Computer Supported Cooperative Work in Design, 2004. Proceedings. The 8th International Conference on},
organization = {IEEE},
pages = {727--732},
title = {{An approach to extract the Chinese calligraphy's approximate skeleton}},
volume = {2},
year = {2004}
}
@article{levien2009spiral,
author = {Levien, Raphael Linus},
title = {{From spiral to spline: Optimal techniques in interactive curve design}},
year = {2009}
}
@incollection{Gonczarowski1998,
author = {Gonczarowski, Jakob},
booktitle = {Electronic Publishing, Artistic Imaging, and Digital Typography},
pages = {66--76},
publisher = {Springer},
title = {{Producing the Skeleton of a Character}},
year = {1998}
}
@misc{OctetFramework,
author = {Thomason, Andy},
title = {{Octet Rendering Framework}},
url = {https://github.com/andy-thomason/octet},
year = {2015}
}
@article{Smyth1987,
author = {Smyth, Mary M and Silvers, Gil},
journal = {Acta Psychologica},
number = {1},
pages = {47--64},
publisher = {Elsevier},
title = {{Functions of vision in the control of handwriting}},
volume = {65},
year = {1987}
}
@article{Hogan1985,
author = {Hogan, Neville},
journal = {Biological cybernetics},
number = {5},
pages = {315--331},
publisher = {Springer},
title = {{The mechanics of multi-joint posture and movement control}},
volume = {52},
year = {1985}
}
@inproceedings{Prusinkiewicz1986,
author = {Prusinkiewicz, Przemyslaw},
booktitle = {Proceedings of graphics interface},
number = {1986},
pages = {247--253},
title = {{Graphical applications of L-systems}},
volume = {86},
year = {1986}
}
@article{Flash2005,
author = {Flash, Tamar and Hochner, Binyamin},
journal = {Current opinion in neurobiology},
number = {6},
pages = {660--666},
title = {{Motor primitives in vertebrates and invertebrates}},
volume = {15},
year = {2005}
}
@book{cozzi20113d,
author = {Cozzi, Patrick and Ring, Kevin},
publisher = {CRC Press},
title = {{3D engine design for virtual globes}},
year = {2011}
}
@article{Freeman2003,
author = {Freeman, William T and Tenenbaum, Joshua B and Pasztor, Egon C},
journal = {ACM Transactions on Graphics (TOG)},
number = {1},
pages = {33--46},
publisher = {ACM},
title = {{Learning style translation for the lines of a drawing}},
volume = {22},
year = {2003}
}
@inproceedings{chen1997piecewise,
author = {Chen, Hao and Agazzi, Oscar E and Suen, Ching Y},
booktitle = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
organization = {IEEE},
pages = {363--367},
title = {{Piecewise linear modulation model of handwriting}},
volume = {1},
year = {1997}
}
@book{wann1991development,
author = {Wann, John and Wing, Alan M and S{\o}vik, Nils},
publisher = {Academic Press London:},
title = {{The Development of Graphic Skills}},
year = {1991}
}
@article{kyprianidis2012state,
address = {Piscataway, NJ, USA},
author = {Kyprianidis, Jan Eric and Collomosse, John and Wang, Tinghuai and Isenberg, Tobias},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {5},
pages = {866--885},
publisher = {IEEE Educational Activities Department},
title = {{State of the "Art": A Taxonomy of Artistic Stylization Techniques for Images and Video}},
volume = {19},
year = {2013}
}
@article{Nelson1983,
author = {Nelson, Winston L},
journal = {Biological cybernetics},
number = {2},
pages = {135--147},
publisher = {Springer},
title = {{Physical principles for economies of skilled movements}},
volume = {46},
year = {1983}
}
@article{teulings1993invariant,
author = {Teulings, H-L. and Schomaker, L},
journal = {Acta psychologica},
number = {1},
pages = {69--88},
title = {{Invariant properties between stroke features in handwriting}},
volume = {82},
year = {1993}
}
@book{arnheim1974entropy,
author = {Arnheim, Rudolf},
publisher = {University of California Pr},
title = {{Entropy and art: An essay on disorder and order}},
year = {1974}
}
@misc{Liu2011,
annote = {US Patent 7,983,478},
author = {Liu, Peng and Wu, Yi-Jian and Ma, Lei and Soong, Frank Kao-PingK},
publisher = {Google Patents},
title = {{Hidden markov model based handwriting/calligraphy generation}},
year = {2011}
}
@inproceedings{Ltaief2012,
author = {Ltaief, Majda and Bezine, Hala and Alimi, Adel M},
booktitle = {Frontiers in Handwriting Recognition (ICFHR), 2012 International Conference on},
organization = {IEEE},
pages = {803--808},
title = {{A neuro-Beta-elliptic model for handwriting generation movements}},
year = {2012}
}
@article{Bartholdi2012,
author = {Bartholdi, Laurent and Henriques, Andr{\'{e}}},
journal = {The mathematical intelligencer},
pages = {1--3},
publisher = {Springer},
title = {{Orange peels and Fresnel integrals}},
year = {2012}
}
@misc{sensless,
author = {Kanno, So and Yamaguchi, Takahiro},
howpublished = {$\backslash$url{\{}kanno.so/senseless-drawing-bot/{\}}},
title = {{Sensless Drawing Bot}},
year = {2012}
}
@inproceedings{guerfali1995delta,
author = {Guerfali, Wacef and Plamondon, R{\'{e}}jean},
booktitle = {Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on},
organization = {IEEE},
pages = {495--498},
title = {{The delta lognormal theory for the generation and modeling of cursive characters}},
volume = {1},
year = {1995}
}
@article{Xu2006,
author = {Xu, Songhua and Xu, Yingqing and Kang, Sing Bing and Salesin, David H and Pan, Yunhe and Shum, Heung-Yeung},
journal = {ACM Transactions on Graphics (TOG)},
number = {2},
pages = {239--267},
publisher = {ACM},
title = {{Animating Chinese paintings through stroke-based decomposition}},
volume = {25},
year = {2006}
}
@book{Gombrich1977,
author = {Gombrich, Ernst Hans},
publisher = {Phaidon London},
title = {{Art and illusion: A study in the psychology of pictorial representation}},
volume = {5},
year = {1977}
}
@inproceedings{Zhang2013global,
author = {Zhang, Yi and Liu, Yanbin and He, Jianing and Zhang, Jiawan},
booktitle = {Multimedia and Expo (ICME), 2013 IEEE International Conference on},
organization = {IEEE},
pages = {1--6},
title = {{Recognition of calligraphy style based on global feature descriptor}},
year = {2013}
}
@article{kudoh2009painting,
author = {Kudoh, Shunsuke and Ogawara, Koichi and Ruchanurucks, Miti and Ikeuchi, Katsushi},
journal = {Robotics and Autonomous Systems},
number = {3},
pages = {279--288},
publisher = {Elsevier},
title = {{Painting robot with multi-fingered hands and stereo vision}},
volume = {57},
year = {2009}
}
@book{Rosin2013,
editor = {Rosin, Paul L and Collomosse, John P},
isbn = {978-1-4471-4518-9, 978-1-4471-4519-6},
publisher = {Springer},
title = {{Image and Video-Based Artistic Stylisation}},
year = {2013}
}
@article{Todorov2004,
author = {Todorov, Emanuel},
journal = {Nature neuroscience},
number = {9},
pages = {907--915},
publisher = {Nature Publishing Group},
title = {{Optimality principles in sensorimotor control}},
volume = {7},
year = {2004}
}
@article{plamondon1995kinematic,
author = {Plamondon, R{\'{e}}jean},
journal = {Biological cybernetics},
number = {4},
pages = {295--307},
publisher = {Springer},
title = {{A Kinematic Theory of Rapid Human Movements. Part I . Movement Representation and Generation}},
volume = {72},
year = {1995}
}
@article{Lotze2006,
author = {Lotze, Martin and Halsband, Ulrike},
journal = {Journal of Physiology-paris},
number = {4},
pages = {386--395},
publisher = {Elsevier},
title = {{Motor imagery}},
volume = {99},
year = {2006}
}
@article{Lu2009,
author = {Lu, Weiming and Zhuang, Yueting and Wu, Jiangqin},
journal = {Multimedia systems},
number = {4},
pages = {221--242},
publisher = {Springer},
title = {{Discovering calligraphy style relationships by supervised learning weighted random walk model}},
volume = {15},
year = {2009}
}
@misc{luft2007ivy,
author = {Luft, Thomas},
title = {{An ivy generator}},
year = {2007}
}
@misc{progen,
howpublished = {www.doc.gold.ac.uk/progen},
title = {{ProGen website}},
year = {2009}
}
@article{Wada1993,
author = {Wada, Yasuhiro and Kawato, Mitsuo},
journal = {Neural Networks},
number = {7},
pages = {919--932},
publisher = {Elsevier},
title = {{A neural network model for arm trajectory formation using forward and inverse dynamics models}},
volume = {6},
year = {1993}
}
@inproceedings{varga2005template,
author = {Varga, Tamas and Kilchhofer, Daniel and Bunke, Horst},
booktitle = {Proc. of 12th Conf. of the International Graphonomics Society},
pages = {206--211},
title = {{Template-based Synthetic Handwriting Generation for the Training of Recognition Systems}},
year = {2005}
}
@incollection{Bautista2013,
author = {Bautista, Miguel Angel and Hernandez-Vela, Antonio and Ponce, Victor and Perez-Sala, Xavier and Bar{\'{o}}, Xavier and Pujol, Oriol and Angulo, Cecilio and Escalera, Sergio},
booktitle = {Advances in Depth Image Analysis and Applications},
pages = {126--135},
publisher = {Springer},
title = {{Probability-based dynamic time warping for gesture recognition on RGB-D data}},
year = {2013}
}
@article{stiny1972shape,
author = {Stiny, G and Gips, J},
journal = {Information processing},
number = {1460-1465},
publisher = {Amsterdam: North Holland},
title = {{Shape grammars and the generative specification of painting and sculpture}},
volume = {71},
year = {1972}
}
@book{Hansen1999,
author = {Hansen, Per Christian},
publisher = {IMM, Department of Mathematical Modelling, Technical Universityof Denmark},
title = {{The L-curve and its use in the numerical treatment of inverse problems}},
year = {1999}
}
@article{Morasso1986,
author = {Morasso, Pietro},
journal = {Graphonomics},
pages = {137--167},
title = {{Understanding Cursive Script as a Trajectory Formation Paradigm}},
volume = {37},
year = {1986}
}
@article{todd1994evolutionary,
author = {Todd, S and Latham, W},
publisher = {Academic Press, Inc.},
title = {{Evolutionary art and computers}},
year = {1994}
}
@article{Plamondon2014,
author = {Plamondon, R and Others},
journal = {Pattern Recognition Letters},
pages = {225--235},
title = {{Recent developments in the study of rapid human movements with the kinematic theory}},
volume = {35},
year = {2014}
}
@article{Douglas1973,
author = {Douglas, David H and Peucker, Thomas K},
journal = {Cartographica: The International Journal for Geographic Information and Geovisualization},
number = {2},
pages = {112--122},
publisher = {University of Toronto Press},
title = {{Algorithms for the reduction of the number of points required to represent a digitized line or its caricature}},
volume = {10},
year = {1973}
}
@inproceedings{Li2013,
author = {Li, Honghua and Zhang, Hao and Wang, Yanzhen and Cao, Junjie and Shamir, Ariel and Cohen-Or, Daniel},
booktitle = {Computer Graphics Forum},
number = {6},
organization = {Wiley Online Library},
pages = {77--88},
title = {{Curve style analysis in a set of shapes}},
volume = {32},
year = {2013}
}
@article{Ghez1997,
author = {Ghez, C and Favilla, M and Ghilardi, M F and Gordon, J and Bermejo, R and Pullman, S},
journal = {Experimental Brain Research},
number = {2},
pages = {217--233},
publisher = {Springer},
title = {{Discrete and continuous planning of hand movements and isometric force trajectories}},
volume = {115},
year = {1997}
}
@article{Koenderink2011,
author = {Koenderink, Jan},
journal = {Gestalt Theory},
number = {3},
pages = {289},
title = {{Gestalts and pictorial worlds}},
volume = {33},
year = {2011}
}
@article{fitts1954information,
author = {Fitts, Paul M},
journal = {Journal of experimental psychology},
number = {6},
pages = {381},
publisher = {American Psychological Association},
title = {{The information capacity of the human motor system in controlling the amplitude of movement.}},
volume = {47},
year = {1954}
}
@article{Collins2005,
author = {Collins, Steve and Ruina, Andy and Tedrake, Russ and Wisse, Martijn},
journal = {Science},
number = {5712},
pages = {1082--1085},
publisher = {American Association for the Advancement of Science},
title = {{Efficient bipedal robots based on passive-dynamic walkers}},
volume = {307},
year = {2005}
}
@article{Hepp-Reymond2009,
author = {Hepp-Reymond, Marie-Claude and Chakarov, Vihren and Schulte-M{\"{o}}nting, J{\"{u}}rgen and Huethe, Frank and Kristeva, Rumyana},
journal = {Brain research bulletin},
number = {6},
pages = {365--370},
publisher = {Elsevier},
title = {{Role of proprioception and vision in handwriting}},
volume = {79},
year = {2009}
}
@article{hoffman1997,
author = {Hoffman, D D and Singh, M},
doi = {10.1016/S0010-0277(96)00791-3},
isbn = {0010-0277 (Print){\$}\backslash{\$}r0010-0277 (Linking)},
issn = {00100277},
journal = {Cognition},
number = {February 1996},
pages = {29--78},
pmid = {9187064},
title = {{Salience of visual parts.}},
volume = {63},
year = {1997}
}
@article{plamondon2009recent,
author = {Plamondon, Rejean and Djioua, Moussa and O'Reilly, Christian},
issn = {0765-0019},
journal = {Traitement Du Signal},
pages = {377--394},
title = {{Recent Developments in the Study of Rapid Human Movements with the Kinematic Theory}},
volume = {26},
year = {2009}
}
@article{Su2009,
author = {Su, Zhewen and Cao, Zhongsheng and Wang, Yuanzhen},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
number = {2},
pages = {109--121},
publisher = {Springer},
title = {{Stroke extraction based on ambiguous zone detection: a preprocessing step to recover dynamic information from handwritten Chinese characters}},
volume = {12},
year = {2009}
}
@article{Haines2016,
address = {New York, NY, USA},
author = {Haines, Tom S F and {Mac Aodha}, Oisin and Brostow, Gabriel J},
issn = {0730-0301},
journal = {ACM Trans. Graph.},
month = {may},
number = {3},
pages = {26:1----26:18},
publisher = {ACM},
title = {{My Text in Your Handwriting}},
volume = {35},
year = {2016}
}
@article{zimmer1982,
author = {Zimmer, Alf},
doi = {10.1007/BF00308448},
issn = {03400727},
journal = {Psychological Research},
number = {2},
pages = {165--174},
pmid = {7146241},
title = {{Do we see what makes our script characteristic - or do we only feel it? Modes of sensory control in handwriting}},
volume = {44},
year = {1982}
}
@article{Lun2015,
author = {Lun, Zhaoliang and Kalogerakis, Evangelos and Sheffer, Alla},
journal = {ACM Transactions on Graphics (TOG)},
number = {4},
pages = {84},
publisher = {ACM},
title = {{Elements of style: learning perceptual shape style similarity}},
volume = {34},
year = {2015}
}
@article{Basak2009,
author = {Basak, Prasanta and Others},
journal = {Computational Statistics {\&} Data Analysis},
number = {10},
pages = {3580--3592},
publisher = {Elsevier},
title = {{Estimation for the three-parameter lognormal distribution based on progressively censored data}},
volume = {53},
year = {2009}
}
@article{Plamondon1993,
author = {Plamondon, R and Others},
journal = {Biological cybernetics},
number = {2},
pages = {119--128},
title = {{Modelling velocity profiles of rapid movements: A comparative study}},
volume = {69},
year = {1993}
}
@book{freeman1914teaching,
author = {Freeman, Frank Nugent},
publisher = {Houghton, Mifflin Company},
title = {{The teaching of handwriting}},
year = {1914}
}
@inproceedings{tesseract2007overview,
author = {Smith, Ray},
booktitle = {ICDAR},
number = {1},
pages = {629--633},
title = {{An Overview of the Tesseract OCR Engine.}},
volume = {7},
year = {2007}
}
@article{Lindenmayer1968,
author = {Lindenmayer, Aristid},
journal = {Journal of theoretical biology},
number = {3},
pages = {280--299},
publisher = {Elsevier},
title = {{Mathematical models for cellular interactions in development I. Filaments with one-sided inputs}},
volume = {18},
year = {1968}
}
@article{Elarian2014,
author = {Elarian, Yousef and Abdel-Aal, Radwan and Ahmad, Irfan and Parvez, Mohammad Tanvir and Zidouri, Abdelmalek},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
number = {4},
pages = {455--469},
publisher = {Springer},
title = {{Handwriting synthesis: classifications and techniques}},
volume = {17},
year = {2014}
}
@article{Latash2010,
author = {Latash, Mark L},
journal = {Motor control},
number = {3},
pages = {294},
publisher = {NIH Public Access},
title = {{Motor synergies and the equilibrium-point hypothesis}},
volume = {14},
year = {2010}
}
@article{Kimia2003Euler,
author = {Kimia, Bb and Frankel, Ilana and Popescu, Am},
doi = {10.1023/A:1023713602895},
isbn = {0920-5691},
issn = {0920-5691},
journal = {International journal of computer vision},
pages = {159--182},
title = {{Euler spiral for shape completion}},
url = {http://link.springer.com/article/10.1023/A:1023713602895},
volume = {54},
year = {2003}
}
@inproceedings{Deussen:1998:RMR:280814.280898,
address = {New York, NY, USA},
author = {Deussen, Oliver and Hanrahan, Pat and Lintermann, Bernd and M{\v{e}}ch, Radom$\backslash$'$\backslash$ir and Pharr, Matt and Prusinkiewicz, Przemyslaw},
booktitle = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques},
doi = {10.1145/280814.280898},
isbn = {0-89791-999-8},
pages = {275--286},
publisher = {ACM},
series = {SIGGRAPH '98},
title = {{Realistic Modeling and Rendering of Plant Ecosystems}},
url = {http://doi.acm.org/10.1145/280814.280898},
year = {1998}
}
@article{mohan2011shapes,
author = {Mohan, Vishwanathan and Morasso, Pietro and Zenzeri, Jacopo and Metta, Giorgio and Chakravarthy, V Srinivasa and Sandini, Giulio},
journal = {Autonomous Robots},
number = {1},
pages = {21--53},
publisher = {Springer},
title = {{Teaching a humanoid robot to draw Shapes}},
volume = {31},
year = {2011}
}
@inproceedings{sustr2010computer,
author = {Sustr, Vil{\'{e}}m},
booktitle = {Computational Science and Its Applications (ICCSA), 2010 International Conference on},
organization = {IEEE},
pages = {103--110},
title = {{Computer Aided Calligraphy in Haptic Virtual Environment}},
year = {2010}
}
@book{boden2003creative,
author = {Boden, M},
publisher = {Routledge},
title = {{The creative mind: Myths and mechanisms}},
year = {2003}
}
@inproceedings{Stettiner1994,
author = {Stettiner, Orly and Chazan, Dan},
booktitle = {Pattern Recognition, 1994. Vol. 2-Conference B: Computer Vision {\&} Image Processing., Proceedings of the 12th IAPR International. Conference on},
organization = {IEEE},
pages = {34--38},
title = {{A statistical parametric model for recognition and synthesis of handwriting}},
volume = {2},
year = {1994}
}
@article{Yang2012,
author = {Yang, LiJie and Xu, TianChen},
doi = {10.1007/s11432-012-4740-2},
journal = {Science China Information Sciences},
month = {dec},
number = {1},
pages = {1--13},
publisher = {Springer Science {\$}\backslashmathplus{\$} Business Media},
title = {{Animating Chinese ink painting through generating reproducible brush strokes}},
url = {http://dx.doi.org/10.1007/s11432-012-4740-2},
volume = {56},
year = {2012}
}
@article{pignocchi2010,
author = {Pignocchi, Alessandro},
isbn = {1053-8100},
issn = {10538100},
journal = {Consciousness and Cognition},
number = {4},
pages = {887--898},
pmid = {20472474},
title = {{How the Intentions of the Draftsman Shape Perception of a Drawing}},
volume = {19},
year = {2010}
}
@article{Polit1978,
author = {Polit, Andres and Bizzi, Emilio},
journal = {Science},
number = {4362},
pages = {1235--1237},
publisher = {American Association for the Advancement of Science},
title = {{Processes controlling arm movements in monkeys}},
volume = {201},
year = {1978}
}
@inproceedings{eom1992Curvature,
author = {Eom, K.-B. and Park, J},
booktitle = {Pattern Recognition, 1992. Vol.II. Conference B: Pattern Recognition Methodology and Systems, Proceedings., 11th IAPR International Conference on},
month = {aug},
pages = {393--396},
title = {{Contour models for curvature estimation and shape decomposition}},
year = {1992}
}
@article{feldman2005information,
author = {Feldman, Jacob and Singh, Manish},
journal = {Psychological review},
number = {1},
pages = {243},
publisher = {American Psychological Association},
title = {{Information along contours and object boundaries.}},
volume = {112},
year = {2005}
}
@article{lacquaniti1984global,
author = {Lacquaniti, F and Terzuolo, Carlo and Viviani, Paolo},
journal = {Preparatory states and processes},
pages = {357--370},
publisher = {Erlbaum Hillsdale, NJ},
title = {{Global metric properties and preparatory processes in drawing movements}},
year = {1984}
}
@article{Newell2003,
author = {Newell, Karl M},
journal = {Research quarterly for exercise and sport},
number = {4},
pages = {383--388},
publisher = {Taylor {\&} Francis},
title = {{Schema theory (1975): Retrospectives and prospectives}},
volume = {74},
year = {2003}
}
@article{Wagemans2011,
author = {Wagemans, Johan and van Doorn, Andrea J and Koenderink, Jan J},
journal = {i-Perception},
number = {1},
pages = {77},
publisher = {Pion Publications},
title = {{Measuring 3D point configurations in pictorial space}},
volume = {2},
year = {2011}
}
@article{Meary2005,
author = {Meary, David and Chary, Catherine and Palluel-Germain, Richard and Orliaguet, Jean-Pierre},
journal = {PERCEPTION-LONDON-},
number = {9},
pages = {1061},
publisher = {Pion Ltd},
title = {{Visual perception of writing and pointing movements}},
volume = {34},
year = {2005}
}
@phdthesis{Aristizabal2012,
author = {Aristizabal, Rodrigo J},
school = {Florida International University},
title = {{Estimating the parameters of the three-parameter lognormal distribution}},
type = {{\{}FIU{\}} theses 575},
year = {2012}
}
@book{spiller1964paul,
author = {Spiller, J and KLEE, P and EYE, T H E THINKING.},
publisher = {London},
title = {{Paul Klee: the thinking eye: The notebooks of Paul Klee}},
year = {1964}
}
@inproceedings{Calinon2005,
author = {Calinon, Sylvain and Others},
booktitle = {5th IEEE-RAS Int'l Conf. on Humanoid Robots},
pages = {161--166},
title = {{A humanoid robot drawing human portraits}},
year = {2005}
}
@misc{calinonPico,
author = {Calinon, Sylvain},
howpublished = {$\backslash$url{\{}http://calinon.ch/showVideo.php?video=30{\}}},
title = {{Interaction with a robot endowed with a Kinect and pico-projector}},
year = {2013}
}
@article{DjiouaIGS2009,
author = {Djioua, Moussa and Plamondon, R{\'{e}}jean},
journal = {Advances in Graphonomics: Proceedings of IGS 2009},
pages = {221--225},
title = {{A Comparison of Some Analytical Models Describing the Velocity Profile of Rapid Movements}},
year = {2009}
}
@article{bezine2004beta,
author = {Bezine, Hala and Alimi, Adel M and Sherkat, Nasser},
isbn = {0769521878},
issn = {15505235},
journal = {Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR},
number = {2},
pages = {515--520},
title = {{Generation and analysis of handwriting script with the beta-elliptic model}},
volume = {8},
year = {2004}
}
@article{Plamondon1997,
author = {Plamondon, R{\'{e}}jean and Alimi, Adel M},
journal = {Behavioral and Brain Sciences},
number = {02},
pages = {279--303},
publisher = {Cambridge Univ Press},
title = {{Speed/accuracy trade-offs in target-directed movements}},
volume = {20},
year = {1997}
}
@article{freeman1914experimental,
author = {Freeman, Frank Nugent},
journal = {Psychological Monographs: General and Applied},
number = {4},
pages = {1--57},
publisher = {Hogrefe {\&} Huber},
title = {{Experimental analysis of the writing movement}},
volume = {17},
year = {1914}
}
@inproceedings{Fischer2014,
author = {Fischer, Anath and Plamondon, Rejean and O'Reilly, Colin and Savaria, Yvon},
booktitle = {Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
organization = {IEEE},
pages = {222--227},
title = {{Neuromuscular Representation and Synthetic Generation of Handwritten Whiteboard Notes}},
year = {2014}
}
@misc{SciPy,
annote = {[Online; accessed 2016-03-29]},
author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and Others},
title = {{{\{}SciPy{\}}: Open source scientific tools for {\{}Python{\}}}},
url = {http://www.scipy.org/}
}
@inproceedings{gips1999computer,
author = {Gips, J},
booktitle = {NSF/MIT Workshop on Shape Computation},
title = {{Computer implementation of shape grammars}},
year = {1999}
}
@inproceedings{sarkar2001style,
author = {Sarkar, Prateek and Nagy, George},
booktitle = {Document Analysis and Recognition, 2001. Proceedings. Sixth International Conference on},
organization = {IEEE},
pages = {1169--1174},
title = {{Style-consistency in isogenous patterns}},
year = {2001}
}
@article{mouraRobot2006,
author = {Moura, Leonel},
title = {{Robot Art: A New Kind of Art}},
url = {http://www.leonelmoura.com/robot.html},
year = {2007}
}
@article{Chan1995,
author = {Chan, Tan Fung and Dubey, Rajiv V},
journal = {Robotics and Automation, IEEE transactions on},
number = {2},
pages = {286--292},
publisher = {IEEE},
title = {{A weighted least-norm solution based scheme for avoiding joint limits for redundant joint manipulators}},
volume = {11},
year = {1995}
}
@article{GpuGems3SpeedTree,
author = {Kharlamov, Alexander and Cantlay, Iain and Stepanenko, Yuri},
edition = {First},
isbn = {9780321545428},
journal = {GPU Gems},
pages = {69--92},
publisher = {Addison-Wesley Professional},
title = {{Next-generation speedtree rendering}},
volume = {3},
year = {2007}
}
@incollection{Shamir1998,
author = {Shamir, Ariel and Rappoport, Ari},
booktitle = {Electronic Publishing, Artistic Imaging, and Digital Typography},
pages = {93--108},
publisher = {Springer},
title = {{Feature-based design of fonts using constraints}},
year = {1998}
}
@article{Koster1971,
author = {Koster, W G and Vredenbregt, J},
publisher = {Karger Publishers},
title = {{Analysis and synthesis of handwriting}},
year = {1971}
}
@article{Ferrer2015,
author = {Ferrer, Miguel and Diaz-Cabrera, Moises and Morales, Aythami and Others},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {3},
pages = {667--680},
publisher = {IEEE},
title = {{Static signature synthesis: A neuromotor inspired approach for biometrics}},
volume = {37},
year = {2015}
}
@article{freyd1983,
author = {Freyd, J J},
isbn = {0090-502X (Print){\$}\backslash{\$}r0090-502X (Linking)},
issn = {0090-502X},
journal = {Memory {\&} cognition},
number = {4},
pages = {342--346},
pmid = {6633251},
title = {{Representing the dynamics of a static form.}},
volume = {11},
year = {1983}
}
@article{leymarie2008infinitely,
author = {Leymarie, F F and Kimia, B B},
journal = {Medial Representations},
pages = {327--351},
publisher = {Springer},
title = {{From the Infinitely Large to the Infinitely Small}},
year = {2008}
}
@article{Burkhardt2013,
author = {Burkhardt, Richard W},
journal = {Genetics},
number = {4},
pages = {793--805},
publisher = {Genetics Soc America},
title = {{Lamarck, evolution, and the inheritance of acquired characters}},
volume = {194},
year = {2013}
}
@inproceedings{Mueller2013,
author = {Mueller, Steffen and Others},
booktitle = {IEEE Proc. IROS},
pages = {1734--1739},
title = {{Robotic Calligraphy}},
year = {2013}
}
@article{jacob2010,
author = {Kimvall, Jacob},
journal = {By courtesy of the author},
title = {{Article on Mare139}},
year = {2010}
}
@article{Bayar2009,
author = {Bayar, Abdelouahad and Sami, Khalid},
journal = {Int. Arab J. e-Technol.},
number = {1},
pages = {1--18},
title = {{How a Font Can Respect Basic Rules of Arabic Calligraphy.}},
volume = {1},
year = {2009}
}
@article{Bizzi1979,
author = {Bizzi, E and Polit, A},
journal = {Neuropsychologia},
number = {2},
pages = {203--213},
publisher = {Elsevier},
title = {{Processes controlling visually evoked movements}},
volume = {17},
year = {1979}
}
@book{Fong1992,
author = {Fong, Wen},
publisher = {Metropolitan Museum of Art},
title = {{Beyond representation: Chinese painting and calligraphy, 8th-14th century}},
volume = {48},
year = {1992}
}
@article{Meulenbroek1996,
author = {Meulenbroek, Ruud G J and Thomassen, AJWK and Rosebaum, D A and Loukopoulos, Loukia D and Vaughan, Jonathan},
journal = {Psychological Research},
number = {1},
pages = {64--74},
publisher = {Springer},
title = {{Adaptation of a reaching model to handwriting: How different effectors can produce the same written output, and other results}},
volume = {59},
year = {1996}
}
@article{Levien2008Euler,
author = {Levien, Raph},
journal = {Opera},
pages = {1--14},
title = {{The Euler spiral: a mathematical history}},
url = {http://raph.levien.com/phd/euler{\_}hist.pdf},
year = {2008}
}
@article{Garces2014,
author = {Garces, Elena and Agarwala, Aseem and Gutierrez, Diego and Hertzmann, Aaron},
journal = {ACM Transactions on Graphics (TOG)},
number = {4},
pages = {93},
publisher = {ACM},
title = {{A similarity measure for illustration style}},
volume = {33},
year = {2014}
}
@article{Mussa-Ivaldi1999,
author = {Mussa-Ivaldi, Ferdinando A and Gantchev, N and Gantchev, G},
journal = {From Basic Motor Control to Functional Recovery. Academic Publishing House" Prof. M. Drinov", Sofia, Bulgaria},
pages = {392--398},
publisher = {Citeseer},
title = {{Motor primitives, force-fields and the equilibrium point theory}},
year = {1999}
}
@inproceedings{de2004saliency,
author = {{De Stefano}, Claudio and Garruto, Marco and Marcelli, Angelo},
booktitle = {Frontiers in Handwriting Recognition, 2004. IWFHR-9 2004. Ninth International Workshop on},
organization = {IEEE},
pages = {124--129},
title = {{A saliency-based multiscale method for on-line cursive handwriting shape description}},
year = {2004}
}
@article{plamondon1998generation,
author = {Plamondon, R{\'{e}}jean and Guerfali, Wacef},
journal = {Biological Cybernetics},
number = {2},
pages = {119--132},
publisher = {Springer},
title = {{The generation of handwriting with delta-lognormal synergies}},
volume = {78},
year = {1998}
}
@misc{wikiasemic2016,
author = {Wikipedia},
booktitle = {Wikipedia, The Free Encyclopedia},
title = {{Asemic writing - Wikipedia, The Free Encyclopedia}},
url = {https://en.wikipedia.org/w/index.php?title=Asemic{\_}writing{\&}oldid=744873186},
year = {2016}
}
@inproceedings{Nake2005,
author = {Nake, Frieder},
booktitle = {Proceedings of the 5th conference on Creativity {\&} cognition},
organization = {ACM},
pages = {54--62},
title = {{Computer art: a personal recollection}},
year = {2005}
}
@article{Dietterich2000,
abstract = {Ensemble methods are learning algorithms that construct a set of classiiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian aver-aging, but more recent algorithms include error-correcting output coding, Bagging, and boosting. This paper reviews these methods and explains why ensembles can often perform better than any single classiier. Some previous studies comparing ensemble methods are reviewed, and some new experiments are presented to uncover the reasons that Adaboost does not overrt rapidly.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dietterich, Thomas G},
doi = {10.1007/3-540-45014-9_1},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Dietterich - 2000 - Ensemble Methods in Machine Learning.pdf:pdf},
isbn = {3-540-67704-6},
issn = {03029743},
journal = {MCS '00: Proceedings of the First International Workshop on Multiple Classifier Systems},
pages = {1--15},
pmid = {25246403},
title = {{Ensemble Methods in Machine Learning}},
url = {http://www.cs.orst.edu/{~}tgd},
year = {2000}
}
@article{Langmann2012,
author = {Langmann, Benjamin and Hartmann, Klaus and Loffeld, Otmar},
doi = {10.5220/0003778304380444},
file = {:home/memo/Mendeley/data/Langmann, Hartmann, Loffeld - 2012 - Depth Camera Technology Comparison and Performance Evaluation.pdf:pdf},
isbn = {0003778304},
pages = {438--444},
title = {{Depth Camera Technology Comparison and Performance Evaluation}},
year = {2012}
}
@article{Bird,
author = {Bird, Sarah and Barocas, Solon and Diaz, Fernando and Crawford, Kate and Wallach, Hanna},
file = {:home/memo/Mendeley/data/Bird et al. - Unknown - Exploring or Exploiting Social and Ethical Implications of Autonomous Experimentation in AI.pdf:pdf},
title = {{Exploring or Exploiting ? Social and Ethical Implications of Autonomous Experimentation in AI}}
}
@article{Barad2012,
author = {Barad, Karen},
file = {:home/memo/Mendeley/data/Barad - 2012 - Intra-active Entanglements.pdf:pdf},
journal = {Kvinder, K{\o}n og Forskning/Women, Gender and Research},
number = {1},
pages = {10--23},
title = {{Intra-active Entanglements}},
volume = {1-2},
year = {2012}
}
@article{Barad2003,
abstract = {Fundet gennem Lykke artikel, kan m{\aa}ske bruges i positioning teori afsnit?},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Barad, Karen},
doi = {10.1086/345321},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Barad - 2003 - Posthumanist Performativity Toward an Understanding of How Matter Comes to Matter.pdf:pdf},
isbn = {00979740},
issn = {0097-9740},
journal = {Signs: Journal of Women in Culture and Society},
number = {3},
pages = {801--831},
pmid = {25246403},
title = {{Posthumanist Performativity: Toward an Understanding of How Matter Comes to Matter}},
volume = {28},
year = {2003}
}
@article{Kleinman2013,
author = {Kleinman, Adam},
file = {:home/memo/Mendeley/data/Kleinman - 2013 - Intra-actions.pdf:pdf},
journal = {Mousse},
number = {34},
pages = {76--81},
title = {{Intra-actions}},
year = {2013}
}
@article{Clifford2009,
author = {Clifford, Colin W G},
doi = {10.1016/j.cub.2009.09.006},
file = {:home/memo/Mendeley/data/Clifford - 2009 - Binocular rivalry.pdf:pdf},
isbn = {1879-0445 (Electronic)$\backslash$r0960-9822 (Linking)},
issn = {1879-0445},
journal = {Current biology : CB},
number = {22},
pages = {R1022--R1023},
pmid = {19948135},
title = {{Binocular rivalry.}},
volume = {19},
year = {2009}
}
@article{Tong2006,
abstract = {During binocular rivalry, conflicting monocular images compete for access to consciousness in a stochastic, dynamical fashion. Recent human neuroimaging and psychophysical studies suggest that rivalry entails competitive interactions at multiple neural sites, including sites that retain eye-selective information. Rivalry greatly suppresses activity in the ventral pathway and attenuates visual adaptation to form and motion; nonetheless, some information about the suppressed stimulus reaches higher brain areas. Although rivalry depends on low-level inhibitory interactions, high-level excitatory influences promoting perceptual grouping and selective attention can extend the local dominance of a stimulus over space and time. Inhibitory and excitatory circuits considered within a hybrid model might account for the paradoxical properties of binocular rivalry and provide insights into the neural bases of visual awareness itself. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Tong, Frank and Meng, Ming and Blake, Randolph},
doi = {10.1016/j.tics.2006.09.003},
file = {:home/memo/Mendeley/data/Tong, Meng, Blake - 2006 - Neural bases of binocular rivalry.pdf:pdf},
isbn = {1364-6613 (Print)$\backslash$n1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {11},
pages = {502--511},
pmid = {16997612},
title = {{Neural bases of binocular rivalry}},
volume = {10},
year = {2006}
}
@article{Datta2015,
abstract = {To partly address people's concerns over web tracking, Google has created the Ad Settings webpage to provide information about and some choice over the profiles Google creates on users. We present AdFisher, an automated tool that explores how user behaviors, Google's ads, and Ad Settings interact. AdFisher can run browser-based experiments and analyze data using machine learning and significance tests. Our tool uses a rigorous experimental design and statistical analysis to ensure the statistical soundness of our results. We use AdFisher to find that the Ad Settings was opaque about some features of a user's profile, that it does provide some choice on ads, and that these choices can lead to seemingly discriminatory ads. In particular, we found that visiting webpages associated with substance abuse changed the ads shown but not the settings page. We also found that setting the gender to female resulted in getting fewer instances of an ad related to high paying jobs than setting it to male. We cannot determine who caused these findings due to our limited visibility into the ad ecosystem, which includes Google, advertisers, websites, and users. Nevertheless, these results can form the starting point for deeper investigations by either the companies themselves or by regulatory bodies.},
archivePrefix = {arXiv},
arxivId = {1408.6491},
author = {Datta, Amit and Tschantz, Michael Carl and Datta, Anupam},
doi = {10.1515/popets-2015-0007},
eprint = {1408.6491},
file = {:home/memo/Mendeley/data/Datta, Tschantz, Datta - 2015 - Automated experiments on ad privacy settings A tale of opacity, choice, and discrimination.pdf:pdf},
issn = {2299-0984},
journal = {Proceedings on Privacy Enhancing Technologies},
keywords = {behav-ioral advertising,blackbox analysis,choice,discrimination,information flow,transparency},
number = {1},
pages = {92--112},
title = {{Automated experiments on ad privacy settings: A tale of opacity, choice, and discrimination}},
url = {http://www.degruyter.com/downloadpdf/j/popets.2015.1.issue-1/popets-2015-0007/popets-2015-0007.xml},
volume = {2015},
year = {2015}
}
@article{Cherla2016,
author = {Cherla, Srikanth},
file = {:home/memo/Mendeley/data/Cherla - 2016 - Neural Probabilistic Models for Melody Prediction , Sequence Labelling and Classification.pdf:pdf},
title = {{Neural Probabilistic Models for Melody Prediction , Sequence Labelling and Classification}},
year = {2016}
}
@article{Pistono2016,
abstract = {Cybersecurity research involves publishing papers about malicious exploits as much as publishing information on how to design tools to protect cyber-infrastructure. It is this information exchange between ethical hackers and security experts, which results in a well-balanced cyber-ecosystem. In the blooming domain of AI Safety Engineering, hundreds of papers have been published on different proposals geared at the creation of a safe machine, yet nothing, to our knowledge, has been published on how to design a malevolent machine. Availability of such information would be of great value particularly to computer scientists, mathematicians, and others who have an interest in AI safety, and who are attempting to avoid the spontaneous emergence or the deliberate creation of a dangerous AI, which can negatively affect human activities and in the worst case cause the complete obliteration of the human species. This paper provides some general guidelines for the creation of a Malevolent Artificial Intelligence (MAI).},
archivePrefix = {arXiv},
arxivId = {1605.02817},
author = {Pistono, Federico and Yampolskiy, Roman V},
eprint = {1605.02817},
file = {:home/memo/Mendeley/data/Pistono, Yampolskiy - 2016 - Unethical Research How to Create a Malevolent Artificial Intelligence.pdf:pdf},
title = {{Unethical Research: How to Create a Malevolent Artificial Intelligence}},
url = {http://arxiv.org/abs/1605.02817},
year = {2016}
}
@article{Steele2005,
abstract = {Abstract. Over the last fifty years, How to Lie with Statistics has sold more$\backslash$ncopies than any other statistical text. This note explores the factors that contributed$\backslash$nto its success and provides biographical sketches of its creators: author$\backslash$nDarrell Huff and illustrator Irving Geis.$\backslash$nKey words and phrases: Darrell Huff, Irving Geis, How to Lie with Statistics,$\backslash$nnumeracy, graphs, crescent cow.},
author = {Steele, J. Michael},
doi = {10.1214/088342305000000205},
file = {:home/memo/Mendeley/data/Steele - 2005 - Darrell Huff and Fifty Years of How to Lie with Statistics.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {1,and phrases,crescent cow,darrell huff,graphs,homes and gardens editor,how to lie with,in 1954 former better,irving geis,numeracy,statis-,tics,touching a million lives},
number = {3},
pages = {205--209},
title = {{Darrell Huff and Fifty Years of How to Lie with Statistics}},
volume = {20},
year = {2005}
}
@article{Clark1998,
abstract = {Where does the mind stop and the rest of the world begin? The question invites two standard replies. Some accept the demarcations of skin and skull, and say that what is outside the body is outside the mind. Others are impressed by arguments suggesting that the meaning of our words "just ain't in the head", and hold that this externalism about meaning carries over into anexternalism about mind. We propose to pursue a third position. We advocate a very different sort of externalism: an active externalism, based on the active role of the environment in driving cognitive processes.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Clark, Andy and Chalmers, David},
doi = {10.1111/j.1467-9744.2009.01021.x},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Clark, Chalmers - 1998 - The Extended Mind.pdf:pdf},
isbn = {9780262014038},
issn = {05912385},
journal = {Analysis},
keywords = {Environment,Extended mind,Functionalism,Markof the cognitive},
number = {1},
pages = {7--19},
pmid = {20499217},
publisher = {JSTOR},
title = {{The Extended Mind}},
volume = {58},
year = {1998}
}
@article{Harnad1990,
author = {Harnad, Stevan},
file = {:home/memo/Mendeley/data/Harnad - 1990 - The symbol grounding problem.pdf:pdf},
keywords = {1,1 from behaviorism to,category learning,cognitive models,cognitivism,connectionism,for many years the,its only explanatory tools,modeling the mind,neural models,only empirical approach in,psychology was behaviorism,symbol systems},
pages = {335--346},
title = {{The symbol grounding problem}},
volume = {42},
year = {1990}
}
@article{Taddeo2005,
abstract = {This article reviews eight proposed strategies for solving the Symbol Grounding Problem (SGP), which was given its classic formulation in Harnad (1990). After a concise introduction, we provide an analysis of the requirement that must be satisfied by any hypothesis seeking to solve the SGP, the zero semantical commitment condition. We then use it to assess the eight strategies, which are organised into three main approaches: representationalism, semi-representationalism and non- representationalism. The conclusion is that all the strategies are semantically committed and hence that none of them provides a valid solution to the SGP, which remains an open problem.},
author = {Taddeo, Mariarosaria and Floridi, Luciano},
doi = {10.1080/09528130500284053},
file = {:home/memo/Mendeley/data/Taddeo, Floridi - 2005 - Solving the Symbol Grounding Problem a Critical Review of Fifteen Years of Research.pdf:pdf},
isbn = {0952-813X},
issn = {0952-813X},
journal = {Artificial Intelligence},
keywords = {artificial agent,representationalism,semantical commitment,semantics,symbol grounding problem},
pages = {1--40},
title = {{Solving the Symbol Grounding Problem: a Critical Review of Fifteen Years of Research}},
year = {2005}
}
@article{Steels2008,
abstract = {In the nineteen eighties, a lot of ink was spent on the question of$\backslash$nsymbol grounding, largely triggered by Searle�s Chinese Room story.$\backslash$nSearle�s article had the advantage of stirring up discussion about$\backslash$nwhen and how symbols could be about things in the world, whether$\backslash$nintelligence involves representa- tions or not, what embodiment means$\backslash$nand under what conditions cognition is embodied, etc. But almost$\backslash$ntwenty years of philosophical discussion have shed little light on$\backslash$nthe issue, partly because the discussion has been mixed up with arguments$\backslash$nwhether artificial intelligence was possible or not. Today I believe$\backslash$nthat sufficient progress has been made in cognitive science and AI$\backslash$nthat we can move forward and study the processes involved in representations$\backslash$ninstead of worrying about the general framework with which this should$\backslash$nbe done.},
author = {Steels, Luc},
file = {:home/memo/Mendeley/data/Steels - 2012 - The symbol grounding problem has been solved, so what's next.pdf:pdf},
journal = {Symbols and Embodiment: Debates on Meaning and Cognition},
keywords = {Color guessing game,Embodiment,Language emergence,Meanings,Symbol grounding problem,Symbols},
pages = {223--244},
publisher = {Oxford University Press Oxford},
title = {{The symbol grounding problem has been solved, so what's next?}},
year = {2008}
}
@book{Christl,
author = {Christl, Wolfie and Spiekermann, Sarah},
file = {:home/memo/Mendeley/data/Christl, Spiekermann - Unknown - Wolfie Christl, Sarah Spiekermann Networks of Control.pdf:pdf},
isbn = {9783708914732},
title = {{Wolfie Christl, Sarah Spiekermann Networks of Control}}
}
@article{Fodor1920,
author = {Fodor, Jerry A},
file = {:home/memo/Mendeley/data/Fodor - 1920 - The mind body problem.pdf:pdf},
journal = {Scientific American},
keywords = {converted},
pages = {114--123},
title = {{The mind body problem}},
year = {1920}
}
@article{Rumelhart1986,
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vecotr of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units wich are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpoler methods such as the perceptron-convergence procedure.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
doi = {10.1038/323533a0},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Rumelhart, Hinton, Williams - 1986 - Learning representations by back-propagating errors.pdf:pdf},
isbn = {0262661160},
issn = {0028-0836},
journal = {Nature},
number = {6088},
pages = {533--536},
pmid = {134},
title = {{Learning representations by back-propagating errors}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=FJblV{\_}iOPjIC{\&}oi=fnd{\&}pg=PA213{\&}dq=Learning+representations+by+back-propagating+errors{\&}ots=zZDj2mGYVQ{\&}sig=mcyEACaE{\_}ZB4FB4xsoTgXgcbE2g{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=FJblV{\_}iOPjIC{\&}oi=fnd{\&}pg=PA213{\&}dq=Lea},
volume = {323},
year = {1986}
}
@article{Yuille2006,
author = {Yuille, Alan and Kersten, Daniel},
file = {:home/memo/Mendeley/data/Yuille, Kersten - 2006 - Vision as Bayesian Inference Analysis by Synthesis Introduction Perception as inference.pdf:pdf},
journal = {Trends in cognitive sciences},
number = {7},
pages = {301--308},
title = {{Vision as Bayesian Inference : Analysis by Synthesis ? Introduction : Perception as inference}},
volume = {10},
year = {2006}
}
@article{Clifford2007,
abstract = {The term visual adaptation describes the processes by which the visual system alters its operating properties in response to changes in the environment. These continual adjustments in sensory processing are diagnostic as to the computational principles underlying the neural coding of information and can have profound consequences for our perceptual experience. New physiological and psychophysical data, along with emerging statistical and computational models, make this an opportune time to bring together experimental and theoretical perspectives. Here, we discuss functional ideas about adaptation in the light of recent data and identify exciting directions for future research. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Clifford, Colin W G and Webster, Michael A. and Stanley, Garrett B. and Stocker, Alan A. and Kohn, Adam and Sharpee, Tatyana O. and Schwartz, Odelia},
doi = {10.1016/j.visres.2007.08.023},
file = {:home/memo/Mendeley/data/Clifford et al. - 2007 - Visual adaptation Neural, psychological and computational aspects.pdf:pdf},
isbn = {0042-6989 (Print)$\backslash$r0042-6989 (Linking)},
issn = {00426989},
journal = {Vision Research},
keywords = {Information processing,Perception,Physiology,Psychophysics,Sensory coding,Theoretical neuroscience},
number = {25},
pages = {3125--3131},
pmid = {17936871},
title = {{Visual adaptation: Neural, psychological and computational aspects}},
volume = {47},
year = {2007}
}
@article{Dayan1995,
abstract = {Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.},
author = {Dayan, P and Hinton, G.E. E and Neal, R.M. M and Zemel, R.S. S},
doi = {10.1162/neco.1995.7.5.889},
file = {:home/memo/Mendeley/data/Dayan et al. - 1995 - The helmholtz machine.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Automated,Feedback,Humans,Models,Pattern Recognition,Perception,Perception: physiology,Psychological,Stochastic Processes,Visual},
number = {5},
pages = {889--904},
pmid = {7584891},
title = {{The helmholtz machine}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7584891{\%}5Cnhttp://www.mitpressjournals.org/doi/pdf/10.1162/neco.1995.7.5.889},
volume = {7},
year = {1995}
}
@article{Linsker1989,
author = {Linsker, Ralph},
file = {:home/memo/Mendeley/data/Linsker - 1989 - An application of the principle of maximum information preservation to linear systems.pdf:pdf},
isbn = {1-558-60015-9},
journal = {Advances in neural information processing systems},
number = {L},
pages = {186--194},
title = {{An application of the principle of maximum information preservation to linear systems}},
url = {http://papers.nips.cc/paper/102-an-application-of-the-principle-of-maximum-information-preservation-to-linear-systems},
year = {1989}
}
@article{Huang2011,
abstract = {Predictive coding is a unifying framework for understanding redundancy reduction and efficient coding in the nervous system. By transmitting only the unpredicted portions of an incoming sensory signal, predictive coding allows the nervous system to reduce redundancy and make full use of the limited dynamic range of neurons. Starting with the hypothesis of efficient coding as a design principle in the sensory system, predictive coding provides a functional explanation for a range of neural responses and many aspects of brain organization. The lateral and temporal antagonism in receptive fields in the retina and lateral geniculate nucleus occur naturally as a consequence of predictive coding of natural images. In the higher visual system, predictive coding provides an explanation for oriented receptive fields and contextual effects as well as the hierarchical reciprocally connected organization of the cortex. Predictive coding has also been found to be consistent with a variety of neurophysiological and psychophysical data obtained from different areas of the brain.},
author = {Huang, Yanping and Rao, Rajesh P N},
doi = {10.1002/wcs.142},
file = {:home/memo/Mendeley/data/Huang, Rao - 2011 - Predictive coding.pdf:pdf},
isbn = {19395078},
issn = {19395078},
journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
number = {5},
pages = {580--593},
pmid = {1000185202},
title = {{Predictive coding}},
volume = {2},
year = {2011}
}
@article{Seth2013,
abstract = {The concept of the brain as a prediction machine has enjoyed a resurgence in the context of the Bayesian brain and predictive coding approaches within cognitive science. To date, this perspective has been applied primarily to exteroceptive perception (e.g., vision, audition), and action. Here, I describe a predictive, inferential perspective on interoception: 'interoceptive inference' conceives of subjective feeling states (emotions) as arising from actively-inferred generative (predictive) models of the causes of interoceptive afferents. The model generalizes 'appraisal' theories that view emotions as emerging from cognitive evaluations of physiological changes, and it sheds new light on the neurocognitive mechanisms that underlie the experience of body ownership and conscious selfhood in health and in neuropsychiatric illness. {\textcopyright} 2013 Elsevier Ltd.},
author = {Seth, Anil K.},
doi = {10.1016/j.tics.2013.09.007},
file = {:home/memo/Mendeley/data/Seth - 2013 - Interoceptive inference, emotion, and the embodied self.pdf:pdf},
isbn = {1879-307X (Electronic)$\backslash$n1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {Active inference,Emotion,Experience of body ownership,Interoception,Predictive coding,Rubber hand illusion},
number = {11},
pages = {565--573},
pmid = {24126130},
publisher = {Elsevier Ltd},
title = {{Interoceptive inference, emotion, and the embodied self}},
url = {http://dx.doi.org/10.1016/j.tics.2013.09.007},
volume = {17},
year = {2013}
}
@article{Edelman2007,
author = {Edelman, Shimon},
file = {:home/memo/Mendeley/data/Edelman - 2007 - Computing the Mind.pdf:pdf},
isbn = {987-0-19-532067-1},
number = {August},
pages = {1--85},
title = {{Computing the Mind}},
year = {2007}
}
@book{Chemero2009,
abstract = {While philosophers of mind have been arguing over the status of mental representations in cognitive science, cognitive scientists have been quietly engaged in studying perception, action, and cognition without explaining them in terms of mental representation. In this book, Anthony Chemero describes this nonrepresentational approach (which he terms radical embodied cognitive science), puts it in historical and conceptual context, and applies it to traditional problems in the philosophy of mind. Radical embodied cognitive science is a direct descendant of the American naturalist psychology of William James and John Dewey, and follows them in viewing perception and cognition to be understandable only in terms of action in the environment. Chemero argues that cognition should be described in terms of agent-environment dynamics rather than in terms of computation and representation. After outlining this orientation to cognition, Chemero proposes a methodology: dynamical systems theory, which would explain things dynamically and without reference to representation. He also advances a background theory: Gibsonian ecological psychology, "shored up" and clarified. Chemero then looks at some traditional philosophical problems (reductionism, epistemological skepticism, metaphysical realism, consciousness) through the lens of radical embodied cognitive science and concludes that the comparative ease with which it resolves these problems, combined with its empirical promise, makes this approach to cognitive science a rewarding one. "Jerry Fodor is my favorite philosopher," Chemero writes in his preface, adding, "I think that Jerry Fodor is wrong about nearly everything." With this book, Chemero explains nonrepresentational, dynamical, ecological cognitive science as clearly and as rigorously as Jerry Fodor explained computational cognitive science in his classic work The Language of Thought.},
author = {Chemero, Anthony},
booktitle = {Cognitive Science},
doi = {10.1016/B978-012601730-4/50004-4},
file = {:home/memo/Mendeley/data/Chemero - 2009 - Radical Embodied Cognitive Science.pdf:pdf},
isbn = {9780126017304},
issn = {2153-599X},
pages = {272},
pmid = {21136224},
title = {{Radical Embodied Cognitive Science}},
url = {http://www.sciencedirect.com/science/article/pii/B9780126017304500044},
year = {2009}
}
@article{,
file = {:home/memo/Mendeley/data/Unknown - 1989 - Is the universe computable.pdf:pdf},
journal = {The Economist},
title = {{Is the universe computable}},
year = {1989}
}
@article{Journal2016,
author = {van Gelder, Tim},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Journal - 2016 - What Might Cognition Be , If Not Computation Author ( s ) Tim Van Gelder Published by Journal of Philosophy , Inc . S.pdf:pdf},
journal = {The Journal of Philosophy},
number = {7},
pages = {345--381},
title = {{What Might Cognition Be , If Not Computation?}},
volume = {92},
year = {1995}
}
@article{Clark2013,
abstract = {Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this “hierarchical prediction machine” approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency},
archivePrefix = {arXiv},
arxivId = {0140-525X},
author = {Clark, Andy},
doi = {10.1017/S0140525X12000477},
eprint = {0140-525X},
file = {:home/memo/Mendeley/data/Clark - 2013 - Whatever next Predictive brains, situated agents, and the future of cognitive science.pdf:pdf},
isbn = {1469-1825 (Electronic)$\backslash$r0140-525X (Linking)},
issn = {1469-1825},
journal = {Behavioral and Brain Sciences (2013) 36, 181–253},
keywords = {1,action,attention,bayesian brain,expectation,from helmholtz to action-oriented,generative model,hierarchy,introduction,perception,precision,prediction,prediction error,prediction machines,predictive,predictive coding,top-down processing},
pages = {181--253},
pmid = {23663408},
title = {{Whatever next? Predictive brains, situated agents, and the future of cognitive science}},
year = {2013}
}
@article{Unknown2011,
author = {Unknown},
file = {:home/memo/Mendeley/data/Unknown - 2011 - Review of Shapiro EC 2011.pdf:pdf},
journal = {Unknown},
number = {2},
pages = {267--273},
title = {{Review of Shapiro EC 2011}},
volume = {8},
year = {2011}
}
@article{Wilson2002,
abstract = {The emerging viewpoint of embodied cognition holds that cognitive processes are deeply rooted in the body's interactions with the world. This position actually houses a number of distinct claims, some of which are more controversial than others. This paper distinguishes and evaluates the following six claims: (1) cognition is situated; (2) cognition is time-pressured; (3) we off-load cognitive work onto the environment; (4) the environment is part of the cognitive system; (5) cognition is for action; (6) off-line cognition is body based. Of these, the first three and the fifth appear to be at least partially true, and their usefulness is best evaluated in terms of the range of their applicability. The fourth claim, I argue, is deeply problematic. The sixth claim has received the least attention in the literature on embodied cognition, but it may in fact be the best documented and most powerful of the six claims.},
author = {Wilson, Margaret},
doi = {10.3758/BF03196322},
file = {:home/memo/Mendeley/data/Wilson - 2002 - Six views of embodied cognition.pdf:pdf},
isbn = {1069-9384 (Print)$\backslash$n1069-9384 (Linking)},
issn = {1069-9384},
journal = {Psychonomic bulletin {\&} review},
number = {4},
pages = {625--636},
pmid = {12613670},
title = {{Six views of embodied cognition.}},
url = {papers3://publication/uuid/874080EC-0FF9-47FF-9EBC-A60047C9781B},
volume = {9},
year = {2002}
}
@book{Brooks1999,
author = {Brooks, Rodney A.},
file = {:home/memo/Mendeley/data/Brooks - 1999 - Cambrian Intelligence The Early History of the New AI.pdf:pdf},
isbn = {0262024683},
keywords = {ISBN: 0262522632},
publisher = {MIT press Cambridge, MA},
title = {{Cambrian Intelligence: The Early History of the New AI}},
year = {1999}
}
@article{Brooks1990,
abstract = {There is an alternative route to Artificial Intelligence that diverges from the directions pursued under that banner for the last thirty some years. The traditional approach has emphasized the abstract manipulation of symbols, whose grounding, in physical reality has . rarely been achieved. We explore a research methodology which emphasizes ongoing physical interaction with the environment as the primary source of constraint on the design of intelligent systems. We show how this methodology has recently had significant successes on a par with the most successful classical efforts. We outline plausible future work along these lines which can lead to vastly more ambitious systems},
author = {Brooks, Rodney a},
doi = {10.1016/S0921-8890(05)80025-9},
file = {:home/memo/Mendeley/data/Brooks - 1990 - Elephants Don ' t Play Chess.pdf:pdf},
isbn = {0780372689},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {a ph,adelaide,and faculty positions at,and the,artificial intelligence,associate professor of electrical,at carnegie mellon university,australia,brooks was born in,d,from stanford in computer,he is currently an,he studied mathematics at,held research associate positions,i,massachusetts institute of technology,mobile robots,planning,rodney a,science in 1981,since then he has,situated activity,south australia and received,stanford and m,subsumption architecture,t,the flinders university of},
pages = {3--15},
title = {{Elephants Don ' t Play Chess}},
volume = {6},
year = {1990}
}
@article{Friedman2002,
author = {Friedman, Andy},
file = {:home/memo/Mendeley/data/Friedman - 2002 - The fundamental distinction between brains and turing machines.pdf:pdf},
journal = {Berkeley Scientific},
number = {1},
pages = {28--33},
title = {{The fundamental distinction between brains and turing machines}},
volume = {6},
year = {2002}
}
@article{Brooks1991,
abstract = {Artificial intelligence research has foundered on the issue of representation. When intelligence is approached in an incremental manner, with strict reliance on interfacing to the real world through perception and action, reliance on representation disappears. In this paper we outline our approach to incrementally building complete intelligent Creatures. The fundamental decomposition of the intelligent system is not into independent information processing units which must interface with each other via representations. Instead, the intelligent system is decomposed into independent and parallel activity producers which all interface directly to the world through perception and action, rather than interface to each other particularly much. The notions of central and peripheral systems evaporate-everything is both central and peripheral. Based on these principles we have built a very successful series of mobile robots which operate without supervision as Creatures in standard office environments. ?? 1991.},
author = {Brooks, Rodney A.},
doi = {10.1016/0004-3702(91)90053-M},
file = {:home/memo/Mendeley/data/Brooks - 1991 - Intelligence without representation.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
number = {1-3},
pages = {139--159},
pmid = {14599324},
title = {{Intelligence without representation}},
volume = {47},
year = {1991}
}
@article{caruana2015intelligible,
abstract = {In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.},
author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
doi = {10.1145/2783258.2788613},
file = {:home/memo/Mendeley/data/Caruana et al. - 2015 - Intelligible models for healthcare Predicting pneumonia risk and hospital 30-day readmission.pdf:pdf},
isbn = {9781450336642},
journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {additive models,classification,healthcare,intelligibility,interaction detection,logistic regression,risk prediction},
pages = {1721--1730},
title = {{Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission}},
url = {http://dl.acm.org/citation.cfm?id=2783258.2788613},
year = {2015}
}
@article{Grunwald2004,
abstract = {We compare the elementary theories of Shannon information and Kolmogorov complexity, the extent to which they have a common purpose, and where they are fundamentally different. We discuss and relate the basic notions of both theories: Shannon entropy versus Kolmogorov complexity, the relation of both to universal coding, Shannon mutual information versus Kolmogorov (`algorithmic') mutual information, probabilistic sufficient statistic versus algorithmic sufficient statistic (related to lossy compression in the Shannon theory versus meaningful information in the Kolmogorov theory), and rate distortion theory versus Kolmogorov's structure function. Part of the material has appeared in print before, scattered through various publications, but this is the first comprehensive systematic comparison. The last mentioned relations are new.},
archivePrefix = {arXiv},
arxivId = {cs/0410002},
author = {Grunwald, Peter and Vitanyi, Paul},
eprint = {0410002},
file = {:home/memo/Mendeley/data/Grunwald, Vitanyi - 2004 - Shannon Information and Kolmogorov Complexity.pdf:pdf},
journal = {CoRR},
pages = {54},
primaryClass = {cs},
title = {{Shannon Information and Kolmogorov Complexity}},
url = {http://arxiv.org/abs/cs/0410002},
volume = {cs.IT/0410},
year = {2004}
}
@article{Vinge2013,
abstract = {The original version of this article was presented at the VISION-21 Symposium sponsored by NASA Lewis$\backslash$nResearch Center and the Ohio Aerospace Institute, March 30-31, 1993. [This annotated version$\backslash$nwas done for the Spring 2003 issue of Whole Earth$\backslash$nReview, http://wholeearth.com/},
author = {Vinge, Vernor},
doi = {10.1002/9781118555927.ch35},
file = {:home/memo/Mendeley/data/Vinge - 2013 - The Coming Technological Singularity.pdf:pdf},
isbn = {9781118334294},
journal = {The Transhumanist Reader: Classical and Contemporary Essays on the Science, Technology, and Philosophy of the Human Future},
keywords = {Intelligence amplification (IA),Superhumanity,Technological Singularity},
pages = {365--375},
title = {{The Coming Technological Singularity}},
year = {2013}
}
@article{Dong2016,
abstract = {Echo-State Networks and Reservoir Computing have been studied for more than a decade. As they provide an elegant yet powerful alternative to traditional computing, researchers have tried to implement them using physical systems, in particular non-linear optical elements, achieving high bandwidth and low power consumption. Here we present a completely different optical implementation of Echo-State Networks using light-scattering materials. As a proof of concept, binary networks have been successfully trained to perform non-linear operations on time series and memory of such networks has been evaluated. This new method is fast, power efficient and easily scalable to very large networks.},
archivePrefix = {arXiv},
arxivId = {1609.05204},
author = {Dong, Jonathan and Gigan, Sylvain and Krzakala, Florent and Wainrib, Gilles},
eprint = {1609.05204},
file = {:home/memo/Mendeley/data/Dong et al. - 2016 - Scaling up Echo-State Networks with multiple light scattering.pdf:pdf},
title = {{Scaling up Echo-State Networks with multiple light scattering}},
url = {http://arxiv.org/abs/1609.05204},
year = {2016}
}
@article{lipton2016mythos,
abstract = {Supervised machine learning models boast re-markable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but inter-pretable. And yet the task of interpretation ap-pears underspecified. Papers provide diverse and sometimes non-overlapping motivations for in-terpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim inter-pretability axiomatically, absent further explana-tion. In this paper, we seek to refine the dis-course on interpretability. First, we examine the motivations underlying interest in interpretabil-ity, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of dif-ferent notions, and question the oft-made asser-tions that linear models are interpretable and that deep neural networks are not.},
author = {Lipton, Zachary C and Kale, David C and Elkan, Charles and Wetzell, Randall and Vikram, Sharad and McAuley, Julian and Wetzell, Randall C and Ji, Zhanglong and Narayaswamy, Balakrishnan and Wang, Cheng-I and Others},
file = {:home/memo/Mendeley/data/Lipton et al. - 2016 - The Mythos of Model Interpretability.pdf:pdf},
journal = {IEEE Spectrum},
keywords = {Black Box,Deep Learning,Interpretability,Machine Learning,Supervised Learning},
title = {{The Mythos of Model Interpretability}},
year = {2016}
}
@techreport{bellman1957markovian,
author = {Bellman, Richard},
booktitle = {Bellman, Richard},
file = {:home/memo/Mendeley/data/Bellman - 1957 - A Markovian decision process.pdf:pdf},
institution = {DTIC Document},
title = {{A Markovian decision process}},
year = {1957}
}
@misc{LogoManual,
author = {Abelson, Hal and Goodman, Nat and Rudolph, Lee},
file = {:home/memo/Mendeley/data/Abelson, Goodman, Rudolph - 1974 - LOGO Manual.pdf:pdf},
title = {{LOGO Manual}},
year = {1974}
}
@article{Schuster1997,
abstract = {In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported},
author = {Schuster, M. and Paliwal, K. K},
file = {:home/memo/Mendeley/data/Schuster, Paliwal - 1997 - Bidirectional recurrent neural networks.pdf:pdf},
journal = {IEEE Transactions on Signal Processing},
number = {11},
pages = {2673--2681},
title = {{Bidirectional recurrent neural networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=650093},
volume = {45},
year = {1997}
}
@article{Sarbolandi2015a,
abstract = {Recently, the new Kinect One has been issued by Microsoft, providing the next generation of real-time range sensing devices based on the Time-of-Flight (ToF) principle. As the first Kinect version was using a structured light approach, one would expect various differences in the characteristics of the range data delivered by both devices. This paper presents a detailed and in-depth comparison between both devices. In order to conduct the comparison, we propose a framework of seven different experimental setups, which is a generic basis for evaluating range cameras such as Kinect. The experiments have been designed with the goal to capture individual effects of the Kinect devices as isolatedly as possible and in a way, that they can also be adopted, in order to apply them to any other range sensing device. The overall goal of this paper is to provide a solid insight into the pros and cons of either device. Thus, scientists who are interested in using Kinect range sensing cameras in their specific application scenario can directly assess the expected, specific benefits and potential problem of either device.},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.05459v1},
author = {Sarbolandi, Hamed and Lefloch, Damien and Kolb, Andreas},
doi = {10.1016/j.cviu.2015.05.006},
eprint = {arXiv:1505.05459v1},
file = {:home/memo/Mendeley/data/Sarbolandi, Lefloch, Kolb - 2015 - Kinect range sensing Structured-light versus Time-of-Flight Kinect.pdf:pdf;:home/memo/Mendeley/data/Sarbolandi, Lefloch, Kolb - 2015 - Kinect range sensing Structured-light versus Time-of-Flight Kinect(2).pdf:pdf},
isbn = {1077-3142},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {3D,Depth sensor,Evaluation,Kinect},
number = {May},
pages = {1--20},
title = {{Kinect range sensing: Structured-light versus Time-of-Flight Kinect}},
volume = {139},
year = {2015}
}
@misc{ofxaddons,
title = {{ofxAddons}},
url = {http://ofxaddons.com/},
year = {2015}
}
@article{Miller2014,
abstract = {Revelations of large scale electronic surveillance and data mining by governments and corporations have fueled increased adoption of HTTPS. We present a traffic analysis attack against over 6000 webpages spanning the HTTPS deployments of 10 widely used, industry-leading websites in areas such as healthcare, finance, legal services and streaming video. Our attack identifies individual pages in the same website with 90{\%} accuracy, exposing personal details including medical conditions, financial and legal affairs and sexual orientation. We examine evaluation methodology and reveal accuracy variations as large as 17{\%} caused by assumptions affecting caching and cookies. We present a novel defense reducing attack accuracy to 25{\%} with a 9{\%} traffic increase, and demonstrate significantly increased effectiveness of prior defenses in our evaluation context, inclusive of enabled caching, user-specific cookies and pages within the same website.},
archivePrefix = {arXiv},
arxivId = {arXiv:1403.0297v1},
author = {Miller, Brad and Huang, Ling and Joseph, A. D. and Tygar, J. D.},
doi = {10.1007/978-3-319-08506-7_8},
eprint = {arXiv:1403.0297v1},
file = {:home/memo/Mendeley/data/Miller et al. - 2014 - I know why you went to the clinic Risks and realization of HTTPS traffic analysis.pdf:pdf},
isbn = {9783319085050},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {143--163},
title = {{I know why you went to the clinic: Risks and realization of HTTPS traffic analysis}},
volume = {8555 LNCS},
year = {2014}
}
@article{kingma2014adam,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik and Ba, Jimmy},
eprint = {1412.6980},
file = {:home/memo/Mendeley/data/Kingma, Ba - 2014 - Adam A method for stochastic optimization.pdf:pdf},
journal = {arXiv preprint arXiv:1412.6980},
pages = {1--13},
title = {{Adam: A method for stochastic optimization}},
url = {http://arxiv.org/abs/1412.6980},
year = {2014}
}
@article{Zhao,
author = {Zhao, Mingmin and Adib, Fadel and Katabi, Dina},
file = {:home/memo/Mendeley/data/Zhao, Adib, Katabi - Unknown - Emotion Recognition using Wireless Signals.pdf:pdf},
isbn = {9781450342261},
keywords = {affective computing,emotion recognition,heart rate variability,wireless sensing,wireless signals},
title = {{Emotion Recognition using Wireless Signals}}
}
@article{Gonzalez,
author = {Gonz{\'{a}}lez, Bernat},
file = {:home/memo/Mendeley/data/Gonz{\'{a}}lez - Unknown - Brain Computer Interfaces ( BCIs ) based on the P300 Event Related Potential ( ERP ).pdf:pdf},
journal = {Neuroscience},
keywords = {bci,eeg,erp,multimodal integration,p300},
pages = {1--26},
title = {{Brain Computer Interfaces ( BCIs ) based on the P300 Event Related Potential ( ERP )}}
}
@article{Picton1992,
abstract = {The P300 wave is a positive deflection in the human event-related potential. It is most commonly elicited in an "oddball" paradigm when a subject detects an occasional "target" stimulus in a regular train of standard stimuli. The P300 wave only occurs if the subject is actively engaged in the task of detecting the targets. Its amplitude varies with the improbability of the targets. Its latency varies with the difficulty of discriminating the target stimulus from the standard stimuli. A typical peak latency when a young adult subject makes a simple discrimination is 300 ms. In patients with decreased cognitive ability, the P300 is smaller and later than in age-matched normal subjects. The intracerebral origin of the P300 wave is not known and its role in cognition not clearly understood. The P300 may have multiple intracerebral generators, with the hippocampus and various association areas of the neocortex all contributing to the scalp-recorded potential. The P300 wave may represent the transfer of information to consciousness, a process that involves many different regions of the brain.},
author = {Picton, T W},
doi = {10.1097/00004691-199210000-00002},
file = {:home/memo/Mendeley/data/Picton - 1992 - The P300 wave of the human event-related potential.pdf:pdf},
isbn = {0736-0258},
issn = {0736-0258},
journal = {Journal of clinical neurophysiology : official publication of the American Electroencephalographic Society},
number = {4},
pages = {456--479},
pmid = {1464675},
title = {{The P300 wave of the human event-related potential.}},
volume = {9},
year = {1992}
}
@article{Gray2004,
abstract = {Past work suggests that information related to the self receives 'preferential access' to the limited pool of attentional resources. However, these studies have been limited by their reliance on response-time measures, which require overt responding and represent the combined effects of multiple stages of information processing. One aim of the present study was to extend past work by obtaining a response-independent index of attention allocation sensitive to changes in discrete stages of information processing. An additional goal was to explore the potential time course of differential sensitivity to self-relevant cues. We assessed the P300, an ERP component that provides an index of attentional resources, evoked by autobiographical self-relevant stimuli (e.g., one's own name). As expected, P300 was augmented for self-relevant stimuli relative to control stimuli. In addition, analyses of P300 latency indicate that the effects of self-relevance are present during higher-order stages of cognitive processing related to selective attention. These results complement and extend previous work on the role of self-relevance in the selection of material for further processing. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
author = {Gray, Heather M. and Ambady, Nalini and Lowenthal, William T. and Deldin, Patricia},
doi = {10.1016/S0022-1031(03)00092-1},
file = {:home/memo/Mendeley/data/Gray et al. - 2004 - P300 as an index of attention to self-relevant stimuli.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Attentional resources,P300,Self-relevant material},
number = {2},
pages = {216--224},
pmid = {22040},
title = {{P300 as an index of attention to self-relevant stimuli}},
volume = {40},
year = {2004}
}
@article{TheLIGOScientificCollaboration2016,
abstract = {On September 14, 2015, the Laser Interferometer Gravitational-wave Observatory (LIGO) detected a gravitational-wave transient (GW150914); we characterise the properties of the source and its parameters. The data around the time of the event were analysed coherently across the LIGO network using a suite of accurate waveform models that describe gravitational waves from a compact binary system in general relativity. GW150914 was produced by a nearly equal mass binary black hole of {\$}36{\^{}}{\{}+5{\}}{\_}{\{}-4{\}} M{\_}\backslashodot{\$} and {\$}29{\^{}}{\{}+4{\}}{\_}{\{}-4{\}} M{\_}\backslashodot{\$} (for each parameter we report the median value and the range of the 90{\%} credible interval). The dimensionless spin magnitude of the more massive black hole is bound to be {\$}0.7{\$} (at 90{\%} probability). The luminosity distance to the source is {\$}410{\^{}}{\{}+160{\}}{\_}{\{}-180{\}}{\$} Mpc, corresponding to a redshift {\$}0.09{\^{}}{\{}+0.03{\}}{\_}{\{}-0.04{\}}{\$} assuming standard cosmology. The source location is constrained to an annulus section of {\$}590{\$} deg{\$}{\^{}}2{\$}, primarily in the southern hemisphere. The binary merges into a black hole of {\$}62{\^{}}{\{}+4{\}}{\_}{\{}-4{\}} M{\_}\backslashodot{\$} and spin {\$}0.67{\^{}}{\{}+0.05{\}}{\_}{\{}-0.07{\}}{\$}. This black hole is significantly more massive than any other known in the stellar-mass regime.},
archivePrefix = {arXiv},
arxivId = {1602.03840},
author = {{The LIGO Scientific Collaboration} and {the Virgo Collaboration}},
eprint = {1602.03840},
file = {:home/memo/Mendeley/data/The LIGO Scientific Collaboration, the Virgo Collaboration - 2016 - Properties of the binary black hole merger GW150914.pdf:pdf},
number = {February},
pages = {1--19},
title = {{Properties of the binary black hole merger GW150914}},
url = {http://arxiv.org/abs/1602.03840},
year = {2016}
}
@article{Social2016,
author = {Social, The},
file = {:home/memo/Mendeley/data/Social - 2016 - The AI Now Report.pdf:pdf},
pages = {1--25},
title = {{The AI Now Report}},
year = {2016}
}
@misc{Nake1971,
author = {Nake, Frieder},
booktitle = {Bulletin of the computer arts society},
file = {:home/memo/Mendeley/data/Nake - 1971 - There Should Be No Computer Art.pdf:pdf},
pages = {18--19},
title = {{There Should Be No Computer Art}},
year = {1971}
}
@article{Yan1998,
author = {Yan, Yajie and Sykes, Kyle and Chambers, Erin and Letscher, David},
doi = {10.1145/2897824.2925938},
file = {:home/memo/Mendeley/data/Yan et al. - 1998 - Erosion Thickness on Medial Axes of 3D Shapes.pdf:pdf},
isbn = {9781450342797},
issn = {15577368},
keywords = {Medial axis, skeletons, shape analysis,a bumpy 3d shape,computational geometry,computing methodologies,concepts,contains numer-,figure 1,medial axis,shape analysis,skeletons,the medial axis of,theory of computation},
number = {0},
pages = {1--12},
title = {{Erosion Thickness on Medial Axes of 3D Shapes}},
volume = {0},
year = {1998}
}
@article{Tagliasacchi2016,
author = {Tagliasacchi, Andrea and Delame, Thomas and Spagnuolo, Michela and Amenta, Nina and Tagliasacchi, Andrea and Delame, Thomas and Spagnuolo, Michela and Amenta, Nina and Telea, Alexandru},
file = {:home/memo/Mendeley/data/Tagliasacchi et al. - 2016 - 3D Skeletons A State-of-the-Art Report To cite this version 3D Skeletons A State-of-the-Art Report.pdf:pdf},
title = {{3D Skeletons : A State-of-the-Art Report To cite this version : 3D Skeletons : A State-of-the-Art Report}},
url = {https://hal.archives-ouvertes.fr/hal-01300281/file/3D{\_}Skeletons{\_}STAR.pdf},
year = {2016}
}
@article{Meredith1996,
author = {Meredith, David},
file = {:home/memo/Mendeley/data/Meredith - 1996 - Music Analysis and Kolmogorov Complexity.pdf:pdf},
title = {{Music Analysis and Kolmogorov Complexity}},
year = {1996}
}
@article{Marblestone2016,
archivePrefix = {arXiv},
arxivId = {1606.03813},
author = {Marblestone, Adam H and Wayne, Greg and Kording, Konrad P},
doi = {10.1101/058545},
eprint = {1606.03813},
file = {:home/memo/Mendeley/data/Marblestone, Wayne, Kording - 2016 - Towards an integration of deep learning and neuroscience.pdf:pdf},
isbn = {10.1101/058545},
issn = {1662-5188},
keywords = {cognitive architecture,cost functions,neural networks,neuroscience},
number = {September},
pages = {1--61},
title = {{Towards an integration of deep learning and neuroscience}},
volume = {10},
year = {2016}
}
@article{Thrun2002,
abstract = {In recent years, particle filters have solved several hard perceptual problems in robotics. Early successes of particle filters were limited to low-dimensional estimation problems, such as the problem of robot localization in environments with known maps. More recently, researchers have begun exploiting structural properties of robotic domains that have led to successful particle filter applications in spaces with as many as 100,000 dimensions. The fact that every model--no mater how detailed--fails to capture the full complexity of even the most simple robotic environments has lead to specific tricks and techniques essential for the success of particle filters in robotic domains. This article surveys some of these recent innovations, and provides pointers to in-depth articles on the use of particle filters in robotics.},
archivePrefix = {arXiv},
arxivId = {1301.0607},
author = {Thrun, Sebastian},
eprint = {1301.0607},
file = {:home/memo/Mendeley/data/Thrun - 2002 - Particle Filters in Robotics.pdf:pdf},
isbn = {1558608974},
issn = {00222275},
journal = {Proceedings of Uncertainty in AI},
pages = {511--518},
title = {{Particle Filters in Robotics}},
url = {http://uai.sis.pitt.edu/papers/02/p511-thrun.pdf{\%}5Cnhttp://robots.stanford.edu/papers/thrun.pf-in-robotics-uai02.pdf},
volume = {1},
year = {2002}
}
@article{Doucet2011,
abstract = {Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented},
author = {Doucet, Arnaud and Johansen, Am},
doi = {10.1.1.157.772},
file = {:home/memo/Mendeley/data/Doucet, Johansen - 2011 - A tutorial on particle filtering and smoothing fifteen years later.pdf:pdf},
isbn = {978-0199532902},
issn = {01677152},
journal = {Handbook of Nonlinear Filtering},
number = {December},
pages = {656--704},
title = {{A tutorial on particle filtering and smoothing: fifteen years later}},
url = {http://automatica.dei.unipd.it/tl{\_}files/utenti/lucaschenato/Classes/PSC10{\_}11/Tutorial{\_}PF{\_}doucet{\_}johansen.pdf},
year = {2011}
}
@article{Harper2006,
author = {Harper, Charles Neely and Mccormack, Jon and Gagn{\'{e}}, Christian and Parizeau, Marc and Luca, Pier and Eic, Lanzi and Davis, Lawrence David and Mccormack, Jon},
file = {:home/memo/Mendeley/data/Harper et al. - 2006 - SIGEVOlution.pdf:pdf},
number = {1},
title = {{SIGEVOlution}},
volume = {1},
year = {2006}
}
@article{Silver2016,
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and Driessche, George Van Den and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
file = {:home/memo/Mendeley/data/Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf:pdf},
journal = {Nature},
number = {7587},
pages = {484--489},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go with deep neural networks and tree search}},
volume = {529},
year = {2016}
}
@article{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
doi = {10.1038/nature14236},
eprint = {1312.5602},
file = {:home/memo/Mendeley/data/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:pdf;:home/memo/Mendeley/data/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
journal = {arXiv preprint arXiv: {\ldots}},
pages = {1--9},
pmid = {25719670},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}
@article{Xue2008,
abstract = {We compare discriminative and generative learning as typified by logistic regression and naive Bayes. We show, contrary to a widely- held belief that discriminative classifiers are almost always to be preferred, that there can often be two distinct regimes of per- formance as the training set size is increased, one in which each algorithm does better. This stems from the observation- which is borne out in repeated experiments- that while discriminative learning has lower asymptotic error, a generative classifier may also approach its (higher) asymptotic error much faster.},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1007/s11063-008-9088-7},
author = {Xue, Jing Hao and Titterington, D. Michael},
doi = {10.1007/s11063-008-9088-7},
eprint = {/dx.doi.org/10.1007/s11063-008-9088-7},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xue, Titterington - 2008 - Comment on on discriminative vs. generative classifiers A comparison of logistic regression and naive baye(2).pdf:pdf},
isbn = {1106300890},
issn = {13704621},
journal = {Neural Processing Letters},
keywords = {Asymptotic relative efficiency,Discriminative classifiers,Generative classifiers,Logistic regression,Na??ve Bayes classifier,Normal-based discriminant analysis},
number = {3},
pages = {169--187},
primaryClass = {http:},
title = {{Comment on "on discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes"}},
volume = {28},
year = {2008}
}
@inproceedings{Grierson2013a,
abstract = {NoiseBear is a malleable multiparametric interface, currently being developed in a series of participatory design workshops with disabled children. It follows a soft toy design, using conductive textiles for pressure sensing and circuitry. The system is a highly sensitive deformable controller; it can be used flexibly in a range of scenarios for continuous or discrete control, allowing interaction to be designed at a range of complexity levels. The controller is wireless, and can be used to extend the interactive possibilities of mobile computing devices. Multiple controllers may also be networked together in collaborative scenarios.},
author = {Grierson, Mick and Kiefer, Chris},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
doi = {10.1145/2468356.2479575},
file = {:home/memo/Mendeley/data/Grierson, Kiefer - 2013 - NoiseBear a wireless malleable multiparametric controller for.pdf:pdf},
isbn = {978-1-4503-1952-2},
keywords = {electrotextiles,malleable controller assistive technology,malleable interaction,participatory design},
pages = {2923--2926},
title = {{NoiseBear: a wireless malleable multiparametric controller for use in assistive technology contexts}},
url = {http://doi.acm.org/10.1145/2468356.2479575},
year = {2013}
}
@misc{Jaeger2002,
author = {Jaeger, Herbert},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaeger - 2002 - A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the echo state network approach(2).pdf:pdf},
pages = {1--46},
title = {{A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the "echo state network" approach}},
volume = {2},
year = {2002}
}
@article{Worgotter2005,
abstract = {In this review, we compare methods for temporal sequence learning (TSL) across the disciplines machine-control, classical conditioning, neuronal models for TSL as well as spike-timing-dependent plasticity (STDP). This review introduces the most influential models and focuses on two questions: To what degree are reward-based (e.g., TD learning) and correlation-based (Hebbian) learning related? and How do the different models correspond to possibly underlying biological mechanisms of synaptic plasticity? We first compare the different models in an open-loop condition, where behavioral feedback does not alter the learning. Here we observe that reward-based and correlation-based learning are indeed very similar. Machine control is then used to introduce the problem of closed-loop control (e.g., actor-critic architectures). Here the problem of evaluative (rewards) versus nonevaluative (correlations) feedback from the environment will be discussed, showing that both learning approaches are fundamentally different in the closed-loop condition. In trying to answer the second question, we compare neuronal versions of the different learning architectures to the anatomy of the involved brain structures (basal-ganglia, thalamus, and cortex) and the molecular biophysics of glutamatergic and dopaminergic synapses. Finally, we discuss the different algorithms used to model STDP and compare them to reward-based learning rules. Certain similarities are found in spite of the strongly different timescales. Here we focus on the biophysics of the different calcium-release mechanisms known to be involved in STDP.},
author = {W{\"{o}}rg{\"{o}}tter, Florentin and Porr, Bernd},
doi = {10.1162/0899766053011555},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/W{\"{o}}rg{\"{o}}tter, Porr - 2005 - Temporal sequence learning, prediction, and control a review of different models and their relation to bio(2).pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
number = {2},
pages = {245--319},
pmid = {15720770},
title = {{Temporal sequence learning, prediction, and control: a review of different models and their relation to biological mechanisms.}},
volume = {17},
year = {2005}
}
@article{Bradford1995,
abstract = {Abstract This paper describes an experimental computer program that applies the techniques of artificial intelligence to the creation of dance. Specifically, a user expresses a set of dance rules (in a special English-like rule language) which describes some of the dynamic aspects of a dance. These rules are applied nondeterministically by a rule driver program. The rules themselves are similar to those that form the knowledge base of expert systems. The rule driver embodies a heuristic algorithm of the type found in many artificial intelligence programs.},
author = {Bradford, James H. and C{\^{o}}t{\'{e}}-Laurence, Paulette},
doi = {10.1007/BF01830393},
file = {:home/memo/Mendeley/data/Bradford, C{\^{o}}t{\'{e}}-Laurence - 1995 - An application of artificial intelligence to the choreography of dance.pdf:pdf},
issn = {00104817},
journal = {Computers and the Humanities},
keywords = {artificial intelligence and dance,computer-aided choreography},
number = {4},
pages = {233--240},
title = {{An application of artificial intelligence to the choreography of dance}},
volume = {29},
year = {1995}
}
@article{Chen2013,
author = {Chen, Xi and Koskela, Markus},
doi = {10.1145/2522848.2532591},
file = {:home/memo/Mendeley/data/Chen, Koskela - 2013 - Online RGB-D gesture recognition with extreme learning machines.pdf:pdf},
isbn = {9781450321297},
journal = {Proceedings of the 15th ACM on International conference on multimodal interaction - ICMI '13},
keywords = {d,extreme learning machine,hog,online gesture recognition,rgb-,skeleton model},
pages = {467--474},
title = {{Online RGB-D gesture recognition with extreme learning machines}},
url = {http://dl.acm.org/citation.cfm?doid=2522848.2532591},
year = {2013}
}
@article{Timonen2012,
author = {Timonen, Ville},
doi = {10.1111/j.1467-8659.2012.03155.x},
file = {:home/memo/Mendeley/data/Timonen - 2012 - Low-Complexity Intervisibility in Height Fields.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {3,7,according to acm ccs,and texture,categories and subject descriptors,color,computer graphics,global illumination,height field,i,intervisibility,shading,shadowing},
month = {dec},
number = {8},
pages = {2348--2362},
title = {{Low-Complexity Intervisibility in Height Fields}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2012.03155.x},
volume = {31},
year = {2012}
}
@article{Bressloff2001,
abstract = {This paper is concerned with a striking visual experience: that of seeing geometric visual hallucinations. Hallucinatory images were classified by Kl{\"{u}}ver into four groups called form constants comprising (i) gratings, lattices, fretworks, filigrees, honeycombs and chequer-boards, (ii) cobwebs, (iii) tunnels, funnels, alleys, cones and vessels, and (iv) spirals. This paper describes a mathematical investigation of their origin based on the assumption that the patterns of connection between retina and striate cortex (henceforth referred to as V1)-the retinocortical map-and of neuronal circuits in V1, both local and lateral, determine their geometry. In the first part of the paper we show that form constants, when viewed in V1 coordinates, essentially correspond to combinations of plane waves, the wavelengths of which are integral multiples of the width of a human Hubel-Wiesel hypercolumn, ca. 1.33-2 mm. We next introduce a mathematical description of the large-scale dynamics of V1 in terms of the continuum limit of a lattice of interconnected hypercolumns, each of which itself comprises a number of interconnected iso-orientation columns. We then show that the patterns of interconnection in V1 exhibit a very interesting symmetry, i.e. they are invariant under the action of the planar Euclidean group E(2)-the group of rigid motions in the plane-rotations, reflections and translations. What is novel is that the lateral connectivity of V1 is such that a new group action is needed to represent its properties: by virtue of its anisotropy it is invariant with respect to certain shifts and twists of the plane. It is this shift-twist invariance that generates new representations of E(2). Assuming that the strength of lateral connections is weak compared with that of local connections, we next calculate the eigenvalues and eigenfunctions of the cortical dynamics, using Rayleigh-Schr{\"{o}}dinger perturbation theory. The result is that in the absence of lateral connections, the eigenfunctions are degenerate, comprising both even and odd combinations of sinusoids in straight phi, the cortical label for orientation preference, and plane waves in r, the cortical position coordinate. 'Switching-on' the lateral interactions breaks the degeneracy and either even or else odd eigenfunctions are selected. These results can be shown to follow directly from the Euclidean symmetry we have imposed. In the second part of the paper we study the nature of various even and odd combinations of eigenfunctions or planforms, the symmetries of which are such that they remain invariant under the particular action of E(2) we have imposed. These symmetries correspond to certain subgroups of E(2), the so-called axial subgroups. Axial subgroups are important in that the equivariant branching lemma indicates that when a symmetrical dynamical system becomes unstable, new solutions emerge which have symmetries corresponding to the axial subgroups of the underlying symmetry group. This is precisely the case studied in this paper. Thus we study the various planforms that emerge when our model V1 dynamics become unstable under the presumed action of hallucinogens or flickering lights. We show that the planforms correspond to the axial subgroups of E(2), under the shift-twist action. We then compute what such planforms would look like in the visual field, given an extension of the retinocortical map to include its action on local edges and contours. What is most interesting is that, given our interpretation of the correspondence between V1 planforms and perceived patterns, the set of planforms generates representatives of all the form constants. It is also noteworthy that the planforms derived from our continuum model naturally divide V1 into what are called linear regions, in which the pattern has a near constant orientation, reminiscent of the iso-orientation patches constructed via optical imaging. The boundaries of such regions form fractures whose points of intersection correspond to the well-known 'pinwheels'. To complete the study we then investigate the stability of the planforms, using methods of nonlinear stability analysis, including Liapunov-Schmidt reduction and Poincar{\'{e}}-Lindstedt perturbation theory. We find a close correspondence between stable planforms and form constants. The results are sensitive to the detailed specification of the lateral connectivity and suggest an interesting possibility, that the cortical mechanisms by which geometric visual hallucinations are generated, if sited mainly in V1, are closely related to those involved in the processing of edges and contours.},
author = {Bressloff, P C and Cowan, J D and Golubitsky, M and Thomas, P J and Wiener, M C},
doi = {10.1098/rstb.2000.0769},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bressloff et al. - 2001 - Geometric visual hallucinations, Euclidean symmetry and the functional architecture of striate cortex(3).pdf:pdf;:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bressloff et al. - 2001 - Geometric visual hallucinations, Euclidean symmetry and the functional architecture of striate cortex(4).pdf:pdf},
isbn = {0962-8436 (Print)$\backslash$n0962-8436 (Linking)},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
number = {1407},
pages = {299--330},
pmid = {11316482},
title = {{Geometric visual hallucinations, Euclidean symmetry and the functional architecture of striate cortex.}},
volume = {356},
year = {2001}
}
@article{LeCun1998a,
abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observedb y practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposedin serious technical publications. This paper gives some of those tricks, ando.ers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most “classical” second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {LeCun, Yann A. and Bottou, L{\'{e}}on and Orr, Genevieve B. and M{\"{u}}ller, Klaus Robert},
doi = {10.1007/978-3-642-35289-8-3},
eprint = {9809069v1},
file = {:home/memo/Mendeley/data/LeCun et al. - 1998 - Efficient backprop.pdf:pdf},
isbn = {9783642352881},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {9--48},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{Efficient backprop}},
volume = {7700 LECTU},
year = {1998}
}
@unpublished{Report2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.09249v1},
author = {Schmidhuber, J{\"{u}}rgen},
eprint = {arXiv:1511.09249v1},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2015 - On Learning to Think Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers(2).pdf:pdf},
pages = {1--36},
title = {{On Learning to Think : Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models}},
year = {2015}
}
@misc{Akten2016-ofxMSATensorFlow,
author = {Akten, Memo},
title = {{ofxMSATensorFlow}},
url = {https://github.com/memo/ofxMSATensorFlow},
year = {2016}
}
@article{Mital2013,
author = {Mital, Parag K. and Grierson, Mick and Smith, Tim J.},
doi = {10.1145/2492494.2492505},
isbn = {9781450322621},
journal = {Proceedings of the ACM Symposium on Applied Perception - SAP '13},
keywords = {augmented reality hallucination,memory mosaicing},
number = {July},
pages = {51--58},
title = {{Corpus-based visual synthesis}},
url = {http://dl.acm.org/citation.cfm?id=2492494.2492505 http://dl.acm.org/citation.cfm?doid=2492494.2492505},
year = {2013}
}
@article{Perovsek2013,
author = {Perov{\v{s}}ek, Matic and Cestnik, Bojan and Urban{\v{c}}i{\v{c}}, Tanja and Colton, Simon and Lavra{\v{c}}, Nada},
doi = {10.1007/978-3-642-41398-8_29},
file = {:home/memo/Mendeley/data/Perov{\v{s}}ek et al. - 2013 - Towards narrative ideation via cross-context link discovery using banded matrices.pdf:pdf},
isbn = {9783642413971},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {333--344},
title = {{Towards narrative ideation via cross-context link discovery using banded matrices}},
volume = {8207 LNCS},
year = {2013}
}
@article{Coltoni,
author = {Colton, Simon and Cook, Michael and Raad, Azalea},
file = {:home/memo/Mendeley/data/Colton, Cook, Raad - Unknown - Ludic Considerations of Tablet-Based Evo-Art.pdf:pdf},
title = {{Ludic Considerations of Tablet-Based Evo-Art}}
}
@article{Tuking1936,
author = {Turing, Alan M},
file = {:home/memo/Mendeley/data/Turing - 1936 - On Computable Numbers, with an application to The Entscheidungs Problem.pdf:pdf},
number = {1931},
pages = {173--198},
title = {{On Computable Numbers, with an application to The Entscheidungs Problem}},
volume = {38},
year = {1936}
}
@misc{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - OlivaPBR2006.pdf.pdf:pdf},
title = {{OlivaPBR2006.pdf}}
}
@article{Colton2011,
abstract = {We introduce two descriptive models for evaluating creative software, the FACE model which describes creative acts performed by software in terms of tuples of generative acts, and the IDEA model which describes how such creative acts can have an impact upon an ideal audience, given ideal information about background knowledge and the software development process. We motivate these models in three ways. Firstly, we describe a case study of human creativity in mathematics, and discuss how various key aspects have inspired the development of our models. Secondly, we embed aspects from the two models into work within psychology, computational creativity and philosophy. Finally, we discuss criteria identified by philosophers of science on what constitutes a good theory, and suggest how this has inspired aspects of our two models.},
author = {Colton, Simon and Pease, Alison and Charnley, John},
isbn = {9786074774870},
journal = {Proceedings of the Second International Conference on Computational Creativity},
pages = {90--95},
title = {{Computational creativity theory: The FACE and IDEA descriptive models}},
url = {https://www.doc.ic.ac.uk/{~}jwc04/papers/conferences/colton{\_}iccc11.pdf},
year = {2011}
}
@misc{openframeworks,
author = {Lieberman, Zachary and Watson, Theo and Castro, Arturo},
title = {{OpenFrameworks}},
url = {www.openframeworks.cc},
year = {2016}
}
@article{Henry2014,
author = {Henry, Desmond Paul and Oxon, Elaine O Hanrahan B A},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henry, Oxon - 2014 - Artistic intuition meets technical ingenuity the unique contribution to Digital Art History of 1960 ' s computer.pdf:pdf},
number = {2012},
title = {{Artistic intuition meets technical ingenuity : the unique contribution to Digital Art History of 1960 ' s computer}},
volume = {1},
year = {2014}
}
@article{Bryce,
author = {Bryce, Jo and Rutter, Jason},
file = {:home/memo/Mendeley/data/Bryce, Rutter - Unknown - Killing Like a Girl Gendered Gaming and Girl Gamers ' Visibility.pdf:pdf},
keywords = {computer games,gender,gendered technology,leisure spaces},
pages = {243--255},
title = {{Killing Like a Girl : Gendered Gaming and Girl Gamers ' Visibility}}
}
@article{Chater2006,
abstract = {Remarkable progress in the mathematics and computer science of probability has led to a revolution in the scope of probabilistic models. In particular, 'sophisticated' probabilistic methods apply to structured relational systems such as graphs and grammars, of immediate relevance to the cognitive sciences. This Special Issue outlines progress in this rapidly developing field, which provides a potentially unifying perspective across a wide range of domains and levels of explanation. Here, we introduce the historical and conceptual foundations of the approach, explore how the approach relates to studies of explicit probabilistic reasoning, and give a brief overview of the field as it stands today. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Chater, Nick and Tenenbaum, Joshua B. and Yuille, Alan},
doi = {10.1016/j.tics.2006.05.007},
file = {:home/memo/Mendeley/data/Chater, Tenenbaum, Yuille - 2006 - Probabilistic models of cognition conceptual foundations.pdf:pdf;:home/memo/Mendeley/data/Chater, Tenenbaum, Yuille - 2006 - Probabilistic models of cognition conceptual foundations.pdf:pdf},
isbn = {1364-6613},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
number = {7},
pages = {287--291},
pmid = {16807064},
title = {{Probabilistic models of cognition: conceptual foundations.}},
volume = {10},
year = {2006}
}
@article{Schmidhuber2015,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
file = {:home/memo/Mendeley/data/Schmidhuber - 2015 - Deep Learning in Neural Networks An Overview(2).pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning},
pages = {85--117},
publisher = {Elsevier},
title = {{Deep Learning in Neural Networks: An Overview}},
volume = {61},
year = {2015}
}
@phdthesis{Sutskever2013,
abstract = {Recurrent Neural Networks (RNNs) are powerful sequence models that were believed to be difficult to train, and as a result they were rarely used in machine learning applications. This thesis presents methods that overcome the difficulty of training RNNs, and applications of RNNs to challenging problems. We first describe a newprobabilistic sequence model that combines Restricted Boltzmann Machines and RNNs. The new model is more powerful than similar models while being less difficult to train. Next, we present a new variant of the Hessian-free (HF) optimizer and show that it can train RNNs on tasks that have extreme long-range temporal dependencies, which were previously considered to be impossibly hard. We then apply HF to character-level language modelling and get excellent results. We also apply HF to optimal control and obtain RNN control laws that can successfully operate under conditions of delayed feedback and unknown disturbances. Finally, we describe a random parameter initialization scheme that allows gradient descent with mo- mentum to train RNNs on problems with long-term dependencies. This directly contradicts widespread beliefs about the inability of first-order methods to do so, and suggests that previous attempts at training RNNs failed partly due to flaws in the random initialization},
archivePrefix = {arXiv},
arxivId = {arXiv:submit/1456339},
author = {Sutskever, Ilya},
booktitle = {PhD thesis},
eprint = {1456339},
file = {:home/memo/Mendeley/data/Sutskever - 2013 - Training Recurrent neural Networks.pdf:pdf},
pages = {101},
primaryClass = {arXiv:submit},
school = {University of Toronto},
title = {{Training Recurrent neural Networks}},
year = {2013}
}
@article{Hinton2015,
abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
archivePrefix = {arXiv},
arxivId = {1503.02531},
author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
eprint = {1503.02531},
file = {:home/memo/Mendeley/data/Hinton, Vinyals, Dean - 2015 - Distilling the Knowledge in a Neural Network(2).pdf:pdf;:home/memo/Mendeley/data/Hinton, Vinyals, Dean - 2015 - Distilling the Knowledge in a Neural Network.pdf:pdf},
journal = {NIPS 2014 Deep Learning Workshop},
pages = {1--9},
title = {{Distilling the Knowledge in a Neural Network}},
url = {http://arxiv.org/abs/1503.02531},
year = {2015}
}
@article{Zliobaite2015,
archivePrefix = {arXiv},
arxivId = {1505.05723},
author = {{\v{Z}}liobaitė, Indrė},
eprint = {1505.05723},
file = {:home/memo/Mendeley/data/{\v{Z}}liobaitė - 2015 - On the relation between accuracy and fairness in binary classification.pdf:pdf},
journal = {FaTML},
keywords = {Indre ̇Zˇliobaite ̇},
title = {{On the relation between accuracy and fairness in binary classification}},
url = {http://www.fatml.org/papers/?liobait?.pdf},
year = {2015}
}
@article{Cook2013,
author = {Cook, Michael and Colton, Simon and Gow, Jeremy},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cook, Colton, Gow - 2013 - Nobody ' s A Critic On The Evaluation Of Creative Code Generators – A Case Study In Videogame Design.pdf:pdf},
number = {Sicart 2008},
pages = {123--130},
title = {{Nobody ' s A Critic : On The Evaluation Of Creative Code Generators – A Case Study In Videogame Design}},
year = {2013}
}
@inproceedings{Wu2016,
abstract = {Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feed-forward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.},
author = {Wu, Zhizheng and King, Simon},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
file = {:home/memo/Mendeley/data/Wu, King - 2016 - Investigating Gated Recurrent Neural Networks for Speech Synthesis.pdf:pdf},
pages = {5140--5144},
publisher = {IEEE},
title = {{Investigating Gated Recurrent Neural Networks for Speech Synthesis}},
year = {2016}
}
@article{Krb,
author = {Kr, J},
file = {:home/memo/Mendeley/data/Kr - Unknown - Acceleration Techniques for GPU-based Volume Rendering.pdf:pdf},
keywords = {programmable graphics hard-,volume rendering},
title = {{Acceleration Techniques for GPU-based Volume Rendering}}
}
@article{Caramiaux2013a,
abstract = {We present an overview of machine learning (ML) techniques and theirapplication in interactive music and new digital instruments design. We firstgive to the non-specialist reader an introduction to two ML tasks,classification and regression, that are particularly relevant for gesturalinteraction. We then present a review of the literature in current NIMEresearch that uses ML in musical gesture analysis and gestural sound control.We describe the ways in which machine learning is useful for creatingexpressive musical interaction, and in turn why live music performance presentsa pertinent and challenging use case for machine learning.},
author = {Caramiaux, Baptiste and Tanaka, Atau},
file = {:home/memo/Mendeley/data/Caramiaux, Tanaka - 2013 - Machine Learning of Musical Gestures.pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {Analysis,Control,Data mining,Gesture,Machine Learning,Musical Expression,Musical Gestures,Sound},
pages = {513--518},
title = {{Machine Learning of Musical Gestures}},
url = {http://nime2013.kaist.ac.kr/},
year = {2013}
}
@article{Museth2013a,
author = {Museth, K E N},
file = {:home/memo/Mendeley/data/Museth - 2013 - VDB High-Resolution Sparse Volumes with Dynamic Topology.pdf:pdf},
number = {3},
title = {{VDB : High-Resolution Sparse Volumes with Dynamic Topology}},
volume = {32},
year = {2013}
}
@article{Baraff2001d,
author = {Baraff, David and Ode, Example Stiff},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baraff, Ode - 2001 - Physically Based Modeling Implicit Methods for Differential Equations Implicit Methods for Differential Equation(2).pdf:pdf},
title = {{Physically Based Modeling Implicit Methods for Differential Equations Implicit Methods for Differential Equations}},
year = {2001}
}
@article{Akten2015-ofxMSAmcts,
author = {Akten, Memo},
title = {{ofxMSAmcts}},
url = {https://github.com/memo/ofxmsamcts},
year = {2015}
}
@article{Rodrigues2013,
author = {Rodrigues, Danilo Gasques and Grenader, Emily and Nos, Fernando Da Silva and Dall'Agnol, Marcel De Sena and Hansen, Troels E. and Weibel, Nadir},
doi = {10.1145/2468356.2468570},
file = {:home/memo/Mendeley/data/Rodrigues et al. - 2013 - MotionDraw.pdf:pdf},
isbn = {9781450319522},
journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
keywords = {design,drawing,experimentation,interactivity,kinect,performance,projection,real-time},
pages = {1197},
title = {{MotionDraw}},
url = {http://dl.acm.org/citation.cfm?id=2468356.2468570},
year = {2013}
}
@article{Zatorre2011,
author = {Zatorre, Robert J and Salimpoor, Valorie N and Benovoy, Mitchel and Larcher, Kevin and Dagher, Alain and Zatorre, Robert J},
doi = {10.1038/nn.2726},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zatorre et al. - 2011 - ‘ Anatomically Distinct Dopamine Release during Anticipation and Experience of Peak Emotion to Music ' Anatomi.pdf:pdf},
issn = {1097-6256},
journal = {Nature Publishing Group},
number = {2},
pages = {257--262},
publisher = {Nature Publishing Group},
title = {{‘ Anatomically Distinct Dopamine Release during Anticipation and Experience of Peak Emotion to Music ' Anatomically distinct dopamine release during anticipation and experience of peak emotion to music}},
url = {http://dx.doi.org/10.1038/nn.2726},
volume = {14},
year = {2011}
}
@article{Paper2015,
author = {Paper, Conference},
file = {:home/memo/Mendeley/data/Paper - 2015 - Viewpoints AI.pdf:pdf},
number = {OCTOBER 2013},
title = {{Viewpoints AI}},
year = {2015}
}
@article{Anderson2009,
abstract = {Three experiments examined the impact of excessive violence in sport video games on aggression-related variables. Participants played either a nonviolent simulation-based sports video game (baseball or football) or a matched excessively violent sports video game. Participants then completed measures assessing aggressive cognitions (Experiment 1), aggressive affect and attitudes towards violence in sports (Experiment 2), or aggressive behavior (Experiment 3). Playing an excessively violent sports video game increased aggressive affect, aggressive cognition, aggressive behavior, and attitudes towards violence in sports. Because all games were competitive, these findings indicate that violent content uniquely leads to increases in several aggression-related variables, as predicted by the General Aggression Model and related social-cognitive models. ?? 2009 Elsevier Inc. All rights reserved.},
author = {Anderson, Craig a. and Carnagey, Nicholas L.},
doi = {10.1016/j.jesp.2009.04.019},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson, Carnagey - 2009 - Causal effects of violent sports video games on aggression Is it competitiveness or violent content(2).pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Aggression,Aggressive affect,Aggressive cognition,General aggression model,Media violence,Video game violence},
month = {jul},
number = {4},
pages = {731--739},
publisher = {Elsevier Inc.},
title = {{Causal effects of violent sports video games on aggression: Is it competitiveness or violent content?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103109001000},
volume = {45},
year = {2009}
}
@article{Lomont2002,
author = {Lomont, Chris},
file = {:home/memo/Mendeley/data/Lomont - 2002 - Fast inverse square root.pdf:pdf},
pages = {1--12},
title = {{Fast inverse square root}},
year = {2002}
}
@article{Witkin2001m,
author = {Witkin, Andrew},
file = {:home/memo/Mendeley/data/Witkin - 2001 - Physically Based Modeling Constrained Dynamics Constrained Dynamics.pdf:pdf},
title = {{Physically Based Modeling Constrained Dynamics Constrained Dynamics}},
year = {2001}
}
@article{Felixd,
author = {Felix, Hummel and Alexander, Jenisch},
file = {:home/memo/Mendeley/data/Felix, Alexander - Unknown - Simple Motion Blur in OpenGL.pdf:pdf},
title = {{Simple Motion Blur in OpenGL}}
}
@article{Corriveau,
author = {Corriveau, Philip J and Sheedy, James E and Ph, D},
file = {:home/memo/Mendeley/data/Corriveau, Sheedy, Ph - Unknown - IndividualDifferencesAndSeatingPositionAffectImmersionAndSymptomsInStereoscopic3DViewing.pdf:pdf},
keywords = {3d,acknowledgement,by intel,immersion,manuscript was partly funded,motion sickness,stereoscopic display,study reported in the,visual symptoms},
pages = {1--44},
title = {{IndividualDifferencesAndSeatingPositionAffectImmersionAndSymptomsInStereoscopic3DViewing}}
}
@inproceedings{Bengio2013b,
archivePrefix = {arXiv},
arxivId = {arXiv:1212.0901v2},
author = {Bengio, Yoshua and Boulanger-Lewandowski, Nicolas and Pascanu, Razvan},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing},
eprint = {arXiv:1212.0901v2},
file = {:home/memo/Mendeley/data/Bengio, Boulanger-Lewandowski, Pascanu - 2013 - Advances in Optimizing Recurrent Neural Networks.pdf:pdf},
pages = {8624--8628},
title = {{Advances in Optimizing Recurrent Neural Networks}},
year = {2013}
}
@article{Jr2014,
author = {Jr, Kevin J Ryan},
file = {:home/memo/Mendeley/data/Jr - 2014 - Editor ' s Note Introduction to Special Issue on Music and Embodied Cognition.pdf:pdf},
number = {3},
pages = {159--160},
title = {{Editor ' s Note : Introduction to Special Issue on Music and Embodied Cognition}},
volume = {9},
year = {2014}
}
@misc{Microsoft,
author = {Microsoft},
title = {{Kinect 2}},
url = {https://dev.windows.com/en-us/kinect}
}
@article{Musethe,
author = {Museth, Ken},
file = {:home/memo/Mendeley/data/Museth - Unknown - A Flexible Image Processing Approach to the Surfacing of Particle-Based Fluid Animation.pdf:pdf},
pages = {1--4},
title = {{A Flexible Image Processing Approach to the Surfacing of Particle-Based Fluid Animation}}
}
@misc{Guerra2009a,
abstract = {The integration of usable and flexible analysis support in modelling environments is a key success factor in Model-Driven Development. In this paradigm, models are the core asset from which code is automatically generated, and thus ensuring model correctness is a fundamental quality control activity. For this purpose, a common approach is to transform the system models into formal semantic domains for verification. However, if the analysis results are not shown in a proper way to the end-user (e.g. in terms of the original language) they may become useless. In this paper we present a novel DSVL called BaVeL that facilitates the flexible annotation of verification results obtained in semantic domains to different formats, including the context of the original language. BaVeL is used in combination with a consistency framework, providing support for all steps in a verification process: acquisition of additional input data, transformation of the system models into semantic domains, verification, and flexible annotation of analysis results. The approach has been validated analytically by the cognitive dimensions framework, and empirically by its implementation and application to several DSVLs. Here we present a case study of a notation in the area of Digital Libraries, where the analysis is performed by transformations into Petri nets and a process algebra. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0402594v3},
author = {Guerra, Esther and de Lara, Juan and Malizia, Alessio and D{\'{i}}az, Paloma},
booktitle = {Information and Software Technology},
doi = {10.1016/j.infsof.2008.09.005},
eprint = {0402594v3},
isbn = {0950-5849},
issn = {09505849},
keywords = {Back-annotation,Consistency,Domain-specific visual languages,Formal methods,Model transformation,Modelling environments},
number = {4},
pages = {769--784},
primaryClass = {arXiv:cond-mat},
title = {{Supporting user-oriented analysis for multi-view domain-specific visual languages}},
volume = {51},
year = {2009}
}
@article{Bengio2009,
abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.},
archivePrefix = {arXiv},
arxivId = {submit/0500581},
author = {Bengio, Yoshua},
doi = {10.1561/2200000006},
eprint = {0500581},
file = {:home/memo/Mendeley/data/Bengio - 2009 - Learning Deep Architectures for AI.pdf:pdf;:home/memo/Mendeley/data/Bengio - 2009 - Learning Deep Architectures for AI(2).pdf:pdf},
isbn = {2200000006},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--127},
pmid = {17348934},
primaryClass = {submit},
title = {{Learning Deep Architectures for AI}},
volume = {2},
year = {2009}
}
@article{Friedman2014,
author = {Friedman, Ken},
file = {:home/memo/Mendeley/data/Friedman - 2014 - Writing for the PhD in Art and Design . Issues for Research Supervisors and Research Students Working Paper.pdf:pdf},
title = {{Writing for the PhD in Art and Design . Issues for Research Supervisors and Research Students Working Paper}},
year = {2014}
}
@article{Greena,
author = {Green, Simon},
file = {:home/memo/Mendeley/data/Green - Unknown - CUDA Particle-based Fluid Simulation.pdf:pdf},
title = {{CUDA Particle-based Fluid Simulation}}
}
@article{Timonen,
author = {Timonen, Ville},
file = {:home/memo/Mendeley/data/Timonen - 2013 - Screen-Space Far-Field Ambient Obscurance.pdf:pdf},
journal = {Proceedings of the 5th High-Performance Graphics {\ldots}},
title = {{Screen-Space Far-Field Ambient Obscurance}},
url = {http://dl.acm.org/citation.cfm?id=2492049},
volume = {1280},
year = {2013}
}
@article{Jr2013,
abstract = {3D gestural interaction provides a powerful and natural way to interact with computers using the hands and body for a variety of different applications including video games, training and simulation, and medicine. However, accurately recognizing 3D gestures so that they can be reliably used in these applications poses many different research challenges. In this paper, we examine the state of the field of 3D gestural interfaces by presenting the latest strategies on how to collect the raw 3D gesture data from the user and how to accurately analyze this raw data to correctly recognize 3D gestures users perform. In addition, we examine the latest in 3D gesture recognition performance in terms of accuracy and gesture set size and discuss how different applications are making use of 3D gestural interaction. Finally, we present ideas for future research in this thriving and active research area.},
author = {{LaViola Jr.}, J. J.},
doi = {10.1155/2013/514641},
issn = {2090-7443},
journal = {ISRN Artificial Intelligence 2013},
number = {2},
pages = {1 -- 18},
title = {{3D Gestural Interaction: The State of the Field}},
volume = {2013},
year = {2013}
}
@inproceedings{Schuster1999,
author = {Schuster, Mike},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {589--595},
title = {{Better Generative Models for Sequential Data Problems: Bidirectional Recurrent Mixture Density Networks}},
year = {1999}
}
@article{Elinas2000b,
author = {Elinas, Pantelis and Stuerzlinger, Wolfgang},
doi = {10.1080/10867651.2000.10487531},
file = {:home/memo/Mendeley/data/Elinas, Stuerzlinger - 2000 - Real-time Rendering of 3D Clouds.pdf:pdf},
issn = {1086-7651},
journal = {Journal of Graphics Tools},
month = {jan},
number = {4},
pages = {33--45},
title = {{Real-time Rendering of 3D Clouds}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10867651.2000.10487531},
volume = {5},
year = {2000}
}
@misc{Karpathy2015charrnn,
author = {Karpathy, Andrej},
title = {char-rnn},
url = {https://github.com/karpathy/char-rnn},
year = {2015}
}
@misc{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - 163886229.pdf.pdf:pdf},
title = {163886229.pdf}
}
@article{Witkin2001b,
author = {Witkin, Andrew and Baraff, David},
file = {:home/memo/Mendeley/data/Witkin, Baraff - 2001 - Physically Based Modeling Differential Equation Basics Differential Equation Basics.pdf:pdf},
title = {{Physically Based Modeling Differential Equation Basics Differential Equation Basics}},
year = {2001}
}
@article{Graves2014,
abstract = {We extend the capabilities of neural networks by coupling them to external memory re-sources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demon-strate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.5401v2},
author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
eprint = {arXiv:1410.5401v2},
file = {:home/memo/Mendeley/data/Graves, Wayne, Danihelka - 2014 - Neural Turing Machines.pdf:pdf;:home/memo/Mendeley/data/Graves, Wayne, Danihelka - 2014 - Neural Turing Machines(2).pdf:pdf},
journal = {arXiv preprint arXiv:1410.5401},
pages = {1--26},
title = {{Neural Turing Machines}},
url = {http://arxiv.org/abs/1410.5401},
year = {2014}
}
@article{Bastian2012c,
abstract = {Across two studies we show that engaging in violent video game play diminishes perceptions of our own human qualities. In addition, when other players are the targets of this violence it reduces our perceptions of their humanity also. In Study 1, we demonstrate that playing Mortal Kombat against another player reduces the perceived humanity of the self as well as the humanity of one's opponent (compared to playing a non-violent game). In Study 2 we replicate this effect on perceived humanity of the self when playing a violent game with a co-player. However, we find no dehumanization of co-players who are not the targets of violence. We demonstrate these effects cannot be reduced to mood, self-esteem, gender, or other characteristics of the game such as excitement and enjoyment. The findings provide a broader perspective from which to view previous work on the adverse effects of violent video games. ?? 2011 Elsevier Inc..},
author = {Bastian, Brock and Jetten, Jolanda and Radke, Helena R.M. M},
doi = {10.1016/j.jesp.2011.10.009},
file = {:home/memo/Mendeley/data/Bastian, Jetten, Radke - 2012 - Cyber-dehumanization Violent video game play diminishes our humanity.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Dehumanization,Self-perception,Video game,Violence},
month = {mar},
number = {2},
pages = {486--491},
publisher = {Elsevier Inc.},
title = {{Cyber-dehumanization: Violent video game play diminishes our humanity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103111002526},
volume = {48},
year = {2012}
}
@article{Carre2013,
abstract = {Initially thought of as a unitary ability, empathy has been more recently considered to consist of 2 components (i.e., an affective and a cognitive component). The Basic Empathy Scale (BES) is a tool that has been used to assess empathy in young people and adolescents on the basis of this dual-component conception (Jolliffe {\{}{\&}{\}} Farrington, 2006). Recent studies of empathy have led to it being defined as underpinned by 3 components, namely, emotional contagion, emotional disconnection, and cognitive empathy. The aims of this study were (a) to validate the BES in Adults and (b) to compare the different conceptions of empathy. Three hundred seventy French adults took part in the study, and 160 of them filled out complementary scales measuring empathy, alexithymia, and emotional consciousness. The confirmatory factor analyses showed that the 3-factor model was the model that was best able to account for the data. Complementary tools confirmed the relationships previously observed between empathy as assessed with the BES and other scales assessing emotional processes. The results of this study make it clear that empathy can be seen as process-dependent. This conception of empathy, which is based on 3 factors, is consistent with the current, more integrated view of empathy. The implications of this conception and the opportunity to use the 2 or 3 factors of the BES in adults are presented in the discussion.},
author = {Carr{\'{e}}, Arnaud and Stefaniak, Nicolas and D'Ambrosio, Fanny and Bensalah, Le{\"{i}}la and Besche-Richard, Chrystel},
doi = {10.1037/a0032297},
file = {:home/memo/Mendeley/data/Carr{\'{e}} et al. - 2013 - The Basic Empathy Scale in adults (BES-A) factor structure of a revised form.pdf:pdf},
issn = {1939-134X},
journal = {Psychological assessment},
keywords = {Adult,Affective Symptoms,Affective Symptoms: diagnosis,Affective Symptoms: psychology,Emotions,Empathy,Factor Analysis,Female,Humans,Male,Psychological Tests,Psychometrics,Questionnaires,Reproducibility of Results,Statistical},
month = {sep},
number = {3},
pages = {679--691},
pmid = {23815121},
title = {{The Basic Empathy Scale in adults (BES-A): factor structure of a revised form.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23815121},
volume = {25},
year = {2013}
}
@article{Schmidhuber2007,
abstract = {I postulate that human or other intelligent agents function or should function as follows. They store all sensory observations as they come - the data is holy. At any time, given some agent's current coding capabilities, part of the data is compressible by a short and hopefully fast program description explanation world model. In the agent's subjective eyes, such data is more regular and more "beautiful" than other data. It is well-known that knowledge of regularity and repeatability may improve the agent's ability to plan actions leading to external rewards. In absence of such rewards, however, known beauty is boring. Then "interestingness" becomes the first derivative of subjective beauty: as the learning agent improves its compression algorithm, formerly apparently random data parts become subjectively more regular and beautiful. Such progress in compressibility is measured and maximized by the curiosity drive: create action sequences that extend the observation history and yield previously unknown unpredictable but quickly learnable algorithmic regularity. We discuss how all of the above can be naturally implemented on computers, through an extension of passive unsupervised learning to the case of active data selection: we reward a general reinforcement learner (with access to the adaptive compressor) for actions that improve the subjective compressibility of the growing data. An unusually large breakthrough in compressibility deserves the name "discovery". The "creativity" of artists, dancers, musicians, pure mathematicians can be viewed as a by-product of this principle. Several qualitative examples support this hypothesis.},
archivePrefix = {arXiv},
arxivId = {arXiv:0709.0674v1},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1007/978-3-540-75488-6},
eprint = {arXiv:0709.0674v1},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2007 - Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective Attention, Curiosity {\&} Creativity(2).pdf:pdf},
isbn = {9783540752240},
issn = {03029743},
journal = {Discovery Science},
number = {September},
pages = {15},
title = {{Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective Attention, Curiosity {\&} Creativity}},
url = {http://arxiv.org/abs/0709.0674},
volume = {4755},
year = {2007}
}
@article{Greff2015,
abstract = {Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search and their importance was assessed using the powerful fANOVA framework. In total, we summarize the results of 5400 experimental runs (about 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
archivePrefix = {arXiv},
arxivId = {1503.04069},
author = {Greff, Klaus and Srivastava, Rupesh Kumar and Koutn{\'{i}}k, Jan and Steunebrink, Bas R and Schmidhuber, J{\"{u}}rgen},
doi = {10.1017/CBO9781107415324.004},
eprint = {1503.04069},
file = {:home/memo/Mendeley/data/Greff et al. - 2015 - LSTM A Search Space Odyssey.pdf:pdf},
isbn = {9788578110796},
issn = {19454589},
journal = {arXiv preprint arXiv:1503.04069},
pages = {10},
pmid = {25246403},
title = {{LSTM: A Search Space Odyssey}},
url = {http://arxiv.org/abs/1503.04069},
year = {2015}
}
@article{Dourish2001a,
abstract = {Context-aware computing is generally associated with elements of the ubiquitous computing program, and the opportunity to distribute computation and interaction through the environment rather than concentrating it at the desktop computer. However, issues of context have also been important in other areas of human-computer interaction research. I argue that the scope of context-based computing should be extended to include not only ubiquitous computing, but also recent trends in tangible interfaces as well as work on sociological investigations of the organization of interactive behavior. By taking a view of context-aware computing that integrates these different perspectives, we can begin to understand the foundational relations that tie them all together, and that provide a framework for understanding the basic principles behind these various forms of embodied interaction. In particular, I point to phenomenology as a basis for the development of a new framework for design and evaluation of context-aware technologies.},
author = {Dourish, Paul},
doi = {10.1207/S15327051HCI16234_07},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dourish - 2001 - Seeking a Foundation for Context-Aware Computing Corresponding Author ' s Contact Information Department of Informatio.pdf:pdf},
issn = {07370024},
journal = {Human–Computer Interaction},
pages = {229--241},
pmid = {19090989},
title = {{Seeking a Foundation for Context-Aware Computing Corresponding Author ' s Contact Information : Department of Information}},
url = {http://portal.acm.org/citation.cfm?id=1463108.1463115},
volume = {16},
year = {2001}
}
@article{ORegan2001,
abstract = {Many current neurophysiological, psychophysical, and psychological approaches to vision rest on the idea that when we see, the brain produces an internal representation of the world. The activation of this internal representation is assumed to give rise to the experience of seeing. The problem with this kind of approach is that it leaves unexplained how the existence of such a detailed internal representation might produce visual consciousness. An alternative proposal is made here. We propose that seeing is a way of acting. It is a particular way of exploring the environment. Activity in internal representations does not generate the experience of seeing. The outside world serves as its own, external, representation. The experience of seeing occurs when the organism masters what we call the governing laws of sensorimotor contingency. The advantage of this approach is that it provides a natural and principled way of accounting for visual consciousness, and for the differences in the perceived quality of sensory experience in the different sensory modalities. Several lines of empirical evidence are brought forward in support of the theory, in particular: evidence from experiments in sensorimotor adaptation, visual "filling in," visual stability despite eye movements, change blindness, sensory substitution, and color perception.},
author = {O'Regan, J K and No{\"{e}}, a},
doi = {10.1017/S0140525X01000115},
file = {:home/memo/Mendeley/data/O'Regan, No{\"{e}} - 2001 - A sensorimotor account of vision and visual consciousness.pdf:pdf},
isbn = {0140-525X},
issn = {0140-525X},
journal = {The Behavioral and brain sciences},
keywords = {action,change blindness,consciousness,experience,perception,qualia,sensation,sensorimotor},
pages = {939--1031},
pmid = {12239892},
title = {{A sensorimotor account of vision and visual consciousness.}},
volume = {24},
year = {2001}
}
@inproceedings{Le2012unsupervised,
abstract = {We consider the problem of building high- level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 bil- lion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental re- sults reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod- ies. Starting with these learned features, we trained our network to obtain 15.8{\%} accu- racy in recognizing 20,000 object categories from ImageNet, a leap of 70{\%} relative im- provement over the previous state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1112.6209},
author = {Le, Quoc V. and Ranzato, Marc'Aurelio Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
booktitle = {Proceedings of the 29th International Conference on Machine Learning},
doi = {10.1109/MSP.2011.940881},
eprint = {1112.6209},
file = {:home/memo/Mendeley/data/Le et al. - 2012 - Building high-level features using large scale unsupervised learning.pdf:pdf},
isbn = {9781450312851},
issn = {10535888},
keywords = {deep learning,unsupervised learning},
title = {{Building high-level features using large scale unsupervised learning}},
year = {2012}
}
@article{Schmidhuber2009b,
author = {Schmidhuber, J{\"{u}}rgen},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2009 - Art {\{}{\&}{\}} science as by-products of the search for novel patterns, or data compressible in unknown yet learnable ways.pdf:pdf},
journal = {Multiple ways to design research. Research cases that reshape the design discipline},
pages = {98--112},
title = {{Art {\{}{\&}{\}} science as by-products of the search for novel patterns, or data compressible in unknown yet learnable ways}},
year = {2009}
}
@article{Tramer2016,
archivePrefix = {arXiv},
arxivId = {1609.02943},
author = {Tram{\`{e}}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael and Ristenpart, Thomas},
eprint = {1609.02943},
file = {:home/memo/Mendeley/data/Tram{\`{e}}r et al. - 2016 - Stealing Machine Learning Models via Prediction APIs.pdf:pdf;:home/memo/Mendeley/data/Tram{\`{e}}r et al. - 2016 - Stealing Machine Learning Models via Prediction APIs(2).pdf:pdf},
isbn = {9781931971324},
journal = {Usenix Security},
number = {Ml},
pages = {2016},
title = {{Stealing Machine Learning Models via Prediction APIs}},
year = {2016}
}
@article{Caramiaux,
author = {Caramiaux, Baptiste and Donnarumma, Marco and Tanaka, Atau},
file = {:home/memo/Mendeley/data/Caramiaux, Donnarumma, Tanaka - 2015 - Understanding Gesture Expressivity through Muscle Sensing.pdf:pdf;:home/memo/Mendeley/data/Caramiaux, Donnarumma, Tanaka - 2015 - Understanding Gesture Expressivity through Muscle Sensing(2).pdf:pdf},
journal = {ACM Transactions on Computer-Human Interaction},
number = {0},
pages = {1--27},
title = {{Understanding Gesture Expressivity through Muscle Sensing}},
volume = {0},
year = {2015}
}
@article{Schofield2013a,
author = {Schofield, Tom and Vines, John and Higham, Tom and Carter, Ed and Akten, Mehmet and Golding, Amy and Atken, Memo and Golding, Amy},
doi = {10.1145/2466627.2466640},
file = {:home/memo/Mendeley/data/Schofield et al. - 2013 - Trigger Shift Participatory Design of an Augmented Theatrical Performance with Young People(2).pdf:pdf;:home/memo/Mendeley/data/Schofield et al. - 2013 - Trigger Shift Participatory Design of an Augmented Theatrical Performance with Young People.pdf:pdf},
isbn = {9781450321501},
journal = {Proceedings of C{\&}C 2013},
pages = {203--212},
title = {{Trigger Shift: Participatory Design of an Augmented Theatrical Performance with Young People}},
url = {http://di.ncl.ac.uk/publicweb/publications/Schofield et al - 2013 - TriggerShift.pdf},
year = {2013}
}
@article{Wigner1960,
abstract = {Richard courant lecture in mathematical sciences delivered at New York University, May 11, 1959},
author = {Wigner, Eugene P},
doi = {10.1002/cpa.3160130102},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wigner - 1960 - The unreasonable effectiveness of mathematics in the natural sciences. Richard courant lecture in mathematical scienc(2).pdf:pdf},
isbn = {053403201X},
issn = {00103640},
journal = {Communications on Pure and Applied Mathematics},
number = {1},
pages = {1--14},
pmid = {12384684},
title = {{The unreasonable effectiveness of mathematics in the natural sciences. Richard courant lecture in mathematical sciences delivered at New York University, May 11, 1959}},
url = {http://dx.doi.org/10.1002/cpa.3160130102{\%}7B{\%}25{\%}7D5Cnhttp://doi.wiley.com/10.1002/cpa.3160130102 http://dx.doi.org/10.1002/cpa.3160130102{\%}5Cnhttp://doi.wiley.com/10.1002/cpa.3160130102},
volume = {13},
year = {1960}
}
@article{Hornacek2014,
author = {Horn{\'{a}}{\v{c}}ek, Michael and Fitzgibbon, Andrew and Rother, Carsten},
doi = {10.1109/CVPR.2014.451},
file = {:home/memo/Mendeley/data/Horn{\'{a}}{\v{c}}ek, Fitzgibbon, Rother - 2014 - SphereFlow 6 DoF Scene Flow from RGB-D Pairs.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Cvpr},
title = {{SphereFlow: 6 DoF Scene Flow from RGB-D Pairs}},
year = {2014}
}
@article{Raptis2011,
abstract = {We present a real-time gesture classification system for skeletal wireframe motion. Its key components include an angular representation of the skeleton designed for recognition robustness under noisy input, a cascaded correlation-based classifier for multivariate time-series data, and a distance metric based on dynamic time-warping to evaluate the difference in motion between an acquired gesture and an oracle for the matching gesture. While the first and last tools are generic in nature and could be applied to any gesture-matching scenario, the classifier is conceived based on the assumption that the input motion adheres to a known, canonical time-base: a musical beat. On a benchmark comprising 28 gesture classes, hundreds of gesture instances recorded using the XBOX Kinect platform and performed by dozens of subjects for each gesture class, our classifier has an average accuracy of 96:9{\%}, for approximately 4-second skeletal motion recordings. This accuracy is remarkable given the input noise from the real-time depth sensor.},
author = {Raptis, Michalis and Kirovski, Darko and Hoppe, Hugues},
doi = {10.1145/2019406.2019426},
file = {:home/memo/Mendeley/data/Raptis, Kirovski, Hoppe - 2011 - Real-time classification of dance gestures from skeleton animation.pdf:pdf},
isbn = {9781450309233},
journal = {Proceedings of the 2011 ACM SIGGRAPHEurographics Symposium on Computer Animation SCA 11},
pages = {147},
title = {{Real-time classification of dance gestures from skeleton animation}},
url = {http://dl.acm.org/citation.cfm?doid=2019406.2019426},
volume = {1},
year = {2011}
}
@article{Gillian2013,
author = {Gillian, Nicholas and Environments, Responsive},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gillian, Environments - 2013 - IAP Gesture Recognition Workshop Session 1 Gesture Recognition {\{}{\&}{\}} Machine Learning Fundamentals My Rese.pdf:pdf},
title = {{IAP Gesture Recognition Workshop Session 1 : Gesture Recognition {\{}{\&}{\}} Machine Learning Fundamentals My Research}},
year = {2013}
}
@inproceedings{Nguyen2015,
abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between com- puter and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the- art DNNs believe to be recognizable objects with 99.99{\{}{\%}{\}} confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neu- ral networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possi- ble to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling ex- amples). Our results shed light on interesting differences between human vision and current DNNs, and raise ques- tions about the generality of DNN computer vision},
author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
file = {:home/memo/Mendeley/data/Nguyen, Anh aYosinski, Jason and Clune - 2015 - Deep neural networks are easily fooled High confidence predictions for unrecognizable im.pdf:pdf},
pages = {427--436},
title = {{Deep neural networks are easily fooled: High confidence predictions for unrecognizable images}},
year = {2015}
}
@misc{LeapMotion,
author = {LeapMotion},
title = {{LeapMotion}},
url = {https://www.leapmotion.com/}
}
@article{Carnagey2007,
abstract = {Past research shows that violent video game exposure increases aggressive thoughts, angry feelings, physiological arousal, aggressive behaviors, and decreases helpful behaviors. However, no research has experimentally examined violent video game effects on physiological desensitization, defined as showing less physiological arousal to violence in the real world after exposure to video game violence in the virtual world. This experiment attempts to fill this gap. Participants reported their media habits and then played one of eight violent or nonviolent video games for 20 min. Next, participants watched a 10-min videotape containing scenes of real-life violence while heart rate (HR) and galvanic skin response (GSR) were monitored. Participants who previously played a violent video game had lower HR and GSR while viewing filmed real violence, demonstrating a physiological desensitization to violence. Results are interpreted using an expanded version of the General Aggression Model. Links between desensitization, antisocial, and prosocial behavior are discussed. {\{}{\textcopyright}{\}} 2006 Elsevier Inc. All rights reserved.},
author = {Carnagey, Nicholas L. and Anderson, Craig A. and Bushman, Brad J.},
doi = {10.1016/j.jesp.2006.05.003},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carnagey, Anderson, Bushman - 2007 - The effect of video game violence on physiological desensitization to real-life violence.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Desensitization,Helping,Prosocial,Violent media,Violent video games},
pages = {489--496},
title = {{The effect of video game violence on physiological desensitization to real-life violence}},
volume = {43},
year = {2007}
}
@article{Witkin2001k,
author = {Witkin, Andrew},
file = {:home/memo/Mendeley/data/Witkin - 2001 - Physically Based Modeling Particle System Dynamics Particle System Dynamics.pdf:pdf},
title = {{Physically Based Modeling Particle System Dynamics Particle System Dynamics}},
year = {2001}
}
@article{Wallenius2008b,
abstract = {This study investigated the roles of sex, age, and parent-child communication in moderating the association between digital game violence and direct aggression in a two-year longitudinal study. Finnish 12- and 15-year-old adolescents (N = 316) participated in the follow-up survey. As hypothesized, digital game violence was linked to direct aggression both longitudinally and synchronously, and the link was moderated by parent-child communication in interaction with sex and age. Results suggest that the moderating role of parent-child communication changes with increasing age. Poor parent-child communication may be one of the factors in an adolescent's development that may strengthen the negative effects of digital game violence, but even good parent-child communication does not necessarily protect the adolescent in the long run. Digital game violence seems to be one of the risk factors of increased aggressive behavior. {\{}{\textcopyright}{\}} 2008 Elsevier B.V. All rights reserved.},
author = {Wallenius, Marjut and Punam{\"{a}}ki, Raija-Leena Leena},
doi = {10.1016/j.appdev.2008.04.010},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallenius, Punam{\"{a}}ki - 2008 - Digital game violence and direct aggression in adolescence A longitudinal study of the roles of sex, ag(2).pdf:pdf},
isbn = {0193-3973},
issn = {01933973},
journal = {Journal of Applied Developmental Psychology},
keywords = {Adolescents,Digital game violence,Direct aggression,Longitudinal study,Parent-child communication},
month = {jul},
number = {4},
pages = {286--294},
title = {{Digital game violence and direct aggression in adolescence: A longitudinal study of the roles of sex, age, and parent-child communication}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0193397308000336},
volume = {29},
year = {2008}
}
@misc{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - 75020514.pdf.pdf:pdf},
title = {75020514.pdf}
}
@article{Trobe1995,
author = {Trobe, La and Melbourne, Street},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trobe, Melbourne - 1995 - From Proceedings of the First International Conference on Multiagent Systems. Copyright {\{}{\textcopyright}{\}} 1995, AAAI (www.a.pdf:pdf},
journal = {Practice},
title = {{From: Proceedings of the First International Conference on Multiagent Systems. Copyright {\{}{\textcopyright}{\}} 1995, AAAI (www.aaai.org). All rights reserved.}},
year = {1995}
}
@article{Schmidhuber2010a,
abstract = {I have argued that a simple but general formal theory of creativity explains many essential aspects of intelligence including science, art, music, humor. It is based on the concept of maximizing reward for the creation or discovery of novel patterns allowing for improved data compression or prediction. Here I discuss what kind of general bias towards algorithmic regularities we insert into our robots by implementing the principle, why that bias is good, and how the approach greatly generalizes the ﬁeld of active learning. I emphasize the importance of limited computational resources for online prediction and compression, and provide discrete and continuous time formulations for ongoing work on building an Artiﬁcial General Intelligence (AGI) based on variants of the artiﬁcial creativity framework.},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.2991/agi.2010.32},
file = {:home/memo/Mendeley/data/Schmidhuber - 2010 - Artificial scientists {\{}{\&}{\}} artists based on the formal theory of creativity.pdf:pdf},
isbn = {9789078677369},
journal = {Proceedings of the 3d Conference on Artificial General Intelligence (AGI 2010), Lugano, Switzerland},
pages = {145--150},
title = {{Artificial scientists {\{}{\&}{\}} artists based on the formal theory of creativity}},
url = {http://agi-conf.org/2010/wp-content/uploads/2009/06/paper{\_}46.pdf http://agi-conf.org/2010/wp-content/uploads/2009/06/paper{\%}7B{\_}{\%}7D46.pdf},
year = {2010}
}
@article{Oetiker2014,
author = {Oetiker, T and Partl, Hubert and Hyna, Irene and Schlegl, Elisabeth},
file = {:home/memo/Mendeley/data/Oetiker et al. - 2014 - The not so short introduction to LATEX2{\$}\epsilon{\$}.pdf:pdf},
title = {{The not so short introduction to LATEX2{\$}\epsilon{\$}}},
url = {http://jamsb.austms.org.au/resources/LaTeX/lshort.pdf},
year = {2014}
}
@article{Whatley,
author = {Whatley, David},
file = {:home/memo/Mendeley/data/Whatley - Unknown - GPU Gems - Chapter 1{\{}{\_}{\}} Toward Photorealism in Virtual Botany.pdf:pdf},
title = {{GPU Gems - Chapter 1{\{}{\_}{\}} Toward Photorealism in Virtual Botany}},
volume = {3}
}
@misc{Akten2015-msaOscML,
author = {Akten, Memo},
title = {{msaOscML}},
url = {https://github.com/memo/msaOscML},
year = {2015}
}
@article{hornik1989multilayer,
author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
file = {:home/memo/Mendeley/data/Hornik, Stinchcombe, White - 1989 - Multilayer feedforward networks are universal approximators.pdf:pdf},
journal = {Neural networks},
number = {5},
pages = {359--366},
publisher = {Elsevier},
title = {{Multilayer feedforward networks are universal approximators}},
volume = {2},
year = {1989}
}
@article{Tenenbaum,
author = {Tenenbaum, Joshua B and Kemp, Charles and Shafto, Patrick},
file = {:home/memo/Mendeley/data/Tenenbaum, Kemp, Shafto - 2007 - Theory-based Bayesian models of inductive reasoning.pdf:pdf},
title = {{Theory-based Bayesian Models of Inductive Reasoning}}
}
@misc{Beckermann1992,
author = {Beckermann, Ansgar},
booktitle = {{\{}{\{}{\}}E{\{}{\}}{\}}mergence or reduction?},
isbn = {3110128802},
keywords = {Philosophie;Philosophie des Geistes;Emergenztheori},
pages = {94--118},
title = {{{\{}{\{}{\}}S{\{}{\}}{\}}upervenience, {\{}{\{}{\}}E{\{}{\}}{\}}mergence, and {\{}{\{}{\}}R{\{}{\}}{\}}eduction}},
year = {1992}
}
@article{Gillies2011,
abstract = {We present the results of a group interview of choreographers aimed at understanding their conceptions of how movement can be used to in live performance. This understanding intended to inform research into full body interaction for live performance and other more general full body interfaces. The results of the interview suggest a new way of conceiving of interaction with digital technology, neither as a representation of movement, not as an interface that responds to movement but as a means of transforming movement. This transformed movement can then serve as a starting point for a dancers responses to transformations of their own movement thus setting up an improvisational feedback loop.},
author = {Gillies, Marco and Worgan, Max and Peppe, Hestia and Robinson, Will and Kov, Nina},
keywords = {Choreography,Human-computer Interaction},
title = {{Exploring Choreographers' Conceptions of Motion Capture for Full Body Interaction}},
url = {http://eprints.gold.ac.uk/5779/},
volume = {3},
year = {2011}
}
@misc{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - Gold67Limit.pdf:pdf},
title = {{Gold67Limit}}
}
@article{White2016,
author = {White, Tom},
file = {:home/memo/Mendeley/data/White - 2016 - Notes on a Few Effective Techniques.pdf:pdf},
keywords = {analogies with j-diagrams,and genearting local manifolds,close to the trained,combined generate low,dimensional embeddings of images,gan,generative,manifold,mine grids,sampling,these techniques can be,vae,with},
title = {{Notes on a Few Effective Techniques}},
year = {2016}
}
@article{Naftaly1997,
abstract = {Based on an observation about the different effect of ensemble averaging on the bias and variance portions of the prediction error, we discuss training methodologies for ensembles of networks. We demonstrate the effect of variance reduction and present a method of extrapolation to the limit of an infinite ensemble. A significant reduction of variance is obtained by averaging just over initial conditions of the neural networks, without varying architectures or training sets. The minimum of the ensemble prediction error is reached later than that of a single network. In the vicinity of the minimum, the ensemble prediction error appears to be flatter than that of the single network, thus simplifying optimal stopping decision. The results are demonstrated on sunspots data, where the predictions are among the best obtained, and on the 1993 energy prediction competition data set B. {\textcopyright} 1997 IOP Publishing Ltd.},
author = {Naftaly, U and Intrator, N and Horn, D},
doi = {10.1088/0954-898X/8/3/004},
file = {:home/memo/Mendeley/data/Naftaly, Intrator, Horn - 1997 - Optimal ensemble averaging of neural networks.pdf:pdf},
issn = {0954898X (ISSN)},
journal = {Network: Computation in Neural Systems},
number = {3},
pages = {283--296},
title = {{Optimal ensemble averaging of neural networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0001066312{\&}partnerID=40{\&}md5=518dc0c4b4faf90847263a1330eeacc5},
volume = {8},
year = {1997}
}
@article{Williams1989,
abstract = {The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Williams, Ronald J. and Zipser, David},
doi = {10.1162/neco.1989.1.2.270},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Williams, Zipser - 1989 - A Learning Algorithm for Continually Running Fully Recurrent Neural Networks.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
number = {2},
pages = {270--280},
pmid = {20505160},
title = {{A Learning Algorithm for Continually Running Fully Recurrent Neural Networks}},
volume = {1},
year = {1989}
}
@article{Oord2016a,
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder, creating . Additionally, the gated convolutional layers in the proposed model improve the loglikelihood of PixelCNN to match the stateoftheart performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
author = {van den Oord, Aaron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
file = {:home/memo/Mendeley/data/Oord et al. - 2016 - Conditional Image Generation with PixelCNN Decoders.pdf:pdf},
journal = {arXiv preprint arXiv:1606.05328},
title = {{Conditional Image Generation with PixelCNN Decoders}},
year = {2016}
}
@article{Kiros2014,
abstract = {Inspired by recent advances in multimodal learning and machine translation, we introduce an encoder-decoder pipeline that learns (a): a multimodal joint embedding space with images and text and (b): a novel language model for decoding distributed representations from our space. Our pipeline effectively unifies joint image-text embedding models with multimodal neural language models. We introduce the structure-content neural language model that disentangles the structure of a sentence to its content, conditioned on representations produced by the encoder. The encoder allows one to rank images and sentences while the decoder can generate novel descriptions from scratch. Using LSTM to encode sentences, we match the state-of-the-art performance on Flickr8K and Flickr30K without using object detections. We also set new best results when using the 19-layer Oxford convolutional network. Furthermore we show that with linear encoders, the learned embedding space captures multimodal regularities in terms of vector space arithmetic e.g. *image of a blue car* - "blue" + "red" is near images of red cars. Sample captions generated for 800 images are made available for comparison.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.2539v1},
author = {Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S},
eprint = {arXiv:1411.2539v1},
file = {:home/memo/Mendeley/data/Kiros, Salakhutdinov, Zemel - 2014 - Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models.pdf:pdf},
journal = {arXiv preprint arXiv:1411.2539},
pages = {1--13},
title = {{Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models}},
year = {2014}
}
@article{Oord2016,
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.},
author = {van den Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
file = {:home/memo/Mendeley/data/Oord, Kalchbrenner, Kavukcuoglu - 2016 - Pixel Recurrent Neural Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1601.06759},
title = {{Pixel Recurrent Neural Networks}},
year = {2016}
}
@article{Wackermann2008,
abstract = {Ganzfeld, i.e., exposure to an unstructured, uniform stimulation field, elicits in most observers pseudo-hallucinatory percepts, and may even induce global functional state changes ('altered states of consciousness'). The present paper gives a comprehensive overview of the phenomenology of subjective experience in the ganzfeld and its electrophysiological correlates. Laboratory techniques for visual or multi-modal ganzfeld induction are explained. The spectrum of ganzfeld-induced phenomena, ranging from elementary percepts to complex, vivid, dream-like imagery is described, and the latter illustrated by transcripts of subjects' reports. Similarities and differences to related sensory/perceptual phenomena are also discussed. Earlier findings on electrophysiological correlates of the ganzfeld are reviewed. Our own studies of electroencephalographic (EEG) activity in the ganzfeld are presented in some detail, and a re-analysis of data on EEG correlates of hallucinatory percepts in statu nascendi is reported. The results do not support the hypothesis of the hypnagogic origin of the percepts; the ganzfeld-induced steady-state is an activated state, and the spectral EEG dynamics in the alpha frequency range reveals processes of attention shifts and percept formation. The final section is devoted to the controversial topic of allegedly anomalous communication between human subjects ('ganzfeld telepathy'). It is shown that the use of ganzfeld in this research field relies partly on unsupported hypotheses concerning ganzfeld-induced states, partly on a weak conceptual background of the experimental procedure. The r??le of a particular belief system shared by the participants and experimenters is critically discussed. ?? 2008 Elsevier Srl. All rights reserved.},
author = {Wackermann, Ji???? and P??tz, Peter and Allefeld, Carsten},
doi = {10.1016/j.cortex.2007.05.003},
file = {:home/memo/Mendeley/data/Wackermann, Ptz, Allefeld - 2008 - Ganzfeld-induced hallucinatory experience, its phenomenology and cerebral electrophysiology.pdf:pdf},
isbn = {0010-9452 (Print)$\backslash$r0010-9452 (Linking)},
issn = {00109452},
journal = {Cortex},
keywords = {Altered states of consciousness,Electroencephalogram,Ganzfeld,Imagery,Subjective perceptual phenomena,Telepathy},
number = {10},
pages = {1364--1378},
pmid = {18621366},
title = {{Ganzfeld-induced hallucinatory experience, its phenomenology and cerebral electrophysiology}},
volume = {44},
year = {2008}
}
@article{dieleman2016wavenet,
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
file = {:home/memo/Mendeley/data/Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf:pdf},
journal = {arXiv preprint arXiv:1609.03499},
title = {{WaveNet: A Generative Model for Raw Audio}},
year = {2016}
}
@phdthesis{gers2001long,
author = {Gers, Felix},
file = {:home/memo/Mendeley/data/Gers - 2001 - Long Short-Term Memory in Recurrent Neural Networks.pdf:pdf},
school = {ECOLE POLYTECHNIQUE F´ ERALE DE LAUSANNE},
title = {{Long Short-Term Memory in Recurrent Neural Networks}},
volume = {2366},
year = {2001}
}
@article{Torralba,
author = {Torralba, Antonio and Efros, Alexei A},
file = {:home/memo/Mendeley/data/Torralba, Efros - Unknown - Unbiased Look at Dataset Bias.pdf:pdf},
title = {{Unbiased Look at Dataset Bias}}
}
@article{Chung2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1609.01704v2},
author = {Chung, Junyoung and Ahn, Sungjin and Bengio, Yoshua},
eprint = {arXiv:1609.01704v2},
file = {:home/memo/Mendeley/data/Chung, Ahn, Bengio - 2016 - Hierarchical Multiscale Recurrent Neural Networks.pdf:pdf},
title = {{Hierarchical Multiscale Recurrent Neural Networks}},
year = {2016}
}
@article{gers2000learning,
author = {Gers, Felix A and Schmidhuber, J{\"{u}}rgen and Cummins, Fred},
file = {:home/memo/Mendeley/data/Gers, Schmidhuber, Cummins - 2000 - Learning to forget Continual prediction with LSTM.pdf:pdf},
journal = {Neural Computation},
number = {10},
pages = {2451--2471},
publisher = {MIT Press},
title = {{Learning to forget: Continual prediction with LSTM}},
volume = {12},
year = {2000}
}
@techreport{rumelhart1985learning,
author = {{Rumelhart, David E and Hinton, Geoffrey E and Williams}, Ronald J},
file = {:home/memo/Mendeley/data/Rumelhart, David E and Hinton, Geoffrey E and Williams - 1985 - Learning internal representations by error propagation.pdf:pdf},
institution = {DTIC Document},
title = {{Learning internal representations by error propagation}},
year = {1985}
}
@article{werbos1990backpropagation,
author = {Werbos, Paul J},
file = {:home/memo/Mendeley/data/Werbos - 1990 - Backpropagation through time what it does and how to do it.pdf:pdf},
journal = {Proceedings of the IEEE},
number = {10},
pages = {1559--1560},
publisher = {IEEE},
title = {{Backpropagation through time: what it does and how to do it}},
volume = {78},
year = {1990}
}
@techreport{Hutter2007,
author = {Hutter, Marcus},
file = {:home/memo/Mendeley/data/Hutter - 2007 - Algorithmic Information Theory a brief non-technical guide to the field.pdf:pdf},
title = {{Algorithmic Information Theory [ a brief non-technical guide to the field ]}},
year = {2007}
}
@article{Crooks2016,
author = {Crooks, Gavin E},
file = {:home/memo/Mendeley/data/Crooks - 2016 - Field Guide to Continuous Probability Distributions.pdf:pdf},
title = {{Field Guide to Continuous Probability Distributions}},
year = {2016}
}
@misc{otoro2015handwriting,
author = {Ha, David},
title = {{Generative Handwriting Demo using TensorFlow}},
url = {https://github.com/hardmaru/write-rnn-tensorflow},
year = {2015}
}
@article{Szegedy2016,
abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at rel-atively low computational cost. Recently, the introduction of residual connections in conjunction with a more tradi-tional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Incep-tion networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These varia-tions improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We fur-ther demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08{\%} top-5 error on the test set of the ImageNet classification (CLS) challenge.},
author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent},
file = {:home/memo/Mendeley/data/Szegedy, Ioffe, Vanhoucke - 2016 - Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.pdf:pdf},
journal = {arXiv preprint arXiv:1602.07261},
title = {{Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning}},
year = {2016}
}
@article{LaurentOrseau2016,
abstract = {Reinforcement learning agents interacting with a complex environment like the real world are unlikely to behave optimally all the time. If such an agent is operating in real-time under human supervision, now and then it may be necessary for a human operator to press the big red button to prevent the agent from continuing a harmful sequence of actions—harmful either for the agent or for the environment—and lead the agent into a safer situation. However, if the learning agent expects to receive rewards from this sequence, it may learn in the long run to avoid such interruptions, for example by disabling the red button — which is an undesirable outcome. This paper explores a way to make sure a learning agent will not learn to prevent (or seek!) being interrupted by the environment or a human operator. We provide a formal definition of safe interruptibility and exploit the off-policy learning property to prove that either some agents are already safely interruptible, like Q-learning, or can easily be made so, like Sarsa. We show that even ideal, uncomputable reinforcement learning agents for (deterministic) general computable environments can be made safely interruptible.},
author = {{Laurent Orseau} and Armstrong, Stuart},
file = {:home/memo/Mendeley/data/Laurent Orseau, Armstrong - 2016 - Safely interruptible agents.pdf:pdf},
journal = {32nd Conference on Uncertainty in Artificial Intelligence.},
title = {{Safely interruptible agents}},
url = {https://intelligence.org/files/Interruptibility.pdf},
year = {2016}
}
@article{Author2016a,
archivePrefix = {arXiv},
arxivId = {1608.04062},
author = {Author, Anonymous and Address, Affiliation},
eprint = {1608.04062},
file = {:home/memo/Mendeley/data/Author, Address - 2016 - Stacked Approximated Regression Machine A Simple Deep Learning Approach.pdf:pdf},
number = {Nips},
title = {{Stacked Approximated Regression Machine : A Simple Deep Learning Approach}},
year = {2016}
}
@article{Lin2016,
abstract = {We show how the success of deep learning depends not only on mathematics but also on physics: although well-known mathematical theorems guarantee that neural networks can approximate arbitrary functions well, the class of functions of practical interest can be approximated through "cheap learning" with exponentially fewer parameters than generic ones, because they have simplifying properties tracing back to the laws of physics. The exceptional simplicity of physics-based functions hinges on properties such as symmetry, locality, compositionality and polynomial log-probability, and we explore how these properties translate into exceptionally simple neural networks approximating both natural phenomena such as images and abstract representations thereof such as drawings. We further argue that when the statistical process generating the data is of a certain hierarchical form prevalent in physics and machine-learning, a deep neural network can be more efficient than a shallow one. We formalize these claims using information theory and discuss the relation to renormalization group procedures. Various "no-flattening theorems" show when these efficient deep networks cannot be accurately approximated by shallow ones without efficiency loss - even for linear networks.},
author = {Lin, Henry W and Tegmark, Max},
file = {:home/memo/Mendeley/data/Lin, Tegmark - 2016 - Why does deep and cheap learning work so well.pdf:pdf},
journal = {arXiv preprint arXiv:1608.08225},
title = {{Why does deep and cheap learning work so well?}},
year = {2016}
}
@article{Horvitz2016,
author = {Horvitz, Eric},
file = {:home/memo/Mendeley/data/Horvitz - 2016 - Artificial intelligence and life in 2030.pdf:pdf},
title = {{Artificial intelligence and life in 2030}},
year = {2016}
}
@article{bengio1994learning,
archivePrefix = {arXiv},
arxivId = {arXiv:1211.5063v2},
author = {Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
eprint = {arXiv:1211.5063v2},
file = {:home/memo/Mendeley/data/Bengio, Simard, Frasconi - 1994 - Learning long-term dependencies with gradient descent is difficult.pdf:pdf},
journal = {IEEE Transactions on Neural Networks},
number = {2},
pages = {157--166},
publisher = {IEEE},
title = {{Learning long-term dependencies with gradient descent is difficult}},
volume = {5},
year = {1994}
}
@article{Dick1910,
abstract = {Hello again, O Constant Reader. This is the third in my series of digitised American classics of literature. This text comes out about a month after the release of the movie Minority Report, which played no small part in its selection for conversion to eBook format. Those of you who enjoy science fiction and are tech savvy will undoubtedly notice the somewhat vague or antiquated word usage as far as the technology in the story is Stories by Philip K. Dick concerned. At present, I am working on a revised and expanded version of this story, to reflect the state of current technology and some of the possible avenues that are being pursued; you can expect to see that sometime later this year. On the topic of source, the text has been extracted from the book and, as always, the spelling conforms with my native British English, but doesn't at all The detract from the feeling of the story. Of course, if you wish to edit this, please feel free. I hope you enjoy it thoroughly. God Bless — Bastylle Minority Report and Other Classic},
author = {Dick, Philip K.},
doi = {10.1016/S0140-6736(00)51271-9},
file = {:home/memo/Mendeley/data/Dick - 1910 - The Minority Report.pdf:pdf},
isbn = {0806512768},
issn = {01406736},
journal = {The Eugenics review},
pages = {233--241},
pmid = {21259501},
title = {{The Minority Report}},
volume = {2},
year = {1910}
}
@unpublished{Jozefowicz2015,
author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
file = {:home/memo/Mendeley/data/Jozefowicz, Zaremba, Sutskever - 2015 - An Empirical Exploration of Recurrent Network Architectures.pdf:pdf},
title = {{An Empirical Exploration of Recurrent Network Architectures}},
volume = {37},
year = {2015}
}
@article{pascanu2012understanding,
author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
file = {:home/memo/Mendeley/data/Pascanu, Mikolov, Bengio - 2012 - Understanding the exploding gradient problem.pdf:pdf},
journal = {Computing Research Repository (CoRR) abs/1211.5063},
title = {{Understanding the exploding gradient problem}},
year = {2012}
}
@inproceedings{Gers2000,
author = {Gers, Felix A and Schmidhuber, J{\"{u}}rgen},
booktitle = {Neural Networks, 2000. IJCNN 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference on},
file = {:home/memo/Mendeley/data/Gers, Schmidhuber - 2000 - Recurrent nets that time and count.pdf:pdf},
pages = {189--194},
publisher = {IEEE},
title = {{Recurrent nets that time and count}},
year = {2000}
}
@inproceedings{Pascanu2013,
author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
booktitle = {International Conference on Machine Learning ICML},
file = {:home/memo/Mendeley/data/Pascanu, Mikolov, Bengio - 2013 - On the difficulty of training recurrent neural networks.pdf:pdf},
number = {3},
pages = {1310--1318},
title = {{On the difficulty of training recurrent neural networks}},
volume = {28},
year = {2013}
}
@article{Schmidhuber1992,
author = {Schmidhuber, J{\"{u}}rgen},
file = {:home/memo/Mendeley/data/Schmidhuber - 1992 - Learning complex, extended sequences using the principle of history compression.pdf:pdf},
journal = {Neural Computation},
number = {2},
pages = {234--242},
publisher = {MIT Press},
title = {{Learning complex, extended sequences using the principle of history compression}},
volume = {4},
year = {1992}
}
@misc{otorochinese2015,
author = {Ha, David},
title = {{Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow}},
url = {http://blog.otoro.net/2015/12/28/recurrent-net-dreams-up-fake-chinese-characters-in-vector-format-with-tensorflow/},
year = {2015}
}
@article{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - Set theory and functions.pdf:pdf},
pages = {1--29},
title = {{Set theory and functions}}
}
@article{Doersch2016,
abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
archivePrefix = {arXiv},
arxivId = {1606.05908},
author = {Doersch, Carl},
eprint = {1606.05908},
file = {:home/memo/Mendeley/data/Doersch - 2016 - Tutorial on Variational Autoencoders.pdf:pdf},
keywords = {neural networks,prediction,structured,unsupervised learning,variational autoencoders},
pages = {1--23},
title = {{Tutorial on Variational Autoencoders}},
url = {http://arxiv.org/abs/1606.05908},
year = {2016}
}
@article{Halevy2009,
abstract = {At Brown University, there is excitement of having access to the Brown Corpus, containing one million English words. Since then, we have seen several notable corpora that are about 100 times larger, and in 2006, Google released a trillion-word corpus with frequency counts for all sequences up to five words long. In some ways this corpus is a step backwards from the Brown Corpus: it's taken from unfiltered Web pages and thus contains incomplete sentences, spelling errors, grammatical errors, and all sorts of other errors. It's not annotated with carefully hand-corrected part-of-speech tags. But the fact that it's a million times larger than the Brown Corpus outweighs these drawbacks. A trillion-word corpus - along with other Web-derived corpora of millions, billions, or trillions of links, videos, images, tables, and user interactions - captures even very rare aspects of human behavior. So, this corpus could serve as the basis of a complete model for certain tasks - if only we knew how to extract the model from the data.},
archivePrefix = {arXiv},
arxivId = {arXiv:1201.1832v1},
author = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
doi = {10.1109/MIS.2009.36},
eprint = {arXiv:1201.1832v1},
file = {:home/memo/Mendeley/data/Halevy, Norvig, Pereira - 2009 - The Unreasonable Effectiveness of Data.pdf:pdf},
isbn = {1541-1672 VO - 24},
issn = {1541-1672},
journal = {IEEE Intelligent Systems},
keywords = {Semantic Web,machine learning,very large data bases},
number = {2},
pages = {8--12},
title = {{The Unreasonable Effectiveness of Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4804817},
volume = {24},
year = {2009}
}
@article{Martay2016,
abstract = {There are a number of ways to procedurally generate interesting three-dimensional shapes, and a method where a cellular neural network is combined with a mesh growth algorithm is presented here. The aim is to create a shape from a genetic code in such a way that a crude search can find interesting shapes. Identical neural networks are placed at each vertex of a mesh which can communicate with neural networks on neighboring vertices. The output of the neural networks determine how the mesh grows, allowing interesting shapes to be produced emergently, mimicking some of the complexity of biological organism development. Since the neural networks' parameters can be freely mutated, the approach is amenable for use in a genetic algorithm.},
archivePrefix = {arXiv},
arxivId = {1603.08551},
author = {Martay, Hugo},
eprint = {1603.08551},
file = {:home/memo/Mendeley/data/Martay - 2016 - Genetic cellular neural networks for generating three-dimensional geometry.pdf:pdf},
pages = {7},
title = {{Genetic cellular neural networks for generating three-dimensional geometry}},
url = {http://arxiv.org/abs/1603.08551},
year = {2016}
}
@article{Feldman2014,
abstract = {What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a definition of a protected class (ethnicity, gender, religious practice) and an explicit description of the process. When the process is implemented using computers, determining disparate impact (and hence bias) is harder. It might not be possible to disclose the process. In addition, even if the process is open, it might be hard to elucidate in a legal setting how the algorithm makes its decisions. Instead of requiring access to the algorithm, we propose making inferences based on the data the algorithm uses. We make four contributions to this problem. First, we link the legal notion of disparate impact to a measure of classification accuracy that while known, has received relatively little attention. Second, we propose a test for disparate impact based on analyzing the information leakage of the protected class from the other data attributes. Third, we describe methods by which data might be made unbiased. Finally, we present empirical evidence supporting the effectiveness of our test for disparate impact and our approach for both masking bias and preserving relevant information in the data. Interestingly, our approach resembles some actual selection practices that have recently received legal scrutiny.},
archivePrefix = {arXiv},
arxivId = {1412.3756},
author = {Feldman, Michael and Friedler, Sorelle and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
doi = {10.1145/2783258.2783311},
eprint = {1412.3756},
file = {:home/memo/Mendeley/data/Feldman et al. - 2014 - Certifying and removing disparate impact.pdf:pdf},
isbn = {9781450336642},
journal = {arXiv Prepr. arXiv1412.3756},
pages = {1--28},
title = {{Certifying and removing disparate impact}},
url = {http://arxiv.org/abs/1412.3756},
year = {2014}
}
@article{Author2016,
archivePrefix = {arXiv},
arxivId = {1608.05343},
author = {Author, Anonymous and Address, Affiliation},
eprint = {1608.05343},
file = {:home/memo/Mendeley/data/Author, Address - 2016 - Decoupled Neural Interfaces using Synthetic Gradients.pdf:pdf},
number = {Nips},
title = {{Decoupled Neural Interfaces using Synthetic Gradients}},
year = {2016}
}
@article{Zhang2016,
abstract = {Recent deep learning based approaches have achieved great success on handwriting recognition. Chinese characters are among the most widely adopted writing systems in the world. Previous research has mainly focused on recognizing handwritten Chinese characters. However, recognition is only one aspect for understanding a language, another challenging and interesting task is to teach a machine to automatically write (pictographic) Chinese characters. In this paper, we propose a framework by using the recurrent neural network (RNN) as both a discriminative model for recognizing Chinese characters and a generative model for drawing (generating) Chinese characters. To recognize Chinese characters, previous methods usually adopt the convolutional neural network (CNN) models which require transforming the online handwriting trajectory into image-like representations. Instead, our RNN based approach is an end-to-end system which directly deals with the sequential structure and does not require any domain-specific knowledge. With the RNN system (combining an LSTM and GRU), state-of-the-art performance can be achieved on the ICDAR-2013 competition database. Furthermore, under the RNN framework, a conditional generative model with character embedding is proposed for automatically drawing recognizable Chinese characters. The generated characters (in vector format) are human-readable and also can be recognized by the discriminative RNN model with high accuracy. Experimental results verify the effectiveness of using RNNs as both generative and discriminative models for the tasks of drawing and recognizing Chinese characters.},
author = {Zhang, Xu-Yao and Yin, Fei and Zhang, Yan-Ming and Liu, Cheng-Lin and Bengio, Yoshua},
file = {:home/memo/Mendeley/data/Zhang et al. - 2016 - Drawing and Recognizing Chinese Characters with Recurrent Neural Network.pdf:pdf},
journal = {arXiv preprint arXiv:1606.06539},
title = {{Drawing and Recognizing Chinese Characters with Recurrent Neural Network}},
year = {2016}
}
@article{bergstra2012random,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza-tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar-ison with a large previous study that used grid search and manual search to configure neural net-works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con-figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent " High Throughput " methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural base-line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {Bergstra, James and Bengio, Yoshua},
file = {:home/memo/Mendeley/data/Bergstra, Bengio - 2012 - Random Search for Hyper-Parameter Optimization.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface modeling},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}
@article{Graves2012,
author = {Graves, Alex},
file = {:home/memo/Mendeley/data/Graves - 2012 - Sequence transduction with recurrent neural networks.pdf:pdf},
journal = {arXiv preprint arXiv:1211.3711},
title = {{Sequence transduction with recurrent neural networks}},
year = {2012}
}
@article{Bolukbasi2016a,
abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
archivePrefix = {arXiv},
arxivId = {1607.06520},
author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
eprint = {1607.06520},
file = {:home/memo/Mendeley/data/Bolukbasi et al. - 2016 - Man is to Computer Programmer as Woman is to Homemaker Debiasing Word Embeddings.pdf:pdf},
pages = {1--25},
title = {{Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings}},
url = {http://arxiv.org/abs/1607.06520},
year = {2016}
}
@article{Xu2015,
abstract = {Data-driven methods play an increasingly important role in discovering geometric, structural, and semantic re- lationships between 3D shapes in collections, and applying this analysis to support intelligent modeling, editing, and visualization of geometric data. In contrast to traditional approaches, a key feature of data-driven approaches is that they aggregate information from a collection of shapes to improve the analysis and processing of individ- ual shapes. In addition, they are able to learn models that reason about properties and relationships of shapes without relying on hard-coded rules or explicitly programmed instructions. We provide an overview of the main concepts and components of these techniques, and discuss their application to shape classification, segmentation, matching, reconstruction, modeling and exploration, as well as scene analysis and synthesis, through reviewing the literature and relating the existing works with both qualitative and numerical comparisons. We conclude our report with ideas that can inspire future research in data-driven shape analysis and processing.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.06686v1},
author = {Xu, Kai and Kim, Vladimir G. and Huang, Qixing and Kalogerakis, Evangelos},
doi = {10.1111/cgf.12790},
eprint = {arXiv:1502.06686v1},
file = {:home/memo/Mendeley/data/Xu et al. - 2015 - Data-Driven Shape Analysis and Processing.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {3,5,acm ccs,computational geometry and object,computer graphics,data-driven approach,i,machine learning,modeling,shape analysis,shape modeling,shape processing},
number = {0},
pages = {1--27},
title = {{Data-Driven Shape Analysis and Processing}},
volume = {xx},
year = {2015}
}
@article{Rezende2016a,
abstract = {A key goal of computer vision is to recover the underlying 3D structure from 2D observations of the world. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 3D and 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the first benchmarks in the literature. We also show how these models and their inference networks can be trained end-to-end from 2D images. This demonstrates for the first time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner.},
archivePrefix = {arXiv},
arxivId = {1607.00662},
author = {Rezende, Danilo Jimenez and Eslami, S. M. Ali and Mohamed, Shakir and Battaglia, Peter and Jaderberg, Max and Heess, Nicolas},
eprint = {1607.00662},
file = {:home/memo/Mendeley/data/Rezende et al. - 2016 - Unsupervised Learning of 3D Structure from Images.pdf:pdf},
title = {{Unsupervised Learning of 3D Structure from Images}},
url = {http://arxiv.org/abs/1607.00662},
year = {2016}
}
@book{Bucksch2011,
author = {Bucksch, Alxander Klaus},
file = {:home/memo/Mendeley/data/Bucksch - 2011 - Revealing the skeleton from imperfect point clouds.pdf:pdf},
isbn = {9783868538779},
title = {{Revealing the skeleton from imperfect point clouds}},
year = {2011}
}
@article{Lehman,
author = {Lehman, Joel and Clune, Jeff},
file = {:home/memo/Mendeley/data/Lehman, Clune - Unknown - Creative Generation of 3D Objects with Deep Learning and Innovation Engines.pdf:pdf},
title = {{Creative Generation of 3D Objects with Deep Learning and Innovation Engines}}
}
@article{Leymarie2001,
abstract = {The usefulness of the 3D Medial Axis (MA) is dependent on both the availability$\backslash$n$\backslash$nof accurate and stable methods for computing individual MA points and on$\backslash$n$\backslash$nschemes for deriving the local structure and connectivity among these points. We$\backslash$n$\backslash$npropose a framework which achieves both by combining the advantages of exact$\backslash$n$\backslash$nbisector computations used in computational geometry, on the one hand, and the$\backslash$n$\backslash$nlocal nature of propagation-based algorithms, on the other, but without the computational$\backslash$n$\backslash$ncomplexity,...},
author = {Leymarie, Frederic F and Kimia, Benjamin B},
file = {:home/memo/Mendeley/data/Leymarie, Kimia - 2001 - The Shock Scaffold for Representing 3D Shape.pdf:pdf},
isbn = {3540421203},
issn = {16113349},
journal = {Iwvf},
keywords = {shape,shape{\_}matching,shock},
number = {May},
pages = {216--228},
title = {{The Shock Scaffold for Representing 3D Shape}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.3745},
year = {2001}
}
@article{Chen2003,
abstract = {A large number of 3D models are created and available on the Web, since more and more 3D modelling anddigitizing tools are developed for ever increasing applications. The techniques for content-based 3D model retrievalthen become necessary. In this paper, a visual similarity-based 3D model retrieval system is proposed.This approach measures the similarity among 3D models by visual similarity, and the main idea is that if two 3Dmodels are similar, they also look similar from all viewing angles. Therefore, one hundred orthogonal projectionsof an object, excluding symmetry, are encoded both by Zernike moments and Fourier descriptors as features forlater retrieval. The visual similarity-based approach is robust against similarity transformation, noise, model degeneracyetc., and provides 42{\%}, 94{\%} and 25{\%} better performance (precision-recall evaluation diagram) thanthree other competing approaches: (1) the spherical harmonics approach developed by Funkhouser et al., (2) theMPEG-7 Shape 3D descriptors, and (3) the MPEG-7 Multiple View Descriptor. The proposed system is on the Webfor practical trial use (http://3d.csie.ntu.edu.tw), and the database contains more than 10,000 publicly available3D models collected from WWW pages. Furthermore, a user friendly interface is provided to retrieve 3D modelsby drawing 2D shapes. The retrieval is fast enough on a server with Pentium IV 2.4 GHz CPU, and it takes about2 seconds and 0.1 seconds for querying directly by a 3D model and by hand drawn 2D shapes, respectively. Categories and Subject Descriptors (according to ACM CCS): H.3.1 [Information Storage and Retrieval]: Indexing Methods},
author = {Chen, Ding-Yun and Tian, Xiao-Pei and Shen, Yu-Te and Ouhyoung, Ming},
doi = {10.1111/1467-8659.00669},
file = {:home/memo/Mendeley/data/Chen et al. - 2003 - On Visual Similarity Based 3D Model Retrieval.pdf:pdf},
isbn = {0769522238},
issn = {1467-8659},
journal = {Computer Graphics Forum},
number = {3},
pages = {223--232},
title = {{On Visual Similarity Based 3D Model Retrieval}},
url = {http://dx.doi.org/10.1111/1467-8659.00669},
volume = {22},
year = {2003}
}
@article{Wu2015a,
abstract = {3D shape is a crucial but heavily underutilized cue in today's computer vision systems, mostly due to the lack of a good generic shape representation. With the recent availability of inexpensive 2.5D depth sensors (e.g. Microsoft Kinect), it is becoming increasingly important to have a powerful 3D shape representation in the loop. Apart from category recognition, recovering full 3D shapes from viewbased 2.5D depth maps is also a critical part of visual understanding. To this end, we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network. Our model, 3D ShapeNets, learns the distribution of complex 3D shapes across different object categories and arbitrary poses from raw CAD data, and discovers hierarchical compositional part representations automatically. It naturally supports joint object recognition and shape completion from 2.5D depth maps, and it enables active object recognition through view planning. To train our 3D deep learning model, we construct ModelNet – a large-scale 3D CAD model dataset. Extensive experiments show that our 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1406.5670v3},
author = {Wu, Zhirong and Song, Shuran},
doi = {10.1109/CVPR.2015.7298801},
eprint = {arXiv:1406.5670v3},
file = {:home/memo/Mendeley/data/Wu, Song - 2015 - 3D ShapeNets A Deep Representation for Volumetric Shapes.pdf:pdf},
isbn = {9781467369640},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR2015)},
pages = {1--9},
title = {{3D ShapeNets : A Deep Representation for Volumetric Shapes}},
year = {2015}
}
@article{Sturm2015a,
author = {Sturm, Bob L and Santos, Felipe},
file = {:home/memo/Mendeley/data/Sturm, Santos - 2015 - Folk Music Style Modelling By Recurrent Neural Networks With Long Short Term Memory Units.pdf:pdf},
number = {Smc},
title = {{Folk Music Style Modelling By Recurrent Neural Networks With Long Short Term Memory Units}},
volume = {2013},
year = {2015}
}
@article{Sturm2016,
abstract = {We apply deep learning methods, specifically long short-term memory (LSTM) networks, to music transcription modelling and composition. We build and train LSTM networks using approximately 23,000 music transcriptions expressed with a high-level vocabulary (ABC notation), and use them to generate new transcriptions. Our practical aim is to create music transcription models useful in particular contexts of music composition. We present results from three perspectives: 1) at the population level, comparing descriptive statistics of the set of training transcriptions and generated transcriptions; 2) at the individual level, examining how a generated transcription reflects the conventions of a music practice in the training transcriptions (Celtic folk); 3) at the application level, using the system for idea generation in music composition. We make our datasets, software and sound examples open and available: $\backslash$url{\{}https://github.com/IraKorshunova/folk-rnn{\}}.},
archivePrefix = {arXiv},
arxivId = {1604.08723},
author = {Sturm, Bob L. and Santos, Jo{\~{a}}o Felipe and Ben-Tal, Oded and Korshunova, Iryna},
eprint = {1604.08723},
file = {:home/memo/Mendeley/data/Sturm et al. - 2016 - Music transcription modelling and composition using deep learning.pdf:pdf},
keywords = {algorithmic composition,deep learning,music modelling,recurrent neural network},
pages = {16},
title = {{Music transcription modelling and composition using deep learning}},
url = {http://arxiv.org/abs/1604.08723},
year = {2016}
}
@article{Bolukbasi2016,
abstract = {Machine learning algorithms are optimized to model statistical properties of the training data. If the input data reflects stereotypes and biases of the broader society, then the output of the learning algorithm also captures these stereo-types. In this paper, we initiate the study of gender stereotypes in word embedding, a pop-ular framework to represent text data. As their use becomes increasingly common, applications can inadvertently amplify unwanted stereotypes. We show across multiple datasets that the em-beddings contain significant gender stereotypes, especially with regard to professions. We created a novel gender analogy task and combined it with crowdsourcing to systematically quantify the gender bias in a given embedding. We developed an efficient algorithm that reduces gender stereotype using just a handful of training examples while preserving the useful geometric properties of the embedding. We evaluated our algorithm on several metrics. While we focus on male/female stereotypes, our framework may be applicable to other types of embedding biases.},
archivePrefix = {arXiv},
arxivId = {1606.06121},
author = {Bolukbasi, Tolga and Chang, Kai-Wei and Net, Kw@kwchang and Zou, James and Saligrama, Venkatesh and Kalai, Adam and Com, Adam Kalai@microsoft},
eprint = {1606.06121},
file = {:home/memo/Mendeley/data/Bolukbasi et al. - 2016 - Quantifying and Reducing Stereotypes in Word Embeddings.pdf:pdf},
title = {{Quantifying and Reducing Stereotypes in Word Embeddings}},
year = {2016}
}
@article{Jain2016,
abstract = {Deep Recurrent Neural Network architectures, though remarkably capable at modeling sequences, lack an intuitive high-level spatio-temporal structure. That is while many problems in computer vision inherently have an underlying high-level structure and can benefit from it. Spatio-temporal graphs are a popular flexible tool for imposing such high-level intuitions in the formulation of real world problems. In this paper, we propose an approach for combining the power of high-level spatio-temporal graphs and sequence learning success of Recurrent Neural Networks{\~{}}(RNNs). We develop a scalable method for casting an arbitrary spatio-temporal graph as a rich RNN mixture that is feedforward, fully differentiable, and jointly trainable. The proposed method is generic and principled as it can be used for transforming any spatio-temporal graph through employing a certain set of well defined steps. The evaluations of the proposed approach on a diverse set of problems, ranging from modeling human motion to object interactions, shows improvement over the state-of-the-art with a large margin. We expect this method to empower a new convenient approach to problem formulation through high-level spatio-temporal graphs and Recurrent Neural Networks, and be of broad interest to the community.},
archivePrefix = {arXiv},
arxivId = {1511.05298},
author = {Jain, Ashesh and Zamir, Amir R and Savarese, Silvio and Saxena, Ashutosh},
eprint = {1511.05298},
file = {:home/memo/Mendeley/data/Jain et al. - 2016 - Structural-RNN Deep Learning on Spatio-Temporal Graphs.pdf:pdf},
journal = {Cvpr},
title = {{Structural-RNN: Deep Learning on Spatio-Temporal Graphs}},
url = {http://arxiv.org/abs/1511.05298},
year = {2016}
}
@article{Friis2016,
archivePrefix = {arXiv},
arxivId = {1605.06921},
author = {Crnkovic-friis, Luka and Crnkovic-friis, Louise},
eprint = {1605.06921},
file = {:home/memo/Mendeley/data/Crnkovic-friis, Crnkovic-friis - 2016 - Generative Choreography using Deep Learning.pdf:pdf},
journal = {arXiv preprint arXiv:1605.06921},
title = {{Generative Choreography using Deep Learning}},
year = {2016}
}
@article{Graves2009,
abstract = {Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters, combined with the need to exploit surrounding context, has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed, most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition, despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network, specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases, our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data, significantly outperforming a state-of-the-art HMM-based system. In addition, we demonstrate the network's robustness to lexicon size, measure the individual influence of its hidden layers, and analyze its use of context. Last, we provide an in-depth discussion of the differences between the network and HMMs, suggesting reasons for the network's superior performance.},
author = {Graves, Alex and Liwicki, Marcus and Fern{\'{a}}ndez, Santiago and Bertolami, Roman and Bunke, Horst and Schmidhuber, J{\"{u}}rgen},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Bidirectional long short-term memory,Connectionist temporal classification,Handwriting recognition,Hidden Markov model,Offline handwriting,Online handwriting,Recurrent neural networks},
number = {5},
pages = {855--868},
title = {{A novel connectionist system for unconstrained handwriting recognition}},
volume = {31},
year = {2009}
}
@inproceedings{Pham2014,
abstract = {Recurrent neural networks (RNNs) with Long Short-Term memory cells currently hold the best known results in unconstrained handwriting recognition. We show that their performance can be greatly improved using dropout - a recently proposed regularization method for deep architectures. While previous works showed that dropout gave superior performance in the context of convolutional networks, it had never been applied to RNNs. In our approach, dropout is carefully used in the network so that it does not affect the recurrent connections, hence the power of RNNs in modeling sequence is preserved. Extensive experiments on a broad range of handwritten databases confirm the effectiveness of dropout on deep architectures even when the network mainly consists of recurrent and shared connections.},
author = {Pham, Vu and Bluche, Th{\'{e}}odore and Kermorvant, Christopher and Louradour, J{\'{e}}r{\^{o}}me},
booktitle = {Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
file = {:home/memo/Mendeley/data/Pham et al. - 2014 - Dropout Improves Recurrent Neural Networks for Handwriting Recognition.pdf:pdf},
keywords = {Dropout,Handwriting Recognition,Recurrent Neural Networks},
pages = {285--290},
publisher = {IEEE},
title = {{Dropout Improves Recurrent Neural Networks for Handwriting Recognition}},
year = {2014}
}
@phdthesis{Hochreiter1991,
author = {Hochreiter, Sepp},
file = {:home/memo/Mendeley/data/Hochreiter - 1991 - Untersuchungen zu dynamischen neuronalen Netzen.pdf:pdf},
school = {Technische Universit{\"{a}}t M{\"{u}}nchen},
title = {{Untersuchungen zu dynamischen neuronalen Netzen}},
year = {1991}
}
@inproceedings{Zaremba2014,
abstract = {Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are widely used because they are expressive and are easy to train. Our interest lies in empirically evaluating the expressiveness and the learnability of LSTMs in the sequence-to-sequence regime by training them to evaluate short computer programs, a domain that has traditionally been seen as too complex for neural networks. We consider a simple class of programs that can be evaluated with a single left-to-right pass using constant memory. Our main result is that LSTMs can learn to map the character-level representations of such programs to their correct outputs. Notably, it was necessary to use curriculum learning, and while conventional curriculum learning proved ineffective, we developed a new variant of curriculum learning that improved our networks' performance in all experimental conditions. The improved curriculum had a dramatic impact on an addition problem, making it possible to train an LSTM to add two 9-digit numbers with 99{\%} accuracy.},
author = {Zaremba, Wojciech and Sutskever, Ilya},
booktitle = {2nd International Conference on Learning Representations (ICLR2014)},
title = {{Learning to Execute}},
year = {2014}
}
@misc{project-gutenberg,
author = {Hart, Michael S. and {the Project Gutenberg Team}},
booktitle = {http://www.gutenberg.org/},
title = {{Project Gutenberg}},
url = {http://www.gutenberg.org/},
year = {1971}
}
@misc{goodwin-wordsynth,
author = {Goodwin, Ross},
booktitle = {http://rossgoodwin.com/wordsynth/},
title = {{Word Synth}},
url = {http://rossgoodwin.com/wordsynth/},
year = {2016}
}
@misc{stacks-project,
author = {{Stacks Project Authors}},
booktitle = {http://stacks.math.columbia.edu},
title = {{Stacks Project}},
url = {http://stacks.math.columbia.edu},
year = {2016}
}
@misc{Keras,
author = {Chollet, Fran{\c{c}}ois},
title = {{Keras: Deep Learning library for Theano and TensorFlow}},
url = {https://github.com/fchollet/keras},
year = {2015}
}
@misc{Theano,
abstract = {Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.},
archivePrefix = {arXiv},
arxivId = {1605.02688},
author = {{The Theano Development Team}},
eprint = {1605.02688},
file = {:home/memo/Mendeley/data/The Theano Development Team - 2016 - Theano A Python framework for fast computation of mathematical expressions.pdf:pdf},
title = {{Theano: A Python framework for fast computation of mathematical expressions}},
url = {http://arxiv.org/abs/1605.02688},
year = {2016}
}
@article{lyu04,
author = {Lyu, Siwei and Rockmore, Daniel and Farid, Hany},
journal = {Proceedings of the National Academy of Sciences},
number = {49},
pages = {17006--17010},
title = {{A Digital Technique for Art Authentication}},
volume = {101},
year = {2004}
}
@techreport{OZ,
address = {Pittsburgh, PA},
author = {Kantrowitz, Mark},
institution = {School of Computer Science, Carnegie Mellon University},
number = {CMU-CS-90-158},
title = {{Natural Language Text Generation in the {\{}OZ{\}} Interactive Fiction Project}},
type = {Technical Report},
year = {1990}
}
@book{Ruch07,
address = {Berlin},
editor = {Ruch, Willibald},
publisher = {Mouton de Gruyter},
series = {Mouton Select},
title = {{The Sense of Humor: Explorations of a Personality Characteristic}},
year = {2007}
}
@incollection{Woods81,
address = {Cambridge, UK},
author = {Woods, W A},
booktitle = {Elements of Discourse Understanding},
editor = {Joshi, A K and Webber, B L and Sag, I},
pages = {300--334},
publisher = {Cambridge University Press},
title = {{Procedural semantics as a theory of meaning}},
year = {1981}
}
@book{boden92,
address = {London},
author = {Boden, Margaret},
publisher = {Abacus},
title = {{The Creative Mind}},
year = {1992}
}
@misc{UCI,
annote = {http://www.ics.uci.edu/{\~{}}mlearn/MLRepository.html},
author = {Asuncion, A and Newman, D J},
howpublished = {University of California, Irvine, School of Information and Computer Sciences},
title = {{{\{}UCI{\}} Machine Learning Repository}}
}
@article{ritchie07,
author = {Ritchie, Graeme},
journal = {Minds and Machines},
pages = {76--99},
publisher = {Springer},
title = {{Some Empirical Criteria for Attributing Creativity to a Computer Program}},
volume = {17},
year = {2007}
}
@inproceedings{veale07,
address = {Vancouver, British Columbia},
author = {Veale, Tony and Hao, Yanfen},
booktitle = {Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence (AAAI-07)},
pages = {1471--1476},
publisher = {AAAI Press},
title = {{Comprehending and Generating Apt Metaphors: A Web-driven, Case-based Approach to Figurative Language}},
year = {2007}
}
@article{Song2015,
abstract = {Deep neural network (DNN) based natural language processing models rely on a word embedding matrix to transform raw words into vectors. Recently, a deep structured semantic model (DSSM) has been proposed to project raw text to a continuously-valued vector for Web Search. In this technical report, we propose learning word embedding using DSSM. We show that the DSSM trained on large body of text can produce meaningful word embedding vectors as demonstrated on semantic word clustering and semantic word analogy tasks.},
author = {Song, Xinying and He, Xiaodong and Gao, Jianfeng and Deng, Li},
file = {:home/memo/Mendeley/data/Song et al. - 2015 - Unsupervised Learning of Word Semantic Embedding using the Deep Structured Semantic Model.pdf:pdf},
journal = {Technical Report},
title = {{Unsupervised Learning of Word Semantic Embedding using the Deep Structured Semantic Model}},
url = {http://research.microsoft.com/pubs/226586/msrtr2014{\_}wordembedding.pdf},
year = {2015}
}
@article{Mikolov2013,
abstract = {Continuous space language models have re-cently demonstrated outstanding results across a variety of tasks. In this paper, we ex-amine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, " King -Man + Woman " results in a vector very close to " Queen. " We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40{\%} of the questions. We demonstrate that the word vectors capture semantic regu-larities by using the vector offset method to answer SemEval-2012 Task 2 questions. Re-markably, this method outperforms the best previous systems.},
author = {Mikolov, Tomas and Yih, Wen-Tau and Zweig, Geoffrey},
file = {:home/memo/Mendeley/data/Mikolov, Yih, Zweig - 2013 - Linguistic Regularities in Continuous Space Word Representations.pdf:pdf},
isbn = {9781937284473},
number = {June},
pages = {746--751},
pmid = {1938007},
title = {{Linguistic Regularities in Continuous Space Word Representations}},
year = {2013}
}
@article{Bengio2009a,
abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illus- trates gradually more concepts, and gradu- ally more complex ones. Here, we formal- ize such training strategies in the context of machine learning, and call them “curricu- lum learning”. In the context of recent re- search studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neu- ral networks), we explore curriculum learn- ing in various set-ups. The experiments show that significant improvements in generaliza- tion can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bengio, Yoshua and Louradour, J{\'{e}}r{\^{o}}me and Collobert, Ronan and Weston, Jason},
doi = {10.1145/1553374.1553380},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Bengio et al. - 2009 - Curriculum learning.pdf:pdf},
isbn = {9781605585161},
issn = {0022-5193},
journal = {Proceedings of the 26th annual international conference on machine learning},
pages = {41--48},
pmid = {5414602},
title = {{Curriculum learning}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553380},
year = {2009}
}
@article{Tankard1979,
abstract = {A widely disseminated quotation by H.G. Wells on the importance of statistics is shown to have been misrepresented. ?? 1979.},
author = {Tankard, James W.},
doi = {10.1016/0315-0860(79)90101-0},
file = {:home/memo/Mendeley/data/Tankard - 1979 - The H.G. Wells quote on statistics A question of accuracy.pdf:pdf},
issn = {1090249X},
journal = {Historia Mathematica},
number = {1},
pages = {30--33},
title = {{The H.G. Wells quote on statistics: A question of accuracy}},
volume = {6},
year = {1979}
}
@article{Pennington2014,
abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arith- metic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global log- bilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word co- occurrence matrix, rather than on the en- tire sparse matrix or on individual context windows in a large corpus. On a recent word analogy task our model obtains 75{\%} accuracy, an improvement of 11{\%} over Mikolov et al. (2013). It also outperforms related word vector models on similarity tasks and named entity recognition.},
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
doi = {10.3115/v1/D14-1162},
file = {:home/memo/Mendeley/data/Pennington, Socher, Manning - 2014 - GloVe Global Vectors for Word Representation.pdf:pdf},
isbn = {9781937284961},
issn = {10495258},
journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing},
pages = {1532--1543},
pmid = {1710995},
title = {{GloVe: Global Vectors for Word Representation}},
year = {2014}
}
@article{Kumaran2016,
author = {Kumaran, Dharshan and Hassabis, Demis and McClelland, James L.},
doi = {10.1016/j.tics.2016.05.004},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumaran, Hassabis, McClelland - 2016 - What learning systems do intelligent agents need Complementary Learning Systems Theory Updated.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {7},
pages = {512--534},
publisher = {Elsevier Ltd},
title = {{What learning systems do intelligent agents need? Complementary Learning Systems Theory Updated}},
url = {http://dx.doi.org/10.1016/j.tics.2016.05.004},
volume = {20},
year = {2016}
}
@incollection{Murphy1987,
author = {Murphy, Kevin},
file = {:home/memo/Mendeley/data/Murphy - 1987 - Mixture Models.pdf:pdf},
isbn = {978-0-8247-7691-6},
number = {3},
pages = {14},
title = {{Mixture Models}},
url = {https://books.google.com/books?id=1Id9QgAACAAJ},
year = {1987}
}
@article{Son,
author = {Son, Le Hai and Kombrink, Stefan},
file = {:home/memo/Mendeley/data/Son, Kombrink - Unknown - Subword Language modeling with Neural Networks.pdf:pdf},
number = {June 2016},
title = {{Subword Language modeling with Neural Networks}}
}
@misc{Hinton2013a,
author = {Hinton, Geoffrey},
file = {:home/memo/Mendeley/data/Hinton - 2013 - CSC2535 2013 Advanced Machine Learning Lecture 10 Recurrent neural networks.pdf:pdf},
title = {{CSC2535 2013 : Advanced Machine Learning Lecture 10 Recurrent neural networks}},
year = {2013}
}
@inproceedings{Cho2014,
abstract = {In this paper, we propose a novel neural network model called RNN Encoder--Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder--Decoder as an additional feature in the existing linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
archivePrefix = {arXiv},
arxivId = {1406.1078},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
eprint = {1406.1078},
file = {:home/memo/Mendeley/data/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.pdf:pdf},
keywords = {decoder,for statistical machine translation,rning phrase representations using,rnn encoder},
pages = {1724--1734},
publisher = {Association for Computational Linguistics},
title = {{Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}},
year = {2014}
}
@unpublished{Baluja2016,
abstract = {Typography is a ubiquitous art form that affects our understanding, perception, and trust in what we read. Thousands of different font-faces have been created with enormous variations in the characters. In this paper, we learn the style of a font by analyzing a small subset of only four letters. From these four letters, we learn two tasks. The first is a discrimination task: given the four letters and a new candidate letter, does the new letter belong to the same font? Second, given the four basis letters, can we generate all of the other letters with the same characteristics as those in the basis set? We use deep neural networks to address both tasks, quantitatively and qualitatively measure the results in a variety of novel manners, and present a thorough investigation of the weaknesses and strengths of the approach.},
archivePrefix = {arXiv},
arxivId = {1603.04000},
author = {Baluja, Shumeet},
eprint = {1603.04000},
file = {:home/memo/Mendeley/data/Baluja - 2016 - Learning Typographic Style.pdf:pdf},
keywords = {image generation,learning,style analysis,typography},
publisher = {arXiv},
title = {{Learning Typographic Style}},
url = {http://arxiv.org/abs/1603.04000},
year = {2016}
}
@article{DzmitryBahdana2014,
abstract = {Neural machine translation is a recently proposed approach to machine transla-tion. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neu-ral machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architec-ture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
archivePrefix = {arXiv},
arxivId = {1409.0473},
author = {{Dzmitry Bahdana} and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
doi = {10.1146/annurev.neuro.26.041002.131047},
eprint = {1409.0473},
file = {:home/memo/Mendeley/data/Dzmitry Bahdana et al. - 2014 - Neural Machine Translation By Jointly Learning To Align and Translate.pdf:pdf},
isbn = {0147-006X (Print)},
issn = {0147-006X},
journal = {Iclr 2015},
keywords = {Neural machine translation is a recently proposed,Unlike the traditional statistical machine transla,a source sentence into a fixed-length vector from,and propose to extend this by allowing a model to,bottleneck in improving the performance of this ba,for parts of a source sentence that are relevant t,having to form these parts as a hard segment expli,machine translation often belong to a family of en,maximize the translation performance. The models p,phrase-based system on the task of English-to-Fren,qualitative analysis reveals that the (soft-)align,the neural machine,translation aims at building a single neural netwo,translation. In this paper,we achieve a translation performance comparable to,we conjecture that the use of a fixed-length vecto,well with our intuition,without},
pages = {1--15},
pmid = {14527267},
title = {{Neural Machine Translation By Jointly Learning To Align and Translate}},
url = {http://arxiv.org/abs/1409.0473v3},
year = {2014}
}
@article{Andrychowicz2016,
abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
archivePrefix = {arXiv},
arxivId = {1606.04474},
author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and de Freitas, Nando},
eprint = {1606.04474},
file = {:home/memo/Mendeley/data/Andrychowicz et al. - 2016 - Learning to learn by gradient descent by gradient descent.pdf:pdf},
journal = {arXiv preprint arXiv:1606.04474},
title = {{Learning to learn by gradient descent by gradient descent}},
year = {2016}
}
@article{Alemi2016,
archivePrefix = {arXiv},
arxivId = {1606.04442},
author = {Alemi, Alex A. and Chollet, Francois and Irving, Geoffrey and Szegedy, Christian and Urban, Josef},
eprint = {1606.04442},
file = {:home/memo/Mendeley/data/Alemi et al. - 2016 - DeepMath - Deep Sequence Models for Premise Selection.pdf:pdf},
title = {{DeepMath - Deep Sequence Models for Premise Selection}},
year = {2016}
}
@article{Xing2015,
abstract = {Word embedding has been found to be high-ly powerful to translate words from one lan-guage to another by a simple linear transfor-m. However, we found some inconsistence among the objective functions of the embed-ding and the transform learning, as well as the distance measurement. This paper propos-es a solution which normalizes the word vec-tors on a hypersphere and constrains the lin-ear transform as an orthogonal transform. The experimental results confirmed that the pro-posed solution can offer better performance on a word similarity task and an English-to-Spanish word translation task.},
author = {Xing, Chao and Liu, Chao and Wang, Dong and Lin, Yiye},
file = {:home/memo/Mendeley/data/Xing et al. - 2015 - Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation.pdf:pdf},
isbn = {9781941643495},
journal = {Naacl-2015},
pages = {1005--1010},
title = {{Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation}},
year = {2015}
}
@article{Rehurek2010,
abstract = {Abstract$\backslash$r$\backslash$nLarge corpora are ubiquitous in today's world and memory quickly becomes the limiting factor in practical applications of the Vector$\backslash$r$\backslash$nSpace Model (VSM). In this paper, we identify a gap in existing implementations of many of the popular algorithms, which is their$\backslash$r$\backslash$nscalability and ease of use. We describe a Natural Language Processing software framework which is based on the idea of document$\backslash$r$\backslash$nstreaming, i.e. processing corpora document after document, in a memory independent fashion. Within this framework, we implement$\backslash$r$\backslash$nseveral popular algorithms for topical inference, including Latent Semantic Analysis and Latent Dirichlet Allocation, in a way that makes$\backslash$r$\backslash$nthem completely independent of the training corpus size. Particular emphasis is placed on straightforward and intuitive framework design,$\backslash$r$\backslash$nso that modifications and extensions of the methods and/or their application by interested practitioners are effortless. We demonstrate the$\backslash$r$\backslash$nusefulness of our approach on a real-world scenario of computing document similarities within an existing digital library DML-CZ.},
author = {Rehurek, Radim and Sojka, Petr},
file = {:home/memo/Mendeley/data/Rehurek, Sojka - 2010 - Software Framework for Topic Modelling with Large Corpora.pdf:pdf},
isbn = {2-9517408-6-7},
issn = {2951740867},
journal = {Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks},
pages = {45--50},
title = {{Software Framework for Topic Modelling with Large Corpora}},
year = {2010}
}
@article{Pedregosa2012,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
archivePrefix = {arXiv},
arxivId = {1201.0490},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'{E}}douard},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {1201.0490},
file = {:home/memo/Mendeley/data/Pedregosa et al. - 2012 - Scikit-learn Machine Learning in Python.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {{\ldots} of Machine Learning {\ldots}},
pages = {2825--2830},
pmid = {1000044560},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=2078195{\%}5Cnhttp://arxiv.org/abs/1201.0490},
volume = {12},
year = {2012}
}
@inproceedings{SutskeverVinyals2014,
abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
file = {:home/memo/Mendeley/data/Sutskever, Vinyals, Le - 2014 - Sequence to Sequence Learning with Neural Networks(2).pdf:pdf},
pages = {3104--3112},
title = {{Sequence to Sequence Learning with Neural Networks}},
year = {2014}
}
@article{Sutskever,
archivePrefix = {arXiv},
arxivId = {arXiv:1409.3215v3},
author = {Sutskever, Ilya},
eprint = {arXiv:1409.3215v3},
file = {:home/memo/Mendeley/data/Sutskever, Vinyals, Le - 2014 - Sequence to Sequence Learning with Neural Networks(2).pdf:pdf},
pages = {1--9},
title = {{Sequence to Sequence Learning with Neural Networks}}
}
@article{Zaremba2014,
abstract = {We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation.},
archivePrefix = {arXiv},
arxivId = {1409.2329},
author = {Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
eprint = {1409.2329},
file = {:home/memo/Mendeley/data/Zaremba, Sutskever, Vinyals - 2014 - Recurrent Neural Network Regularization.pdf:pdf},
isbn = {078036404X},
journal = {Icrl},
keywords = {Natural Language Processing, Recurrent Neural Netw},
number = {2013},
pages = {1--8},
title = {{Recurrent Neural Network Regularization}},
url = {http://arxiv.org/abs/1409.2329},
year = {2014}
}
@article{Goldberg2014,
abstract = {The word2vec software of Tomas Mikolov and colleagues1 has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers [1, 2]. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations. This note is an attempt to explain equation (4) (negative sampling) in “Dis- tributed Representations ofWords and Phrases and their Compositionality” by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean [2].},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.3722v1},
author = {Goldberg, Yoav and Levy, Omer},
eprint = {arXiv:1402.3722v1},
file = {:home/memo/Mendeley/data/Goldberg, Levy - 2014 - word2vec Explained Deriving Mikolov et al.'s Negative-Sampling Word-Embedding Method.pdf:pdf},
journal = {arXiv preprint arXiv:1402.3722},
number = {2},
pages = {1--5},
title = {{word2vec Explained: Deriving Mikolov et al.'s Negative-Sampling Word-Embedding Method}},
url = {http://arxiv.org/abs/1402.3722},
year = {2014}
}
@article{Xu1994,
abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the cor- responding words in the output sequence. We validate the use of attention with state-of-the- art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO. 1.},
archivePrefix = {arXiv},
arxivId = {arXiv:1211.5063v2},
author = {Xu, Kelvin and Kiros, Jimmy Lei Ba Ryan and Courville, Kyunghyun Cho Aaron and Bengio, Ruslan Salakhutdinov Richard S. Zemel Yoshua},
doi = {10.1109/72.279181},
eprint = {arXiv:1211.5063v2},
file = {:home/memo/Mendeley/data/Xu et al. - 1994 - Show, Attend and Tell Neural Image Caption Generation with Visual Attention.pdf:pdf},
isbn = {1045-9227 VO - 5},
issn = {19410093},
journal = {IEEE Transactions on Neural Networks},
number = {2},
pages = {157--166},
pmid = {18267787},
title = {{Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}},
volume = {5},
year = {1994}
}
@article{Levy2014,
abstract = {We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word simi-larity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization.},
archivePrefix = {arXiv},
arxivId = {1405.4053},
author = {Levy, Omer and Goldberg, Yoav},
eprint = {1405.4053},
file = {:home/memo/Mendeley/data/Levy, Goldberg - 2014 - Neural Word Embedding as Implicit Matrix Factorization.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {2177--2185},
title = {{Neural Word Embedding as Implicit Matrix Factorization}},
url = {http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization},
year = {2014}
}
@article{Bengio2003,
abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
archivePrefix = {arXiv},
arxivId = {arXiv:1301.3781v3},
author = {Bengio, Yoshua and Ducharme, R{\'{e}}jean and Vincent, Pascal and Janvin, Christian},
doi = {10.1162/153244303322533223},
eprint = {arXiv:1301.3781v3},
file = {:home/memo/Mendeley/data/Bengio et al. - 2003 - A Neural Probabilistic Language Model.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {The Journal of Machine Learning Research},
keywords = {artificial neural networks,curse of dimensionality,distributed representation,statistical language modeling},
pages = {1137--1155},
pmid = {18244602},
title = {{A Neural Probabilistic Language Model}},
volume = {3},
year = {2003}
}
@article{Mikolov2013a,
abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
author = {Mikolov, Tomas and Corrado, Greg and Chen, Kai and Dean, Jeffrey},
file = {:home/memo/Mendeley/data/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf:pdf},
journal = {Proceedings of the International Conference on Learning Representations (ICLR 2013)},
pages = {1--12},
title = {{Efficient Estimation of Word Representations in Vector Space}},
year = {2013}
}
@article{Mikolov2013b,
abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large num- ber of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alterna- tive to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of “Canada” and “Air” cannot be easily combined to obtain “Air Canada”. Motivated by this example,we present a simplemethod for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
archivePrefix = {arXiv},
arxivId = {1310.4546},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
doi = {10.1162/jmlr.2003.3.4-5.951},
eprint = {1310.4546},
file = {:home/memo/Mendeley/data/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases and their Compositionality.pdf:pdf},
isbn = {2150-8097},
issn = {10495258},
journal = {NIPS},
pages = {1--9},
pmid = {903},
title = {{Distributed Representations of Words and Phrases and their Compositionality}},
year = {2013}
}
@article{Kiros,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.06726v1},
author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan and Zemel, Richard S and Torralba, Antonio and Urtasun, Raquel and Fidler, Sanja},
eprint = {arXiv:1506.06726v1},
file = {:home/memo/Mendeley/data/Kiros et al. - Unknown - Skip-Thought Vectors arXiv 1506 . 06726v1 cs . CL 22 Jun 2015.pdf:pdf},
number = {786},
pages = {1--11},
title = {{Skip-Thought Vectors arXiv : 1506 . 06726v1 [ cs . CL ] 22 Jun 2015}}
}
@article{Nguyen2016,
abstract = {Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right—similar to why we study the human brain—and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images).},
author = {Nguyen, Anh and Dosovitskiy, Alexey and Yosinski, Jason and Brox, Thomas and Clune, Jeff},
file = {:home/memo/Mendeley/data/Nguyen et al. - 2016 - Synthesizing the preferred inputs for neurons in neural networks via deep generator networks.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 29},
title = {{Synthesizing the preferred inputs for neurons in neural networks via deep generator networks}},
year = {2016}
}
@article{Hoppe2008,
abstract = {We show that surface reconstruction from oriented points can be cast as a spatial Poisson problem. This Poisson formulation considers all the points at once, without resorting to heuristic spatial partitioning or blending, and is therefore highly resilient to data noise. Unlike radial basis function schemes, our Poisson approach allows a hierarchy of locally supported basis functions, and therefore the solution reduces to a well conditioned sparse linear system. We describe a spatially adaptive multiscale algorithm whose time and space complexities are proportional to the size of the reconstructed model. Experimenting with publicly available scan data, we demonstrate reconstruction of surfaces with greater detail than previously achievable.},
author = {Hoppe, Hugues},
doi = {10.1145/1364901.1364904},
file = {:home/memo/Mendeley/data/Hoppe - 2008 - Poisson surface reconstruction and its applications.pdf:pdf},
isbn = {9781605581062},
issn = {30905673},
journal = {Proceedings of the 2008 ACM symposium on Solid and physical modeling - SPM '08},
pages = {10},
pmid = {15096211},
title = {{Poisson surface reconstruction and its applications}},
url = {http://faculty.cs.tamu.edu/schaefer/teaching/689{\_}Fall2006/poissonrecon.pdf{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1364901.1364904},
year = {2008}
}
@article{Beyer2015,
abstract = {This survey gives an overview of the current state of the art in GPU techniques for interactive large-scale volume visualization. Modern techniques in this field have brought about a sea change in how interactive visualization and analysis of giga-, tera-, and petabytes of volume data can be enabled on GPUs. In addition to combining the parallel processing power of GPUs with out-of-core methods and data streaming, a major enabler for interactivity is making both the computational and the visualization effort proportional to the amount and resolution of data that is actually visible on screen, i.e., output-sensitive algorithms and system designs. This leads to recent output-sensitive approaches that are ray-guided, visualization-driven, or display-aware. In this survey, we focus on these characteristics and propose a new categorization of GPU-based large-scale volume visualization techniques based on the notions of actual output-resolution visibility and the current working set of volume bricks - the current subset of data that is minimally required to produce an output image of the desired display resolution. For our purposes here, we view parallel (distributed) visualization using clusters as an orthogonal set of techniques that we do not discuss in detail but that can be used in conjunction with what we discuss in this survey.},
author = {Beyer, Johanna and Hadwiger, Markus and Pfister, Hanspeter},
doi = {10.1111/cgf.12605},
file = {:home/memo/Mendeley/data/Beyer, Hadwiger, Pfister - 2015 - State-of-the-Art in GPU-Based Large-Scale Volume Visualization.pdf:pdf},
isbn = {-},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {GPU,STAR,large data,ray-guided,volume rendering},
number = {8},
pages = {13--37},
title = {{State-of-the-Art in GPU-Based Large-Scale Volume Visualization}},
volume = {34},
year = {2015}
}
@article{Margulis2015,
abstract = {The speech-to-song illusion (Deutsch et al., 2011) tracks the perceptual transformation from speech to song across repetitions of a brief spoken utterance. Because it involves no change in the stimulus itself, but a dramatic change in its perceived affiliation to speech or to music, it presents a unique opportunity to comparatively investigate the processing of language and music. In this study, native English-speaking participants were presented with brief spoken utterances that were subsequently repeated ten times. The utterances were drawn either from languages that are relatively difficult for a native English speaker to pronounce, or languages that are relatively easy for a native English speaker to pronounce. Moreover, the repetition could occur at regular or irregular temporal intervals. Participants rated the utterances before and after the repetitions on a 5-point Likert-like scale ranging from "sounds exactly like speech" to "sounds exactly like singing." The difference in ratings before and after was taken as a measure of the strength of the speech-to-song illusion in each case. The speech-to-song illusion occurred regardless of whether the repetitions were spaced at regular temporal intervals or not; however, it occurred more readily if the utterance was spoken in a language difficult for a native English speaker to pronounce. Speech circuitry seemed more liable to capture native and easy-to-pronounce languages, and more reluctant to relinquish them to perceived song across repetitions.},
author = {Margulis, Elizabeth H. and Simchy-Gross, Rhimmon and Black, Justin L.},
doi = {10.3389/fpsyg.2015.00048},
file = {:home/memo/Mendeley/data/Margulis, Simchy-Gross, Black - 2015 - Pronunciation difficulty, temporal regularity, and the speech-to-song illusion.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Meter,Music and language,Music perception,Repetition,Speech-to-song illusion},
number = {JAN},
pages = {1--7},
pmid = {25688225},
title = {{Pronunciation difficulty, temporal regularity, and the speech-to-song illusion}},
volume = {6},
year = {2015}
}
@inproceedings{Goodfellow2014b,
abstract = {We propose a new framework for estimating generative models via an adversar- ial process; in which we simultaneously train two models: a generative model G that captures the data distribution; and a discriminative model D that estimates the probability that a sample came from the training data rather thanG. The train- ing procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D; a unique solution exists; with G recovering the training data distribution andD equal to 1 2 everywhere. In the case where G andD are defined by multilayer perceptrons; the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference net- works during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 1},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
file = {:home/memo/Mendeley/data/Goodfellow, Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio.pdf:pdf},
pages = {2672--2680},
title = {{Generative Adversarial Nets}},
year = {2014}
}
@phdthesis{Nanjappa2012,
abstract = {The Delaunay triangulation of points in R 3 is a fundamental computational geometry structure that is useful for representing and studying objects from the physical world. The 3D Delaunay triangulation has desirable qualities that make it useful in many applications like FEM, surface reconstruction and tessellating solids. Algorithms for 3D Delaunay have been devised that utilize a multitude of techniques and are suitable for single and multi-core CPUs and distributed memory systems. With the ubiquity of the GPU in cellphones, tablets, workstations and cloud computers, there has been a growing interest in 3D Delaunay triangulation algorithms for the GPU. This thesis presents 3D Delaunay triangulation algorithms that effectively utilize the massive parallelism of the GPU. The gFlip3D algorithm is designed to enable massively parallel point insertion and flipping in 3D on the GPU. The algorithm achieves a high level of parallelism performing one point insertion per thread and one flip operation per thread. For any type of input, less than 0.0001 of the facets in the output from this algorithm are not locally Delaunay. The CUDA implementation of this algorithm achieves a speedup of up to 6 times over the 3D Delaunay triangulator of CGAL. To provide a better quality triangulation as input to massively parallel flipping algorithms, this thesis examines the coloring and dualization of the digital grid in R 3 . We show that it is difficult to color a digital grid in 3D such that the dualized triangulation is topologically and geometrically valid. We also show that dualizing a 3D digital Voronoi vertex is not possible. As an alternative technique, we demonstrate the utility of grid perturbation to coloring and dualization so that a triangulation can be obtained from it. This thesis presents the gStar4D algorithm that constructs the 3D Delaunay triangulation by using the neighbourhood information in the digital grid as an approximation of the Delaunay triangulation. It achieves this by the massively parallel creation of stars of each input point lifted to R 4 and the use of an unique star splaying approach to splay these 4D stars in parallel and make them consistent. The result is a convex hull of the lifted points and the 3D Delaunay triangulation can be obtained from its lower hull. The algorithm introduces a concept of reciprocated insertions that simplifies the inconsistency handling and an elegant technique to find the confinement proof of a point in a star. The CUDA implementation of gStar4D achieves a speedup of up to 5 times over the 3D Delaunay triangulator of CGAL. gDel3D is a heterogeneous GPU-CPU algorithm that repairs the near-Delaunay output of gFlip3D using a conservative star splaying approach on the CPU to obtain the 3D Delaunay triangulation. Stars are created only for the points in non-locally-Delaunay facets by using working sets from the triangulation. The star splaying approach conservatively creates other stars directly from the triangulation and once they are consistent repairs only the affected portion of the triangulation to obtain the 3D Delaunay triangulation. Our implementation of gDel3D achieves a speedup of up to 6 times over the 3D Delaunay triangulator of CGAL. The running time of gDel3D includes both the time taken by gFlip3D and that for fixing its output to Delaunay. The massively parallel techniques presented in this thesis are not only useful for 3D Delaunay triangulation, but can be extended and adopted to solve other computational geometry problems in R 3 and R 4 using the GPU. To demonstrate this, we extend the star splaying concepts of gStar4D and gDel3D algorithms to devise the gReg3D algorithm that can construct the 3D regular triangulation on the GPU. This algorithm allows stars to die, finds their death certificate and uses methods to propagate this information to other stars. The implementation of this algorithm achieves a speedup of up to 4 times over the 3D regular triangulator of CGAL. We also explore the concept of non-optimal flipping as a means to improve the quality of triangulation constructed from massively parallel point insertion. The algorithms described in this thesis show that the massive parallelism of the GPU can be harnessed to construct the Delaunay and regular triangulation in R 3 for all types of inputs. We also show that these techniques can be adapted easily to solve other computational geometry problems in R 3 and R 4 using the GPU. This thesis also contributes the optimized and robust implementation in CUDA of all its algorithms that can be used with all types of inputs. This is made freely available on the internet to anybody from the scientific and engineering community. With these contributions this thesis lays the foundation for further work on computing the 3D Delaunay triangulation on the GPU.},
author = {Nanjappa, Ashwin},
booktitle = {Comp.Nus.Edu.Sg},
file = {:home/memo/Mendeley/data/Nanjappa - 2012 - Delaunay Triangulation in R3 on the GPU.pdf:pdf},
pages = {191},
title = {{Delaunay Triangulation in R3 on the GPU}},
url = {http://www.comp.nus.edu.sg/{~}tants/gdel3d{\_}files/AshwinNanjappaThesis.pdf},
year = {2012}
}
@article{Theis2015,
abstract = {Probabilistic generative models can be used for compression, denoising, inpainting, texture synthesis, semi-supervised learning, unsupervised feature learning, and other tasks. Given this wide range of applications, it is not surprising that a lot of heterogeneity exists in the way image models are formulated, trained, and evaluated. As a consequence, direct comparison between image models is often difficult. This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models. In particular, we show that three of the currently most commonly used criteria---average log-likelihood, Parzen window estimates, and visual fidelity of samples---are largely independent of each other when images are high-dimensional. Good performance with respect to one criterion therefore need not imply good performance with respect to the other criteria. Our results show that extrapolation from one criterion to another is not warranted and generative models need to be evaluated directly with respect to the application(s) they were intended for. In addition, we provide examples demonstrating that Parzen window estimates should generally be avoided.},
archivePrefix = {arXiv},
arxivId = {1511.01844},
author = {Theis, Lucas and van den Oord, A{\"{a}}ron and Bethge, Matthias},
doi = {10.1177/096032717100300408},
eprint = {1511.01844},
file = {:home/memo/Mendeley/data/Theis, Oord, Bethge - 2015 - A note on the evaluation of generative models.pdf:pdf},
isbn = {1511.01844},
issn = {1477-1535},
journal = {Lighting Research and Technology},
number = {4},
pages = {284--285},
title = {{A note on the evaluation of generative models}},
url = {http://arxiv.org/abs/1511.01844},
volume = {3},
year = {2015}
}
@article{VandenBosch2013,
abstract = {Emotional arousal appears to be a major contributing factor to the pleasure that listeners experience in response to music. Accordingly, a strong positive correlation between self-reported pleasure and electrodermal activity (EDA), an objective indicator of emotional arousal, has been demonstrated when individuals listen to familiar music. However, it is not yet known to what extent familiarity contributes to this relationship. In particular, as listening to familiar music involves expectations and predictions over time based on veridical knowledge of the piece, it could be that such memory factors plays a major role. Here, we tested such a contribution by using musical stimuli entirely unfamiliar to listeners. In a second experiment we repeated the novel music to experimentally establish a sense of familiarity. We aimed to determine whether (1) pleasure and emotional arousal would continue to correlate when listeners have no explicit knowledge of how the tones will unfold, and (2) whether this could be enhanced by experimentally-induced familiarity. In the first experiment, we presented 33 listeners with 70 unfamiliar musical excerpts in two sessions. There was no relationship between the degree of experienced pleasure and emotional arousal as measured by EDA. In the second experiment, 7 participants listened to 35 unfamiliar excerpts over two sessions separated by 30 min. Repeated exposure significantly increased EDA, even though individuals did not explicitly recall having heard all the pieces before. Furthermore, increases in self-reported familiarity significantly enhanced experienced pleasure and there was a general, though not significant, increase in EDA. These results suggest that some level of expectation and predictability mediated by prior exposure to a given piece of music play an important role in the experience of emotional arousal in response to music.},
author = {van den Bosch, Iris and Salimpoor, Valorie N and Zatorre, Robert J},
doi = {10.3389/fnhum.2013.00534},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van den Bosch, Salimpoor, Zatorre - 2013 - Familiarity mediates the relationship between emotional arousal and pleasure during music lis.pdf:pdf},
isbn = {1662-5161},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {2008,and,are,eda,emotional arousal,familiarity,for as long as,history can tell us,is present in all,it continues to evolve,known cultures around the,mcdermott,moreover,music,music has been around,music, familiarity, pleasure, emotional arousal, p,new pieces of music,pleasure,psychophysiology,world},
number = {September},
pages = {534},
pmid = {24046738},
title = {{Familiarity mediates the relationship between emotional arousal and pleasure during music listening.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3763198{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Salimpoor2013,
abstract = {We used functional magnetic resonance imaging to investigate neural processes when music gains reward value the first time it is heard. The degree of activity in the mesolimbic striatal regions, especially the nucleus accumbens, during music listening was the best predictor of the amount listeners were willing to spend on previously unheard music in an auction paradigm. Importantly, the auditory cortices, amygdala, and ventromedial prefrontal regions showed increased activity during listening conditions requiring valuation, but did not predict reward value, which was instead predicted by increasing functional connectivity of these regions with the nucleus accumbens as the reward value increased. Thus, aesthetic rewards arise from the interaction between mesolimbic reward circuitry and cortical networks involved in perceptual analysis and valuation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Salimpoor, Valorie N and van den Bosch, Iris and Kovacevic, Natasa and McIntosh, Anthony Randal and Dagher, Alain and Zatorre, Robert J},
doi = {10.1126/science.1231059},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Salimpoor et al. - 2013 - Interactions between the nucleus accumbens and auditory cortices predict music reward value.pdf:pdf},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Adolescent,Adult,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Brain Mapping,Caudate Nucleus,Caudate Nucleus: physiology,Esthetics,Female,Humans,Magnetic Resonance Imaging,Male,Music,Nerve Net,Nerve Net: physiology,Neural Pathways,Neural Pathways: physiology,Nucleus Accumbens,Nucleus Accumbens: physiology,Reward,Young Adult},
number = {6129},
pages = {216--9},
pmid = {23580531},
title = {{Interactions between the nucleus accumbens and auditory cortices predict music reward value.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876311088{\&}partnerID=tZOtx3y1},
volume = {340},
year = {2013}
}
@article{Papadopoulos2014,
author = {Papadopoulos, Alexandre and Roy, Pierre and Pachet, Fran{\c{c}}ois},
file = {:home/memo/Mendeley/data/Papadopoulos, Roy, Pachet - 2014 - Avoiding Plagiarism in Markov Sequence Generation.pdf:pdf},
isbn = {9781577356806},
journal = {Proceedings of the 28th AAAI Conference on Artificial Intelligence},
pages = {2731--2737},
title = {{Avoiding Plagiarism in Markov Sequence Generation}},
url = {http://www.csl.sony.fr/downloads/papers/2014/papadopoulos-14a.pdf},
year = {2014}
}
@article{Tononi2016,
author = {Tononi, Giulio and Boly, Melanie and Massimini, Marcello and Koch, Christof},
doi = {10.1038/nrn.2016.44},
file = {:home/memo/Mendeley/data/Tononi et al. - 2016 - Integrated Information Theory from consciousness to its physical substrates.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
publisher = {Nature Publishing Group},
title = {{Integrated Information Theory: from consciousness to its physical substrates}},
url = {http://dx.doi.org/10.1038/nrn.2016.44},
volume = {in press},
year = {2016}
}
@article{Yosinski2015,
abstract = {Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.},
archivePrefix = {arXiv},
arxivId = {1506.06579},
author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
eprint = {1506.06579},
file = {:home/memo/Mendeley/data/Yosinski et al. - 2015 - Understanding Neural Networks Through Deep Visualization(2).pdf:pdf;:home/memo/Mendeley/data/Yosinski et al. - 2015 - Understanding Neural Networks Through Deep Visualization.pdf:pdf},
journal = {International Conference on Machine Learning - Deep Learning Workshop 2015},
pages = {12},
title = {{Understanding Neural Networks Through Deep Visualization}},
url = {http://arxiv.org/abs/1506.06579},
year = {2015}
}
@article{Kulkarni,
abstract = {Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. The primary difficulty arises due to insufficient exploration, resulting in an agent being unable to learn robust value functions. Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical value functions, operating at different temporal scales, with intrinsically motivated deep reinforcement learning. A top-level value function learns a policy over intrinsic goals, and a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse, delayed feedback: (1) a complex discrete MDP with stochastic transitions, and (2) the classic ATARI game 'Montezuma's Revenge'.},
archivePrefix = {arXiv},
arxivId = {1604.06057},
author = {Kulkarni, Tejas D and Narasimhan, Karthik R and {Saeedi CSAIL}, Ardavan and {Tenenbaum BCS}, Joshua B},
eprint = {1604.06057},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulkarni et al. - Unknown - Hierarchical Deep Reinforcement Learning Integrating Temporal Abstraction and Intrinsic Motivation.pdf:pdf},
pages = {1--13},
title = {{Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation}}
}
@article{Santoro2016,
abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.},
archivePrefix = {arXiv},
arxivId = {1605.06065},
author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
eprint = {1605.06065},
file = {:home/memo/Mendeley/data/Santoro et al. - 2016 - One-shot Learning with Memory-Augmented Neural Networks.pdf:pdf},
title = {{One-shot Learning with Memory-Augmented Neural Networks}},
url = {http://arxiv.org/abs/1605.06065},
year = {2016}
}
@article{Arora2015,
abstract = {Semantic word embeddings represent the meaning of a word via a vector, and are created by diverse methods including Vector Space Methods (VSMs) such as Latent Semantic Analysis (LSA), generative text models such as topic models, matrix factorization, neural nets, and energy-based models. Many of these use nonlinear operations on co-occurrence statistics, such as computing Pairwise Mutual Information (PMI). Some use hand-tuned hyperparameters and term reweighting. Often a generative model can help provide theoretical insight into such modeling choices, but there appears to be no such model to explain the above nonlinear models. For example, we know of no generative model for which the correct solution is the usual (dimension-restricted) PMI model. This paper gives a new generative model, a dynamic version of the loglinear topic model of Mnih and Hinton (2007),, as well as a pair of training objectives called RAND-WALK to compute word embeddings. The methodological novelty is to use the prior to compute closed form expressions for word statistics. These provide an explanation for the PMI model and other recent models, as well as hyperparameter choices. Experimental support is provided for the generative model assumptions, the most important of which is that latent word vectors are spatially isotropic. The model also helps explain why linear algebraic structure arises in low-dimensional semantic embeddings. Such structure has been used to solve analogy tasks by Mikolov et al. (2013a) and many subsequent papers. This theoretical explanation is to give an improved analogy solving method that improves success rates on analogy solving by a few percent.},
archivePrefix = {arXiv},
arxivId = {1502.03520},
author = {Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
eprint = {1502.03520},
file = {:home/memo/Mendeley/data/Arora et al. - 2015 - RAND-WALK A Latent Variable Model Approach to Word Embeddings.pdf:pdf},
pages = {1--32},
title = {{RAND-WALK: A Latent Variable Model Approach to Word Embeddings}},
url = {http://arxiv.org/abs/1502.03520},
year = {2015}
}
@article{Stanford2015,
author = {Stanford, Philosophy Encyclopedia},
doi = {10.1111/1467-9973.00225},
file = {:home/memo/Mendeley/data/Stanford - 2015 - The Computational Theory of Mind.pdf:pdf},
isbn = {0-87548-354-2},
issn = {00261068},
journal = {The Stanford Encyclopedia of Philosophy},
pages = {1--36},
title = {{The Computational Theory of Mind}},
year = {2015}
}
@article{Piccinini2009,
abstract = {Computationalism has been the mainstream view of cognition for decades. There are periodic reports of its demise, but they are greatly exaggerated. This essay surveys some recent literature on computationalism and reaches the following conclusions. Computationalism is a family of theories about the mechanisms of cognition. The main relevant evidence for testing computational theories comes from neuroscience, though psychology and AI are relevant too. Computationalism comes in many versions, which continue to guide competing research programs in philosophy of mind as well as psychology and neuroscience. Although our understanding of computationalism has deepened in recent years, much work in this area remains to be done.},
author = {Piccinini, Gualtiero},
doi = {10.1111/j.1747-9991.2009.00215.x},
file = {:home/memo/Mendeley/data/Piccinini - 2009 - Computationalism in the Philosophy of Mind.pdf:pdf},
isbn = {1747-9991},
issn = {17479991},
journal = {Philosophy Compass},
number = {3},
pages = {515--532},
title = {{Computationalism in the Philosophy of Mind.}},
volume = {4},
year = {2009}
}
@article{McBeath1995,
abstract = {Current theory proposes that baseball outfielders catch fly balls by selecting a running path to achieve optical acceleration cancellation of the ball. Yet people appear to lack the ability to discriminate accelerations accurately. This study supports the idea that outfielders convert the temporal problem to a spatial one by selecting a running path that maintains a linear optical trajectory (LOT) for the ball. The LOT model is a strategy of maintaining "control" over the relative direction of optical ball movement in a manner that is similar to simple predator tracking behavior.},
author = {McBeath, Michael K. and Shaffer, Dennis M. and Kaiser, Mary K.},
file = {:home/memo/Mendeley/data/McBeath, Shaffer, Kaiser - 1995 - How baseball outfielders determine where to run to catch fly balls.pdf:pdf},
journal = {Science},
number = {5210},
pages = {569--573},
title = {{How baseball outfielders determine where to run to catch fly balls}},
volume = {268},
year = {1995}
}
@article{Blake,
author = {Blake, William},
file = {:home/memo/Mendeley/data/Blake - Unknown - The physical , mathematical and, computational models.pdf:pdf},
number = {1967},
title = {{The physical , mathematical and, computational models}}
}
@misc{Ironic1991,
abstract = {from http://en.wikipedia.org/wiki/A{\_}Cyborg{\_}Manifesto A Cyborg Manifesto is an essay written by Donna Haraway. Haraway began writing the Manifesto in 1983 to address the Socialist Review request of American socialist feminists to ponder over the future of socialist feminism in the context of the early Reagan era and the decline of leftist politics. The first versions of the essay had a strong socialist and European connection that the Socialist Review East Coast Collective found too controversial to publish. The Berkeley Socialist Review Collective published the essay in 1985 under the editor Jeff Escoffier. The essay is most well known for being published in Donna Haraway's 1991 book Simians, Cyborgs and Women. $\backslash$nDonna Haraway's essay is an attempt to break away from Oedipal narratives and Christian origin doctrines like Genesis; the concept of the cyborg is a rejection of rigid boundaries, notably those separating "human" from "animal" and "human" from "machine." In A Cyborg Manifesto, she writes: "The cyborg does not dream of community on the model of the organic family, this time without the oedipal project. The cyborg would not recognize the Garden of Eden; it is not made of mud and cannot dream of returning to dust." $\backslash$nThe Manifesto criticizes traditional notions of feminism—particularly its strong emphasis on identity, rather than affinity. She uses the metaphor of a cyborg to urge feminists to move beyond the limitations of traditional gender, feminism, and politics.[2] Marisa Olson summarized Haraway's thoughts as a belief that there is no distinction between natural life and artificial man-made machines.},
author = {Haraway, Donna},
booktitle = {Nature},
file = {:home/memo/Mendeley/data/Ironic et al. - 1991 - Donna Haraway, A Cyborg Manifesto.pdf:pdf},
isbn = {0415903866},
issn = {15736776},
pages = {1--6},
pmid = {19731043},
title = {{Donna Haraway, "A Cyborg Manifesto :}},
year = {1991}
}
@article{Wei2015,
abstract = {Convolutional Neural Network (CNN) has been successful in image recognition tasks, and recent works shed lights on how CNN separates different classes with the learned inter-class knowledge through visualization. In this work, we instead visualize the intra-class knowledge inside CNN to better understand how an object class is represented in the fully-connected layers. To invert the intra-class knowledge into more interpretable images, we propose a non-parametric patch prior upon previous CNN visualization models. With it, we show how different "styles" of templates for an object class are organized by CNN in terms of location and content, and represented in a hierarchical and ensemble way. Moreover, such intra-class knowledge can be used in many interesting applications, e.g. style-based image retrieval and style-based object completion.},
archivePrefix = {arXiv},
arxivId = {1507.02379},
author = {Wei, Donglai and Zhou, Bolei and Torrabla, Antonio and Freeman, William},
eprint = {1507.02379},
file = {:home/memo/Mendeley/data/Wei et al. - 2015 - Understanding Intra-Class Knowledge Inside CNN.pdf:pdf},
journal = {CoRR},
number = {2},
pages = {6--12},
title = {{Understanding Intra-Class Knowledge Inside CNN}},
url = {http://arxiv.org/abs/1507.02379},
volume = {6},
year = {2015}
}
@article{Mahendran2015,
abstract = {Image representations, from SIFT and bag of visual words to Convolutional Neural Networks (CNNs), are a crucial component of almost all computer vision systems. However, our understanding of them remains limited. In this paper we study several landmark representations, both shallow and deep, by a number of complementary visualization techniques. These visualizations are based on the concept of "natural pre-image", namely a naturally-looking image whose representation has some notable property. We study in particular three such visualizations: inversion, in which the aim is to reconstruct an image from its representation, activation maximization, in which we search for patterns that maximally stimulate a representation component, and caricaturization, in which the visual patterns that a representation detects in an image are exaggerated. We pose this as a regularized energy-minimization framework and demonstrate its generality and effectiveness. In particular, we show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.},
archivePrefix = {arXiv},
arxivId = {1512.02017},
author = {Mahendran, Aravindh and Vedaldi, Andrea},
eprint = {1512.02017},
file = {:home/memo/Mendeley/data/Mahendran, Vedaldi - 2015 - Visualizing Deep Convolutional Neural Networks Using Natural Pre-Images.pdf:pdf},
title = {{Visualizing Deep Convolutional Neural Networks Using Natural Pre-Images}},
url = {http://arxiv.org/abs/1512.02017},
year = {2015}
}
@article{Low2012,
abstract = {We declare the following: The absence of a neocortex does not appear to preclude an organism from experiencing affective states. Convergent evidence indicates that non-human animals have the neuroanatomical, neurochemical, and neurophysiological substrates of conscious states along with the capacity to exhibit intentional behaviors. Consequently, the weight of evidence indicates that humans are not unique in possessing the neurological substrates that generate consciousness. Nonhuman animals, including all mammals and birds, and many other creatures, including octopuses, also possess these neurological substrates.},
author = {Low, Philip and Panksepp, Jaak and Reiss, Diana and Edelman, David and {Van Swinderen}, Bruno and Koch, Christof},
doi = {http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf},
file = {:home/memo/Mendeley/data/Low et al. - 2012 - The Cambridge Declaration on Consciousness.pdf:pdf},
journal = {Francis Crick Memorial Conference on Consciousness in Human and non-Human Animals},
title = {{The Cambridge Declaration on Consciousness}},
url = {http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf},
year = {2012}
}
@phdthesis{Graves2008,
abstract = {Recurrent neural networks are powerful sequence learners. They are able to incorporate context information in a flexible way, and are robust to lo- calised distortions of the input data. These properties make them well suited to sequence labelling, where input sequences are transcribed with streams of labels. Long short-term memory is an especially promising recurrent archi- tecture, able to bridge long time delays between relevant input and output events, and thereby access long range context. The aim of this thesis is to advance the state-of-the-art in supervised sequence labelling with recurrent networks in general, and long short-term memory in particular. Its two main contributions are (1) a new type of output layer that allows recurrent networks to be trained directly for sequence labelling tasks where the align- ment between the inputs and the labels is unknown, and (2) an extension of long short-term memory to multidimensional data, such as images and video sequences. Experimental results are presented on speech recognition, online and offline handwriting recognition, keyword spotting, image segmen- tation and image classification, demonstrating the advantages of advanced recurrent networks over other sequential algorithms, such as hidden Markov Models. ii},
author = {Graves, Alex},
booktitle = {Image Rochester NY},
file = {:home/memo/Mendeley/data/Graves - 2008 - Supervised Sequence Labelling with Recurrent Neural Networks.pdf:pdf},
pages = {124},
title = {{Supervised Sequence Labelling with Recurrent Neural Networks}},
year = {2008}
}
@article{Schmidhuber2012,
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1007/978-3-642-31727-9_12},
file = {:home/memo/Mendeley/data/Schmidhuber - 2012 - A formal theory of creativity to model the creation of art.pdf:pdf},
isbn = {9783642317279},
issn = {2050-6406},
journal = {Computers and Creativity},
pages = {323--337},
pmid = {24967091},
title = {{A formal theory of creativity to model the creation of art}},
volume = {9783642317},
year = {2012}
}
@article{Schmidhuber2009,
abstract = {In this summary of previous work, I argue that data becomes temporarily interesting by itself to some selfimproving, but computationally limited, subjective observer once he learns to predict or compress the data in a better way, thus making it subjectively more “beautiful.” Curiosity is the desire to create or discover more non-random, non-arbitrary, “truly novel,” regular data that allows for compression progress because its regularity was not yet known. This drive maximizes “interestingness,” the first derivative of subjective beauty or compressibility, that is, the steepness of the learning curve. It motivates exploring infants, pure mathematicians, composers, artists, dancers, comedians, yourself, and recent artificial systems.},
archivePrefix = {arXiv},
arxivId = {0812.4360},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {http://dx.doi.org/10.1007/978-3-642-02565-5_4},
eprint = {0812.4360},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber, Schmidhuber - 2009 - Simple Algorithmic Theory of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosi.pdf:pdf},
isbn = {978-3-642-02564-8},
journal = {Journal of SICE},
keywords = {art,beauty,compression,creativity,jokes,music,science},
pages = {21--32},
title = {{Simple Algorithmic Theory of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes}},
volume = {48},
year = {2009}
}
@article{Schmidhuber2009a,
archivePrefix = {arXiv},
arxivId = {0812.4360},
author = {Schmidhuber, J{\"{u}}rgen},
eprint = {0812.4360},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2009 - Driven by Compression Progress A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surpris.pdf:pdf},
isbn = {978-3-642-02564-8},
journal = {Anticipatory Behavior in Adaptive Learning Systems},
number = {April 2009},
pages = {48--76},
title = {{Driven by Compression Progress: A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes}},
volume = {5499},
year = {2009}
}
@article{Toll2013,
author = {Toll, B and Cheng, F},
file = {:home/memo/Mendeley/data/Toll, Cheng - 2013 - Surface reconstruction from point clouds.pdf:pdf},
journal = {Machining Impossible Shapes},
title = {{Surface reconstruction from point clouds}},
url = {http://link.springer.com/chapter/10.1007/978-0-387-35392-0{\_}18},
year = {2013}
}
@article{Berger2014,
abstract = {The area of surface reconstruction has seen substantial progress in the past two decades. The traditional problem addressed by surface reconstruction is to recover the digital representation of a physical shape that has been scanned, where the scanned data contains a wide variety of defects. While much of the earlier work has been focused on reconstructing a piece-wise smooth representation of the original shape, recent work has taken on more specialized priors to address significantly challenging data imperfections, where the reconstruction can take on different representations – not necessarily the explicit geometry. This state-of-the-art report surveys the field of surface reconstruction, providing a categorization with respect to priors, data imperfections, and reconstruction output. By considering a holistic view of surface reconstruction, this report provides a detailed characterization of the field, highlights similarities between diverse reconstruction techniques, and provides directions for future work in surface reconstruction.},
author = {Berger, Matthew and Alliez, Pierre and Tagliasacchi, Andrea and Seversky, Lee M and Silva, Claudio T. and Levine, Joshua a. and Sharf, Andrei},
doi = {10.2312/egst.20141040},
file = {:home/memo/Mendeley/data/Berger et al. - 2014 - State of the Art in Surface Reconstruction from Point Clouds.pdf:pdf},
isbn = {http://hdl.handle.net/10.2312/egst.20141040.161-185},
issn = {1017-4656},
journal = {Proceedings of the Eurographics 2014, Eurographics STARs},
keywords = {3D,point cloud,surface},
pages = {161--185},
title = {{State of the Art in Surface Reconstruction from Point Clouds}},
url = {http://lgg.epfl.ch/reconstar},
year = {2014}
}
@article{Lake2016,
archivePrefix = {arXiv},
arxivId = {1604.00289},
author = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
eprint = {1604.00289},
file = {:home/memo/Mendeley/data/Lake et al. - 2016 - Building Machines That Learn and Think Like People.pdf:pdf},
pages = {1--44},
title = {{Building Machines That Learn and Think Like People}},
volume = {2},
year = {2016}
}
@article{Rocki2016,
abstract = {There exists a theory of a single general-purpose learning algorithm which could explain the principles of its operation. This theory assumes that the brain has some initial rough architecture, a small library of simple innate circuits which are prewired at birth and proposes that all significant mental algorithms can be learned. Given current understanding and observations, this paper reviews and lists the ingredients of such an algorithm from both architectural and functional perspectives.},
archivePrefix = {arXiv},
arxivId = {1603.08262},
author = {Rocki, Kamil},
eprint = {1603.08262},
file = {:home/memo/Mendeley/data/Rocki - 2016 - Towards Machine Intelligence.pdf:pdf},
title = {{Towards Machine Intelligence}},
url = {http://arxiv.org/abs/1603.08262},
year = {2016}
}
@article{Turing1950,
abstract = {Seminal paper on the topic of artificial intelligence in which the concept of what is now known as the Turing test was introduced to a wide audience. Turing's paper considers the question "Can machines think?" Since the words "think" and "machine" can't be defined in a clear way that satisfies everyone, Turing suggests we "replace the question by another, which is closely related to it and is expressed in relatively unambiguous words." To do this, he must first find a simple and unambiguous idea to replace the word "think", second he must explain exactly which "machines" he is considering, and finally, armed with these tools, he formulates a new question, related to the first, that he believes he can answer in the affirmative.},
author = {Turing, Alan M},
doi = {http://dx.doi.org/10.1093%2Fmind%2FLIX.236.433},
file = {:home/memo/Mendeley/data/Turing - 1950 - Computing Machinery and Intelligence.pdf:pdf},
isbn = {2723415155},
issn = {0026-4423},
journal = {Mind},
number = {236},
pages = {433--460},
title = {{Computing Machinery and Intelligence}},
url = {papers2://publication/uuid/E74CAAC6-F3DD-47E7-AEA6-5FB511730877 http://mind.oxfordjournals.org/content/LIX/236/433},
volume = {59},
year = {1950}
}
@article{Society,
author = {Society, The Royal and Transactions, Philosophical and Society, Royal and Sciences, Biological},
doi = {10.1098/rsta.1892.0001},
file = {:home/memo/Mendeley/data/Society et al. - Unknown - Downloaded from httprstb.royalsocietypublishing.org on March 16 , 2015.pdf:pdf},
pmid = {1000105633},
title = {{Downloaded from http://rstb.royalsocietypublishing.org/ on March 16 , 2015}}
}
@article{Szegedy2015,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5{\%} top-5 error and 17.3{\%} top-1 error.},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
file = {:home/memo/Mendeley/data/Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer Vision.pdf:pdf},
journal = {arXiv preprint arXiv:1512.00567},
title = {{Rethinking the Inception Architecture for Computer Vision}},
year = {2015}
}
@article{Nivel2014,
author = {Nivel, Eric and Th{\'{o}}risson, Kristinn R and Steunebrink, Bas R and Schmidhuber, J{\"{u}}rgen and Sanz, Ricardo and Helgason, Helgi P and Chella, Antonio and Jonsson, Gudberg K},
file = {:home/memo/Mendeley/data/Nivel et al. - 2014 - Autonomous Acquisition of Natural Language.pdf:pdf},
isbn = {9789898704108},
keywords = {autonomy,communication,knowledge acquisition,natural language},
number = {July 2015},
pages = {58--66},
title = {{Autonomous Acquisition of Natural Language}},
year = {2014}
}
@misc{Papert1980,
author = {Papert, Seymour and Valente, Jose Armando and Bitelman, Beatriz},
publisher = {Brasiliense},
title = {{Logo: computadores e educa}},
year = {1980}
}
@article{Inverno,
author = {Inverno, Mark and Mccormack, Jon},
file = {:home/memo/Mendeley/data/Inverno, Mccormack - Unknown - Heroic vs Collaborative AI for the Arts.pdf:pdf},
title = {{Heroic vs Collaborative AI for the Arts}}
}
@article{Galway2009,
author = {Galway, Leo and Charles, Darryl and Black, Michaela},
doi = {10.1007/s10462-009-9112-y},
file = {:home/memo/Mendeley/data/Galway, Charles, Black - 2009 - Machine learning in digital games a survey.pdf:pdf},
keywords = {computational intelligence,digital games,game ai,machine learning},
number = {August},
pages = {123--161},
title = {{Machine learning in digital games : a survey}},
year = {2009}
}
@article{Caheny2012,
abstract = {Realtime 3D modelling of the environment and objects in it using a freehand Microsoft Kinect has recently been demonstrated. The Simultaneous Localisation and Mapping (SLAM) technique employed was possible in realtime due to almost the entire compu-tational pipeline for the system being executed by GPGPU. Such modelling systems are of wide interest in Computer Vision, Robotics and Augmented Reality research but also have more practical applications such as 3D scanning. The Point Cloud Library (PCL) , is a wide ranging open source software project for 2D/3D image and point cloud processing which is developing a Kinect {\&} GPU based 3D scanning system named KinFu. This MSc. dissertation has evaluated the compute per-formance of the existing KinFu implementation and investigated possible performance improvements both on its existing CUDA platform implementation and via prototype porting to OpenCL for access to a wider range of hardware vendors and architectures. A 30{\%} increase in the overall performance of the CUDA KinFu app was achieved by the removal of an unnecessary type conversion which is a particularly expensive operation on the Kepler generation of NVidia GPUs The most computationally expensive kernel of KinFu was successfully ported to OpenCL and tested on an AMD GPU.},
author = {Caheny, Paul},
file = {:home/memo/Mendeley/data/Caheny - 2012 - GPU accelerated Realtime 3D Modelling with Microsoft Kinect.pdf:pdf},
title = {{GPU accelerated Realtime 3D Modelling with Microsoft Kinect}},
year = {2012}
}
@article{Rezende2016,
archivePrefix = {arXiv},
arxivId = {1603.05106},
author = {Rezende, Danilo J and Mohamed, Shakir and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
eprint = {1603.05106},
file = {:home/memo/Mendeley/data/Rezende et al. - 2016 - One-Shot Generalization in Deep Generative Models.pdf:pdf},
title = {{One-Shot Generalization in Deep Generative Models}},
year = {2016}
}
@article{Rao,
author = {Rao, Delip},
file = {:home/memo/Mendeley/data/Rao - Unknown - Fairness in Machine Learning.pdf:pdf},
title = {{Fairness in Machine Learning}}
}
@book{Romei2010,
abstract = {Ontology evolution aims at maintaining an ontology up to date with respect to changes in the domain that it models or novel requirements of information systems that it enables. The recent industrial adoption of Semantic Web techniques, which rely on ontologies, has led to the increased importance of the ontology evolution research. Typical approaches to ontology evolution are designed as multiple-stage processes combining techniques from a variety of fields (e.g., natural language processing and reasoning). However, the few existing surveys on this topic lack an in-depth analysis of the various stages of the ontology evolution process. This survey extends the literature by adopting a process-centric view of ontology evolution. Accordingly, we first provide an overall process model synthesized from an overview of the existing models in the literature. Then we survey the major approaches to each of the steps in this process and conclude on future challenges for techniques aiming to solve that particular stage.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.0049v1},
author = {Romei, Andrea and Ruggieri, Salvatore},
booktitle = {The Knowledge Engineering Review},
doi = {10.1017/S000000000000000},
eprint = {arXiv:1312.0049v1},
file = {:home/memo/Mendeley/data/Romei, Ruggieri - 2010 - A multidisciplinary survey on discrimination analysis.pdf:pdf},
isbn = {0000000000000},
issn = {0269-8889},
pages = {1--31},
title = {{A multidisciplinary survey on discrimination analysis}},
volume = {00},
year = {2010}
}
@article{Dwork2011,
abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
archivePrefix = {arXiv},
arxivId = {1104.3913},
author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Rich},
eprint = {1104.3913},
file = {:home/memo/Mendeley/data/Dwork et al. - 2011 - Fairness Through Awareness.pdf:pdf},
title = {{Fairness Through Awareness}},
url = {http://arxiv.org/abs/1104.3913},
year = {2011}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei a and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
eprint = {1312.5602},
file = {:home/memo/Mendeley/data/Mnih et al. - 2015 - Human-level control through deep reinforcement learning.pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7540},
pages = {529--533},
pmid = {25719670},
publisher = {Nature Publishing Group},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}
@article{Champandard2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1603.01768v1},
author = {Champandard, Alex J},
eprint = {arXiv:1603.01768v1},
file = {:home/memo/Mendeley/data/Champandard - 2016 - Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks ( Paper Type Technical Paper ).pdf:pdf},
title = {{Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks ( Paper Type : Technical Paper )}},
year = {2016}
}
@article{Brand2000,
author = {Brand, M and Hertzmann, A},
file = {:home/memo/Mendeley/data/Brand, Hertzmann - 2000 - Style Machines.pdf:pdf},
isbn = {1581132085},
journal = {Proc. ACM SIGGRAPH},
pages = {183--192},
title = {{Style Machines}},
url = {citeseer.ist.psu.edu/brand00style.html},
year = {2000}
}
@article{Kovar2002,
abstract = {In this paper we present a novel method for creating realistic, controllable motion. Given a corpus of motion capture data, we automatically construct a directed graph called a motion graph that encapsulates connections among the database. The motion graph consists both of pieces of original motion and automatically generated transitions. Motion can be generated simply by building walks on the graph. We present a general framework for extracting particular graph walks that meet a user's specifications. We then show how this framework can be applied to the specific problem of generating different styles of locomotion along arbitrary paths.},
author = {Kovar, Lucas and Gleicher, Michael and Pighin, Fr{\'{e}}d{\'{e}}ric},
doi = {10.1145/566654.566605},
file = {:home/memo/Mendeley/data/Kovar, Gleicher, Pighin - 2002 - Motion graphs.pdf:pdf},
isbn = {1581135211},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {animation with con-,motion capture,motion synthesis},
number = {3},
pages = {1--10},
pmid = {15493324},
title = {{Motion graphs}},
volume = {21},
year = {2002}
}
@article{Arikan2002,
abstract = {There are many applications that demand large quantities of natural looking motion. It is difficult to synthesize motion that looks natural, particularly when it is people who must move. In this paper, we present a framework that generates human motions by cutting and pasting motion capture data. Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs. This approach can generate motion sequences that satisfy a variety of constraints automatically. The motions are smooth and human-looking. They are generated in real time so that we can author complex motions interactively. The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator. It can easily synthesize multiple motions that interact with each other using constraints. This framework allows the extensive re-use of motion capture data for new purposes.},
author = {Arikan, Okan and Forsyth, D. a.},
doi = {10.1145/566654.566606},
file = {:home/memo/Mendeley/data/Arikan, Forsyth - 2002 - Interactive motion generation from examples.pdf:pdf},
isbn = {1581135211},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {2,ani-,animation with constraints,clustering,do exactly what the,graph search,human motion,is difficult,it is very hard,mator wants,motion capture,motion synthesis,satisfying complex timed constraints,to obtain motions that},
number = {3},
pages = {483--490},
title = {{Interactive motion generation from examples}},
volume = {21},
year = {2002}
}
@article{Wang2008,
abstract = {This thesis introduces Gaussian process dynamical models (GPDMs) for nonlinear time series analysis. A GPDM comprises a low-dimensional latent space with associated dy- namics, and a map from the latent space to an observation space. We marginalize out the model parameters in closed-form, which leads to modeling both dynamics and ob- servation mappings as Gaussian processes. This results in a nonparametric model for dynamical systems that accounts for uncertainty in the model. We train the model on human motion capture data in which each pose is 62-dimensional, and synthesize new motions by sampling from the posterior distribution. A comparison of forecasting results between different covariance functions and sampling methods is provided, and we demon- strate a simple application of GPDM on filling in missing data. Finally, to account for latent space uncertainty, we explore different priors settings on hyperparameters and show some preliminary GPDM learning results using a Monte Carlo expectation-maximization algorithm. ii},
author = {Wang, Jack M and Fleet, David J and Hertzmann, Aaron},
doi = {10.1109/TPAMI.2007.1167},
file = {:home/memo/Mendeley/data/Wang, Fleet, Hertzmann - 2008 - Gaussian process dynamical models for human motion.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on PAMI},
number = {2},
pages = {283--298},
title = {{Gaussian process dynamical models for human motion.}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4359316},
volume = {30},
year = {2008}
}
@article{Li2002,
abstract = {In this paper, we describe a novel technique, called motion texture, for synthesizing complex human-figure motion (e.g., dancing) that is statistically similar to the original motion captured data. We define motion texture as a set of motion textons and their distribution, which characterize the stochastic and dynamic nature of the captured motion. Specifically, a motion texton is modeled by a linear dynamic system (LDS) while the texton distribution is represented by a transition matrix indicating how likely each texton is switched to another. We have designed a maximum likelihood algorithm to learn the motion textons and their relationship from the captured dance motion. The learnt motion texture can then be used to generate new animations automatically and/or edit animation sequences interactively. Most interestingly, motion texture can be manipulated at different levels, either by changing the fine details of a specific motion at the texton level or by designing a new choreography at the distribution level. Our approach is demonstrated by many synthesized sequences of visually compelling dance motion.},
author = {Li, Yan and Wang, Tianshu and Shum, Heung-Yeung},
doi = {10.1145/566654.566604},
file = {:home/memo/Mendeley/data/Li, Wang, Shum - 2002 - Motion texture a two-level statistical model for character motion synthesis.pdf:pdf},
isbn = {1581135211},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {3f beijing sigma center,49 zhichun road,bei-,china,com,email,haidian district,hshum,jing 100080,linear dynamic systems,microsoft,motion editing,motion synthesis,motion texture,no,p,r,texture synthesis,yli},
number = {3},
pages = {465--472},
pmid = {16764513},
title = {{Motion texture: a two-level statistical model for character motion synthesis}},
volume = {21},
year = {2002}
}
@article{Lee2002,
author = {Lee, J and Chai, J and Reitsma, P S A and Hodgins, J K and Pollard, N S},
file = {:home/memo/Mendeley/data/Lee et al. - 2002 - Interactive Control of Avatars with Human Motion Data.pdf:pdf},
isbn = {1581135211},
journal = {Proceedings ACM SIGGRAPH},
keywords = {avatars,controls the avatar,figure 1,human motion,interactive control,motion capture,our system,paths in maze and,real-time avatar control in,ronments,rough,s motion using sketched,the user,top,virtual envi-},
pages = {491--500},
title = {{Interactive Control of Avatars with Human Motion Data}},
year = {2002}
}
@article{Hedblom,
author = {Hedblom, Maria M and Kutz, Oliver and Neuhaus, Fabian},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hedblom, Kutz, Neuhaus - Unknown - Image Schemas as Families of Theories Image schemas are suggested to be the conceptual building block.pdf:pdf},
keywords = {computational creativity,concept invention,image schemas},
title = {{Image Schemas as Families of Theories Image schemas are suggested to be the conceptual building blocks that are}}
}
@article{Neuhaus2014,
author = {Neuhaus, Fabian and Kutz, Oliver and Codescu, Mihai and Mossakowski, Till},
file = {:home/memo/Mendeley/data/Neuhaus et al. - 2014 - Fabricating Monsters is Hard Towards the Automation of Conceptual Blending.pdf:pdf},
pages = {2--5},
title = {{Fabricating Monsters is Hard Towards the Automation of Conceptual Blending}},
year = {2014}
}
@article{Stefanou2015,
author = {Stefanou, Danae},
file = {:home/memo/Mendeley/data/Stefanou - 2015 - Investigating Social Creativity and Concept Invention in Collaborative Musical Situations.pdf:pdf},
title = {{Investigating Social Creativity and Concept Invention in Collaborative Musical Situations}},
volume = {54124},
year = {2015}
}
@article{Hedblom2014,
author = {Hedblom, Maria and Kutz, Oliver and Neuhaus, Fabian},
doi = {10.13140/2.1.4208.5440},
file = {:home/memo/Mendeley/data/Hedblom, Kutz, Neuhaus - 2014 - On the cognitive and logical role of image schemas in computational conceptual blending.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
number = {February 2016},
pages = {110--121},
title = {{On the cognitive and logical role of image schemas in computational conceptual blending}},
volume = {1315},
year = {2014}
}
@article{Gatys2015a,
abstract = {Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition. Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion. Within the model, textures are represented by the correlations between feature maps in several layers of the network. We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit. The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.},
archivePrefix = {arXiv},
arxivId = {1505.07376},
author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
eprint = {1505.07376},
file = {:home/memo/Mendeley/data/Gatys, Ecker, Bethge - 2015 - Texture Synthesis Using Convolutional Neural Networks.pdf:pdf},
journal = {Nips},
pages = {1--10},
title = {{Texture Synthesis Using Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1505.07376},
year = {2015}
}
@article{Purdy,
author = {Purdy, Scott and Purdy, Scott},
file = {:home/memo/Mendeley/data/Purdy, Purdy - Unknown - Encoding Data for HTM Systems Encoding Data for HTM Systems.pdf:pdf},
title = {{Encoding Data for HTM Systems Encoding Data for HTM Systems}}
}
@article{Im2016,
abstract = {Gatys et al. (2015) showed that optimizing pixels to match features in a convolutional network with respect reference image features is a way to render images of high visual quality. We show that unrolling this gradient-based optimization yields a recurrent computation that creates images by incrementally adding onto a visual "canvas". We propose a recurrent generative model inspired by this view, and show that it can be trained using adversarial training to generate very good image samples. We also propose a way to quantitatively compare adversarial networks by having the generators and discriminators of these networks compete against each other.},
archivePrefix = {arXiv},
arxivId = {1602.05110},
author = {Im, Daniel Jiwoong and Kim, Chris Dongjoo and Jiang, Hui and Memisevic, Roland},
eprint = {1602.05110},
file = {:home/memo/Mendeley/data/Im et al. - 2016 - Generating images with recurrent adversarial networks.pdf:pdf},
title = {{Generating images with recurrent adversarial networks}},
url = {http://arxiv.org/abs/1602.05110},
year = {2016}
}
@article{Littman,
author = {Littman, Michael L},
file = {:home/memo/Mendeley/data/Littman - Unknown - Basics of Computational Reinforcement Learning.pdf:pdf},
title = {{Basics of Computational Reinforcement Learning}}
}
@article{Silver,
author = {Silver, David and Deepmind, Google},
file = {:home/memo/Mendeley/data/Silver, Deepmind - Unknown - Tutorial Video Deep Reinforcement Learning.pdf:pdf},
title = {{Tutorial Video: Deep Reinforcement Learning}}
}
@article{Schmidhuber2010,
abstract = {The simple, but general formal theory of fun and intrinsic motivation and creativity (1990-2010) is based on the concept of maximizing intrinsic reward for the active creation or discovery of novel, surprising patterns allowing for improved prediction or data compression. It generalizes the traditional field of active learning, and is related to old, but less formal ideas in aesthetics theory and developmental psychology. It has been argued that the theory explains many essential aspects of intelligence including autonomous development, science, art, music, and humor. This overview first describes theoretically optimal (but not necessarily practical) ways of implementing the basic computational principles on exploratory, intrinsically motivated agents or robots, encouraging them to provoke event sequences exhibiting previously unknown, but learnable algorithmic regularities. Emphasis is put on the importance of limited computational resources for online prediction and compression. Discrete and continuous time formulations are given. Previous practical, but nonoptimal implementations (1991, 1995, and 1997-2002) are reviewed, as well as several recent variants by others (2005-2010). A simplified typology addresses current confusion concerning the precise nature of intrinsic motivation.},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1109/TAMD.2010.2056368},
file = {:home/memo/Mendeley/data/Schmidhuber - 2010 - Formal theory of creativity, fun, and intrinsic motivation (1990-2010).pdf:pdf},
isbn = {1943-0604},
issn = {19430604},
journal = {IEEE Transactions on Autonomous Mental Development},
keywords = {Active learning,aesthetics theory,art,attention,developmental psychology,formal theory of creativity,fun,humor,limited computational resources,music,novel patterns,novelty,science,surprise,typology of intrinsic motivation},
number = {3},
pages = {230--247},
title = {{Formal theory of creativity, fun, and intrinsic motivation (1990-2010)}},
volume = {2},
year = {2010}
}
@article{Kaelbling1996,
abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ``reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
eprint = {9605103},
file = {:home/memo/Mendeley/data/Kaelbling, Littman, Moore - 1996 - Reinforcement Learning A Survey.pdf:pdf},
journal = {Journal of artificial intelligence research},
pages = {237--285},
primaryClass = {cs},
title = {{Reinforcement Learning : A Survey}},
url = {http://arxiv.org/abs/cs/9605103},
volume = {4},
year = {1996}
}
@article{PanandWang2009,
abstract = {A survey on transfer learning. IEEE Trans. Knowl. Data Eng},
author = {{Pan and Wang}},
file = {:home/memo/Mendeley/data/Pan and Wang - 2009 - A survey on transfer learning.pdf:pdf},
pages = {1--15},
title = {{A survey on transfer learning}},
year = {2009}
}
@article{Daw1997,
author = {Daw, Nathaniel},
file = {:home/memo/Mendeley/data/Daw - 1997 - optimal and suboptimal control in brain and behavior.pdf:pdf},
title = {optimal and suboptimal control in brain and behavior},
year = {1997}
}
@article{Taylor2009,
abstract = {The reinforcement learning paradigm is a popular way to address problems that have only limited environmental feedback, rather than correctly labeled examples, as is common in other machine learning contexts. While significant progress has been made to improve learning in a single task, the idea of transfer learning has only recently been applied to reinforcement learning tasks. The core idea of transfer is that experience gained in learning to perform one task can help improve learning performance in a related, but different, task. In this article we present a framework that classifies transfer learning methods in terms of their capabilities and goals, and then use it to survey the existing literature, as well as to suggest future directions for transfer learning work.},
author = {Taylor, Matthew E and Stone, Peter},
file = {:home/memo/Mendeley/data/Taylor, Stone - 2009 - Transfer Learning for Reinforcement Learning Domains A Survey.pdf:pdf},
isbn = {15324435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {1,1998,actions with goal,example,leaning agents take sequential,maximizing a reward,multi task learning,problems,reinforcement learning,rl,signal,sutton barto,transfer learning,transfer learning objectives,which may time delayed},
pages = {1633--1685},
title = {{Transfer Learning for Reinforcement Learning Domains : A Survey}},
url = {http://portal.acm.org/citation.cfm?id=1755839},
volume = {10},
year = {2009}
}
@article{Springenberg2015,
abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
archivePrefix = {arXiv},
arxivId = {1412.6806},
author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
eprint = {1412.6806},
file = {:home/memo/Mendeley/data/Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:pdf},
isbn = {9781600066634},
journal = {Iclr},
pages = {1--14},
title = {{Striving for Simplicity: The All Convolutional Net}},
url = {http://arxiv.org/abs/1412.6806},
year = {2015}
}
@article{Veness2011,
abstract = {This paper introduces a principled approach for the design of a scalable general reinforcement learning agent. Our approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general reinforcement learning agents. Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms. We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent. To develop our approximation, we introduce a new Monte-Carlo Tree Search algorithm along with an agent-specific extension to the Context Tree Weighting algorithm. Empirically, we present a set of encouraging results on a variety of stochastic and partially observable domains. We conclude by proposing a number of directions for future research.},
archivePrefix = {arXiv},
arxivId = {0909.0801v2},
author = {Veness, Joel and Ng, Kee Siong and Hutter, Marcus and Uther, William and Silver, David},
doi = {10.1613/jair.3125},
eprint = {0909.0801v2},
file = {:home/memo/Mendeley/data/Veness et al. - 2011 - A Monte-Carlo AIXI approximation.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {95--142},
title = {{A Monte-Carlo AIXI approximation}},
volume = {40},
year = {2011}
}
@article{Schmidhuber2012slim,
author = {Schmidhuber, J{\"{u}}rgen},
file = {:home/memo/Mendeley/data/Schmidhuber - 2012 - Self-Delimiting Neural Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1210.0118},
title = {{Self-Delimiting Neural Networks}},
year = {2012}
}
@article{LeCun2010,
abstract = {The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.},
author = {LeCun, Yann and Cortes, Corinna},
journal = {AT{\&}T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},
title = {{MNIST handwritten digit database}},
year = {2010}
}
@article{Uring2016,
abstract = {The expressive power of a machine learning model is closely related to the num-ber of sequential computational steps it can learn. For example, Deep Neural Networks have been more successful than shallow networks because they can per-form a greater number of sequential computational steps (each highly parallel). The Neural Turing Machine (NTM) [8] is a model that can compactly express an even greater number of sequential computational steps, so it is even more powerful than a DNN. Its memory addressing operations are designed to be differentiable; thus the NTM can be trained with backpropagation. While differentiable memory is relatively easy to implement and train, it necessi-tates accessing the entire memory content at each computational step. This makes it difficult to implement a fast NTM. In this work, we use the Reinforce algorithm to learn where to access the memory, while using backpropagation to learn what to write to the memory. We call this model the RL-NTM. Reinforce allows our model to access a constant number of memory cells at each computational step, so its implementation can be faster. The RL-NTM is the first model that can, in principle, learn programs of unbounded running time. We successfully trained the RL-NTM to solve a number of algorithmic tasks that are simpler than the ones solvable by the fully differentiable NTM. As the RL-NTM is a fairly intricate model, we needed a method for verifying the correctness of our implementation. To do so, we developed a simple technique for numerically checking arbitrary implementations of models that use Reinforce, which may be of independent interest.},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.00521v1},
author = {Zaremba, Wojciech and Sutskever, Ilya},
eprint = {arXiv:1505.00521v1},
file = {:home/memo/Mendeley/data/Zaremba, Sutskever - 2015 - Reinforcement Learning Neural Turing Machines.pdf:pdf},
isbn = {9781424438617},
journal = {Arxiv},
pages = {1--14},
title = {{Reinforcement Learning Neural Turing Machines}},
year = {2015}
}
@article{Ioffe2015,
abstract = {{Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch{\}}. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9{\%} top-5 validation error (and 4.8{\%} test error), exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
file = {:home/memo/Mendeley/data/Ioffe, Szegedy - 2015 - Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf:pdf},
journal = {arXiv},
title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
url = {http://arxiv.org/abs/1502.03167},
year = {2015}
}
@inproceedings{Nair2010,
abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these “Stepped Sigmoid Units” are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
author = {Nair, Vinod and Hinton, Geoffrey E},
booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
file = {:home/memo/Mendeley/data/Nair, Hinton - 2010 - Rectified Linear Units Improve Restricted Boltzmann Machines.pdf:pdf},
pages = {807--814},
title = {{Rectified Linear Units Improve Restricted Boltzmann Machines}},
year = {2010}
}
@inproceedings{Jarrett2009,
author = {Jarrett, Kevin and Kavukcuoglu, Koray and Ranzato, Marc Aurelio and Lecun, Yann},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jarrett et al. - 2009 - What is the best multi-stage architecture for object recognition BT - Computer Vision, 2009 IEEE 12th Internatio.pdf:pdf},
keywords = {feature extraction,object recognition,unsupervis},
pages = {2146--2153},
publisher = {IEEE},
title = {{What is the best multi-stage architecture for object recognition?}},
year = {2009}
}
@incollection{Catmull1974,
author = {Catmull, E. and Rom, R.},
booktitle = {Computer Aided Geometric Design},
pages = {317--326},
title = {{A class of local interpolating splines}},
year = {1974}
}
@article{Lane2006,
author = {Lane, David},
file = {:home/memo/Mendeley/data/Lane - 2006 - A Quick Guide to L E.pdf:pdf},
number = {November},
pages = {1--6},
title = {{A Quick Guide to L E}},
year = {2006}
}
@article{Pinheiro2015,
author = {Pinheiro, Miguel Amavel and Kybic, Jan},
file = {:home/memo/Mendeley/data/Pinheiro, Kybic - 2015 - Geometrical Graph Matching Using Monte Carlo Tree Search.pdf:pdf},
journal = {Icip},
title = {{Geometrical Graph Matching Using Monte Carlo Tree Search}},
year = {2015}
}
@article{Du2015,
abstract = {Human actions can be represented by the trajectories of skeleton joints. Traditional methods generally model the spatial structure and temporal dynamics of human skeleton with hand-crafted features and recognize human actions by well-designed classifiers. In this paper, considering that re- current neural network (RNN) can model the long-term con- textual information of temporal sequences well, we propose an end-to-end hierarchical RNN for skeleton based action recognition. Instead of taking the whole skeleton as the in- put, we divide the human skeleton into five parts accord- ing to human physical structure, and then separately feed them to five subnets. As the number of layers increases, the representations extracted by the subnets are hierarchically fused to be the inputs of higher layers. The final represen- tations of the skeleton sequences are fed into a single-layer perceptron, and the temporally accumulated output of the perceptron is the final decision. We compare with five other deep RNN architectures derived from our model to verify the effectiveness of the proposed network, and also com- pare with several other methods on three publicly available datasets. Experimental results demonstrate that our model achieves the state-of-the-art performance with high compu- tational efficiency.},
author = {Du, Y and Wang, W and Wang, L},
doi = {10.1109/CVPR.2015.7298714},
file = {:home/memo/Mendeley/data/Du, Wang, Wang - 2015 - Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition.pdf:pdf},
isbn = {9781467369640},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {1110----1118},
title = {{Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition}},
url = {http://www.cv-foundation.org/openaccess/content{\_}cvpr{\_}2015/app/1A{\_}121.pdf},
year = {2015}
}
@article{Fragkiadaki,
archivePrefix = {arXiv},
arxivId = {arXiv:1508.00271v2},
author = {Fragkiadaki, Katerina and Malik, Jitendra},
doi = {10.1109/ICCV.2015.494},
eprint = {arXiv:1508.00271v2},
file = {:home/memo/Mendeley/data/Fragkiadaki, Malik - Unknown - Recurrent Network Models for Human Dynamics.pdf:pdf},
title = {{Recurrent Network Models for Human Dynamics}}
}
@article{Harvey2015,
abstract = {Recent work on sequence to sequence translation using Recurrent Neural Networks (RNNs) based on Long Short Term Memory (LSTM) architectures has shown great potential for learning useful representations of sequential data. These architectures, using one recurrent neural network to encode sequences into fixed-length representations, and one or more network(s) to decode representations into new sequences have the advantages of being modular, while also allowing modules to be jointly trained. A one-to-many encoder-decoder(s) scheme allows for a single encoder to provide representations serving multiple purposes. In our case, we present an LSTM encoder network able to produce representations used by two decoders: one that reconstructs, and one that classifies if the training sequence has a labelling. This allows the network to learn representations that are useful for both discriminative and generative tasks at the same time. We show how this paradigm is very well suited for semi-supervised learning with sequences. We test our proposed approach on an action recognition task using motion capture (MOCAP) sequences and show that semi-supervised feature learning can improve movement classification.},
archivePrefix = {arXiv},
arxivId = {1511.06653},
author = {Harvey, F{\'{e}}lix G. and Pal, Christopher},
eprint = {1511.06653},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harvey, Pal - 2015 - Semi-supervised Learning with Encoder-Decoder Recurrent Neural Networks Experiments with Motion Capture Sequences.pdf:pdf},
pages = {1--10},
title = {{Semi-supervised Learning with Encoder-Decoder Recurrent Neural Networks: Experiments with Motion Capture Sequences}},
url = {http://arxiv.org/abs/1511.06653},
year = {2015}
}
@article{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Atten- tive Writer (DRAW) neural network architecture for image generation. DRAWnetworks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distin- guished from real data with the naked eye. 1.},
author = {Gregor, K and Danihelka, I and Graves, A and Wierstra, D},
file = {:home/memo/Mendeley/data/Gregor et al. - 2015 - DRAW A Recurrent Neural Network For Image Generation.pdf:pdf},
journal = {arXiv preprint arXiv:1502.04623},
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
year = {2015}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
file = {:home/memo/Mendeley/data/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes.pdf:pdf},
number = {Ml},
pages = {1--14},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Gregor2013,
abstract = {We introduce a deep, generative autoencoder capable of learning hierarchies of distributed representations from data. Successive deep stochastic hidden layers are equipped with autoregressive connections, which enable the model to be sampled from quickly and exactly via ancestral sampling. We derive an efficient approximate parameter estimation method based on the minimum description length (MDL) principle, which can be seen as maximising a variational lower bound on the log-likelihood, with a feedforward neural network implementing approximate inference. We demonstrate state-of-the-art generative performance on a number of classic data sets: several UCI data sets, MNIST and Atari 2600 games.},
archivePrefix = {arXiv},
arxivId = {1310.8499},
author = {Gregor, Karol and Danihelka, Ivo and Mnih, Andriy and Blundell, Charles and Wierstra, Daan},
eprint = {1310.8499},
file = {:home/memo/Mendeley/data/Gregor et al. - 2013 - Deep AutoRegressive Networks.pdf:pdf},
title = {{Deep AutoRegressive Networks}},
url = {http://arxiv.org/abs/1310.8499},
volume = {32},
year = {2013}
}
@article{Sup2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1601.04920v1},
author = {Sup, Ecole Normale and To, France and Transactions, Philosophical},
eprint = {arXiv:1601.04920v1},
file = {:home/memo/Mendeley/data/Sup, To, Transactions - 2016 - Understanding Deep Convolutional Networks.pdf:pdf},
pages = {1--17},
title = {{Understanding Deep Convolutional Networks}},
year = {2016}
}
@article{Li2016,
abstract = {This paper studies a combination of generative Markov random field (MRF) models and discriminatively trained deep convolutional neural networks (dCNNs) for synthesizing 2D images. The generative MRF acts on higher-levels of a dCNN feature pyramid, controling the image layout at an abstract level. We apply the method to both photographic and non-photo-realistic (artwork) synthesis tasks. The MRF regularizer prevents over-excitation artifacts and reduces implausible feature mixtures common to previous dCNN inversion approaches, permitting synthezing photographic content with increased visual plausibility. Unlike standard MRF-based texture synthesis, the combined system can both match and adapt local features with considerable variability, yielding results far out of reach of classic generative MRF methods.},
archivePrefix = {arXiv},
arxivId = {1601.04589},
author = {Li, Chuan and Wand, Michael},
eprint = {1601.04589},
file = {:home/memo/Mendeley/data/Li, Wand - 2016 - Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis.pdf:pdf},
title = {{Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis}},
url = {http://arxiv.org/abs/1601.04589},
year = {2016}
}
@article{Mansimov2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.02793v1},
author = {Mansimov, Elman and Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
eprint = {arXiv:1511.02793v1},
file = {:home/memo/Mendeley/data/Mansimov et al. - 2016 - GENERATING IMAGES FROM CAPTIONS WITH ATTENTION.pdf:pdf},
pages = {1--12},
title = {{GENERATING IMAGES FROM CAPTIONS WITH ATTENTION}},
year = {2016}
}
@article{Owhadi2013,
abstract = {With the advent of high-performance computing, Bayesian methods are increasingly popular tools for the quantification of uncertainty throughout science and industry. Since these methods impact the making of sometimes critical decisions in increasingly complicated contexts, the sensitivity of their posterior conclusions with respect to the underlying models and prior beliefs is a pressing question for which there currently exist positive and negative results. We report new results suggesting that, although Bayesian methods are robust when the number of possible outcomes is finite or when only a finite number of marginals of the data-generating distribution are unknown, they are generically brittle when applied to continuous systems (and their discretizations) with finite information on the data-generating distribution. If closeness is defined in terms of the total variation metric or the matching of a finite system of moments, then (1) two practitioners who use arbitrarily close models and observe the same (possibly arbitrarily large amount of) data may reach opposite conclusions; and (2) any given prior and model can be slightly perturbed to achieve any desired posterior conclusions. The mechanism causing brittlenss/robustness suggests that learning and robustness are antagonistic requirements and raises the question of a missing stability condition for using Bayesian Inference in a continuous world under finite information.},
archivePrefix = {arXiv},
arxivId = {1308.6306},
author = {Owhadi, Houman and Scovel, Clint and Sullivan, Tim},
doi = {10.1137/130938633},
eprint = {1308.6306},
file = {:home/memo/Mendeley/data/Owhadi, Scovel, Sullivan - 2013 - On the Brittleness of Bayesian Inference.pdf:pdf},
isbn = {9550121038},
issn = {0036-1445},
keywords = {10,1137,130938633,62f15,62g35,ams subject classifications,bayesian inference,bayesian sensitivity analysis,certainty quantification,doi,misspecification,optimal un-,robustness,uncertainty quantification},
number = {4},
pages = {17},
title = {{On the Brittleness of Bayesian Inference}},
url = {http://arxiv.org/abs/1308.6306},
volume = {57},
year = {2013}
}
@article{Machado2012,
abstract = {The combination of a classifier system with an evolutionary image generation engine is explored. The framework is instantiated using an off-the-shelf face detection system and a general purpose, expression-based, genetic programming engine. By default, the classifier returns a binary output, which is inadequate to guide evolution. By retrieving information provided by intermediate results of the classification task, it became possible to develop a suitable fitness function. The experimental results show the ability of the system to evolve images that are classified as faces. A subjective analysis also reveals the unexpected nature and artistic potential of the evolved images.},
author = {Machado, Penousal and Correia, Joao and Romero, Juan},
doi = {doi:10.1007/978-3-642-29142-5_17},
file = {:home/memo/Mendeley/data/Machado, Correia, Romero - 2012 - Expression-Based Evolution of Faces.pdf:pdf},
isbn = {9783642291418},
issn = {03029743},
journal = {Proceedings of the 1st International Conference on Evolutionary and Biologically Inspired Music Sound Art and Design EvoMUSART 2012},
keywords = {automatic fitness assignment,evolutionary art,face detection,genetic algorithms,genetic programming},
pages = {188--199},
title = {{Expression-Based Evolution of Faces}},
volume = {7247},
year = {2012}
}
@misc{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - Turing - Digital Computers Applied to Games.pdf.pdf:pdf},
title = {{Turing - Digital Computers Applied to Games.pdf}}
}
@article{Mitchell2012,
abstract = {Deep structure learning is a promising new area of work in the field of machine learning. Previous work in this area has shown impressive performance, but all of it has used connectionist models. We hope to demonstrate that the utility of deep architectures is not restricted to connectionist models. Our approach is to use simple, non-connectionist dimensionality reduction techniques in conjunction with a deep architecture to examine more precisely the impact of the deep architecture itself. To do this, we use standard PCA as a baseline and compare it with a deep architecture using PCA. We perform several image classification experiments using the features generated by the two techniques, and we conclude that the deep architecture leads to improved classification performance, supporting the deep structure hypothesis.},
author = {Mitchell, B and Sheppard, J},
doi = {10.1109/ICMLA.2012.34},
file = {:home/memo/Mendeley/data/Mitchell, Sheppard - 2012 - Deep Structure Learning Beyond Connectionist Approaches.pdf:pdf},
isbn = {VO  - 1},
journal = {Machine Learning and Applications (ICMLA), 2012 11th International Conference on},
keywords = {Accuracy,Computer architecture,PCA,Standards,Support vector machines,Vectors,connectionist approach,data structures,deep architecture,deep learning,deep structure hypothesis,deep structure learning,feature extraction,image classification,image classification experiment,learning (artificial intelligence),machine learning,nonconnectionist dimensionality reduction,object recognition,principal component analysis},
pages = {162--167},
title = {{Deep Structure Learning: Beyond Connectionist Approaches}},
volume = {1},
year = {2012}
}
@article{LISAlab2014,
author = {LISA lab, University of Montreal},
file = {:home/memo/Mendeley/data/LISA lab - 2014 - theano Documentation.pdf:pdf},
title = {{theano Documentation}},
year = {2014}
}
@article{Nayebi2015,
abstract = {We compare the performance of two different types of recurrent neural networks (RNNs) for the task of algorithmic music generation, with audio waveforms as input. In particular, we focus on RNNs that have a sophisticated gating mecha-nism, namely, the Long Short-Term Memory (LSTM) network and the recently introduced Gated Recurrent Unit (GRU). Our results indicate that the generated outputs of the LSTM network were significantly more musically plausible than those of the GRU.},
author = {Nayebi, Aran and Vitelli, Matt},
file = {:home/memo/Mendeley/data/Nayebi, Vitelli - 2015 - GRUV Algorithmic Music Generation using Recurrent Neural Networks.pdf:pdf},
title = {{GRUV : Algorithmic Music Generation using Recurrent Neural Networks}},
url = {https://cs224d.stanford.edu/reports/NayebiAran.pdf},
year = {2015}
}
@article{Vondrick2015,
author = {Vondrick, Carl},
file = {:home/memo/Mendeley/data/Vondrick - 2015 - Learning visual biases from human imagination.pdf:pdf},
journal = {Nips},
pages = {1--9},
title = {{Learning visual biases from human imagination}},
year = {2015}
}
@article{Lake2014,
author = {Lake, Brenden M},
file = {:home/memo/Mendeley/data/Lake - 2014 - Towards more human-like concept learning in machines Compositionality , causality , and.pdf:pdf},
title = {{Towards more human-like concept learning in machines : Compositionality , causality , and}},
year = {2014}
}
@article{Salakhutdinov2012a,
author = {Salakhutdinov, Ruslan and Tenenbaum, Josh and Torralba, Antonio},
file = {:home/memo/Mendeley/data/Salakhutdinov, Tenenbaum, Torralba - 2012 - One-shot learning with a hierarchical nonparametric bayesian model.pdf:pdf},
journal = {Jmlr W{\&}Cp},
pages = {195--207},
title = {{One-shot learning with a hierarchical nonparametric bayesian model}},
url = {http://dspace.mit.edu/handle/1721.1/60025},
volume = {27},
year = {2012}
}
@article{Macwilliam2009,
author = {Macwilliam, Tommy},
file = {:home/memo/Mendeley/data/Macwilliam - 2009 - Math 21a Multivariable Calculus Formula and Theorem Review.pdf:pdf},
pages = {1--16},
title = {{Math 21a : Multivariable Calculus Formula and Theorem Review}},
year = {2009}
}
@article{Radford2015,
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
file = {:home/memo/Mendeley/data/Radford, Metz, Chintala - 2015 - Unsupervised representation learning with deep convolutional generative adversarial networks.pdf:pdf},
journal = {arXiv preprint arXiv:1511.06434},
title = {{Unsupervised representation learning with deep convolutional generative adversarial networks}},
year = {2015}
}
@article{Goodfellow2014a,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
file = {:home/memo/Mendeley/data/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {2672--2680},
title = {{Generative Adversarial Networks}},
year = {2014}
}
@article{Shannon1948,
abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist and Hartley on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information. The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point. Frequently the messages have meaning; that is they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem. The significant aspect is that the actual message is one selected from a set of possible messages. The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design. If the number of messages in the set is finite then this number or any monotonic function of this number can be regarded as a measure of the information produced when one message is chosen from the set, all choices being equally likely. As was pointed out by Hartley the most natural choice is the logarithmic function. Although this definition must be generalized considerably when we consider the influence of the statistics of the message and when we have a continuous range of messages, we will in all cases use an essentially logarithmic measure.},
archivePrefix = {arXiv},
arxivId = {chao-dyn/9411012},
author = {Shannon, Claude E},
doi = {10.1145/584091.584093},
eprint = {9411012},
file = {:home/memo/Mendeley/data/Shannon - 1948 - A mathematical theory of communication.pdf:pdf},
isbn = {0252725484},
issn = {07246811},
journal = {The Bell System Technical Journal},
number = {July 1928},
pages = {379--423},
pmid = {9230594},
primaryClass = {chao-dyn},
title = {{A mathematical theory of communication}},
url = {http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf},
volume = {27},
year = {1948}
}
@inproceedings{Martens2011,
abstract = {Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely diffi- cult to train them properly. Fortunately, re- cent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence prob- lems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free op- timizer (HF) by applying them to character-level language modeling tasks. The standard RNN ar- chitecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or gated) con- nections which allow the current input charac- ter to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character- level language modeling a hierarchical non- parametric sequence model. To our knowledge this represents the largest recurrent neural net- work application to date.},
author = {Sutskever, Ilya and Martens, James and Hinton, Geoffrey},
booktitle = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
file = {:home/memo/Mendeley/data/Sutskever, Martens, Hinton - 2011 - Generating Text with Recurrent Neural Networks.pdf:pdf},
pages = {1017--1024},
title = {{Generating Text with Recurrent Neural Networks}},
year = {2011}
}
@article{MacCormick2011,
abstract = {Random decision forests, structured light, and more},
author = {MacCormick, John},
file = {:home/memo/Mendeley/data/MacCormick - 2011 - How does the kinect work.pdf:pdf},
journal = {{\ldots} //Users. Dickinson. Edu/∼ Jmac/Selected-Talks/Kinect {\ldots}},
title = {{How does the kinect work?}},
url = {http://irl.postech.ac.kr/class/mr{\_}2013/Kinect{\_}sensor/references/kinect.pdf},
year = {2011}
}
@article{Soediono1989,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Soediono, Budi},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/memo/Mendeley/data/Soediono - 1989 - No Title No Title.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {icle},
pages = {160},
pmid = {25246403},
title = {{No Title No Title}},
volume = {53},
year = {1989}
}
@article{Herculano-Houzel2009,
author = {Herculano-Houzel, Suzana},
doi = {10.3389/neuro.09.031.2009},
file = {:home/memo/Mendeley/data/Herculano-Houzel - 2009 - The human brain in numbers a linearly scaled-up primate brain.pdf:pdf},
issn = {16625161},
journal = {Frontiers in Human Neuroscience},
keywords = {brain scaling,encephalization,human,number of neurons},
number = {November},
pages = {1--11},
title = {{The human brain in numbers: a linearly scaled-up primate brain}},
url = {http://journal.frontiersin.org/article/10.3389/neuro.09.031.2009/abstract},
volume = {3},
year = {2009}
}
@misc{tensorflow2015,
annote = {Abadi, Martin
Agarwal, Ashish
Barham, Paul
Brevdo, Eugene
Chen, Zhifeng
Citro, Craig
Corrado, Greg
Davis, Andy
Dean, Jeffrey
Devin, Matthieu
Ghemawat, Sanjay
Goodfellow, Ian
Harp, Andrew
Irving, Geoffrey
Isard, Michael
Jia, Yangqing
Kaiser, Lukasz
Kudlur, Manjunath
Levenberg, Josh
Man, Dan
Monga, Rajat
Moore, Sherry
Murray, Derek
Shlens, Jon
Steiner, Benoit
Sutskever, Ilya
Tucker, Paul
Vanhoucke, Vincent
Vasudevan, Vijay
Vinyals, Oriol
Warden, Pete
Wicke, Martin
Yu, Yuan
Zheng, Xiaoqiang},
author = {Abadi, Martin and Others, And},
file = {:home/memo/Mendeley/data/Abadi, Others - 2015 - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
title = {{TensorFlow : Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
url = {http://tensorflow.org/},
year = {2015}
}
@article{Ahmad2015,
abstract = {Empirical evidence demonstrates that every region of the neocortex represents information using sparse activity patterns. This paper examines Sparse Distributed Representations (SDRs), the primary information representation strategy in Hierarchical Temporal Memory (HTM) systems and the neocortex. We derive a number of properties that are core to scaling, robustness, and generalization. We use the theory to provide practical guidelines and illustrate the power of SDRs as the basis of HTM. Our goal is to help create a unified mathematical and practical framework for SDRs as it relates to cortical function. I.},
archivePrefix = {arXiv},
arxivId = {1503.07469},
author = {Ahmad, Subutai and Hawkins, Jeff},
eprint = {1503.07469},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmad, Hawkins - 2015 - Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory.pdf:pdf},
pages = {1--18},
title = {{Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory}},
year = {2015}
}
@article{Ferrier2014,
abstract = {A wide range of evidence points toward the existence of a common algorithm underlying the processing of information throughout the cerebral cortex. Several hypothesized features of this cortical algorithm are reviewed, including sparse distributed representation, Bayesian inference, hierarchical organization composed of alternating template matching and pooling layers, temporal slowness and predictive coding. Hierarchical Temporal Memory (HTM) is a family of learning algorithms and corresponding theories of cortical function that embodies these principles. HTM has previously been applied mainly to perceptual tasks typical of posterior cortex. In order to evaluate HTM as a candidate model of cortical function, it is necessary also to investigate its compatibility with the requirements of frontal cortical function. To this end, a variety of models of frontal cortical function are reviewed and integrated, to arrive at the hypothesis that frontal functions including attention, working memory and action selection depend largely upon the same basic algorithms as do posterior functions, with the notable additions of a mechanism for the active maintenance of representations and of multiple cortico-striato-thalamo-cortical loops that allow communication between regions of frontal cortex to be gated in an adaptive manner. Computational models of this system are reviewed. Finally, there is a discussion of how HTM can contribute to the understanding of frontal cortical function, and of what the requirements of frontal cortical function mean for the future development of HTM.},
archivePrefix = {arXiv},
arxivId = {1411.4702},
author = {Ferrier, Michael R.},
eprint = {1411.4702},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrier - 2014 - Toward a Universal Cortical Algorithm Examining Hierarchical Temporal Memory in Light of Frontal Cortical Function.pdf:pdf},
journal = {arXiv preprint},
pages = {1--105},
title = {{Toward a Universal Cortical Algorithm: Examining Hierarchical Temporal Memory in Light of Frontal Cortical Function}},
url = {http://arxiv.org/abs/1411.4702},
year = {2014}
}
@article{Byrne,
archivePrefix = {arXiv},
arxivId = {arXiv:1509.08255v2},
author = {Byrne, Fergal},
eprint = {arXiv:1509.08255v2},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Byrne - Unknown - Encoding Reality Prediction-Assisted Cortical Learning Algorithm in Hierarchical Temporal Memory arXiv 1509 . 08255v.pdf:pdf},
pages = {1--28},
title = {{Encoding Reality : Prediction-Assisted Cortical Learning Algorithm in Hierarchical Temporal Memory arXiv : 1509 . 08255v2 [ cs . NE ] 8 Oct 2015}}
}
@article{Hawkins2015,
abstract = {Neocortical neurons have thousands of excitatory synapses. It is a mystery how neurons integrate the input from so many synapses and what kind of large-scale network behavior this enables. It has been previously proposed that non-linear properties of dendrites enable neurons to recognize multiple patterns. In this paper we extend this idea by showing that a neuron with several thousand synapses arranged along active dendrites can learn to accurately and robustly recognize hundreds of unique patterns of cellular activity, even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where some of the patterns recognized by a neuron lead to action potentials and define the classic receptive field of the neuron, whereas the majority of the patterns recognized by a neuron act as predictions by slightly depolarizing the neuron without immediately generating an action potential. We then present a network model based on neurons with these properties and show that the network learns a robust model of time-based sequences. Given the similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory is a universal property of neocortical tissue. We further propose that cellular layers in the neocortex implement variations of the same sequence memory algorithm to achieve different aspects of inference and behavior. The neuron and network models we introduce are robust over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. The sequence capacity of the network scales linearly with the number of synapses on each neuron. Thus neurons need thousands of synapses to learn the many temporal patterns in sensory stimuli and motor sequences.},
archivePrefix = {arXiv},
arxivId = {1511.00083},
author = {Hawkins, Jeff and Ahmad, Subutai},
eprint = {1511.00083},
file = {:home/memo/Mendeley/data/Hawkins, Ahmad - 2015 - Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex.pdf:pdf},
keywords = {active dendrites,neocortex,neocortical theory,prediction,sequence memory},
pages = {1--20},
title = {{Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex}},
year = {2015}
}
@article{Karlik2010,
abstract = {The activation function used to transform the activati on level of a unit (neuron) into an output signal. There are a number of common activation functi ons in use with artificial neural networks (ANN). The most common choice of activation functions fo r multi layered perceptron (MLP) is used as transfer functions in research and engineerin g. Among the reasons for this popularity are its boundedness in the unit interval, the function's and its derivative's fast computability, and a number of amenable mathematical properties in the re alm of approximation theory. However, considering the huge variety of problem domains MLP i s applied in, it is intriguing to suspect that specific problems call for single or a set of specific a ctivation functions. The aim of this study is to analyze the performance of generalized MLP architectures which has back-propagation algorithm using various different activation functions for the neurons of hidden and output layers. For experimental comparisons, Bi-polar sigmoid, Uni-pola r sigmoid, Tanh, Conic Section, and Radial Bases Function (RBF) were used.},
author = {Karlik, Bekir and Olgac, Av},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karlik, Olgac - 2010 - Performance analysis of various activation functions in generalized MLP architectures of neural networks.pdf:pdf},
issn = {2180124X},
journal = {International Journal of Artificial Intelligence and Expert Systems (IJAE)},
keywords = {activation functions,multi layered perceptron,neural networks,performance analysis},
number = {1},
pages = {111--122},
title = {{Performance analysis of various activation functions in generalized MLP architectures of neural networks}},
url = {http://www.cscjournals.org/csc/manuscript/Journals/IJAE/volume1/Issue4/IJAE-26.pdf},
year = {2010}
}
@article{Cadieu2014,
abstract = {The primate visual system achieves remarkable visual object recognition performance even in brief presentations and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations such as the amount of noise, the number of neural recording sites, and the number trials, and computational limitations such as the complexity of the decoding classifier and the number of classifier training examples. In this work we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds.},
archivePrefix = {arXiv},
arxivId = {1406.3284},
author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel L. K. and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan a. and Majaj, Najib J. and DiCarlo, James J.},
doi = {10.1371/journal.pcbi.1003963},
eprint = {1406.3284},
file = {:home/memo/Mendeley/data/Cadieu et al. - 2014 - Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition.pdf:pdf},
issn = {15537358},
journal = {Arxiv},
pages = {35},
pmid = {25521294},
title = {{Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition}},
url = {http://arxiv.org/abs/1406.3284},
year = {2014}
}
@article{Le2015,
author = {Le, Quoc V},
file = {:home/memo/Mendeley/data/Le - 2015 - A Tutorial on Deep Learning Part 2 Autoencoders , Convolutional Neural Networks and Recurrent Neural Networks.pdf:pdf},
pages = {1--20},
title = {{A Tutorial on Deep Learning Part 2 : Autoencoders , Convolutional Neural Networks and Recurrent Neural Networks}},
year = {2015}
}
@article{Le2014,
author = {Le, Quoc V},
file = {:home/memo/Mendeley/data/Le - 2014 - A Tutorial on Deep Learning Part 1 Nonlinear Classifiers and The Backpropagation Algorithm.pdf:pdf},
pages = {1--18},
title = {{A Tutorial on Deep Learning Part 1: Nonlinear Classifiers and The Backpropagation Algorithm}},
year = {2014}
}
@article{Prusinkiewicz1990,
author = {Prusinkiewicz, Przemyslaw},
doi = {10.1007/978-1-4613-8476-2_1},
file = {:home/memo/Mendeley/data/Prusinkiewicz - 1990 - Graphical modeling using L-systems.pdf:pdf},
journal = {The Algorithmic Beauty of Plants},
pages = {1--50},
title = {{Graphical modeling using L-systems}},
url = {http://algorithmicbotany.org/papers/abop/abop-ch1.pdf},
year = {1990}
}
@article{Ratanamahatana2004,
abstract = {The Dynamic Time Warping (DTW) distance measure is a technique that has long been known in speech recognition community. It allows a non-linear mapping of one signal to another by minimizing the distance between the two. A decade ago, DTW was introduced into Data Mining community as a utility for various tasks for time series problems including classification, clustering, and anomaly detection. The technique has flourished, particularly in the last three years, and has been applied to a variety of problems in various disciplines. In spite of DTW's great success, there are still several persistent “myths” about it. These myths have caused confusion and led to much wasted research effort. In this work, we will dispel these myths with the most comprehensive set of time series experiments ever conducted},
author = {Ratanamahatana, Ca and Keogh, E},
doi = {10.1097/01.CCM.0000279204.24648.44},
file = {:home/memo/Mendeley/data/Ratanamahatana, Keogh - 2004 - Everything you know about dynamic time warping is wrong.pdf:pdf},
issn = {00903493},
journal = {Third Workshop on Mining Temporal and Sequential Data},
keywords = {data mining,dynamic time warping,experimentation},
pages = {22--25},
pmid = {15513920},
title = {{Everything you know about dynamic time warping is wrong}},
url = {http://spoken-number-recognition.googlecode.com/svn/trunk/docs/Dynamic time warping/DTW{\_}myths.pdf},
year = {2004}
}
@article{Ba2013,
abstract = {Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shal- low feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We eval- uate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for train- ing shallow feed-forward nets than those currently available.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {Ba, Lj and Caurana, R},
eprint = {arXiv:1312.6184v5},
file = {:home/memo/Mendeley/data/Ba, Caurana - 2013 - Do Deep Nets Really Need to be Deep.pdf:pdf},
journal = {arXiv preprint arXiv:1312.6184},
pages = {1--6},
title = {{Do Deep Nets Really Need to be Deep ?}},
url = {http://arxiv.org/abs/1312.6184},
year = {2013}
}
@article{Tang2015,
abstract = {Discriminative segmental models, such as segmental conditional random fields (SCRFs) and segmental structured support vector machines (SSVMs), have had success in speech recognition via both lattice rescoring and first-pass decoding. However, such models suffer from slow decoding, hampering the use of computationally expensive features, such as segment neural networks or other high-order features. A typical solution is to use approximate decoding, either by beam pruning in a single pass or by beam pruning to generate a lattice followed by a second pass. In this work, we study discriminative segmental models trained with a hinge loss (i.e., segmental structured SVMs). We show that beam search is not suitable for learning rescoring models in this approach, though it gives good approximate decoding performance when the model is already well-trained. Instead, we consider an approach inspired by structured prediction cascades, which use max-marginal pruning to generate lattices. We obtain a high-accuracy phonetic recognition system with several expensive feature types: a segment neural network, a second-order language model, and second-order phone boundary features.},
archivePrefix = {arXiv},
arxivId = {1507.06073},
author = {Tang, Hao and Wang, Weiran and Gimpel, Kevin and Livescu, Karen},
eprint = {1507.06073},
file = {:home/memo/Mendeley/data/Tang et al. - 2015 - Discriminative Segmental Cascades for Feature-Rich Phone Recognition.pdf:pdf},
title = {{Discriminative Segmental Cascades for Feature-Rich Phone Recognition}},
url = {http://arxiv.org/abs/1507.06073},
year = {2015}
}
@article{Pinto2015,
abstract = {Current learning-based robot grasping approaches exploit human-labeled datasets for training the models. However, there are two problems with such a methodology: (a) since each object can be grasped in multiple ways, manually labeling grasp locations is not a trivial task; (b) human labeling is biased by semantics. While there have been attempts to train robots using trial-and-error experiments, the amount of data used in such experiments remains substantially low and hence makes the learner prone to over-fitting. In this paper, we take the leap of increasing the available training data to 40 times more than prior work, leading to a dataset size of 50K data points collected over 700 hours of robot grasping attempts. This allows us to train a Convolutional Neural Network (CNN) for the task of predicting grasp locations without severe overfitting. In our formulation, we recast the regression problem to an 18-way binary classification over image patches. We also present a multi-stage learning approach where a CNN trained in one stage is used to collect hard negatives in subsequent stages. Our experiments clearly show the benefit of using large-scale datasets (and multi-stage training) for the task of grasping. We also compare to several baselines and show state-of-the-art performance on generalization to unseen objects for grasping.},
archivePrefix = {arXiv},
arxivId = {1509.06825},
author = {Pinto, Lerrel and Gupta, Abhinav},
eprint = {1509.06825},
file = {:home/memo/Mendeley/data/Pinto, Gupta - 2015 - Supersizing Self-supervision Learning to Grasp from 50K Tries and 700 Robot Hours.pdf:pdf},
title = {{Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours}},
url = {http://arxiv.org/abs/1509.06825},
year = {2015}
}
@article{Han,
archivePrefix = {arXiv},
arxivId = {1311.3715},
author = {Han, Helen},
eprint = {1311.3715},
file = {:home/memo/Mendeley/data/Han - Unknown - Recognizing Image Style.pdf:pdf},
pages = {1--20},
title = {{Recognizing Image Style}}
}
@article{Samuel2007,
author = {Samuel, Adrian},
file = {:home/memo/Mendeley/data/Samuel - 2007 - Nietzsche and God ( Part I).pdf:pdf},
journal = {Journal of Philosophy},
number = {Part I},
pages = {1--9},
title = {{Nietzsche and God ( Part I)}},
volume = {14},
year = {2007}
}
@article{Mckinnon2005,
author = {Mckinnon, Andrew M},
file = {:home/memo/Mendeley/data/Mckinnon - 2005 - Opium as Dialectics of Religion Metaphor , Expression and Protest.pdf:pdf},
number = {1},
pages = {15--38},
title = {{Opium as Dialectics of Religion : Metaphor , Expression and Protest}},
volume = {31},
year = {2005}
}
@article{HintonDropout2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets},
author = {Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:home/memo/Mendeley/data/Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov - 2014 - Dropout a simple way to pr.pdf:pdf},
journal = {Journal of Machine Learning Research (JMLR)},
keywords = {deep learning,model combination,neural networks,regularization},
number = {1},
pages = {1929--1958},
title = {{Dropout: a simple way to prevent neural networks from overfitting.}},
volume = {15},
year = {2014}
}
@article{Hinton2013,
abstract = {It is possible to learn multiple layers of non-linear features by backpropagating error derivatives through a feedforward neural network. This is a very effective learning procedure when there is a huge amount of labeled training data, but for many learning tasks very few labeled examples are available. In an effort to overcome the need for labeled data, several different generative models were developed that learned interesting features by modeling the higher order statistical structure of a set of input vectors. One of these generative models, the restricted Boltzmann machine (RBM), has no connections between its hidden units and this makes perceptual inference and learning much simpler. More significantly, after a layer of hidden features has been learned, the activities of these features can be used as training data for another RBM. By applying this idea recursively, it is possible to learn a deep hierarchy of progressively more complicated features without requiring any labeled data. This deep hierarchy can then be treated as a feedforward neural network which can be discriminatively fine-tuned using backpropagation. Using a stack of RBMs to initialize the weights of a feedforward neural network allows backpropagation to work effectively in much deeper networks and it leads to much better generalization. A stack of RBMs can also be used to initialize a deep Boltzmann machine that has many hidden layers. Combining this initialization method with a new method for fine-tuning the weights finally leads to the first efficient way of training Boltzmann machines with many hidden layers and millions of weights.},
author = {Hinton, Geoffrey},
doi = {10.1111/cogs.12049},
file = {:home/memo/Mendeley/data/Hinton - 2013 - Where Do Features Come From.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Backpropagation,Boltzmann machines,Contrastive divergence,Deep learning,Distributed representations,Learning features,Learning graphical models,Variational learning},
pages = {1--33},
pmid = {23800216},
title = {{Where Do Features Come From?}},
year = {2013}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {:home/memo/Mendeley/data/LeCun, Bengio, Hinton - 2015 - Deep learning.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
url = {http://dx.doi.org/10.1038/nature14539{\%}5Cn10.1038/nature14539},
volume = {521},
year = {2015}
}
@article{Botvinick,
author = {Botvinick, Matthew Michael},
file = {:home/memo/Mendeley/data/Botvinick - Unknown - Hierarchical reinforcement learning and decision making.pdf:pdf},
title = {{Hierarchical reinforcement learning and decision making}}
}
@article{Bullock2015,
author = {Bullock, Jamie and Momeni, Ali},
file = {:home/memo/Mendeley/data/Bullock, Momeni - 2015 - ml . lib Robust , Cross-platform , Open-source Machine Learning for Max and Pure Data.pdf:pdf},
pages = {265--270},
title = {{ml . lib : Robust , Cross-platform , Open-source Machine Learning for Max and Pure Data}},
year = {2015}
}
@article{Mnih2014,
abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.},
archivePrefix = {arXiv},
arxivId = {1406.6247},
author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
eprint = {1406.6247},
file = {:home/memo/Mendeley/data/Mnih et al. - 2014 - Recurrent Models of Visual Attention.pdf:pdf},
journal = {Nips},
pages = {1--12},
title = {{Recurrent Models of Visual Attention}},
url = {http://arxiv.org/abs/1406.6247},
year = {2014}
}
@article{Deng2013,
abstract = {In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference (Deng, 2011) are expanded and updated to include more recent developments in deep learning. The previous and the updated materials cover both theory and applications, and analyze its future directions. The goal of this tutorial survey is to introduce the emerging area of deep learning or hierarchical learning to the APSIPA community. Deep learning refers to a class of machine learning techniques, developed largely since 2006, where many stages of nonlinear information processing in hierarchical architectures are exploited for pattern classification and for feature learning. In the more recent literature, it is also connected to representation learning, which involves a hierarchy of features or concepts where higher-level concepts are defined from lower-level ones and where the same lower-level concepts help to define higher-level ones. In this tutorial, a brief history of deep learning research is discussed first. Then, a classificatory scheme is developed to analyze and summarize major work reported in the deep learning literature. Using this scheme, I provide a taxonomy-oriented survey on the existing deep architectures and algorithms in the literature, and categorize them into three classes: generative, discriminative, and hybrid. Three representative deep architectures --- deep auto-encoder, deep stacking network, and deep neural network (pre-trained with deep belief network) --- one in each of the three classes, are presented in more detail. Next, selected applications of deep learning are reviewed in broad areas of signal and information processing including audio/speech, image/vision, multimodality, language modeling, natural language processing, and information retrieval. Finally, future directions of deep learning are discussed and analyzed.},
author = {Deng, Li},
file = {:home/memo/Mendeley/data/Deng - 2013 - Three Classes of Deep Learning Architectures and Their Applications A Tutorial Survey.pdf:pdf},
journal = {Research.Microsoft.Com},
title = {{Three Classes of Deep Learning Architectures and Their Applications: A Tutorial Survey}},
url = {http://research.microsoft.com/pubs/192937/Transactions-APSIPA.pdf},
year = {2013}
}
@article{Colton2012b,
author = {Colton, Simon and Goodwin, Jacob and Veale, Tony},
file = {:home/memo/Mendeley/data/Colton, Goodwin, Veale - 2012 - Full-FACE Poetry Generation.pdf:pdf},
journal = {Proceedings of the Third International Conference on Computational Creativity (ICCC'12)},
pages = {95--102},
title = {{Full-FACE Poetry Generation}},
year = {2012}
}
@article{Wu2015,
author = {Wu, Di and Pigou, Lionel},
file = {:home/memo/Mendeley/data/Wu, Pigou - 2015 - Deep Dynamic Neural Networks for Gesture Segmentation and Recognition.pdf:pdf},
journal = {tPAMI},
keywords = {3d convolutional neural networks,chalearn,deep belief networks,gesture recognition},
number = {December},
pages = {1--10},
title = {{Deep Dynamic Neural Networks for Gesture Segmentation and Recognition}},
year = {2015}
}
@article{Le2011a,
abstract = {Previous work on action recognition has focused on adapting hand-designed local features, such as SIFT or HOG, from static images to the video domain. In this paper, we propose using unsupervised feature learning as a way to learn features directly from video data. More specifically, we present an extension of the Independent Subspace Analysis algorithm to learn invariant spatio-temporal features from unlabeled video data. We discovered that, despite its simplicity, this method performs surprisingly well when combined with deep learning techniques such as stacking and convolution to learn hierarchical representations. By replacing hand-designed features with our learned features, we achieve classification results superior to all previous published results on the Hollywood2, UCF, KTH and YouTube action recognition datasets. On the challenging Hollywood2 and YouTube action datasets we obtain 53.3{\%} and 75.8{\%} respectively, which are approximately 5{\%} better than the current best published results. Further benefits of this method, such as the ease of training and the efficiency of training and prediction, will also be discussed. You can download our code and learned spatio-temporal features here: http://ai.stanford.edu/{\&}{\#}x223C;wzou/},
author = {Le, Quoc V. and Zou, Will Y. and Yeung, Serena Y. and Ng, Andrew Y.},
doi = {10.1109/CVPR.2011.5995496},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le et al. - 2011 - Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis.pdf:pdf},
isbn = {9781457703942},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {3361--3368},
title = {{Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis}},
year = {2011}
}
@article{Larochelle2009,
abstract = {Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. },
author = {Larochelle, Hugo and Larochelle, Hugo and Bengio, Yoshua and Bengio, Yoshua and Lourador, Jerome and Lourador, Jerome and Lamblin, Pascal and Lamblin, Pascal},
file = {:home/memo/Mendeley/data/Larochelle et al. - 2009 - Exploring Strategies for Training Deep Neural Networks.pdf:pdf},
isbn = {3531207857},
issn = {15324435},
journal = {Journal of Machine Learning Research},
pages = {1--40},
title = {{Exploring Strategies for Training Deep Neural Networks}},
volume = {10},
year = {2009}
}
@misc{LeCunMNIST,
abstract = {The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.},
author = {LeCun, Yann and Cortes, Corinna and Burges, Christopher J.C.},
title = {{The MNIST Database}},
url = {http://yann.lecun.com/exdb/mnist/index.html}
}
@article{LeCun2012,
abstract = {Fast visual recognition in the mammalian cortex seems to be a hier- archical process by which the representation of the visual world is transformed in multiple stages from low-level retinotopic features to high-level, global and invariant features, and to object categories. Every single step in this hierarchy seems to be subject to learning. How does the visual cortex learn such hierar- chical representations by just looking at the world? How could computers learn such representations from data? Computer vision models that areweakly inspired by the visual cortex will be described. A number of unsupervised learning algo- rithms to train these models will be presented, which are based on the sparse auto-encoder concept. The effectiveness of these algorithms for learning invari- ant feature hierarchies will be demonstrated with a number of practical tasks such as scene parsing, pedestrian detection, and object classification. 1},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.1091v1},
author = {LeCun, Yann},
doi = {10.1007/978-3-642-33863-2_51},
eprint = {arXiv:1411.1091v1},
file = {:home/memo/Mendeley/data/LeCun - 2012 - Learning Invariant Feature Hierarchies.pdf:pdf},
isbn = {9783642338625},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 1},
pages = {496--505},
pmid = {1000102572},
title = {{Learning Invariant Feature Hierarchies}},
volume = {7583 LNCS},
year = {2012}
}
@article{Guo2014,
abstract = {The combination of modern Reinforcement Learning and Deep Learning approaches holds the promise of making significant progress on challenging applications requiring both rich perception and policy-selection. The Arcade Learning Environment (ALE) provides a set of Atari games that represent a useful benchmark set of such applications. A recent breakthrough in combining model-free reinforcement learning with deep learning, called DQN, achieves the best realtime agents thus far. Planning-based approaches achieve far higher scores than the best model-free approaches, but they exploit information that is not available to human players, and they are orders of magnitude slower than needed for real-time play. Our main goal in this work is to build a better real-time Atari game playing agent than DQN. The central idea is to use the slow planning-based agents to provide training data for a deep-learning architecture capable of real-time play. We proposed new agents based on this idea and show that they outperform DQN.},
author = {Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard and Wang, Xiaoshi},
file = {:home/memo/Mendeley/data/Guo et al. - 2014 - Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning.pdf:pdf},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {3338--3346},
title = {{Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning}},
volume = {2600},
year = {2014}
}
@article{Cruz-Neira1993,
abstract = {This paper describes the CAVE (CAVE Automatic Virtual Environment) virtual reality/scientific visualization system in detail and demonstrates that projection technology applied to virtual-reality goals achieves a system that matches the quality of workstation screens in terms of resolution, color, and flicker-free stereo. In addition, this format helps reduce the effect of common tracking and system latency errors. The off-axis perspective projection techniques we use are shown to be simple and straightforward. Our techniques for doing multi-screen stereo vision are enumerated, and design barriers, past and current, are described. Advantages and disadvantages of the projection paradigm are discussed, with an analysis of the effect of tracking noise and delay on the user. Successive refinement, a necessary tool for scientific visualization, is developed in the virtual reality context. The use of the CAVE as a one-to-many presentation device at SIGGRAPH '92 and Supercomputing '92 for computational science data is also mentioned.},
author = {Cruz-Neira, C and Sandin, Dj and DeFanti, Ta},
doi = {10.1145/166117.166134},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cruz-Neira, Sandin, DeFanti - 1993 - Surround-screen projection-based virtual reality the design and implementation of the CAVE.pdf:pdf},
isbn = {0897916018},
issn = {00978930},
journal = {{\ldots} of the 20Th Annual Conference on {\ldots}},
keywords = {1,3,7,cr categories and subject,descriptors,dimensional graphics and realism,head-,i,projection paradigms,real-time manipulation,stereoscopic display,three-,tracking,virtual reality},
pages = {135--142},
title = {{Surround-screen projection-based virtual reality: the design and implementation of the CAVE}},
url = {http://dl.acm.org/citation.cfm?id=166134},
year = {1993}
}
@article{Jones2013,
abstract = {IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.},
author = {Jones, Brett R and Benko, Hrvoje and Ofek, Eyal and Wilson, Andrew D.},
doi = {10.1145/2470654.2466112},
file = {:home/memo/Mendeley/data/Jones et al. - 2013 - IllumiRoom peripheral projected illusions for interactive experiences.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {869},
title = {{IllumiRoom: peripheral projected illusions for interactive experiences}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466112},
year = {2013}
}
@article{Akten2011-PSVideoStore,
author = {Akten, Memo and Steel, Barney and McNicholas, Robin and Dijk, Dirk Van and Peacock, Jools and Barendt, Tobias and Ziegler, Raffael and Trattler, Alex and Lambeth, Neil and Colledge, Elise and van der Vijver, Oli and Pybus, Robert},
title = {{Sony PlayStation VideoStore Mapping}},
year = {2011}
}
@misc{Rokeby1986,
author = {Rokeby, David},
title = {{Very Nervous System}},
year = {1986}
}
@misc{Akten2015-PR,
author = {Akten, Memo},
title = {{'Pattern Recognition' Dance Performance}},
url = {http://www.memo.tv/pattern-recognition-wip/},
year = {2015}
}
@misc{Nissen2003,
author = {Nissen, Steffen},
title = {{Fast Artificial Neural Network Library}},
url = {http://leenissen.dk/fann/wp/},
year = {2003}
}
@article{Mitra2007,
abstract = {Gesture recognition pertains to recognizingmeaning- ful expressions of motion by a human, involving the hands, arms, face, head, and/or body. It is of utmost importance in designing an intelligent and efficient human–computer interface. The ap- plications of gesture recognition are manifold, ranging from sign language through medical rehabilitation to virtual reality. In this paper, we provide a survey on gesture recognition with particu- lar emphasis on hand gestures and facial expressions.Applications involving hiddenMarkov models, particle filtering and condensa- tion, finite-state machines, optical flow, skin color, and connection- ist models are discussed in detail. Existing challenges and future research possibilities are also highlighted},
author = {Mitra, Sushmita and Acharya, Tinku},
doi = {10.1109/TSMCC.2007.893280},
file = {:home/memo/Mendeley/data/Mitra, Acharya - 2007 - Gesture Recognition A Survey.pdf:pdf},
isbn = {1094-6977 VO - 37},
issn = {10946977},
journal = {IEEE Transactions On Systems, Man, And Cybernetics - Part C: Applications And Reviews},
keywords = {Face recognition,facial expressions,hand ges-,hidden Markov models (HMMs),optical flow.,soft computing,tures},
number = {3},
pages = {311--324},
pmid = {19577412},
title = {{Gesture Recognition : A Survey}},
volume = {37},
year = {2007}
}
@article{Kiefer2014,
abstract = {Echo State Networks (ESNs), a form of recurrent neural network developed in the field of Reservoir Computing, show significant potential for use as a tool in the design of mappings for digital musical instruments. They have, however, seldom been used in this area, so this paper explores their possible uses. This project contributes a new open source library, which was developed to allow ESNs to run in the Pure Data dataflow environment. Several use cases were explored, focusing on addressing current issues in mapping research. ESNs were found to work successfully in scenarios of pattern classification, multiparametric control, explorative mapping and the design of nonlinearities and uncontrol. $\backslash$emph{\{}Un-trained{\}} behaviours are proposed, as augmentations to the conventional reservoir system that allow the player to introduce potentially interesting non-linearities and uncontrol into the reservoir. Interactive evolution style controls are proposed as strategies to help design these behaviours, which are otherwise dependent on arbitrary parameters. A study on sound classification shows that ESNs can reliably differentiate between two drum sounds, and also generalise to other similar input. Following evaluation of the use cases, heuristics are proposed to aid the use of ESNs in computer music scenarios.},
author = {Kiefer, Chris},
file = {:home/memo/Mendeley/data/Kiefer - 2014 - Musical Instrument Mapping Design with Echo State Networks.pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {echo state networks,machine learning,mapping,software},
pages = {293--298},
title = {{Musical Instrument Mapping Design with Echo State Networks}},
url = {http://www.nime.org/proceedings/2014/nime2014{\_}530.pdf},
year = {2014}
}
@article{Jones2014,
abstract = {RoomAlive is a proof-of-concept prototype that transforms any room into an immersive, augmented entertainment experience. Our system enables new interactive projection mapping experiences that dynamically adapts content to any room. Users can touch, shoot, stomp, dodge and steer projected content that seamlessly co-exists with their existing physical environment. The basic building blocks of RoomAlive are projector-depth camera units, which can be combined through a scalable, distributed framework. The projector-depth camera units are individually auto-calibrating, self-localizing, and create a unified model of the room with no user intervention. We investigate the design space of gaming experiences that are possible with RoomAlive and explore methods for dynamically mapping content based on room layout and user position. Finally we showcase four experience prototypes that demonstrate the novel interactive experiences that are possible with RoomAlive and discuss the design challenges of adapting any game to any room.},
author = {Jones, Brett and Shapira, Lior and Sodhi, Rajinder and Murdock, Michael and Mehra, Ravish and Benko, Hrvoje and Wilson, Andrew and Ofek, Eyal and MacIntyre, Blair and Raghuvanshi, Nikunj},
doi = {10.1145/2642918.2647383},
file = {:home/memo/Mendeley/data/Jones et al. - 2014 - RoomAlive Magical Experiences Enabled by Scalable, Adaptive Projector-camera Units.pdf:pdf},
isbn = {9781450330695},
journal = {Proceedings of the 27th annual ACM symposium on User interface software and technology - UIST '14},
pages = {637--644},
title = {{RoomAlive: Magical Experiences Enabled by Scalable, Adaptive Projector-camera Units}},
url = {http://dl.acm.org/citation.cfm?id=2647383{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2642918.2647383},
year = {2014}
}
@inproceedings{Mistry2009,
author = {Mistry, Pranav and Maes, Pattie},
booktitle = {ACM SIGGRAPH ASIA 2009 Sketches},
publisher = {ACM},
title = {{SixthSense: a wearable gestural interface}},
year = {2009}
}
@misc{Cohen2006,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 2006 - AARON, Colorist from Expert System to Expert.pdf:pdf},
keywords = {icle},
title = {{AARON, Colorist: from Expert System to Expert.}},
year = {2006}
}
@article{SimonyanZisserman2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1409.1556v6},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {arXiv:1409.1556v6},
file = {:home/memo/Mendeley/data/Simonyan, Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:pdf},
pages = {1--14},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
year = {2015}
}
@article{Kyprianidis2013,
abstract = {This paper surveys the field of non-photorealistic rendering (NPR), focusing on techniques for transforming 2D input (images and video) into artistically stylized renderings. We first present a taxonomy of the 2D NPR algorithms developed over the past two decades, structured according to the design characteristics and behavior of each technique. We then describe a chronology of development from the semi-automatic paint systems of the early nineties, through to the automated painterly rendering systems of the late nineties driven by image gradient analysis. Two complementary trends in the NPR literature are then addressed, with reference to our taxonomy. First, the fusion of higher level computer vision and NPR, illustrating the trends toward scene analysis to drive artistic abstraction and diversity of style. Second, the evolution of local processing approaches toward edge-aware filtering for real-time stylization of images and video. The survey then concludes with a discussion of open challenges for 2D NPR identified in recent NPR symposia, including topics such as user and aesthetic evaluation.},
author = {Kyprianidis, Jan Eric and Collomosse, John and Wang, Tinghuai and Isenberg, Tobias},
doi = {10.1109/TVCG.2012.160},
file = {:home/memo/Mendeley/data/Kyprianidis et al. - 2013 - State of the 'Art A taxonomy of artistic stylization techniques for images and video.pdf:pdf},
isbn = {10.1109/TVCG.2012.160},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Image and video stylization,artistic rendering,nonphotorealistic rendering (NPR)},
number = {5},
pages = {866--885},
pmid = {22802120},
title = {{State of the 'Art: A taxonomy of artistic stylization techniques for images and video}},
volume = {19},
year = {2013}
}
@book{Todd1992,
author = {Todd, Stephen and Latham, William},
publisher = {Academic Press, Inc.},
title = {{Evolutionary art and computers}},
year = {1992}
}
@article{Cohen2004,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 2004 - A Sorcerer's Apprentice.pdf:pdf},
keywords = {icle},
title = {{A Sorcerer's Apprentice}},
year = {2004}
}
@article{Alves2005,
abstract = {This article examines ways in which musical concepts of harmony can be applied to visual arts of motion. The article discussed several principles extracted from the ideas of computer animation pioneer John Whitney Sr. to create an artistic correspondence between abstract animation and computer music. It discussed Whitney's differential dynamics of music where he assumed that the attractive and repulsive forces of harmony's consonant/dissonant patterns function outside the dominion of music. The article also illustrated possibilities in which the principles of differential motion can be reflected in the rhythmic dimension of the music.},
author = {Alves, Bill},
doi = {10.1162/014892605775179982},
file = {:home/memo/Mendeley/data/Alves - 2005 - Digital Harmony of Sound and Light.pdf:pdf},
isbn = {0148-9267},
issn = {0148-9267},
journal = {Computer Music Journal},
number = {4},
pages = {45--54},
title = {{Digital Harmony of Sound and Light}},
volume = {29},
year = {2005}
}
@article{Sims1994,
abstract = {This paper describes a novel system for creating virtual creatures that move and behave in simulated three-dimensional physical worlds. The morphologies of creatures and the neural systems for controlling their muscle forces are both generated automatically using genetic algorithms. Dif ferent fitness evaluation functions are used to direct simulated evolutions towards specific behaviors such as swimming, walking, jumping, and following. A genetic language is presented that uses nodes and connec- tions as its primitive elements to represent directed graphs, which are used to describe both the morphology and the neural circuitry of these creatures. This genetic language defines a hyperspace con- taining an indefinite number of possible creatures with behaviors, and when it is searched using optimization techniques, a variety of successful and interesting locomotion strategies emer ge, some of which would be dif ficult to invent or build by design.},
author = {Sims, Karl},
doi = {10.1145/192161.192167},
file = {:home/memo/Mendeley/data/Sims - 1994 - Evolving virtual creatures.pdf:pdf},
isbn = {0897916670},
issn = {10645462},
journal = {Siggraph '94},
keywords = {Karl Sims},
number = {July},
pages = {15--22},
pmid = {17355189},
title = {{Evolving virtual creatures}},
url = {http://dl.acm.org/citation.cfm?id=192167{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=192161.192167},
volume = {SIGGRAPH '},
year = {1994}
}
@article{Draves2005,
abstract = {Electric Sheep is a distributed screen-saver that harnesses idle computers into a render farm with the purpose of animating and evolving artificial life-forms known as sheep. The votes of the users form the basis for the fitness function for a genetic algorithm on a space of fractal animations. Users also may design sheep by hand for inclusion in the gene pool. This paper describes the system and its algorithms, and reports statistics from 11 weeks of operation. The data indicate that Electric Sheep functions more as an amplifier of its human collaborators' creativity rather than as a traditional genetic algorithm that optimizes a fitness function.},
author = {Draves, S.},
doi = {10.1007/978-3-540-32003-6_46},
file = {:home/memo/Mendeley/data/Draves - 2005 - The Electric Sheep screen-saver A case study in aesthetic evolution.pdf:pdf},
issn = {03029743},
journal = {Proc. EvoMUSART},
pages = {458--467},
title = {{The Electric Sheep screen-saver: A case study in aesthetic evolution}},
url = {http://dx.doi.org/10.1007/978-3-540-32003-6{\_}46},
year = {2005}
}
@misc{Cope2010,
abstract = {The present invention provides a retrograde recombinant composition algorithm that creates new musical compositions based on existing musical compositions that are preferably written in software and is suitable for implementation in electro-mechanical and electronic devices that generate musical works based on existing bodies of music. The retrograde approach to recomposition according to the present invention provides a highly simplified code that executes at a high speed, and accordingly a reduced need for computational resources},
author = {Cope, David H.},
title = {{Recombinant music composition algorithm and method of using the same}},
year = {2010}
}
@article{Krueger1985,
abstract = {The human-machine interface is generalized beyond traditional control devices to permit physical participation with graphic images. The VIDEOPLACE System combines a participant's live video image with a computer graphic world. It also coordinates the behavior of graphic objects and creatures so that they appear to react to the movements of the participant's image in real-time. A prototype system has been implemented and a number of experiments with aesthetic and practical implications have been conducted. },
author = {Krueger, Myron W. and Gionfriddo, Thomas and Hinrichsen, Katrin},
doi = {10.1145/1165385.317463},
file = {:home/memo/Mendeley/data/Krueger, Gionfriddo, Hinrichsen - 1985 - VIDEOPLACE---an artificial reality.pdf:pdf},
isbn = {0897911490},
issn = {07366906},
journal = {ACM SIGCHI Bulletin},
number = {4},
pages = {35--40},
title = {{VIDEOPLACE---an artificial reality}},
volume = {16},
year = {1985}
}
@article{Cope1991,
author = {Cope, David and Dinsmore, John},
doi = {Book Review},
file = {:home/memo/Mendeley/data/Cope, Dinsmore - 1991 - Computers and Musical Style.pdf:pdf},
isbn = {0895792567},
issn = {00274224},
pages = {566--569},
title = {{Computers and Musical Style}},
year = {1991}
}
@article{Eck2002,
abstract = {In general music composed by recurrent neural networks (RNNs) suffers from a lack of global structure. Though networks can learn note-by-note transition probabilities and even reproduce phrases, attempts at learning an entire musical form and using that knowledge to guide composition have been unsuccessful. The reason for this failure seems to be that RNNs cannot keep track of temporally distant events that indicate global music structure. Long Short-Term Memory (LSTM) has succeeded in similar domains where other RNNs have failed, such as timing {\&} counting and CSL learning. In the current study we show that LSTM is also a good mechanism for learning to compose music. We compare this approach to previous attempts, with particular focus on issues of data representation. We present experimental results showing that LSTM successfully learns a form of blues music and is able to compose novel (and we believe pleasing) melodies in that style. Remarkably, once the network has found the relevant structure it does not drift from it: LSTM is able to play the blues with good timing and proper structure as long as one is willing to listen.},
author = {Eck, Douglas and Schmidhuber, J{\"{u}}rgen},
file = {:home/memo/Mendeley/data/Eck, Schmidhuber - 2002 - A First Look at Music Composition using LSTM Recurrent Neural Networks.pdf:pdf},
journal = {Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale},
title = {{A First Look at Music Composition using LSTM Recurrent Neural Networks}},
volume = {103},
year = {2002}
}
@article{Boulanger-Lewandowski2012,
abstract = {We investigate the problem of modeling symbolic sequences of polyphonic music in a completely general piano-roll representation. We introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high-dimensional sequences. Our approach outperforms many traditional models of polyphonic music on a variety of realistic datasets. We show how our musical language model can serve as a symbolic prior to improve the accuracy of polyphonic transcription.},
archivePrefix = {arXiv},
arxivId = {1206.6392},
author = {Boulanger-Lewandowski, Nicolas and Vincent, Pascal and Bengio, Yoshua},
eprint = {1206.6392},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boulanger-Lewandowski, Vincent, Bengio - 2012 - Modeling Temporal Dependencies in High-Dimensional Sequences Application to Polyphonic M.pdf:pdf},
journal = {arXiv preprint arXiv:1206.6392},
title = {{Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription}},
year = {2012}
}
@misc{MOZER1994,
abstract = {In algorithmic music composition, a simple technique involves selecting notes sequentially according to a $\backslash$ntransition table that specifies the probability of the next note as a function of the previous context. I $\backslash$ndescribe an extension of this transition table approach using a recurrent autopredictive connectionist net- $\backslash$nwork called CONCERT. CONCERT is trained on a set of pieces with the aim of extracting stylistic regulari- $\backslash$nties. CONCERT can then be used to compose new pieces. A central ingredient of CONCERT is the incor- $\backslash$nporation of psychologically-grounded representations of pitch, duration, and harmonic structure. CON- $\backslash$nCERT was tested on sets of examples artificially generated according to simple rules and was shown to $\backslash$nlearn the underlying structure, even where other approaches failed. In larger experiments, CONCERT was $\backslash$ntrained on sets of J. S. Bach pieces and traditional European folk melodies and was then allowed to com- $\backslash$npose novel melodies. Although the compositions are occasionally pleasant, and are preferred over com- $\backslash$npositions generated by a third-order transition table, the compositions suffer from a lack of global coher- $\backslash$nence. To overcome this limitation, several methods are explored to permit CONCERT to induce structure $\backslash$nat both fine and coarse scales. In experiments with a training set of waltzes, these methods yielded lim- $\backslash$nited success, but the overall results cast doubt on the promise of note-by-note prediction for composition.},
author = {MOZER, MICHAEL C.},
booktitle = {Connection Science},
doi = {10.1080/09540099408915726},
isbn = {0954009940891},
issn = {0954-0091},
number = {2-3},
pages = {247--280},
title = {{Neural Network Music Composition by Prediction: Exploring the Benefits of Psychoacoustic Constraints and Multi-scale Processing}},
volume = {6},
year = {1994}
}
@misc{Karpathy2015a,
author = {Karpathy, Andrej},
booktitle = {http://karpathy.github.io/2015/05/21/rnn-effectiveness},
title = {{The Unreasonable Effectiveness of Recurrent Neural Networks}},
url = {http://karpathy.github.io/2015/05/21/rnn-effectiveness},
year = {2015}
}
@misc{Sturm2015,
author = {Sturm, Bob},
title = {{Recurrent Neural Networks for Folk Music Generation}},
url = {https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation},
year = {2015}
}
@article{Karpathy2015b,
abstract = {Recurrent Neural Networks (RNNs), and specifically a variant with Long Short-Term Memory (LSTM), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while LSTMs provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing a comprehensive analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, an extensive analysis with finite horizon n-gram models suggest that these dependencies are actively discovered and utilized by the networks. Finally, we provide detailed error analysis that suggests areas for further study.},
author = {Karpathy, Andrej and Johnson, Justin and Li, Fei-Fei},
file = {:home/memo/Mendeley/data/Karpathy, Johnson, Li - 2015 - Visualizing and Understanding Recurrent Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1506.02078},
title = {{Visualizing and Understanding Recurrent Networks}},
year = {2015}
}
@inproceedings{Caramiaux2015,
author = {Caramiaux, Baptiste},
booktitle = {International Workshop on Movement and Computing (MOCO)},
file = {:home/memo/Mendeley/data/Caramiaux - 2015 - Motion Modeling for Expressive Interaction A Design Proposal using Bayesian Adaptive Systems.pdf:pdf},
isbn = {9781450328142},
keywords = {Adaptive Systems,Bayesian inference,Creative Applications,Expressivity,Interaction Design,Machine Learning,Motion,Particle Filtering},
publisher = {IRCAM},
title = {{Motion Modeling for Expressive Interaction A Design Proposal using Bayesian Adaptive Systems}},
volume = {5},
year = {2015}
}
@article{Bevilacqua2005,
author = {Bevilacqua, Fr{\'{e}}d{\'{e}}ric and Muller, Remy},
file = {:home/memo/Mendeley/data/Bevilacqua, Muller - 2005 - A gesture follower for performing arts.pdf:pdf},
journal = {Proceedings of the International Gesture {\ldots}},
keywords = {gesture recognition,hmm,performing arts,score-following},
pages = {3--4},
title = {{A gesture follower for performing arts}},
url = {http://www.sdela.dds.nl/cinedebate/gesturalfollower.pdf},
year = {2005}
}
@article{Sarroff,
author = {Sarroff, Andy M and Casey, Michael},
file = {:home/memo/Mendeley/data/Sarroff, Casey - Unknown - MUSICAL AUDIO SYNTHESIS USING AUTOENCODING NEURAL NETS.pdf:pdf},
title = {{MUSICAL AUDIO SYNTHESIS USING AUTOENCODING NEURAL NETS}}
}
@article{Parkinson,
author = {Parkinson, Adam and Cameron, David and Tanaka, Atau},
doi = {10.6084/m9.igshare.1327979.},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - 21 ST CENTURY MAKERS AND MATERIALITIES Proceedings of the 2nd Biennial Research Through Design Conference RTD 2015.pdf:pdf},
title = {{HapticWave: Presenting the Multiple Voices, Artefacts and Materials of a Design Research Project}}
}
@inproceedings{Metzinger2003,
abstract = {To have an ontology is to interpret a world. In this paper we argue that the brain, viewed as a representational system aimed at interpreting our world, possesses an ontology too. It creates primitives and makes existence assumptions. It decomposes target space in a way that exhibits a certain invariance, which in turn is functionally significant. We will investigate which are the functional regularities guiding this decomposition process, by answering to the following questions: What are the explicit and implicit assumptions about the structure of reality, which at the same time shape the causal profile of the brain's motor output and its representational deep structure, in particular of the conscious mind arising from it (its "phenomenal output")? How do they constrain high-level phenomena like conscious experience, the emergence of a first-person perspective, or social cognition? By reviewing a series of neuroscientific results and integrating them with a wider philosophical perspective, we will emphasize the contribution the motor system makes to this process. As it will be shown, the motor system constructs goals, actions, and intending selves as basic constituents of the world it interprets. It does so by assigning a single, unified causal role to them. Empirical evidence demonstrates that the brain models movements and action goals in terms of multimodal representations of organism-object- relations. Under a representationalist analysis, this process can be conceived of as an internal, dynamic representation of the intentionality-relation itself. We will show how such a complex form of representational content, once it is in place, can later function as a functional building block for social cognition and for a more complex, consciously experienced representation of the first-person perspective as well. ?? 2003 Elsevier Inc. All rights reserved.},
author = {Metzinger, Thomas and Gallese, Vittorio},
booktitle = {Consciousness and Cognition},
doi = {10.1016/S1053-8100(03)00072-2},
isbn = {1053-8100 (Print)$\backslash$r1053-8100 (Linking)},
issn = {10538100},
number = {4},
pages = {549--571},
pmid = {14656499},
title = {{The emergence of a shared action ontology: Building blocks for a theory}},
volume = {12},
year = {2003}
}
@article{Morris2012,
author = {Morris, Dan and Fiebrink, Rebecca},
doi = {10.1007/s00779-012-0526-1},
file = {:home/memo/Mendeley/data/Morris, Fiebrink - 2012 - Using machine learning to support pedagogy in the arts.pdf:pdf},
isbn = {0077901205261},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
keywords = {machine learning {\'{a}} education,{\'{a}} creativity},
title = {{Using machine learning to support pedagogy in the arts}},
year = {2012}
}
@book{Leman2007,
abstract = {Digital media handles music as encoded physical energy, but humans consider music in terms of beliefs, intentions, interpretations, experiences, evaluations, and significations. In this book, drawing on work in computer science, psychology, brain science, and musicology, Marc Leman proposes an embodied cognition approach to music research that will help bridge this gap. Assuming that the body plays a central role in all musical activities, and basing his approach on a hypothesis about the relationship between musical experience (mind) and sound energy (matter), Leman proposes that the human body is a biologically designed mediator that transfers physical energy to a mental levelengaging experiences, values, and intentionsand, reversing the process, transfers mental representation into material form. He suggests that this idea of the body as mediator offers a promising framework for thinking about music mediation technology. Leman argues that, under certain conditions, the natural mediator (the body) can be extended with artificial technology-based mediators. He explores the necessary conditions and analyzes ways in which they can be studied.Leman outlines his theory of embodied music cognition, introducing a model that describes the relationship between a human subject and its environment, analyzing the coupling of action and perception, and exploring different degrees of the body's engagement with music. He then examines possible applications in two core areas: interaction with music instruments and music search and retrieval in a database or digital library. The embodied music cognition approach, Leman argues, can help us develop tools that integrate artistic expression and contemporary technology.},
author = {Leman, Marc},
booktitle = {Processing},
doi = {10.1525/mp.2009.26.3.289},
isbn = {0262122936},
issn = {0730-7829},
pages = {297},
pmid = {14608693},
title = {{Embodied Music Cognition and Mediation Technology}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=s70oAeq3XYMC{\&}pgis=1},
year = {2007}
}
@article{Kohler2002,
abstract = {Many object-related actions can be recognized by their sound. We found neurons in monkey premotor cortex that discharge when the animal performs a specific action and when it hears the related sound. Most of the neurons also discharge when the monkey observes the same action. These audiovisual mirror neurons code actions independently of whether these actions are performed, heard, or seen. This discovery in the monkey homolog of Broca's area might shed light on the origin of language: audiovisual mirror neurons code abstract contents-the meaning of actions-and have the auditory access typical of human language to these contents.},
author = {Kohler, Evelyne and Keysers, Christian and Umilt{\`{a}}, M Alessandra and Fogassi, Leonardo and Gallese, Vittorio and Rizzolatti, Giacomo},
doi = {10.1126/science.1070311},
file = {:home/memo/Mendeley/data/Kohler et al. - 2002 - Hearing sounds, understanding actions action representation in mirror neurons.pdf:pdf},
isbn = {1095-9203 (Electronic)},
issn = {00368075},
journal = {Science (New York, N.Y.)},
number = {5582},
pages = {846--848},
pmid = {12161656},
title = {{Hearing sounds, understanding actions: action representation in mirror neurons.}},
volume = {297},
year = {2002}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I. and Huang, Thomas S.},
doi = {10.1109/TPAMI.2008.52},
isbn = {9781595938176},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Evaluation/methodology,Human-centered computing,Introductory and Survey},
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: Audio, visual, and spontaneous expressions}},
volume = {31},
year = {2009}
}
@article{Gillies2011,
abstract = {We present the results of a group interview of choreographers aimed at understanding their conceptions of how movement can be used to in live performance. This understanding intended to inform research into full body interaction for live performance and other more general full body interfaces. The results of the interview suggest a new way of conceiving of interaction with digital technology, neither as a representation of movement, not as an interface that responds to movement but as a means of transforming movement. This transformed movement can then serve as a starting point for a dancers responses to transformations of their own movement thus setting up an improvisational feedback loop.},
author = {Gillies, Marco and Worgan, Max and Peppe, Hestia and Robinson, Will and Kov, Nina},
file = {:home/memo/Mendeley/data/Gillies et al. - 2011 - Exploring Choreographers' Conceptions of Motion Capture for Full Body Interaction.pdf:pdf},
keywords = {Choreography,Human-computer Interaction},
title = {{Exploring Choreographers' Conceptions of Motion Capture for Full Body Interaction}},
url = {http://eprints.gold.ac.uk/5779/},
volume = {3},
year = {2011}
}
@article{Bastanlar2014,
abstract = {The machine learning field, which can be briefly defined as enabling computers make successful predictions using past experiences, has exhibited an impressive development recently with the help of the rapid increase in the storage capacity and processing power of computers. Together with many other disciplines, machine learning methods have been widely employed in bioinformatics. The difficulties and cost of biological analyses have led to the development of sophisticated machine learning approaches for this application area. In this chapter, we first review the fundamental concepts of machine learning such as feature assessment, unsupervised versus supervised learning and types of classification. Then, we point out the main issues of designing machine learning experiments and their performance evaluation. Finally, we introduce some supervised learning methods.},
archivePrefix = {arXiv},
arxivId = {0904.3664v1},
author = {Baştanlar, Yalin and {\"{O}}zuysal, Mustafa},
doi = {10.1007/978-1-62703-748-8-7},
eprint = {0904.3664v1},
isbn = {9781627037471},
issn = {10643745},
journal = {Methods in Molecular Biology},
keywords = {Classification,Clustering,Dimensionality reduction,Machine learning,Model complexity,Model evaluation,Performance metrics,Regression,Supervised learning,Unsupervised learning},
pages = {105--128},
pmid = {24272434},
title = {{Introduction to machine learning}},
volume = {1107},
year = {2014}
}
@article{Cowie2001,
abstract = {Two channels have been distinguished in human interaction: one transmits explicit messages, which may be about anything or nothing; the other transmits implicit messages about the speakers themselves. Both linguistics and technology have invested enormous efforts in understanding the first, explicit channel, but the second is not as well understood. Understanding the other party's emotions is one of the key tasks associated with the second, implicit channel. To tackle that task, signal processing and analysis techniques have to be developed, while, at the same time, consolidating psychological and linguistic analyses of emotion. This article examines basic issues in those areas. It is motivated by the PKYSTA project, in which we aim to develop a hybrid system capable of using information from faces and voices to recognize people's emotions},
author = {Cowie, R and Douglas-Cowie, E and Tsapatsoulis, N and Votsis, G and Kollias, S and Fellenz, W and Taylor, J G},
doi = {10.1109/79.911197},
file = {:home/memo/Mendeley/data/Cowie et al. - 2001 - Emotion recognition in human-computer interaction.pdf:pdf},
isbn = {1053-5888},
issn = {1053-5888},
journal = {Signal Processing Magazine, IEEE},
keywords = {PKYSTA project,emotion recognition,faces,human-com},
number = {1},
pages = {32--80},
pmid = {15921887},
title = {{Emotion recognition in human-computer interaction}},
volume = {18},
year = {2001}
}
@article{Mccormack2012,
abstract = {This paper addresses problems in computational creative discovery, either autonomous or in synergetic tandem with humans. A computer program generates output as a combination of base primitives whose interpretation must lie outside the program itself. Concepts of combinatoric and creative emergence are analysed in relation to creative outputs being novel and appropriate combinations of base primitives, with the conclusion that the choice of the generative process that builds and combines the primitives is of high importance. The generalised concept of an artificial ecosystem, which adapts concepts and processes from a biological ecosystem at a metaphoric level, is an appropriate generative system for creative discovery. The fundamental properties of artificial ecosystems are discussed and examples given in two different creative problem domains. Systems are implemented as pure simulation, and where the ecosystem concept is expanded to include real environments and people as ecosystem components, offer an alternative to the `software tool' approach of conventional creative software.},
author = {Mccormack, Jon},
doi = {10.1007/978-3-642-31727-9},
file = {:home/memo/Mendeley/data/Mccormack - 2007 - Creative Ecosystems.pdf:pdf},
isbn = {978-3-642-31726-2},
journal = {Proceedings of the 4th Inter- national Joint Workshop on Computational Creativity},
keywords = {artificial ecosystems,combinationalism},
number = {Boden 2010},
pages = {129--136},
title = {{Creative Ecosystems}},
url = {http://link.springer.com/10.1007/978-3-642-31727-9},
year = {2007}
}
@book{Whitney1981,
author = {Whitney, John},
isbn = {007070015X},
publisher = {McGraw-Hill, Inc.},
title = {{Digital Harmony: On the Complementarity of Music and Visual Art}},
year = {1981}
}
@article{Camurri2001,
abstract = {The paper aims at (i) understanding expressiveness in gestures using computational modeling and (ii) exploit this understanding in artistic applications, where the enhancement of the expressiveness in interactive music/dance/video systems is a major goal. A multi-layered conceptual framework is presented and examples are given of its use in interactive art performances.},
author = {Camurri, Antonio and Poli, Giovanni De and Leman, Marc and Volpe, Gualtiero},
file = {:home/memo/Mendeley/data/Camurri et al. - 2001 - A Multi-layered Conceptual Framework for Expressive Gesture Applications.pdf:pdf},
journal = {In Proceedings of MOSART: Workshop on Current Directions in Computer Music},
pages = {29--34},
title = {{A Multi-layered Conceptual Framework for Expressive Gesture Applications}},
year = {2001}
}
@article{Caramiaux2009,
abstract = {The CAL3QHC model was used to predict carbon monoxide (CO) concentrations from motor vehicles at an existing urban intersection (Star Cinema in Muscat area, Oman). The CO concentrations predicted from the model were compared with those measured in the field. Predicted average CO concentrations were found to compare favorably with measured values obtained at all eight receptors considered within the modeled intersection. In general, the comparison indicates good agreement with some underprediction for CO. For receptor 6, the model overpredicts the average CO concentration. This overprediction is associated with the presence of trees and green area in the location of receptor 6. In general, the measurements and the model results indicated that the highest CO concentrations were found to occur close to the intersection and, hence, a decrease in the concentration levels was seen as the distance from the road increased. The results indicated that the levels of CO were well below the ambient air quality standard and that probably no health risk was present in areas adjacent to the star cinema intersection. However, the predicted worst-case 1-h CO concentrations assuming inversion atmospheric stability conditions (class F) and wind speed of 1 m/s indicated that the levels of CO were close to or higher than the Omans National Ambient Air Quality Standards (NAAQS) value of 35 ppm at all receptors considered. The results of this study are useful in transport development and traffic management planning.},
author = {Caramiaux, Baptiste and Bevilacqua, Fr{\'{e}}d{\'{e}}ric and Schnell, Norbert},
doi = {10.1007/978-3-642-12553-9_14},
file = {:home/memo/Mendeley/data/Caramiaux, Bevilacqua, Schnell - 2009 - Towards a gesture-sound cross-modal analysis.pdf:pdf},
isbn = {3642125522},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Canonical correlation analysis,Gesture analysis,Gesture-sound relationship,Sound perception},
pages = {158--170},
title = {{Towards a gesture-sound cross-modal analysis}},
volume = {5934 LNAI},
year = {2009}
}
@article{Lee1992,
abstract = {In this report we present our tools for prototyping adaptive user interfaces in the context of real—time musical instrument control. Characteristic of most human communication is the simultaneous use of classified events and estimated parameters. We have integrated a neural network object into the MAX language to explore adaptive user interfaces that considers these facets of human communication. By placing the neural processing in the context of a flexible real—time musical programming environment, we can rapidly prototype experiments on applications of adaptive interfaces and learning systems to musical problems. We have trained networks to recognize gestures from a Mathews radio baton, Nintendo Power Glove, and MDI keyboard gestural input devices. In one experiment, a network successfully extracted classification and attribute data from gestural contours transduced by a continuous space controller, suggesting their application in the interpretation of conducting gestures and musical instrument control. We discuss network architectures, low—level features extracted for the networks to operate on, training methods, and musical applications of adaptive techniques.},
author = {Lee, Michael and Freed, Adrian and Wessel, David},
doi = {10.1117/12.139949},
isbn = {0819408719},
issn = {0277786X},
journal = {Proceedings of SPIE},
pages = {244--255},
title = {{Neural networks for simultaneous classification and parameter estimation in musical instrument control}},
url = {http://link.aip.org/link/?PSI/1706/244/1{\&}Agg=doi},
volume = {1706},
year = {1992}
}
@misc{Whitney,
author = {Whitney, John},
booktitle = {Digital Harmony},
file = {:home/memo/Mendeley/data/Whitney - Unknown - The Problem How Shall Motion Pattern Time.pdf:pdf},
pages = {37--45},
title = {{The Problem: How Shall Motion Pattern Time}}
}
@misc{GoogleAdvancedTechnologyAndProjects2014,
author = {{Google Advanced Technology And Projects}},
title = {{Project Tango}},
url = {https://www.google.com/atap/project-tango/},
year = {2014}
}
@article{Bowman2001a,
abstract = {Three-dimensional user interface design is a critical component of any virtual envi- ronment (VE) application. In this paper, we present a broad overview of 3-D inter- action and user interfaces. We discuss the effect of common VE hardware devices on user interaction, as well as interaction techniques for generic 3-D tasks and the use of traditional 2-D interaction styles in 3-D environments. We divide most user- interaction tasks into three categories: navigation, selection/manipulation, and system control. Throughout the paper, our focus is on presenting not only the available techniques but also practical guidelines for 3-D interaction design and widely held myths. Finally, we briey discuss two approaches to 3-D interaction design and some example applications with complex 3-D interaction requirements. We also present an annotated online bibliography as a reference companion to this article.},
author = {Bowman, Doug a. and Kruijff, Ernst and LaViola, Joseph J. and Poupyrev, Ivan},
doi = {10.1162/105474601750182342},
file = {:home/memo/Mendeley/data/Bowman et al. - 2001 - An Introduction to 3-D User Interface Design.pdf:pdf},
isbn = {8177495143},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {96--108},
pmid = {21166522},
title = {{An Introduction to 3-D User Interface Design}},
volume = {10},
year = {2001}
}
@misc{GoogleAdvancedTechnologyAndProjects2015,
author = {{Google Advanced Technology And Projects}},
title = {{Project Soli}},
url = {https://www.google.com/atap/project-soli/},
year = {2015}
}
@article{Cassell1991,
author = {Cassell, Justine and Mcneill, David},
doi = {10.2307/1772644},
file = {:home/memo/Mendeley/data/Cassell, Mcneill - 1991 - Gesture and the Poetics of Prose.pdf:pdf},
issn = {03335372},
journal = {Poetics Today},
number = {3},
pages = {375--404},
title = {{Gesture and the Poetics of Prose}},
volume = {12},
year = {1991}
}
@article{Cadoz2000,
abstract = {In this article, we comment on various definitions of the term gesture in the general literature of human- human and human-computer interaction and in the musica domain. Different propositions of gesture classifications are then discussed and topics from other disciplines, that are important to the discussion on gesture and music, are presented. Concepts developed by the first author related to instrumental gestures, such as energy continuum, gestural channel, and instrumental gesture typology are reviewed in this context. The introduction of case studies on acoustic instruments helps in supporting the theory. Finally, the role of non-obvious (ancillary or accompanist) gestures is discussed with respect to clarinet playing.},
author = {Cadoz, Claude and Wanderley, Mm},
file = {:home/memo/Mendeley/data/Cadoz, Wanderley - 2000 - Gesture-music.pdf:pdf},
journal = {Trends in gestural control of music},
pages = {71--94},
title = {{Gesture-music}},
url = {http://www.vigliensoni.com/McGill/CURSOS/2009{\_}09/MUMT620/READINGS/2/2{\_}Gesture-Music (Cadoz-Wanderley).pdf},
year = {2000}
}
@inproceedings{Fails2003,
abstract = {Perceptual user interfaces (PUIs) are an important part of ubiquitous computing. Creating such interfaces is difficult because of the image and signal processing knowledge required for creating classifiers. We propose an interactive machine-learning (IML) model that allows users to train, classify/view and correct the classifications. The concept and implementation details of IML are discussed and contrasted with classical machine learning models. Evaluations of two algorithms are also presented. We also briefly describe Image Processing with Crayons (Crayons), which is a tool for creating new camera-based interfaces using a simple painting metaphor. The Crayons tool embodies our notions of interactive machine learning},
address = {Miami, Florida, USA},
author = {Fails, Jerry Alan and {Olsen, Jr.}, Dan R. and Olsen, Dan R},
booktitle = {Proceedings of the 8th International Conference on Intelligent User Interfaces},
doi = {10.1145/604045.604056},
file = {:home/memo/Mendeley/data/Fails, Olsen, Jr., Olsen - 2003 - Interactive Machine Learning.pdf:pdf},
isbn = {1581135866},
keywords = {creating a satisfactory classifier,first foremost,however,implementation such a,machine learning,perceptive user interfaces,poses many,problem rapidly,problems,simple solution,tool},
pages = {39--45},
publisher = {ACM},
title = {{Interactive Machine Learning}},
url = {http://portal.acm.org/citation.cfm?doid=604045.604056},
year = {2003}
}
@techreport{McNeill1980,
author = {McNeill, David and Levy, Elena},
institution = {Spencer Foundation, Chicago, IL.; National Inst. of Mental Health (DHHS), Bethesda, MD},
title = {{Conceptual representations in language activity and gesture}},
year = {1980}
}
@incollection{Camurri2004,
abstract = {This paper presents ongoing research on the modelling of expressive gesture in multimodal interaction and on the development of multimodal interactive systems explicitly taking into account the role of non-verbal expressive gesture in the communication process. {\{}I{\}}n this perspective, a particular focus is on dance and music as first-class conveyors of expressive and emotional content. {\{}R{\}}esearch outputs include (i) computational models of expressive gesture, (ii) validation by means of continuous ratings on spectators exposed to real artistic stimuli, and (iii) novel hardware and software components for the {\{}E{\}}yes{\{}W{\}}eb open platform (www.eyesweb.org), such as the recently developed {\{}E{\}}xpressive {\{}G{\}}esture {\{}P{\}}rocessing {\{}L{\}}ibrary. {\{}T{\}}he paper starts with a definition of expressive gesture. {\{}A{\}} unifying framework for the analysis of expressive gesture is then proposed. {\{}F{\}}inally, two experiments on expressive gesture in dance and music are discussed. {\{}T{\}}his research work has been supported by the {\{}EU{\}} {\{}IST{\}} project {\{}MEGA{\}} ({\{}M{\}}ultisensory {\{}E{\}}xpressive {\{}G{\}}esture {\{}A{\}}pplications, www.megaproject.org) and the {\{}EU{\}} {\{}MOSART{\}} {\{}TMR{\}} {\{}N{\}}etwork.},
author = {Camurri, Antonio and Mazzarino, Barabara and Ricchetti, Matteo and Timmers, Renee and Volpe, Gualtiero},
booktitle = {Gesture-based {\{}C{\}}ommunication in {\{}H{\}}uman-{\{}C{\}}omputer {\{}I{\}}nteraction, {\{}LNAI{\}} 2915},
doi = {10.1007/978-3-540-24598-8_3},
isbn = {978-3-540-21072-6},
issn = {03029743},
keywords = {Expressive Gesture,Multimodal Interaction,Multimodal Interactive Systems,Performing Arts},
pages = {20--39},
title = {{Multimodal analysis of expressive gesture in music and dance performances}},
year = {2004}
}
@article{Pavlovic1997,
abstract = {The use of hand gestures provides an attractive alternative to
cumbersome interface devices for human-computer interaction (HCI). In
particular, visual interpretation of hand gestures can help in achieving
the ease and naturalness desired for HCI. This has motivated a very
active research area concerned with computer vision-based analysis and
interpretation of hand gestures. We survey the literature on visual
interpretation of hand gestures in the context of its role in HCI. This
discussion is organized on the basis of the method used for modeling,
analyzing, and recognizing gestures. Important differences in the
gesture interpretation approaches arise depending on whether a 3D model
of the human hand or an image appearance model of the human hand is
used. 3D hand models offer a way of more elaborate modeling of hand
gestures but lead to computational hurdles that have not been overcome
given the real-time requirements of HCI. Appearance-based models lead to
computationally efficient {\&}ldquo;purposive{\&}rdquo; approaches that work
well under constrained situations but seem to lack the generality
desirable for HCI. We also discuss implemented gestural systems as well
as other potential applications of vision-based gesture recognition.
Although the current progress is encouraging, further theoretical as
well as computational advances are needed before gestures can be widely
used for HCI. We discuss directions of future research in gesture
recognition, including its integration with other natural modes of
human-computer interaction},
author = {Pavlovic, Vladimir I. and Sharma, Rajeev and Huang, Thomas S.},
doi = {10.1109/34.598226},
file = {:home/memo/Mendeley/data/Pavlovic, Sharma, Huang - 1997 - Visual interpretation of hand gestures for human-computer interaction A review.pdf:pdf},
isbn = {0162-8828 VO - 19},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Gesture analysis,Hand tracking,Human-computer interaction,Nonrigid motion analysis,Vision-based gesture recognition},
number = {7},
pages = {677--695},
title = {{Visual interpretation of hand gestures for human-computer interaction: A review}},
volume = {19},
year = {1997}
}
@article{Searle1980,
author = {Searle, John R.},
doi = {10.1017/S0140525X00005756},
file = {:home/memo/Mendeley/data/Searle - 1980 - Minds, Brains, and Programs.pdf:pdf},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
pages = {1--19},
title = {{Minds, Brains, and Programs}},
volume = {3},
year = {1980}
}
@article{Karpathy2015,
abstract = {Convolutional neural networks (CNNs) have been extensively applied for image recognition problems giving state-of-the-art results on recognition, detection, segmentation and retrieval. In this work we propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted. We propose two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose we employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN. Our best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1{\%} vs. 60.9{\%}) and the UCF-101 datasets with (88.6{\%} vs. 88.0{\%}) and without additional optical flow information (82.6{\%} vs. 72.8{\%}).},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.2306v2},
author = {Karpathy, Andrej and Fei-Fei, Li and Li, Fei Fei},
doi = {10.1109/CVPR.2015.7298932},
eprint = {arXiv:1412.2306v2},
file = {:home/memo/Mendeley/data/Karpathy, Fei-Fei, Li - 2015 - Deep visual-semantic alignments for generating image descriptions.pdf:pdf;:home/memo/Mendeley/data/Karpathy, Fei-Fei, Li - 2015 - Deep visual-semantic alignments for generating image descriptions(2).pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Cvpr},
pages = {3128--3137},
title = {{Deep visual-semantic alignments for generating image descriptions}},
volume = {07-12-June},
year = {2015}
}
@article{Socher2011,
abstract = {Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning. In order to obtain high accuracy on this task, thorough syntactic and semantic analysis of the two statements is needed. We introduce a method for paraphrase detection based on recursive autoencoders (RAE). Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees. These features are used to measure the word- and phrase-wise similarity between two sentences. Since sentences may be of arbitrary length, the resulting matrix of similarity measures is of variable size. We introduce a novel dynamic pooling layer which computes a fixed-sized representation from the variable-sized matrices. The pooled representation is then used as input to a classifier. Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus.},
author = {Socher, Richard and Huang, Eh and Pennington, Jeffrey},
file = {:home/memo/Mendeley/data/Socher, Huang, Pennington - 2011 - Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {801--809},
title = {{Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection.}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2011{\_}0538.pdf{\%}5Cnhttps://papers.nips.cc/paper/4204-dynamic-pooling-and-unfolding-recursive-autoencoders-for-paraphrase-detection.pdf},
year = {2011}
}
@article{Tompson2014,
abstract = {This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.},
archivePrefix = {arXiv},
arxivId = {1406.2984},
author = {Tompson, Jonathan and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
eprint = {1406.2984},
file = {:home/memo/Mendeley/data/Tompson et al. - 2014 - Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation.pdf:pdf},
pages = {1--9},
title = {{Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation}},
url = {http://arxiv.org/abs/1406.2984},
year = {2014}
}
@article{Bengio2013,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5538v2},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
doi = {3C2DBCEE-8A96-493B-B88B-36B1F52ECA58},
eprint = {arXiv:1206.5538v2},
file = {:home/memo/Mendeley/data/Bengio, Courville, Vincent - 2013 - Representation Learning A Review and New Perspectives.pdf:pdf},
isbn = {0162-8828 VO - 35},
issn = {1939-3539},
journal = {Tpami},
number = {1993},
pages = {1--30},
pmid = {23459267},
title = {{Representation Learning: A Review and New Perspectives.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23459267},
year = {2013}
}
@article{Arel2010,
abstract = {This article provides an overview of the mainstream deep learning approaches and research directions proposed over the past decade. It is important to emphasize that each approach has strengths and "weaknesses, depending on the application and context in "which it is being used. Thus, this article presents a summary on the current state of the deep machine learning field and some perspective into how it may evolve. Convolutional Neural Networks (CNNs) and Deep Belief Networks (DBNs) (and their respective variations) are focused on primarily because they are well established in the deep learning field and show great promise for future work.},
archivePrefix = {arXiv},
arxivId = {1209.5467},
author = {Arel, I and Rose, D C and Karnowski, T P},
doi = {10.1109/MCI.2010.938364},
eprint = {1209.5467},
file = {:home/memo/Mendeley/data/Arel, Rose, Karnowski - 2010 - Deep Machine Learning - A New Frontier in Artificial Intelligence Research Research Frontier.pdf:pdf},
isbn = {1556-603X},
issn = {1556-603X},
journal = {IEEE Computational Intelligence Magazine},
number = {4},
pages = {13--18},
title = {{Deep Machine Learning - A New Frontier in Artificial Intelligence Research [Research Frontier]}},
volume = {5},
year = {2010}
}
@article{LeCun1995a,
abstract = {This paper compares the performance of several classifies algorithms on a standard database of handwritten digits. We consider not only raw accuracy, but also training time, recognition time, and memory requirements. When available, we report measurements of the fraction of patterns that must be rejected so that the remaining patterns have misclassification rates less than a given threshold.},
author = {LeCun, Y and Jackel, L and Bottou, L and Brunot, a and Cortes, C and Denker, J and Drucker, H and Guyon, I and M{\"{u}}ller, U and S{\"{a}}ckinger, E and Simard, P and Vapnik, V},
file = {:home/memo/Mendeley/data/LeCun et al. - 1995 - Comparison of learning algorithms for handwritten digit recognition.pdf:pdf},
journal = {International Conference on artificial neural networks},
pages = {53--60},
title = {{Comparison of learning algorithms for handwritten digit recognition}},
url = {http://mleg.cse.sc.edu/edu/csce822/uploads/Main.ReadingList/KNN{\_}recognition.pdf},
year = {1995}
}
@article{LeCun2004,
abstract = { We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13{\%} for SVM and 7{\%} for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7{\%} error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second.},
author = {LeCun, Y. and Huang, Fu Jie Huang Fu Jie and Bottou, L.},
doi = {10.1109/CVPR.2004.1315150},
file = {:home/memo/Mendeley/data/LeCun, Huang, Bottou - 2004 - Learning methods for generic object recognition with invariance to pose and lighting.pdf:pdf},
isbn = {0-7695-2158-4},
issn = {1063-6919},
journal = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
title = {{Learning methods for generic object recognition with invariance to pose and lighting}},
volume = {2},
year = {2004}
}
@article{LeCun1998,
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
file = {:home/memo/Mendeley/data/LeCun et al. - 1998 - Gradient-based learning applied to document recognition.pdf:pdf},
journal = {Proceedings of the IEEE},
keywords = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR)},
number = {11},
pages = {2278--2323},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@article{Laboratories1994,
author = {Laboratories, T Bell and Montreal, Universite De},
file = {:home/memo/Mendeley/data/Laboratories, Montreal - 1994 - 1 Introduction 2 Word Normalization.pdf:pdf},
pages = {1--9},
title = {{1 Introduction 2 Word Normalization}},
year = {1994}
}
@inproceedings{Ng2013,
abstract = {Graduate Summer School: Deep Learning, Feature Learning "Deep Learning, Self-Taught Learning and Unsupervised Feature Learning (Part 1 Slides1-68; Part 2 Sli...},
author = {Ng, Andrew},
booktitle = {Stanford University},
file = {:home/memo/Mendeley/data/Ng - 2013 - Machine Learning and AI via Brain Simulations.pdf:pdf},
keywords = {AI,deep learning},
title = {{Machine Learning and AI via Brain Simulations}},
url = {http://www.youtube.com/watch?v=n1ViNeWhC24{\%}5Cnpapers3://publication/uuid/FD4F0FE0-BB23-431D-8840-6808135CC089},
year = {2013}
}
@article{Couprie2013,
abstract = {Scene labeling consists in labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape and contextual information.We report results using multiple post-processing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, e.g. they can be taken from a segmentation tree, or from any family of over-segmentations. The system yields record accuracies on the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) and near-record accuracy on Stanford Background Dataset (8 classes), while being an order of magnitude faster than competing approaches, producing a 320×240 image labeling in less than a second, including feature extraction.},
author = {Couprie, Camille and Najman, Laurent and Lecun, Yann},
doi = {10.1109/TPAMI.2012.231},
file = {:home/memo/Mendeley/data/Couprie, Najman, Lecun - 2013 - Learning Hierarchical Features for Scene Labeling.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
keywords = {Convolutional networks,deep learning,image classification,image segmentation,scene parsing},
number = {8},
pages = {1915--1929},
pmid = {23787344},
title = {{Learning Hierarchical Features for Scene Labeling}},
volume = {35},
year = {2013}
}
@inproceedings{Deng2009,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ldquoImageNetrdquo, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009.},
file = {:home/memo/Mendeley/data/Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei - 2009 - Imagenet A large-scale hierarchical image da.pdf:pdf},
pages = {248--255},
publisher = {IEEE},
title = {{Imagenet: A large-scale hierarchical image database}},
year = {2009}
}
@article{Kavukcuoglu2010,
abstract = {We propose an unsupervisedmethod for learningmulti-stage hierarchies of sparse convolutional features. While sparse coding has become an increasingly popular method for learning visual features, it is most often trained at the patch level. Applying the resulting filters convolutionally results in highly redundant codes because overlapping patches are encoded in isolation. By training convolutionally over large image windows, our method reduces the redudancy between feature vectors at neighboring locations and improves the efficiency of the overall repre- sentation. In addition to a linear decoder that reconstructs the image from sparse features, our method trains an efficient feed-forward encoder that predicts quasi- sparse features from the input. While patch-based training rarely produces any- thing but oriented edge detectors, we show that convolutional training produces highly diverse filters, including center-surround filters, corner detectors, cross de- tectors, and oriented grating detectors. We show that using these filters in multi- stage convolutional network architecture improves performance on a number of visual recognition and detection tasks.},
author = {Kavukcuoglu, Koray and Sermanet, Pierre and Boureau, Y-Lan and Gregor, Karol and Mathieu, Michael and LeCun, Yann},
file = {:home/memo/Mendeley/data/Kavukcuoglu et al. - 2010 - Learning Convolutional Feature Hierarchies for Visual Recognition.pdf:pdf},
isbn = {9781617823800},
issn = {-},
journal = {Advances in Neural Information Processing Systems (NIPS)},
number = {1},
pages = {1090--1098},
title = {{Learning Convolutional Feature Hierarchies for Visual Recognition}},
year = {2010}
}
@article{Socher2011a,
author = {Socher, Richard and Pennington, Jeffrey and Huang, Eh},
file = {:home/memo/Mendeley/data/Socher, Pennington, Huang - 2011 - Semi-supervised recursive autoencoders for predicting sentiment distributions.pdf:pdf},
journal = {Conference on Empirical Methods in Natural Language Processing, EMNLP},
number = {i},
pages = {151--161},
title = {{Semi-supervised recursive autoencoders for predicting sentiment distributions}},
url = {http://dl.acm.org/citation.cfm?id=2145450},
year = {2011}
}
@article{LeCun1989,
abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the US Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
author = {LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
file = {:home/memo/Mendeley/data/LeCun, Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel - 1989 - Backpropaga.pdf:pdf},
journal = {Neural Computation},
number = {4},
pages = {541--551},
title = {{Backpropagation applied to handwritten zip code recognition}},
volume = {1},
year = {1989}
}
@article{Hinton2006,
author = {Hinton, G. E. and Salakhutdinov, R. R.},
doi = {10.1126/science.1127647},
file = {:home/memo/Mendeley/data/Hinton, Salakhutdinov - 2006 - Reducing the Dimensionality of Data with Neural Networks.pdf:pdf},
isbn = {3135786504},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
number = {July},
pages = {504--507},
pmid = {16873662},
title = {{Reducing the Dimensionality of Data with Neural Networks}},
volume = {313},
year = {2006}
}
@article{Jia2014,
author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
file = {:home/memo/Mendeley/data/Jia, Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell - 20.pdf:pdf},
journal = {arXiv preprint arXiv:1408.5093},
keywords = {computation,computer vision,corresponding authors,machine learning,neural networks,open source,parallel},
title = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
year = {2014}
}
@article{Collobert2011,
archivePrefix = {arXiv},
arxivId = {1103.0398},
author = {Collobert, Ronan and Weston, Jason and Bottou, L{\'{e}}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
eprint = {1103.0398},
file = {:home/memo/Mendeley/data/Collobert et al. - 2011 - Natural language processing (almost) from scratch.0398v1:0398v1},
isbn = {1532-4435},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
keywords = {deep learning,natural language processing,neural networks},
number = {12},
pages = {2493--2537},
title = {{Natural language processing (almost) from scratch}},
url = {http://dl.acm.org/citation.cfm?id=2078186},
volume = {1},
year = {2011}
}
@misc{NVIDIA2015,
author = {NVIDIA},
title = {{Deep Learning GPU Training System (DIGITS)}},
url = {https://developer.nvidia.com/digits/},
year = {2015}
}
@article{Raina2009,
abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a ﬂurry of machine learning applications (Hinton {\&} Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples. In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y},
doi = {10.1145/1553374.1553486},
file = {:home/memo/Mendeley/data/Raina, Madhavan, Ng - 2009 - Large-scale deep unsupervised learning using graphics processors.pdf:pdf},
isbn = {9781605585161},
issn = {12258687},
journal = {International Conference on Machine Learning ICML},
pages = {873--880},
pmid = {17394762},
title = {{Large-scale deep unsupervised learning using graphics processors.}},
volume = {9},
year = {2009}
}
@article{LeCun1995,
abstract = {The ability of multilayer back-propagation networks to learn complex, high-dimensional, nonlinear mappings from large collections of examples makes them obvious candidates for image recognition or speech recognition tasks (see PATTERN RECOGNITION AND NEURAL NETWORKS). In the traditional model of pattern recognition, a hand-designed feature extractor gathers relevant information from the input and eliminates irrelevant variabilities. A trainable classifier then categorizes the resulting feature vectors (or strings of symbols) into classes. In this scheme, standard, fully-connected multilayer networks can be used as classifiers. A potentially more interesting scheme is to eliminate the feature extractor, feeding the network with "raw" inputs (e.g. normalized images), and to rely on backpropagation to turn the first few layers into an appropriate feature extractor. While this can be done with an ordinary fully connected feed-forward network with some success for tasks such as character recognition, there are problems.},
author = {LeCun, Y and Bengio, Y},
file = {:home/memo/Mendeley/data/LeCun, Bengio - 1995 - Convolutional networks for images, speech, and time series.pdf:pdf},
isbn = {0262511029},
journal = {The handbook of brain theory and neural networks},
pages = {255--258},
title = {{Convolutional networks for images, speech, and time series}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.9297{\&}rep=rep1{\&}type=pdf},
volume = {3361},
year = {1995}
}
@article{Fels1993,
abstract = {To illustrate the potential of multilayer neural networks for adaptive interfaces, a VPL Data-Glove connected to a DECtalk speech synthesizer via five neural networks was used to implement a hand-gesture to speech system. Using minor variations of the standard backpropagation learning procedure, the complex mapping of hand movements to speech is learned using data obtained from a single ;speaker' in a simple training phase. With a 203 gesture-to-word vocabulary, the wrong word is produced less than 1{\%} of the time, and no word is produced about 5{\%} of the time. Adaptive control of the speaking rate and word stress is also available. The training times and final performance speed are improved by using small, separate networks for each naturally defined subtask. The system demonstrates that neural networks can be used to develop the complex mappings required in a high bandwidth interface that adapts to the individual user.},
author = {Fels, S. Sidney and Hinton, Geoffrey E.},
doi = {10.1109/72.182690},
file = {:home/memo/Mendeley/data/Fels, Hinton - 1993 - Glove-talk a neural network interface between a data-glove and a speech synthesizer.pdf:pdf},
isbn = {1045-9227 (Print)$\backslash$r1045-9227 (Linking)},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
number = {1},
pages = {2--8},
pmid = {18267698},
title = {{Glove-talk: a neural network interface between a data-glove and a speech synthesizer}},
volume = {4},
year = {1993}
}
@article{Erhan2010,
author = {Erhan, D and Bengio, Y and Courville, a},
file = {:home/memo/Mendeley/data/Erhan, Bengio, Courville - 2010 - Why does unsupervised pre-training help deep learning.pdf:pdf},
journal = {{\ldots} of Machine Learning {\ldots}},
number = {2007},
pages = {201--208},
title = {{Why does unsupervised pre-training help deep learning?}},
url = {http://dl.acm.org/citation.cfm?id=1756025},
volume = {9},
year = {2010}
}
@article{Lee2009,
abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y},
doi = {10.1145/1553374.1553453},
file = {:home/memo/Mendeley/data/Lee et al. - 2009 - Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations.pdf:pdf},
isbn = {9781605585161},
issn = {02643294},
journal = {International Conference on Machine Learning ICML},
pages = {1--8},
pmid = {20957573},
title = {{Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553453},
volume = {2008},
year = {2009}
}
@article{Cun1990,
abstract = {We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application.},
author = {Cun, Yann Le and Denker, John S and Solla, Sara a},
doi = {10.1.1.32.7223},
file = {:home/memo/Mendeley/data/Cun, Denker, Solla - 1990 - Optimal Brain Damage.pdf:pdf},
isbn = {1558601007},
journal = {Advances in Neural Information Processing Systems (NIPS)},
number = {1},
pages = {598--605},
title = {{Optimal Brain Damage}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract{\%}5Cnhttp://www.lecun.com/exdb/publis/pdf/lecun-90b.pdf{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.7223{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {1990}
}
@inproceedings{LeCun2014,
author = {LeCun, Yann},
booktitle = {Facebook AI Research {\&} Center for Data Science, NYU},
file = {:home/memo/Mendeley/data/LeCun - 2014 - The Unreasonable Effectiveness of Deep Learning.pdf:pdf},
keywords = {Deep learning},
mendeley-tags = {Deep learning},
title = {{The Unreasonable Effectiveness of Deep Learning}},
year = {2014}
}
@article{Ciresan2011,
abstract = {We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53{\%}, 19.51{\%}, 0.35{\%}, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42{\%}, 0.97{\%} and 0.48{\%} after 1, 3 and 17 epochs, respectively.},
author = {Ciresan, Dc and Meier, Ueli and Masci, Jonathan},
doi = {10.5591/978-1-57735-516-8/ijcai11-210},
file = {:home/memo/Mendeley/data/Ciresan, Meier, Masci - 2011 - Flexible, high performance convolutional neural networks for image classification.pdf:pdf},
isbn = {978-1-57735-514-4},
issn = {10450823},
journal = {International Joint Conference on Artificial Intelligence},
pages = {1237--1242},
title = {{Flexible, high performance convolutional neural networks for image classification}},
url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3098/3425},
year = {2011}
}
@article{Thrun2006,
author = {Thrun, Sebastian and Montemerlo, Mike and Dahlkamp, Hendrik and Stavens, David and Aron, Andrei and Diebel, James and Fong, Philip and Gale, John and Halpenny, Morgan and Hoffmann, Gabriel and Lau, Kenny and Oakley, Celia and Palatucci, Mark and Pratt, Vaughan and Stang, Pascal and Strohband, Sven and {Cedric Dupont}, L and Mahoney, Pamela},
doi = {10.1002/rob.20147},
file = {:home/memo/Mendeley/data/Thrun et al. - 2006 - Stanley The Robot That Won the DARPA Grand Challenge.pdf:pdf},
journal = {Journal of Field Robotics},
keywords = {Backstepping,Non-linear control,Path-following},
number = {9},
pages = {661--692},
title = {{Stanley: The Robot That Won the DARPA Grand Challenge}},
volume = {23},
year = {2006}
}
@article{Hinton2012,
abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and Kingsbury, Brian},
file = {:home/memo/Mendeley/data/Hinton et al. - 2012 - Deep Neural Networks for Acoustic Modeling in Speech Recognition.pdf:pdf},
journal = {IEEE Signal Processing Magazine},
number = {6},
pages = {82--97},
title = {{Deep Neural Networks for Acoustic Modeling in Speech Recognition}},
volume = {29},
year = {2012}
}
@article{Zeiler2013a,
abstract = {We introduce a simple and effective method for regularizing large convolutional neural networks. We replace the conventional deterministic pooling operations with a stochastic procedure, randomly picking the activation within each pooling region according to a multinomial distribution, given by the activities within the pooling region. The approach is hyper-parameter free and can be combined with other regularization approaches, such as dropout and data augmentation. We achieve state-of-the-art performance on four image datasets, relative to other approaches that do not utilize data augmentation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1301.3557v1},
author = {Zeiler, Matthew and Fergus, Rob},
eprint = {arXiv:1301.3557v1},
file = {:home/memo/Mendeley/data/Zeiler, Fergus - 2013 - Stochastic pooling for regularization of deep convolutional neural networks.pdf:pdf},
journal = {arXiv preprint arXiv:1301.3557},
pages = {1--9},
title = {{Stochastic pooling for regularization of deep convolutional neural networks}},
url = {http://arxiv.org/abs/1301.3557},
year = {2013}
}
@article{Guzella2009,
abstract = {In this paper, we present a comprehensive review of recent developments in the application of machine learning algorithms to Spam filtering, focusing on both textual- and image-based approaches. Instead of considering Spam filtering as a standard classification problem, we highlight the importance of considering specific characteristics of the problem, especially concept drift, in designing new filters. Two particularly important aspects not widely recognized in the literature are discussed: the difficulties in updating a classifier based on the bag-of-words representation and a major difference between two early naive Bayes models. Overall, we conclude that while important advancements have been made in the last years, several aspects remain to be explored, especially under more realistic evaluation settings. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Guzella, Thiago S. and Caminhas, Walmir M.},
doi = {10.1016/j.eswa.2009.02.037},
file = {:home/memo/Mendeley/data/Guzella, Caminhas - 2009 - A review of machine learning approaches to Spam filtering.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Bag-of-words (BoW),Image Spam,Naive Bayes,Online learning,Spam filtering},
number = {7},
pages = {10206--10222},
publisher = {Elsevier Ltd},
title = {{A review of machine learning approaches to Spam filtering}},
url = {http://dx.doi.org/10.1016/j.eswa.2009.02.037},
volume = {36},
year = {2009}
}
@article{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
eprint = {1102.0183},
file = {:home/memo/Mendeley/data/Krizhevsky, Sutskever, Hinton - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1--9},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2012}
}
@article{Choromanska2014,
abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
archivePrefix = {arXiv},
arxivId = {1412.0233},
author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'{e}}rard Ben and LeCun, Yann},
eprint = {1412.0233},
file = {:home/memo/Mendeley/data/Choromanska et al. - 2014 - The Loss Surfaces of Multilayer Networks.pdf:pdf},
journal = {arXiv:1412.0233 [cs]},
title = {{The Loss Surfaces of Multilayer Networks}},
url = {http://arxiv.org/abs/1412.0233 http://www.arxiv.org/pdf/1412.0233.pdf},
volume = {38},
year = {2014}
}
@inproceedings{Wright1997,
author = {Wright, M. and Freed, A.},
booktitle = {Proceedings of the 1997 International Computer Music Conference (ICMC)},
title = {{Open Sound Control: A new protocol for communicating with sound synthesizers}},
year = {1997}
}
@article{Hinton2007,
author = {Hinton, G and Hinton, G},
doi = {10.1016/j.tics.2007.09.004},
file = {:home/memo/Mendeley/data/Hinton, Hinton - 2007 - Learning multiple layers of representation.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {10},
pages = {428--434},
title = {{Learning multiple layers of representation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661307002173},
volume = {11},
year = {2007}
}
@techreport{Turing1948,
author = {Turing, Alan},
institution = {National Physical Laboratory},
keywords = {Artifiial Intelligence},
mendeley-tags = {Artifiial Intelligence},
title = {{Intelligent Machinery}},
year = {1948}
}
@article{Mumford1992,
author = {Mumford, D},
file = {:home/memo/Mendeley/data/Mumford - 1992 - On the computational architecture of the neocortex II The role of cortico-cortical loops.pdf:pdf},
pages = {241--251},
title = {{On the computational architecture of the neocortex II The role of cortico-cortical loops}},
volume = {251},
year = {1992}
}
@article{Deng2013a,
author = {Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Hinton, Kingsbury - 2013 - New Types of Deep Neural Network Learning for Speech Recognition and Related Applications an Overview.pdf:pdf},
isbn = {9781479903566},
pages = {8599--8603},
title = {{New Types of Deep Neural Network Learning for Speech Recognition and Related Applications : an Overview}},
year = {2013}
}
@article{Hinton2006a,
abstract = {We show how to use complementary priors to eliminate the explaining- away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associa- tive memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive ver- sion of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribu- tion of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning al- gorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
doi = {10.1162/neco.2006.18.7.1527},
file = {:home/memo/Mendeley/data/Hinton, Osindero, Teh - 2006 - A fast learning algorithm for deep belief nets.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
pages = {1527--1554},
pmid = {16764513},
title = {{A fast learning algorithm for deep belief nets}},
volume = {18},
year = {2006}
}
@article{Guez2013,
abstract = {Bayesian planning is a formally elegant approach to learning optimal behaviour under model uncertainty, trading off exploration and exploitation in an ideal way. Unfortunately, planning optimally in the face of uncertainty is notoriously taxing, since the search space is enormous. In this paper we introduce a tractable, sample-based method for approximate Bayes-optimal planning which exploits Monte-Carlo tree search. Our approach avoids expensive applications of Bayes rule within the search tree by sampling models from current beliefs, and furthermore performs this sampling in a lazy manner. This enables it to outperform previous Bayesian model-based reinforcement learning algorithms by a significant margin on several well-known benchmark problems. As we show, our approach can even work in problems with an infinite state space that lie qualitatively out of reach of almost all previous work in Bayesian exploration.},
author = {Guez, Arthur and Silver, David and Dayan, Peter},
doi = {10.1613/jair.4117},
file = {:home/memo/Mendeley/data/Guez, Silver, Dayan - 2013 - Scalable and efficient bayes-adaptive reinforcement learning based on Monte-Carlo tree search.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {841--883},
title = {{Scalable and efficient bayes-adaptive reinforcement learning based on Monte-Carlo tree search}},
volume = {48},
year = {2013}
}
@article{Vien2012,
abstract = {Bayesian model-based reinforcement learning can be formulated as a partially observable Markov decision process (POMDP) to provide a principled framework for optimally balancing exploitation and exploration. Then, a POMDP solver can be used to solve the problem. If the prior distribution over the environment's dynamics is a product of Dirichlet distributions, the POMDP's optimal value function can be represented using a set of multivariate polynomials. Unfortunately, the size of the polynomials grows exponentially with the problem horizon. In this paper, we examine the use of an online Monte-Carlo tree search (MCTS) algorithm for large POMDPs, to solve the Bayesian reinforcement learning problem online. We will show that such an algorithm successfully searches for a near-optimal policy. In addition, we examine the use of a parameter tying method to keep the model search space small, and propose the use of nested mixture of tied models to increase robustness of the method when our prior information does not allow us to specify the structure of tied models exactly. Experiments show that the proposed methods substantially improve scalability of current Bayesian reinforcement learning methods.},
author = {Vien, Ngo Anh and Ertel, Wolfgang},
doi = {10.1109/ICMLA.2012.30},
file = {:home/memo/Mendeley/data/Vien, Ertel - 2012 - Monte carlo tree search for bayesian reinforcement learning.pdf:pdf},
isbn = {9780769549132},
journal = {International Conference on Machine Learning ICML},
keywords = {Bayesian reinforcement learning,Monte-Carlo tree search,POMDP,model-based reinforcement learning},
pages = {138--143},
title = {{Monte carlo tree search for bayesian reinforcement learning}},
volume = {1},
year = {2012}
}
@book{Mitchell1997,
abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. The book is intended to support upper level undergraduate and introductory level graduate courses in machine learning.},
author = {Mitchell, Tom M},
booktitle = {Machine Learning},
doi = {10.1007/BF00116892},
isbn = {0070428077},
issn = {08856125},
keywords = {Artificial Intelligence,Machine Learning},
mendeley-tags = {Artificial Intelligence,Machine Learning},
number = {3},
pages = {432},
pmid = {20236947},
publisher = {McGraw Hill},
title = {{Machine Learning}},
url = {http://www.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077},
volume = {1},
year = {1997}
}
@article{Silvera,
archivePrefix = {arXiv},
arxivId = {1507.04296},
author = {Silver, David and Deepmind, Google},
eprint = {1507.04296},
file = {:home/memo/Mendeley/data/Silver, Deepmind - Unknown - Deep Reinforcement Learning.pdf:pdf},
title = {{Deep Reinforcement Learning}}
}
@incollection{Al-rifaieBishop2015,
author = {Al-rifaie, Mohammad Majid and Bishop, John Mark},
booktitle = {Computational Creativity Research: Towards Creative Machines},
doi = {10.2991/978-94-6239-085-0},
file = {:home/memo/Mendeley/data/Al-rifaie, Bishop - 2015 - Weak and Strong Computational Creativity.pdf:pdf},
isbn = {978-94-6239-084-3},
number = {September},
pages = {0--14},
title = {{Weak and Strong Computational Creativity}},
url = {http://link.springer.com/10.2991/978-94-6239-085-0},
volume = {7},
year = {2015}
}
@misc{Mordvintsev2015,
author = {Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
title = {{Deepdream inceptionism}},
url = {http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html},
year = {2015}
}
@article{Zeiler2013,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky $\backslash$etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
author = {Zeiler, Matthew D and Fergus, Rob},
file = {:home/memo/Mendeley/data/Zeiler, Fergus - 2013 - Visualizing and Understanding Convolutional Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1311.2901},
title = {{Visualizing and Understanding Convolutional Networks}},
year = {2013}
}
@article{Ciresan2012,
abstract = {Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1202.2745v1},
author = {Cireşan, Dan and Meier, Ueli and Schmidhuber, J{\"{u}}rgen},
doi = {10.1109/CVPR.2012.6248110},
eprint = {arXiv:1202.2745v1},
file = {:home/memo/Mendeley/data/Cireşan, Meier, Schmidhuber - 2012 - Multi-column Deep Neural Networks for Image Classification.pdf:pdf},
isbn = {978-1-4673-1228-8},
issn = {1063-6919},
journal = {International Conference of Pattern Recognition},
number = {February},
pages = {3642--3649},
title = {{Multi-column Deep Neural Networks for Image Classification}},
year = {2012}
}
@article{Mumford1991,
abstract = {This paper proposes that each area of the cortex carries on its calculations with the active participation of a nucleus in the thalamus with which it is reciprocally and topographically connected. Each cortical area is responsible for maintaining and updating the organism's knowledge of a specific aspect of the world, ranging from low level raw data to high level abstract representations, and involving interpreting stimuli and generating actions. In doing this, it will draw on multiple sources of expertise, learned from experience, creating multiple, often conflicting, hypotheses which are integrated by the action of the thalamic neurons and then sent back to the standard input layer of the cortex. Thus this nucleus plays the role of an 'active blackboard' on which the current best reconstruction of some aspect of the world is always displayed. Evidence for this theory is reviewed and experimental tests are proposed. A sequel to this paper will discuss the cortico-cortical loops and propose quite different computational roles for them.},
author = {Mumford, D.},
doi = {10.1007/BF00202389},
file = {:home/memo/Mendeley/data/Mumford - 1991 - On the computational architecture of the neocortex - I. The role of the thalamo-cortical loop.pdf:pdf},
isbn = {0340-1200},
issn = {03401200},
journal = {Biological Cybernetics},
number = {2},
pages = {135--145},
pmid = {1912004},
title = {{On the computational architecture of the neocortex - I. The role of the thalamo-cortical loop}},
volume = {65},
year = {1991}
}
@inproceedings{Szegedy2014,
abstract = {Abstract We propose a deep convolutional neural network architecture codenamed Incep- tion, which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
file = {:home/memo/Mendeley/data/Szegedy et al. - 2015 - Going deeper with convolutions.pdf:pdf},
pages = {1--9},
title = {{Going deeper with convolutions}},
year = {2015}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
author = {Bishop, Christopher M},
file = {:home/memo/Mendeley/data/Bishop - 2006 - Pattern recognition and machine learning.pdf:pdf},
publisher = {Springer},
title = {{Pattern recognition and machine learning}},
year = {2006}
}
@misc{Dourish2001,
abstract = {Computer science as an engineering discipline has been spectacularly successful. Yet it is also a philosophical enterprise in the way it represents the world and creates and manipulates models of reality, people, and action. In this book, Paul Dourish addresses the philosophical bases of human-computer interaction. He looks at how what he calls "embodied interaction"an approach to interacting with software systems that emphasizes skilled, engaged practice rather than disembodied rationalityreflects the phenomenological approaches of Martin Heidegger, Ludwig Wittgenstein, and other twentieth-century philosophers. The phenomenological tradition emphasizes the primacy of natural practice over abstract cognition in everyday activity. Dourish shows how this perspective can shed light on the foundational underpinnings of current research on embodied interaction. He looks in particular at how tangible and social approaches to interaction are related, how they can be used to analyze and understand embodied interaction, and how they could affect the design of future interactive systems.},
author = {Dourish, Paul},
booktitle = {Where the action is the foundations of embodied interaction},
doi = {10.1162/leon.2003.36.5.412},
file = {:home/memo/Mendeley/data/Dourish - 2001 - Where the Action Is The Foundations of Embodied Interaction.pdf:pdf},
isbn = {0262041960},
issn = {14711834},
number = {3},
pages = {233},
pmid = {17714179},
title = {{Where the Action Is: The Foundations of Embodied Interaction}},
url = {http://books.google.com/books?id=DCIy2zxrCqcC{\&}pgis=1},
volume = {36},
year = {2001}
}
@book{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - Interactive Media.pdf:pdf},
isbn = {9781848000353},
title = {{Interactive Media}}
}
@article{Antle2009,
abstract = {One of the claimed benefits of embodied interaction is that it is an intuitive form of human?computer interaction. While this claim seems to be widely accepted, few studies explore the underlying cognitive mechanisms of intuition in the context of tangible and embedded interaction design. What is intuitive interaction? What makes an interface intuitive to use? We explore these questions in the context of a responsive auditory environment. We propose that intuitive interaction can be facilitated by instantiating an embodied metaphor in the mapping layer between movement-based input actions and auditory system responses. We search for evidence of benefit through a comparative study of the same responsive auditory environment implemented with and without an embodied metaphor in the interactional mapping layer. Qualitative findings about the complexities and limitations of designing intuitive interaction are summarised and the implications for the design of embodied interaction discussed.},
author = {Antle, Alissa N. and Corness, Greg and Droumeva, Milena},
doi = {10.1504/IJART.2009.028927},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antle, Corness, Droumeva - 2009 - Human-computer-intuition Exploring the cognitive basis for intuition in embodied interaction.pdf:pdf},
issn = {1754-8853},
journal = {International Journal of Arts and Technology},
keywords = {auditory environments,embedded interaction,embodied,embodied schema,embodiment,environments,image schema,interaction,interactive,intuitive interaction,metaphor,responsive environments,tangible user interfaces,whole body interaction},
number = {3},
pages = {235},
title = {{Human-computer-intuition? Exploring the cognitive basis for intuition in embodied interaction}},
volume = {2},
year = {2009}
}
@article{Chen2009,
abstract = {We present a system that composes a realistic picture from a simple freehand sketch annotated with text labels. The composed picture is generated by seamlessly stitching several photographs in agreement with the sketch and text labels; these are found by searching the Internet. Although online image search generates many inappropriate results, our system is able to automatically select suitable photographs to generate a high quality composition, using a filtering scheme to exclude undesirable images. We also provide a novel image blending algorithm to allow seamless image composition. Each blending result is given a numeric score, allowing us to find an optimal combination of discovered images. Experimental results show the method is very successful; we also evaluate our system using the results from two user studies.},
author = {Chen, Tao and Cheng, Ming-Ming and Tan, Ping and Shamir, Ariel and Hu, Shi-Min},
doi = {10.1145/1618452.1618470},
file = {:home/memo/Mendeley/data/Chen et al. - 2009 - Sketch2Photo internet image montage.pdf:pdf},
isbn = {9781605588582},
issn = {0730-0301},
keywords = {QA75 Electronic computers. Computer science},
number = {5},
pages = {1--10},
title = {{Sketch2Photo: internet image montage}},
url = {http://dx.doi.org/10.1145/1618452.1618470},
volume = {28},
year = {2009}
}
@article{Horn,
author = {Horn, Daniel},
file = {:home/memo/Mendeley/data/Horn - Unknown - GPU Gems - Chapter 36. Stream Reduction Operations for GPGPU Applications.pdf:pdf},
keywords = {GPU GPGPU NVIDIA OpenGL Open{\_}GL DirectX DX8 DX9 DX},
title = {{GPU Gems - Chapter 36. Stream Reduction Operations for GPGPU Applications}},
url = {http://http.developer.nvidia.com/GPUGems2/gpugems2{\_}chapter36.html},
volume = {3}
}
@article{Buck2003,
author = {Buck, Ian and Purcell, Tim},
file = {:home/memo/Mendeley/data/Buck, Purcell - 2003 - GPU Gems Chapter 37 . A Toolkit for Computation on GPUs.pdf:pdf},
number = {June},
title = {{GPU Gems Chapter 37 . A Toolkit for Computation on GPUs}},
volume = {3},
year = {2003}
}
@article{Perlin1985,
author = {Perlin, Ken},
file = {:home/memo/Mendeley/data/Perlin - 1985 - GPU Gems Chapter 5 . Implementing Improved Perlin Noise.pdf:pdf},
number = {Perlin},
pages = {1--8},
title = {{GPU Gems Chapter 5 . Implementing Improved Perlin Noise}},
volume = {3},
year = {1985}
}
@article{Green2004,
author = {Green, Simon},
file = {:home/memo/Mendeley/data/Green - 2004 - GPU Gems 2 Chapter 26 . Implementing Improved Perlin Noise.pdf:pdf},
title = {{GPU Gems 2 Chapter 26 . Implementing Improved Perlin Noise}},
volume = {3},
year = {2004}
}
@article{Bunnell1978,
author = {Bunnell, Michael},
file = {:home/memo/Mendeley/data/Bunnell - 1978 - GPU Gems 2 Chapter 7 . Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping.pdf:pdf},
title = {{GPU Gems 2 Chapter 7 . Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping}},
volume = {3},
year = {1978}
}
@article{Lefohn2004,
author = {Lefohn, Aaron and Owens, John},
file = {:home/memo/Mendeley/data/Lefohn, Owens - 2004 - GPU Gems 2 Chapter 33 . Implementing Efficient Parallel Data Structures on GPUs.pdf:pdf},
title = {{GPU Gems 2 Chapter 33 . Implementing Efficient Parallel Data Structures on GPUs}},
volume = {3},
year = {2004}
}
@article{Pharr,
author = {Pharr, Matt},
file = {:home/memo/Mendeley/data/Pharr - Unknown - GPU Gems Chapter 32 . An Introduction to Shader Interfaces.pdf:pdf},
title = {{GPU Gems Chapter 32 . An Introduction to Shader Interfaces}},
volume = {3}
}
@article{Woolley,
author = {Woolley, Cliff},
file = {:home/memo/Mendeley/data/Woolley - Unknown - GPU Gems 2 Chapter 35 . GPU Program Optimization.pdf:pdf},
title = {{GPU Gems 2 Chapter 35 . GPU Program Optimization}},
volume = {3}
}
@article{Carucci,
author = {Carucci, Francesco},
file = {:home/memo/Mendeley/data/Carucci - Unknown - GPU Gems 2 Chapter 3 . Inside Geometry Instancing.pdf:pdf},
title = {{GPU Gems 2 Chapter 3 . Inside Geometry Instancing}},
volume = {3}
}
@article{Donnellya,
author = {Donnelly, William and Demers, Joe},
file = {:home/memo/Mendeley/data/Donnelly, Demers - Unknown - GPU Gems Chapter 13 . Generating Soft Shadows Using Occlusion Interval Maps.pdf:pdf},
title = {{GPU Gems Chapter 13 . Generating Soft Shadows Using Occlusion Interval Maps}},
volume = {3}
}
@article{Kilgariff,
author = {Kilgariff, Emmett and Fernando, Randima},
file = {:home/memo/Mendeley/data/Kilgariff, Fernando - Unknown - GPU Gems 2 Chapter 30 . The GeForce 6 Series GPU Architecture.pdf:pdf},
title = {{GPU Gems 2 Chapter 30 . The GeForce 6 Series GPU Architecture}},
volume = {3}
}
@article{Technique,
author = {Technique, Basic},
file = {:home/memo/Mendeley/data/Technique - Unknown - GPU Gems 2 Chapter 19 . Generic Refraction Simulation.pdf:pdf},
title = {{GPU Gems 2 Chapter 19 . Generic Refraction Simulation}},
volume = {3}
}
@article{Donnelly,
author = {Donnelly, William},
file = {:home/memo/Mendeley/data/Donnelly - Unknown - GPU Gems 2 Chapter 8 . Per-Pixel Displacement Mapping with Distance Functions.pdf:pdf},
number = {1984},
title = {{GPU Gems 2 Chapter 8 . Per-Pixel Displacement Mapping with Distance Functions}},
volume = {3}
}
@article{Harris,
author = {Harris, Mark and Buck, Ian},
file = {:home/memo/Mendeley/data/Harris, Buck - Unknown - GPU Gems 2 Chapter 34 . GPU Flow-Control Idioms.pdf:pdf},
number = {Mimd},
title = {{GPU Gems 2 Chapter 34 . GPU Flow-Control Idioms}},
volume = {3}
}
@article{Owens2005,
author = {Owens, John},
file = {:home/memo/Mendeley/data/Owens - 2005 - GPU Gems 2 Chapter 29 . Streaming Architectures and Technology Trends.pdf:pdf},
title = {{GPU Gems 2 Chapter 29 . Streaming Architectures and Technology Trends}},
volume = {3},
year = {2005}
}
@article{Sumanaweera,
author = {Sumanaweera, Thilaka},
file = {:home/memo/Mendeley/data/Sumanaweera - Unknown - GPU Gems Chapter 40 . Applying Real-Time Shading to 3D Ultrasound Visualization.pdf:pdf},
title = {{GPU Gems Chapter 40 . Applying Real-Time Shading to 3D Ultrasound Visualization}},
volume = {3}
}
@article{Fan1998,
author = {Fan, Zhe and Kaufman, Arie},
file = {:home/memo/Mendeley/data/Fan, Kaufman - 1998 - GPU Gems 2 Chapter 47 . Flow Simulation with Complex Boundaries.pdf:pdf},
journal = {Simulation},
pages = {1--24},
title = {{GPU Gems 2 Chapter 47 . Flow Simulation with Complex Boundaries}},
volume = {3},
year = {1998}
}
@article{Homepage,
author = {Homepage, Developer Site and Homepage, Developer News and Login, Developer and Developer, Registered and Tools, Developer and Sign-up, Newsletter},
file = {:home/memo/Mendeley/data/Homepage et al. - Unknown - GPU Gems 2 Chapter 31 . Mapping Computational Concepts to GPUs.pdf:pdf},
title = {{GPU Gems 2 Chapter 31 . Mapping Computational Concepts to GPUs}},
volume = {3}
}
@article{Harris2004,
author = {Harris, Mark J},
file = {:home/memo/Mendeley/data/Harris - 2004 - GPU Gems - Chapter 38. Fast Fluid Dynamics Simulation on the GPU.pdf:pdf},
isbn = {0321228324},
journal = {GPU Gems},
keywords = {GPU GPGPU NVIDIA OpenGL Open{\_}GL DirectX DX8 DX9 DX},
title = {{GPU Gems - Chapter 38. Fast Fluid Dynamics Simulation on the GPU}},
url = {http://http.developer.nvidia.com/GPUGems/gpugems{\_}ch38.html},
volume = {3},
year = {2004}
}
@article{Buck,
author = {Buck, Ian},
file = {:home/memo/Mendeley/data/Buck - Unknown - GPU Gems - Chapter 32. Taking the Plunge into GPU Computing.pdf:pdf},
journal = {GPUGems2},
keywords = {gpu gpgpu nvidia opengl open{\_}gl directx dx8 dx9 dx},
title = {{GPU Gems - Chapter 32. Taking the Plunge into GPU Computing}},
url = {http://http.developer.nvidia.com/GPUGems2/gpugems2{\_}chapter32.html},
volume = {3}
}
@article{Cebenoyan,
author = {Cebenoyan, Cem},
file = {:home/memo/Mendeley/data/Cebenoyan - Unknown - GPU Gems - Chapter 28. Graphics Pipeline Performance.pdf:pdf},
keywords = {gpu gpgpu nvidia opengl open{\_}gl directx dx8 dx9 dx},
title = {{GPU Gems - Chapter 28. Graphics Pipeline Performance}},
url = {http://http.developer.nvidia.com/GPUGems/gpugems{\_}ch28.html},
volume = {3}
}
@article{Ikits2007,
author = {Ikits, Milan and Kniss, Joe and Lefohn, Aaron and Hansen, Charles},
file = {:home/memo/Mendeley/data/Ikits et al. - 2007 - GPU Gems Chapter 39 Volume Rendering Techniques.pdf:pdf},
title = {{GPU Gems Chapter 39: Volume Rendering Techniques}},
url = {http://http.developer.nvidia.com/GPUGems/gpugems{\_}ch39.html},
volume = {3},
year = {2007}
}
@article{Pharr2004,
author = {Pharr, Matt and Green, Simon},
file = {:home/memo/Mendeley/data/Pharr, Green - 2004 - GPU Gems Chapter 17. Ambient Occlusion.pdf:pdf},
journal = {Http.Developer.Nvidia.Com},
title = {{GPU Gems Chapter 17. Ambient Occlusion}},
url = {http://http.developer.nvidia.com/GPUGems/gpugems{\_}ch17.html},
volume = {3},
year = {2004}
}
@article{Rorke,
author = {Rorke, John O},
file = {:home/memo/Mendeley/data/Rorke - Unknown - GPU Gems - Chapter 15. Managing Visibility for Per-Pixel Lighting.pdf:pdf},
title = {{GPU Gems - Chapter 15. Managing Visibility for Per-Pixel Lighting}},
url = {http://http.developer.nvidia.com/GPUGems/gpugems{\_}ch15.html},
volume = {3}
}
@article{Sylvain2005,
author = {Sylvain, Lefebvre and Samuel, Hornus and Fabrice, Neyret},
file = {:home/memo/Mendeley/data/Sylvain, Samuel, Fabrice - 2005 - GPU Gems 2 Chapter 37 Octree Textures on the GPU.pdf:pdf},
journal = {GPU Gems 2: Chapter 37: Octree Textures on the GPU},
title = {{GPU Gems 2: Chapter 37: Octree Textures on the GPU}},
url = {http://http.developer.nvidia.com/GPUGems2/gpugems2{\_}chapter37.html},
volume = {3},
year = {2005}
}
@article{Asirvatham2005,
author = {Asirvatham, a. and Hoppe, Hugues},
file = {:home/memo/Mendeley/data/Asirvatham, Hoppe - 2005 - Terrain rendering using GPU-based geometry clipmaps.pdf:pdf},
isbn = {0321335597},
journal = {GPU Gems 2},
number = {2},
pages = {27--46},
title = {{Terrain rendering using GPU-based geometry clipmaps}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:terrain+rendering+using+gpu-based+geometry+clipmaps{\#}0{\%}5Cnhttp://http.developer.nvidia.com/GPUGems2/gpugems2{\_}chapter02.html},
volume = {3},
year = {2005}
}
@article{Kooten2007,
abstract = {In this chapter we present a technique for rendering metaballs on state-of-the-art graphics processors at interactive rates. Instead of employing the marching cubes algorithm to generate a list of polygons, our method samples the metaballs' implicit surface by constraining free-moving particles to this surface. Our goal is to visualize the metaballs as a smooth surface by rendering thousands of particles, with each particle covering a tiny surface area. To successfully apply this point-based technique on a GPU, we solve three basic problems. First, we need to evaluate the metaballs' implicit function and its gradient per rendered particle in order to constrain the particles to the surface. For this purpose, we devised a novel data structure for quickly evaluating the implicit functions in a fragment shader. Second, we need to spread the particles evenly across the surface. We present a fast method for performing a nearest- neighbors search on each particle that takes two rendering passes on a GPU. This method is used for computing the repulsion forces according to the method of smoothed particle hydrodynamics. Third, to further accelerate particle dispersion, we present a method for transferring particles from high-density areas to low-density areas on the surface.},
author = {Kooten, Kees Van and Telea, Alex},
file = {:home/memo/Mendeley/data/Kooten, Telea - 2007 - Point-Based Visualization of Metaballs on a GPU.pdf:pdf},
isbn = {978-0321515261},
journal = {Methods},
pages = {123--148},
title = {{Point-Based Visualization of Metaballs on a GPU}},
url = {http://developer.nvidia.com/book/export/html/164},
volume = {3},
year = {2007}
}
@article{Pelzer,
author = {Pelzer, Kurt},
file = {:home/memo/Mendeley/data/Pelzer - Unknown - GPU Gems Chapter 7 . Rendering Countless Blades of Waving Grass.pdf:pdf},
title = {{GPU Gems Chapter 7 . Rendering Countless Blades of Waving Grass}},
volume = {3}
}
@article{Uralsky,
author = {Uralsky, Yury},
file = {:home/memo/Mendeley/data/Uralsky - Unknown - GPU Gems 2 Chapter 17 . Efficient Soft-Edged Shadows Using Pixel Shader Branching.pdf:pdf},
title = {{GPU Gems 2 Chapter 17 . Efficient Soft-Edged Shadows Using Pixel Shader Branching}},
volume = {3}
}
@article{Neil2015,
author = {Neil, Sean O},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neil - 2015 - GPU Gems ­ Chapter 16 . Accurate Atmospheric Scattering GPU Gems ­ Chapter 16 . Accurate Atmospheric Scattering.pdf:pdf},
pages = {1--8},
title = {{GPU Gems ­ Chapter 16 . Accurate Atmospheric Scattering GPU Gems ­ Chapter 16 . Accurate Atmospheric Scattering}},
year = {2015}
}
@article{Maps1998,
author = {Maps, Irradiance Environment},
file = {:home/memo/Mendeley/data/Maps - 1998 - GPU Gems 2 Chapter 10 . Real-Time Computation of Dynamic Irradiance Environment Maps.pdf:pdf},
title = {{GPU Gems 2 Chapter 10 . Real-Time Computation of Dynamic Irradiance Environment Maps}},
volume = {3},
year = {1998}
}
@article{Kryachko,
author = {Kryachko, Yuri},
file = {:home/memo/Mendeley/data/Kryachko - Unknown - GPU Gems 2 Chapter 18 . Using Vertex Texture Displacement for Realistic Water Rendering.pdf:pdf},
title = {{GPU Gems 2 Chapter 18 . Using Vertex Texture Displacement for Realistic Water Rendering}},
volume = {3}
}
@article{Neil1993,
author = {Neil, Sean O},
file = {:home/memo/Mendeley/data/Neil - 1993 - GPU Gems 2 Chapter 16 . Accurate Atmospheric Scattering.pdf:pdf},
title = {{GPU Gems 2 Chapter 16 . Accurate Atmospheric Scattering}},
volume = {3},
year = {1993}
}
@article{Mcguire,
author = {Mcguire, Morgan},
file = {:home/memo/Mendeley/data/Mcguire - Unknown - GPU Gems Chapter 9 . Efficient Shadow Volume Rendering.pdf:pdf},
title = {{GPU Gems Chapter 9 . Efficient Shadow Volume Rendering}},
volume = {3}
}
@article{Nienhaus1990,
author = {Nienhaus, Marc},
file = {:home/memo/Mendeley/data/Nienhaus - 1990 - GPU Gems 2 Chapter 15 . Blueprint Rendering and Sketchy Drawings.pdf:pdf},
title = {{GPU Gems 2 Chapter 15 . Blueprint Rendering and " Sketchy Drawings "}},
volume = {3},
year = {1990}
}
@article{Bunnell1987,
author = {Bunnell, Michael},
file = {:home/memo/Mendeley/data/Bunnell - 1987 - GPU Gems Chapter 11 . Shadow Map Antialiasing.pdf:pdf},
title = {{GPU Gems Chapter 11 . Shadow Map Antialiasing}},
volume = {3},
year = {1987}
}
@article{Pellacini1999,
author = {Pellacini, Fabio},
file = {:home/memo/Mendeley/data/Pellacini - 1999 - GPU Gems Chapter 10 . Cinematic Lighting.pdf:pdf},
title = {{GPU Gems Chapter 10 . Cinematic Lighting}},
volume = {3},
year = {1999}
}
@article{Wesley2014,
author = {Wesley, Addison and Finch, Mark},
file = {:home/memo/Mendeley/data/Wesley, Finch - 2014 - GPU Gems Chapter 1 . Effective Water Simulation from Physical Models.pdf:pdf},
pages = {1--22},
title = {{GPU Gems Chapter 1 . Effective Water Simulation from Physical Models}},
volume = {3},
year = {2014}
}
@article{Wiggins2008,
author = {Wiggins, Geraint a.},
doi = {10.1093/llc/fqm025},
file = {:home/memo/Mendeley/data/Wiggins - 2008 - Computer models of musical creativity A review of computer models of musical creativity by David Cope.pdf:pdf},
isbn = {0268-1145},
issn = {02681145},
journal = {Literary and Linguistic Computing},
number = {1},
pages = {109--116},
title = {{Computer models of musical creativity: A review of computer models of musical creativity by David Cope}},
volume = {23},
year = {2008}
}
@article{Marc2014,
author = {Marc, Joan and Asensio, Llargues},
file = {:home/memo/Mendeley/data/Marc, Asensio - 2014 - Evolving Artificial Neural Networks Applied to Generate Virtual Characters.pdf:pdf},
isbn = {9781479935475},
title = {{Evolving Artificial Neural Networks Applied to Generate Virtual Characters}},
year = {2014}
}
@article{Boyd2000,
abstract = {In order to better understand the interaction between various depth cues, we analyzed two 3D depth cues that are found in both natural spaces and virtual reality environments – shape from shading and motion parallax. We wanted to see how well subjects used these cues as sole information for depth and how they weighted or integrated the two cues. In particular, we were interested in individual variance and potential differences along sex lines. Our results showed that subjects, without practice or experience, are virtually unable to acquire depth information when 2D cues such as luminance and speed are removed and only one 3D cue remains. Because of the irregular performance of our subjects, it is difficult to determine what individual variation exists and whether it was controlled by experience, social influences, or biological factors. We suggest further research be done to disentangle the 2D and 3D cues and to determine the impact of experience on performance. Once systems are in place to properly test for separate cues and give the appropriate level of training, it may be possible to study individual variance. At this juncture, we only know that learning the system improves ability as do the availability of 2D cues.},
author = {Boyd, Danah},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd - 2000 - Depth Cues in Virtual Reality and Real World Understanding Individual Differences in Depth Perception by Studying Shape-f.pdf:pdf},
title = {{Depth Cues in Virtual Reality and Real World : Understanding Individual Differences in Depth Perception by Studying Shape-from-shading and Motion Parallax}},
year = {2000}
}
@article{Levin2000,
abstract = {This thesis presents a new computer interface metaphor for the real-time and simultaneous performance of dynamic imagery and sound. This metaphor is based on the idea of an inexhaustible, infinitely variable, time-based, audiovisual substance which can be gesturally created, deposited, manipulated and deleted in a free-form, non-diagrammatic image space. The interface metaphor is exemplified by five interactive audiovisual synthesis systems whose visual and aural dimensions are deeply plastic, commensurately malleable, and tightly connected by perceptually- motivated mappings. The principles, patterns and challenges which structured the design of these five software systems are extracted and discussed, after which the expressive capacities of the five systems are compared and evaluated.},
author = {Levin, Golan},
file = {:home/memo/Mendeley/data/Levin - 2000 - Painterly Interfaces for Audiovisual Performance.pdf:pdf},
journal = {Media},
pages = {1--151},
title = {{Painterly Interfaces for Audiovisual Performance}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Painterly+Interfaces+for+Audiovisual+Performance{\#}0},
year = {2000}
}
@article{Bostrom2008,
abstract = {When water was discovered on Mars, people got very excited. Where there is water, there may be life. Scientists are planning new missions to study the planet up close. NASA's next Mars rover is scheduled to arrive in 2010. In the decade following, a Mars Sample Return mission might be launched, which would use robotic systems to collect samples of Martian rocks, soils, and atmosphere, and return them to Earth. We could then analyze the sample to see if it contains any traces of life, whether extinct or still active. Such a discovery would be of tremendous scientific significance. What could be more fascinating than discovering life that had evolved entirely independently of life here on Earth? Many people would also find it heartening to learn that we are not entirely alone in this vast cold cosmos.},
author = {Bostrom, Nick},
file = {:home/memo/Mendeley/data/Bostrom - 2008 - Where are they Why I hope the search for extraterrestrial life finds nothing.pdf:pdf},
journal = {Technology Review},
keywords = {Fermi paradox,Great Filter,SETI,extraterrestrial intelligence,search for extraterrestrial life},
pages = {72--77},
title = {{Where are they? Why I hope the search for extraterrestrial life finds nothing}},
year = {2008}
}
@article{Arinbjarnar2010,
abstract = {The growing use of intelligent agents in virtual realities calls for agents that can interact with users in a fluent and believable way. Intelligent agents are expected to react in an increasingly human like manner, showing distinct characteristics and to express emotion. Which calls for increasingly larger datasets for the agents to make informed and plausible decisions. Intelligent agents need to be able to process large knowledge bases and make decisions based on a wide range of relevant factors in real-time in order for the user to find them believable. This is very important for autonomous agents in emergent interactive drama because they need to respond fluently to user interactions in a manner that resembles that of a real actor. Bayesian networks (BNs) are particularly suitable to implement intelligent agents decision mechanism because they support transient emotions and decision making and accommodate for conflicts between the virtual agents goals. In their basic form, BN reasoning algorithms do not scale well, since the cost of updating values in a BN is NP-hard in the worst case. We propose efficient and scalable BN techniques using relevance reasoning, that are suitable for the needs of our autonomous agents in directed emergent drama and allow for real-time decision making.},
author = {Arinbjarnar, Maria and Kudenko, Daniel},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arinbjarnar, Kudenko - 2010 - Bayesian networks Real-time applicable decision mechanisms for intelligent agents in interactive drama.pdf:pdf},
journal = {Proceedings of the 2010 IEEE Conference on Computational Intelligence and Games, CIG2010},
pages = {427--434},
title = {{Bayesian networks: Real-time applicable decision mechanisms for intelligent agents in interactive drama}},
year = {2010}
}
@misc{Ermentrout1979,
abstract = {Neuronal activity in a two-dimensional net is analyzed in the neighborhood of an instability. Bifurcation theory and group theory are used to demonstrate the existence of a variety of doublyperiodic patterns, hexagons, rolls, etc., as solutions to the field equations for the net activity. It is suggested that these simple geometric patterns are the cortical concomitants of the “form constants” seen during visual hallucinosis.},
author = {Ermentrout, G. Bard and Cowan, J. D.},
booktitle = {Biological Cybernetics},
doi = {10.1007/BF00336965},
file = {:home/memo/Mendeley/data/Ermentrout, Cowan - 1979 - A mathematical theory of visual hallucination patterns.pdf:pdf},
isbn = {0340-1200 (Print)},
issn = {0340-1200},
number = {3},
pages = {137--150},
pmid = {486593},
title = {{A mathematical theory of visual hallucination patterns}},
url = {http://www.springerlink.com/content/n627240j45532241/abstract/},
volume = {34},
year = {1979}
}
@article{Mital,
author = {Mital, Parag Kumar and Grierson, Michael},
title = {{Audiovisual Scene Synthesis}}
}
@article{Erhan2009,
abstract = {Deep architectures have demonstrated state-of-the-art results in a variety of settings, especially with vision datasets. Beyond the model definitions and the quantitative analyses, there is a need for qualitative comparisons of the solutions learned by various deep architectures. The goal of this paper is to find good qualitative interpretations of high level features represented by such models. To this end, we contrast and compare several techniques applied on Stacked Denoising Autoencoders and Deep Belief Networks, trained on several vision datasets. We show that, perhaps counter-intuitively, such interpretation is possible at the unit level, that it is simple to accomplish and that the results are consistent across various techniques. We hope that such techniques will allow researchers in deep architectures to understand more of how and why deep architectures work},
author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
file = {:home/memo/Mendeley/data/Erhan et al. - 2009 - Visualizing higher-layer features of a deep network.pdf:pdf},
journal = {Bernoulli},
number = {1341},
pages = {1--13},
title = {{Visualizing higher-layer features of a deep network}},
url = {http://igva2012.wikispaces.asu.edu/file/view/Erhan+2009+Visualizing+higher+layer+features+of+a+deep+network.pdf},
year = {2009}
}
@article{Goodfellow2014,
abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
archivePrefix = {arXiv},
arxivId = {1412.6572},
author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
eprint = {1412.6572},
file = {:home/memo/Mendeley/data/Goodfellow, Shlens, Szegedy - 2014 - Explaining and Harnessing Adversarial Examples.pdf:pdf},
pages = {1--11},
title = {{Explaining and Harnessing Adversarial Examples}},
url = {http://arxiv.org/abs/1412.6572},
year = {2014}
}
@article{Gillian2011thesis,
abstract = {This thesis investigates how machine learning can be applied to the automatic recog- nition of a musical gesture by a computer. The recognition of gestures in a musical domain provides a number of interesting research challenges over and above the recog- nition of gestures in the more general field of human-computer interaction as, due to its real-time musical application, a low-latency, highly robust, user-configurable recognition system is required. These research challenges raise a number of fundamental questions related to the application of gesture recognition for musician-computer interaction; such as what differences, if any, are there between the application of machine learning for the classification of musical gestures from that of the classification of other gestures used throughout various fields within human-computer interaction? This thesis addresses such questions and in doing so tests the applicability of the leading machine learning algorithms for the recognition of musical gestures along with developing a number of new algorithms specifically for the recognition of musical gestures. The work in this thesis focuses primarily on the discrete classification of a musical gesture, as opposed to the continuous mapping of a movement to a sound or control parameter. The scope of the research presented in this thesis is therefore constrained to the design and evaluation of machine learning algorithms that can be used to classify both static musical postures and musical gestures that consist of a cohesive sequence of movements that occur over a variable time period (i.e. temporal gestures). The principal contributions of this thesis include a number of novel machine learning al- gorithms that have been specifically developed for the recognition of both static musical postures and temporal musical gestures. Another major contribution of this thesis is the development of a real-time gesture recognition software tool that has been designed to operate independently from any one specific piece of sensor hardware or audio software. Rather than pre-training the software tool to recognise a specific set of musical gestures, such as the communicative gestures of a conductor or the expressive gestures of a pianist for example; the software has instead been designed to facilitate a musician to train the recognition algorithms with the specific gestures that musician wants to use. The soft- ware has therefore been designed to enable a performer, regardless of their programming abilities, to quickly train a computer to recognise their musical gestures using a num- ber of powerful machine learning algorithms, including the algorithms that have been specifically developed as the result of this thesis. The work in this thesis therefore not only contributes to the domains of musician-computer interaction and the more general field of human-computer interaction; it also facilitates performers to directly apply these contributions to their compositions, performances and/or research.},
author = {Gillian, Nicholas Edward},
file = {:home/memo/Mendeley/data/Gillian - 2011 - Gesture Recognition for Musician Computer Interaction.pdf:pdf},
journal = {Social Sciences},
number = {March},
title = {{Gesture Recognition for Musician Computer Interaction}},
year = {2011}
}
@article{Ikeshiro2013,
author = {Ikeshiro, Ryo},
file = {:home/memo/Mendeley/data/Ikeshiro - 2013 - Studio Composition Live audiovisualisation using emergent generative systems.pdf:pdf},
number = {August},
title = {{Studio Composition Live audiovisualisation using emergent generative systems}},
year = {2013}
}
@article{Mateas2002,
abstract = {Artificial intelligence methods open up new possibilities in art and entertainment, enabling rich and deeply interactive experiences. At the same time as AI opens up new fields of artistic expression, AI-based art itself becomes a fundamental research agenda, posing and answering novel research questions that would not be raised unless doing AI research in the context of art and entertainment. I call this agenda, in which AI research and art mutually inform each other, Expressive AI. Expressive AI takes seriously the problem of building intelligences that robustly function outside of the lab, engaging human participants in intellectually and aesthetically satisfying interactions, which, hopefully, teach us something about ourselves. This thesis describes a specific AI-based art piece, an interactive drama called Fa{\c{c}}ade, and describes the practice of Expressive AI, using Fa{\c{c}}ade, as well as additional AI-based artwork described in the appendices, as case studies. An interactive drama is a dramatically interesting virtual world inhabited by computer-controlled characters, within which the player experiences a story from a first person perspective. Over the past decade, there has been a fair amount of research into believable agents, that is, autonomous characters exhibiting rich personalities, emotions, and social interactions. There has been comparatively little work, however, exploring how the local, reactive behavior of believable agents can be integrated with the more global, deliberative nature of a story plot, so as to build interactive, dramatic worlds. This thesis presents Fa{\c{c}}ade, the first published interactive drama system that integrates character (believable agents), story (drama management) and shallow natural language processing into a complete system. Fa{\c{c}}ade will be publicly released as a free download in 2003. In the Fa{\c{c}}ade architecture, the unit of plot/character integration is the dramatic beat. In the theory of dramatic writing, beats are the smallest unit of dramatic action, consisting of a short dialog exchange or small amount of physical action. As architectural entities, beats organize both the procedural knowledge to accomplish the beats dramatic action, and the declarative knowledge to sequence the beat in an evolving plot. Instead of conceiving of the characters as strongly autonomous entities that coordinate to accomplish dramatic action through purely local decision-making, characters are instead weakly autonomous the characters behavioral repertoire dynamically changes as beats are sequenced. The Fa{\c{c}}ade architecture includes ABL (A Behavior Language), a new reactive planning language for authoring characters that provides language support for joint action, and a drama manager consisting of both a language for authoring the declarative knowledge associated with beats and a runtime system that dynamically sequences beats. Fa{\c{c}}ade is a collaboration with independent artist and researcher Andrew Stern. Expressive AI is not the mere application of off-the-shelf AI techniques to art and entertainment applications. Rather, Expressive AI is a critical technical practice, a way of doing AI research that reflects on the foundations of AI and changes the way AI is done. AI has always been in the business of knowing-by-making, exploring what it means to be human by building systems. Expressive AI just makes this explicit, combining the thought experiments of the AI researcher with the conceptual and aesthetic experiments of the artist. As demonstrated through Fa{\c{c}}ade and the other systems/artworks described in the appendices, combining art and AI, both ways of knowing-by-making, opens up new research questions, provides a novel perspective on old questions, and enables new modes of artistic expression. The firm boundary normally separating art and science is blurred, becoming two components of a single, integrated practice.},
author = {Mateas, Michael and Murray, Janet and Tech, Georgia},
doi = {10.1038/nature06777},
file = {:home/memo/Mendeley/data/Mateas, Murray, Tech - 2002 - Interactive Drama, Art and Artificial Intelligence.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {art,artificial intelligence,believable agents,entertainment,interactive drama},
number = {December},
pages = {--02--206},
pmid = {18432244},
title = {{Interactive Drama, Art and Artificial Intelligence}},
url = {http://www.cs.cmu.edu/{~}burks/ThesisSummaries/mateas{\_}summary.pdf},
volume = {2},
year = {2002}
}
@article{Wen2012,
abstract = {Context: Software development effort estimation (SDEE) is the process of predicting the effort required to develop a software system. In order to improve estimation accuracy, many researchers have proposed machine learning (ML) based SDEE models (ML models) since 1990s. However, there has been no attempt to analyze the empirical evidence on ML models in a systematic way. Objective: This research aims to systematically analyze ML models from four aspects: type of ML technique, estimation accuracy, model comparison, and estimation context. Method: We performed a systematic literature review of empirical studies on ML model published in the last two decades (1991-2010). Results: We have identified 84 primary studies relevant to the objective of this research. After investigating these studies, we found that eight types of ML techniques have been employed in SDEE models. Overall speaking, the estimation accuracy of these ML models is close to the acceptable level and is better than that of non-ML models. Furthermore, different ML models have different strengths and weaknesses and thus favor different estimation contexts. Conclusion: ML models are promising in the field of SDEE. However, the application of ML models in industry is still limited, so that more effort and incentives are needed to facilitate the application of ML models. To this end, based on the findings of this review, we provide recommendations for researchers as well as guidelines for practitioners. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Wen, Jianfeng and Li, Shixian and Lin, Zhiyong and Hu, Yong and Huang, Changqin},
doi = {10.1016/j.infsof.2011.09.002},
file = {:home/memo/Mendeley/data/Wen et al. - 2012 - Systematic literature review of machine learning based software development effort estimation models.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Machine learning,Software effort estimation,Systematic literature review},
number = {1},
pages = {41--59},
publisher = {Elsevier B.V.},
title = {{Systematic literature review of machine learning based software development effort estimation models}},
url = {http://dx.doi.org/10.1016/j.infsof.2011.09.002},
volume = {54},
year = {2012}
}
@article{Vogel2004,
abstract = {We develop design principles and an interaction framework for sharable, interactive public ambient displays that support the transition from implicit to explicit interaction with both public and personal information. A prototype system implementation that embodies these design principles is described. We use novel display and interaction techniques such as simple hand gestures and touch screen input for explicit interaction and contextual body orientation and position cues for implicit interaction. Techniques are presented for subtle notification, self-revealing help, privacy controls, and shared use by multiple people each in their own context. Initial user feedback is also presented, and future directions discussed.},
author = {Vogel, Daniel and Balakrishnan, Ravin},
doi = {10.1145/1029632.1029656},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogel, Balakrishnan - 2004 - Interactive Public Ambient Displays Transitioning from Implicit to Explicit, Public to Personal, Interactio.pdf:pdf},
isbn = {1581139578},
journal = {UIST '04: Proceedings of the 17th annual ACM symposium on User interface software and technology},
keywords = {UIST '04,User interface software and technology},
number = {2},
pages = {137--146},
title = {{Interactive Public Ambient Displays: Transitioning from Implicit to Explicit, Public to Personal, Interaction with Multiple Users}},
url = {http://portal.acm.org/citation.cfm?doid=1029632.1029656},
volume = {6},
year = {2004}
}
@article{Dietrich1986,
author = {Dietrich, Frank},
file = {:home/memo/Mendeley/data/Dietrich - 1986 - Visual The First Decade of Intelligence Computer Art.pdf:pdf},
journal = {Leonardo},
number = {2},
pages = {159--169},
title = {{Visual The First Decade of Intelligence : Computer Art}},
volume = {19},
year = {1986}
}
@article{Krueger1977,
abstract = {This paper introduces the concept of a responsive environment which perceives human behavior and responds with intelligent auditory and visual feedback. Several exhibits of responsive environments, implemented by the author, combining computer graphics, video projection and two-way video communication are described. VIDEOPLACE, an evolving exhibit which defines a conceptual telecommunication environment uniting geographically separated people in a common visual experience, is discussed at some length. Based on these examples a new art form of composed man-machine interaction is defined. Finally, practical applications are suggested for the fields of education, psychology and psychotherapy.},
author = {Krueger, Myron W.},
doi = {10.1145/1499402.1499476},
file = {:home/memo/Mendeley/data/Krueger - 1977 - Responsive environments.pdf:pdf},
isbn = {0750605669},
journal = {Proceedings of the June 13-16, 1977, national computer conference on - AFIPS '77},
pages = {423},
title = {{Responsive environments}},
url = {http://portal.acm.org/citation.cfm?doid=1499402.1499476},
year = {1977}
}
@inproceedings{Katan2015,
author = {Katan, Simon and Grierson, Mick and Fiebrink, Rebecca},
booktitle = {CHI '15 Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Katan, Grierson, Fiebrink - 2015 - Using Interactive Machine Learning to Support Interface Development Through Workshops with Disabled P.pdf:pdf},
isbn = {9781450331456},
title = {{Using Interactive Machine Learning to Support Interface Development Through Workshops with Disabled People}},
year = {2015}
}
@article{Wolf2015,
author = {Wolf, Katieanna E and Gliner, Genna and Fiebrink, Rebecca},
file = {:home/memo/Mendeley/data/Wolf, Gliner, Fiebrink - 2015 - A Model for Data-Driven Sonification Using Soundscapes.pdf:pdf},
isbn = {9781450333085},
title = {{A Model for Data-Driven Sonification Using Soundscapes}},
year = {2015}
}
@article{Wei,
author = {Wei, Wei},
file = {:home/memo/Mendeley/data/Wei - Unknown - The combination of imaginary and real worlds.pdf:pdf},
title = {{The combination of imaginary and real worlds}}
}
@article{Decoro2005,
author = {Decoro, Christopher and Fiebrink, Rebecca},
file = {:home/memo/Mendeley/data/Decoro, Fiebrink - 2005 - BAYESIAN AGGREGATION FOR HIERARCHICAL GENRE CLASSIFICATION.pdf:pdf},
title = {{BAYESIAN AGGREGATION FOR HIERARCHICAL GENRE CLASSIFICATION}},
year = {2005}
}
@article{Media2013,
author = {Media, Xpanded Urban and Discretized, R O M and Collages, Social and Corrugated, T O and Brain, Social and Lei, Yang and Museum, Monument and Art, Digital and Mcarthur, Ian and Arts, Fine and Wales, New South and Email, Sydney and Miller, Brad},
file = {:home/memo/Mendeley/data/Media et al. - 2013 - EXPANDED URBAN MEDIA FROM DISCRETIZED SOCIAL COLLAGES TO CORRUGATED SOCIAL BRAIN.pdf:pdf},
keywords = {china,context and background,data visualization,digital media,smart cities,transcultural,urban space},
pages = {1--5},
title = {{EXPANDED URBAN MEDIA: FROM DISCRETIZED SOCIAL COLLAGES TO CORRUGATED SOCIAL BRAIN}},
year = {2013}
}
@article{Fiebrink2011a,
author = {Fiebrink, Rebecca and Cook, Perry R and Trueman, Dan},
doi = {10.1145/1978942.1978965},
file = {:home/memo/Mendeley/data/Fiebrink, Cook, Trueman - 2011 - Human Model Evaluation in Interactive Supervised Learning.pdf:pdf},
isbn = {978-1-4503-0228-9},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
keywords = {evaluation,gesture,interactive machine learning,music},
pages = {147--156},
title = {{Human Model Evaluation in Interactive Supervised Learning}},
url = {http://doi.acm.org/10.1145/1978942.1978965},
year = {2011}
}
@article{Perin2013,
abstract = {This paper theoretically situates research that explores motion capture data visualization using customized software tools such as MxCap.01. The value of software like MxCap.01 lies in its visualization capabilities including the ability to scale the re-presentation of the force, direction and intensity of movement but also do so within a temporal and emotive structuring.},
author = {Perin, Gavin and Bowman, Chris},
file = {:home/memo/Mendeley/data/Perin, Bowman - 2013 - OBSERVATIONS ON MOTION CAPTURE.pdf:pdf},
keywords = {Animation,Dramaturgy,Motion Capture,MxCAP.01,Representation,Scale,Visualization},
mendeley-tags = {Animation,Dramaturgy,Motion Capture,MxCAP.01,Representation,Scale,Visualization},
title = {{OBSERVATIONS ON MOTION CAPTURE}},
year = {2013}
}
@article{Caramiaux2012,
author = {Caramiaux, Baptiste},
file = {:home/memo/Mendeley/data/Caramiaux - 2012 - Studies on the Relationship between Gesture and Sound in Musical Performance.pdf:pdf},
title = {{Studies on the Relationship between Gesture and Sound in Musical Performance}},
year = {2012}
}
@article{Cordeiro2013,
author = {Cordeiro, Jo{\~{a}}o and Barbosa, {\'{A}}lvaro and Afonso, Bruno},
file = {:home/memo/Mendeley/data/Cordeiro, Barbosa, Afonso - 2013 - Soundscape-Sensing in Social Networks.pdf:pdf},
journal = {Proceedings of AIA-DAGA 2013 Conference on Acoustics},
title = {{Soundscape-Sensing in Social Networks}},
year = {2013}
}
@article{Fiebrink2006,
abstract = {With the recent explosion in the quantity of digital audio libraries and databases, content descriptions play an important role in efficiently managing and retrieving audio files. This doctoral research aims to discover and extract structural description from polyphonic music signals. As repetition and transformations of music structure creates a unique identity of music itself, extracting such information can link low-level and higher-level descriptions of music signal and provide better quality access plus powerful way of interacting with audio content. Finding appropriate boundary truncations is indispensable in certain content-based applications. Thus, temporal audio segmentation at the semantic level and the identification of representative excerpts from music audio signal are also investigated. We make use of higher-level analysis technique for better segment truncation. From both theoretical and practical points of view, this research not only helps in increasing our knowledge of music structure but also facilitates in time-saving browsing and assessing of music.},
author = {Fiebrink, Rebecca and Fujinaga, Ichiro},
file = {:home/memo/Mendeley/data/Fiebrink, Fujinaga - 2006 - Feature Selection Pitfalls and Music Classification.pdf:pdf},
isbn = {1550583492},
journal = {International Conference on Music Information Retrieval},
keywords = {classification,feature selection},
pages = {340--341},
title = {{Feature Selection Pitfalls and Music Classification.}},
url = {http://www.cs.princeton.edu/{~}fiebrink/publications/FiebrinkFujinagaISMIR2006.pdf},
year = {2006}
}
@article{Manford1998,
abstract = {Complex visual hallucinations may affect some normal individuals on going to sleep and are also seen in pathological states, often in association with a sleep disturbance. The content of these hallucinations is striking and relatively stereotyped, often involving animals and human figures in bright colours and dramatic settings. Conditions causing these hallucinations include narcolepsy-cataplexy syndrome, peduncular hallucinosis, treated idiopathic Parkinson's disease, Lewy body dementia without treatment, migraine coma, Charles Bonnet syndrome (visual hallucinations of the blind), schizophrenia, hallucinogen-induced states and epilepsy. We describe cases of hallucinosis due to several of these causes and expand on previous hypotheses to suggest three mechanisms underlying complex visual hallucinations. (i) Epileptic hallucinations are probably due to a direct irritative process acting on cortical centres integrating complex visual information. (ii) Visual pathway lesions cause defective visual input and may result in hallucinations from defective visual processing or an abnormal cortical release phenomenon. (iii) Brainstem lesions appear to affect ascending cholinergic and serotonergic pathways, and may also be implicated in Parkinson's disease. These brainstem abnormalities are often associated with disturbances of sleep. We discuss how these lesions, outside the primary visual system, may cause defective modulation of thalamocortical relationships leading to a release phenomenon. We suggest that perturbation of a distributed matrix may explain the production of similar, complex mental phenomena by relatively blunt insults at disparate sites.},
author = {Manford, M. and Andermann, F.},
doi = {10.1093/brain/121.10.1819},
file = {:home/memo/Mendeley/data/Manford, Andermann - 1998 - Complex visual hallucinations. Clinical and neurobiological insights.pdf:pdf},
isbn = {0006-8950 (Print)$\backslash$r0006-8950 (Linking)},
issn = {00068950},
journal = {Brain},
keywords = {Arousal,Serotonin,Thalamocortical,Visual hallucinations},
number = {10},
pages = {1819--1840},
pmid = {9798740},
title = {{Complex visual hallucinations. Clinical and neurobiological insights}},
volume = {121},
year = {1998}
}
@article{Tsui2015,
author = {Tsui, Katherine M. and Dalphond, James M. and Brooks, Daniel J. and Medvedev, Mikhail S. and McCann, Eric and Allspaw, Jordan and Kontak, David and Yanco, Holly a.},
doi = {10.1515/pjbr-2015-0001},
file = {:home/memo/Mendeley/data/Tsui et al. - 2015 - Accessible Human-Robot Interaction for Telepresence Robots A Case Study.pdf:pdf},
issn = {2081-4836},
journal = {Paladyn, Journal of Behavioral Robotics},
keywords = {accessible user interface,assistive robotics,augmented real-,computer-mediated communication,embodied video conferencing,ence,ity,remote pres-,robot,social telepresence,teleoperation},
number = {1},
pages = {1--29},
title = {{Accessible Human-Robot Interaction for Telepresence Robots: A Case Study}},
url = {http://www.degruyter.com/view/j/pjbr.2015.6.issue-1/pjbr-2015-0001/pjbr-2015-0001.xml},
volume = {6},
year = {2015}
}
@article{Velloso,
author = {Velloso, Eduardo and Turner, Jayson and Alexander, Jason and Bulling, Andreas},
file = {:home/memo/Mendeley/data/Velloso et al. - Unknown - An Empirical Investigation of Gaze Selection in Mid- Air Gestural 3D Manipulation.pdf:pdf},
keywords = {3d user interfaces,eye tracking,mid-air gestures},
title = {{An Empirical Investigation of Gaze Selection in Mid- Air Gestural 3D Manipulation}}
}
@article{Kulshreshth2015,
author = {Kulshreshth, Arun Kumar},
file = {:home/memo/Mendeley/data/Kulshreshth - 2015 - Exploring 3D User Interface Technologies for Improving the Gaming Experience.pdf:pdf},
keywords = {Air-combat game,Finger-Count,Game Design,Game-play metrics,Head tracking,Player Behaviour,Stereoscopic 3D,User Experience.,User Study,Video Games},
title = {{Exploring 3D User Interface Technologies for Improving the Gaming Experience}},
year = {2015}
}
@article{Johannesson2010,
author = {Johannesson, Laurel L},
doi = {10.1145/1873951.1874205},
file = {:home/memo/Mendeley/data/Johannesson - 2010 - Acqua Vellutata Sospesa Interactive Video Painting.pdf:pdf},
isbn = {9781605589336},
journal = {ACM Multimedia},
keywords = {art,installation,interactive painting,interactivity,iphone,msa,painting,processing,remote,underwater video,video art,water},
pages = {1295--1298},
title = {{Acqua Vellutata Sospesa : Interactive Video Painting}},
year = {2010}
}
@article{Bowman2001,
author = {Bowman, Doug a. and Johnson, Donald B. and Hodges, Larry F.},
doi = {10.1162/105474601750182333},
file = {:home/memo/Mendeley/data/Bowman, Johnson, Hodges - 2001 - Testbed Evaluation of Virtual Environment Interaction Techniques.pdf:pdf},
isbn = {1581131410},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {75--95},
title = {{Testbed Evaluation of Virtual Environment Interaction Techniques}},
volume = {10},
year = {2001}
}
@article{Mine1997,
author = {Mine, Mark R. and Brooks, Frederick P. and Sequin, Carlo H.},
doi = {10.1145/258734.258747},
file = {:home/memo/Mendeley/data/Mine, Brooks, Sequin - 1997 - Moving Objects in Space Exploiting Proprioception In Virtual-Environment Interaction.pdf:pdf},
isbn = {0897918967},
journal = {Proceedings of the 24th annual conference on Computer graphics and interactive techniques - SIGGRAPH '97},
keywords = {manipulation,navigation,selection,virtual environments,virtual worlds},
pages = {19--26},
title = {{Moving Objects in Space: Exploiting Proprioception In Virtual-Environment Interaction}},
url = {http://dl.acm.org/citation.cfm?id=258734.258747},
year = {1997}
}
@article{Bowman2002,
abstract = {Virtual environments (VEs) are a relatively new type of human–computer interface in which users perceive and act in a three-dimensional world. The designers of such systems cannot rely solely on design guidelines for traditional two-dimensional interfaces, so usability evaluation is crucial for VEs. This paper presents an overview of VE usability evaluation to organize and critically analyze diverse work from this field. First, we discuss some of the issues that differentiate VE usability evaluation from evaluation of traditional user interfaces such as GUIs. We also present a review of some VE evaluation methods currently in use, and discuss a simple classification space for VE usability evaluation methods. This classification space provides a structured means for comparing evaluation methods according to three key characteristics: involvement of representative users, context of evaluation, and types of results produced. Finally, to illustrate these concepts, we compare two existing evaluation approaches...},
author = {Bowman, Doug a. and Gabbard, Joseph L. and Hix, Deborah},
doi = {10.1162/105474602760204309},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowman, Gabbard, Hix - 2002 - A Survey of Usability Evaluation in Virtual Environments Classification and Comparison of Methods.pdf:pdf},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {4},
pages = {404--424},
title = {{A Survey of Usability Evaluation in Virtual Environments: Classification and Comparison of Methods}},
volume = {11},
year = {2002}
}
@article{Cohen2009,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 2009 - The Art of Self-Assembly the Self-Assembly of Art.pdf:pdf},
number = {July},
title = {{The Art of Self-Assembly: the Self-Assembly of Art}},
year = {2009}
}
@article{Matthies2013,
abstract = {Over the past few years the use of public displays has increased drastically, with the most common public displays being flat surface LED walls or projections on walls. Presently interactive public displays often make use of depth cameras. This paper},
author = {Matthies, Denys J C and Nguyen, Ngo Dieu Huong and Lucas, Shaunna Janine and Botz, Daniel},
doi = {10.1145/2493190.2494433},
file = {:home/memo/Mendeley/data/Matthies et al. - 2013 - Moving shapes a multiplayer game based on color detection running on public displays.pdf:pdf},
isbn = {9781450322737},
journal = {MobileHCI '13: Proceedings of the 15th international conference on Human-computer interaction with mobile devices and services},
pages = {558},
title = {{Moving shapes: a multiplayer game based on color detection running on public displays}},
url = {http://dl.acm.org/citation.cfm?doid=2493190.2494433{\%}5Cnpapers3://publication/doi/10.1145/2493190.2494433},
year = {2013}
}
@article{Doug1997,
author = {Doug, Bowman. and Larry, Hodges.},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doug, Larry - 1997 - An evaluation of techniques for grabbing and manipulating remoting objects in immersive virtual environments.pdf:pdf},
pages = {35--38},
title = {{An evaluation of techniques for grabbing and manipulating remoting objects in immersive virtual environments}},
year = {1997}
}
@article{Argelaguet2013,
abstract = {Computer graphics applications controlled through natural gestures are gaining increasing popularity these days due to recent developments in low-cost tracking systems and gesture recognition technologies. Although interaction techniques through natural gestures have already demonstrated their benefits in manipulation, navigation and avatar-control tasks, effective selection with pointing gestures remains an open problem. In this paper we survey the state-of-the-art in 3D object selection techniques. We review important findings in human control models, analyze major factors influencing selection performance, and classify existing techniques according to a number of criteria. Unlike other components of the application's user interface, pointing techniques need a close coupling with the rendering pipeline, introducing new elements to be drawn, and potentially modifying the object layout and the way the scene is rendered. Conversely, selection performance is affected by rendering issues such as visual feedback, depth perception, and occlusion management. We thus review existing literature paying special attention to those aspects in the boundary between computer graphics and human-computer interaction. ?? 2012 Elsevier Ltd. All rights reserved.},
author = {Argelaguet, Ferran and Andujar, Carlos},
doi = {10.1016/j.cag.2012.12.003},
file = {:home/memo/Mendeley/data/Argelaguet, Andujar - 2013 - A survey of 3D object selection techniques for virtual environments.pdf:pdf},
issn = {00978493},
journal = {Computers and Graphics (Pergamon)},
keywords = {3D interaction,3D selection,Virtual pointing,Virtual reality},
number = {3},
pages = {121--136},
title = {{A survey of 3D object selection techniques for virtual environments}},
volume = {37},
year = {2013}
}
@article{Jankowski2014,
author = {Jankowski, J. and Hachet, M.},
doi = {10.1111/cgf.12466},
file = {:home/memo/Mendeley/data/Jankowski, Hachet - 2014 - Advances in Interaction with 3D Environments.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {3,3d interaction,6 methodology and techniques,7 three-,acm ccs,computer graphics,computer graphics i,dimensional graphics and realism,extended version of the,i,interaction techniques,manipulation,navigation,selection,state-of-the-art report,system control,this paper is an,virtual reality},
number = {1},
pages = {n/a--n/a},
title = {{Advances in Interaction with 3D Environments}},
url = {http://doi.wiley.com/10.1111/cgf.12466},
volume = {34},
year = {2014}
}
@article{Simonyan2013,
abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
archivePrefix = {arXiv},
arxivId = {1312.6034},
author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
eprint = {1312.6034},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Vedaldi, Zisserman - 2013 - Deep Inside Convolutional Networks Visualising Image Classification Models and Saliency Maps.pdf:pdf},
journal = {arXiv preprint arXiv:1312.6034},
pages = {1--8},
title = {{Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}},
url = {http://arxiv.org/abs/1312.6034},
year = {2013}
}
@article{Mahendran2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1412.0035v1},
author = {Mahendran, Aravindh and Vedaldi, Andrea},
eprint = {arXiv:1412.0035v1},
file = {:home/memo/Mendeley/data/Mahendran, Vedaldi - 2014 - Understanding Deep Image Representations by Inverting Them.pdf:pdf},
title = {{Understanding Deep Image Representations by Inverting Them}},
year = {2014}
}
@article{Dosovitskiy2015,
archivePrefix = {arXiv},
arxivId = {1506.02753v1},
author = {Dosovitskiy, Alexey and Brox, Thomas},
eprint = {1506.02753v1},
file = {:home/memo/Mendeley/data/Dosovitskiy, Brox - 2015 - Inverting Convolutional Networks with Convolutional Networks.pdf:pdf},
pages = {1--15},
title = {{Inverting Convolutional Networks with Convolutional Networks}},
year = {2015}
}
@article{Ochiai2014,
author = {Ochiai, Yoichi},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ochiai - 2014 - Fairy Lights in Femtoseconds Aerial and Volumetric Graphics Rendered by Focused Femtosecond Laser Combined with Computa.pdf:pdf},
title = {{Fairy Lights in Femtoseconds : Aerial and Volumetric Graphics Rendered by Focused Femtosecond Laser Combined with Computational Holographic Fields}},
year = {2014}
}
@article{Limerick2014,
abstract = {The sense of agency is the experience of controlling both one's body and the external environment. Although the sense of agency has been studied extensively, there is a paucity of studies in applied ‘real-life' situations. One applied domain that seems highly relevant is human-computer-interaction (HCI), as an increasing number of our everyday agentive interactions involve technology. Indeed, HCI has long recognized the feeling of control as a key factor in how people experience interactions with technology. The aim of this review is to summarize and examine the possible links between sense of agency and understanding control in HCI. We explore the overlap between HCI and sense of agency for computer input modalities and system feedback, computer assistance, and joint actions between humans and computers. An overarching consideration is how agency research can inform HCI and vice versa. Finally, we discuss the potential ethical implications of personal responsibility in an ever-increasing society of technology users and intelligent machine interfaces.},
author = {Limerick, Hannah and Coyle, David and Moore, James W},
doi = {10.3389/fnhum.2014.00643},
file = {:home/memo/Mendeley/data/Limerick, Coyle, Moore - 2014 - The Experience of Agency in Human-Computer Interactions A Review.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {Control,Joint Action,Technology,computer assistance,human computer interaction,sense of agency},
number = {August},
pages = {1--10},
pmid = {25191256},
title = {{The Experience of Agency in Human-Computer Interactions: A Review}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnhum.2014.00643/abstract},
volume = {8},
year = {2014}
}
@article{Hermann2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.03340v1},
author = {Hermann, Karm Moritz and Ko{\v{c}}isk{\'{y}}, Tom{\'{a}}{\v{s}} and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
eprint = {arXiv:1506.03340v1},
file = {:home/memo/Mendeley/data/Hermann et al. - 2015 - Teaching Machines to Read and Comprehend.pdf:pdf},
journal = {arXiv},
pages = {1--13},
title = {{Teaching Machines to Read and Comprehend}},
year = {2015}
}
@article{Jordanous2015,
author = {Jordanous, A and Shepperd, R and Colton, S and Guckelsberger, C},
file = {:home/memo/Mendeley/data/Jordanous et al. - 2015 - Computational Poetry Workshop Making Sense of Work in Progress.pdf:pdf},
keywords = {charts,computer poetry,flow-,s anybody,s workshops,said the tiger-lily,social creativity,we can talk,when there,writer},
number = {June},
pages = {268--275},
title = {{Computational Poetry Workshop : Making Sense of Work in Progress}},
year = {2015}
}
@article{Eigenfeldt2015,
author = {Eigenfeldt, Arne and Bown, Oliver and Carey, Benjamin},
file = {:home/memo/Mendeley/data/Eigenfeldt, Bown, Carey - 2015 - Collaborative Composition with Creative Systems Reflections on the First Musebot Ensemble.pdf:pdf},
number = {June},
pages = {134--141},
title = {{Collaborative Composition with Creative Systems : Reflections on the First Musebot Ensemble}},
year = {2015}
}
@article{Bown2015,
author = {Bown, Oliver},
file = {:home/memo/Mendeley/data/Bown - 2015 - Attributing Creative Agency Are we doing it right.pdf:pdf},
number = {June},
pages = {17--22},
title = {{Attributing Creative Agency : Are we doing it right ?}},
year = {2015}
}
@article{Compton1998,
author = {Compton, Kate and Mateas, Michael},
file = {:home/memo/Mendeley/data/Compton, Mateas - 1998 - A Different Kind of Physics Interactive evolution of expressive dancers and choreography.pdf:pdf},
number = {Guest},
title = {{A Different Kind of Physics Interactive evolution of expressive dancers and choreography}},
year = {1998}
}
@article{Mccormack2004,
abstract = {Generative design offers new modes of aesthetic experience based on the incorporation of system dynamics into the production of artifact and experience. In this paper, we review a number of processes that can be explored by designers and suggest how design as a discipline can benefit from this research. These processes include self-organization, swarm systems and ant colonies, evolution, and generative grammars. We give example applications of these processes to creativity and design.},
author = {Mccormack, Jon and Dorin, Alan and Innocent, Troy},
file = {:home/memo/Mendeley/data/Mccormack, Dorin, Innocent - 2004 - Generative design a paradigm for design research.pdf:pdf},
isbn = {1616890770, 9781616890773},
journal = {Proceedings of Futureground},
number = {June 2015},
title = {{Generative design : a paradigm for design research}},
year = {2004}
}
@article{Lassiter2013,
author = {Lassiter, Daniel and Goodman, Noah D},
file = {:home/memo/Mendeley/data/Lassiter, Goodman - 2013 - Adjectival vagueness in a Bayesian model of interpretation ∗.pdf:pdf},
pages = {1--38},
title = {{Adjectival vagueness in a Bayesian model of interpretation ∗}},
year = {2013}
}
@misc{,
file = {:home/memo/Mendeley/data/Unknown - Unknown - MIT-CSAIL-TR-2005-056.pdf.pdf:pdf},
title = {{MIT-CSAIL-TR-2005-056.pdf}}
}
@article{Murphy2003,
author = {Murphy, Kevin and Torralba, Antonio and Freeman, William},
file = {:home/memo/Mendeley/data/Murphy, Torralba, Freeman - 2003 - Using the Forest to See the TreesA Graphical Model Relating Features, Objects and Scenes.pdf:pdf},
journal = {Nips},
number = {January},
title = {{Using the Forest to See the Trees:A Graphical Model Relating Features, Objects and Scenes}},
year = {2003}
}
@article{Mccormack2005,
abstract = {Applying evolutionary methods to the generation of music and art is a relatively new field of enquiry. While there have been some important developments, it might be argued that to date, successful results in this domain have been limited. Much of the present research can be characterized as finding adhoc methods that can produce subjectively interesting results. In this paper, it is argued that a stronger overall research plan is needed if the field is to develop in the longer term and attract more researchers. Five ‘open problems' are defined and explained as broad principle areas of investigation for evolutionary music and art. Each problem is explained and the impetus and background for it is described in the context of creative evolutionary systems.},
author = {Mccormack, Jon},
doi = {10.1007/b106856},
file = {:home/memo/Mendeley/data/Mccormack - 2005 - Open Problems in Evolutionary Music and Art.pdf:pdf},
isbn = {3540253963},
issn = {03029743},
journal = {LNCS 3449 Applications of Evolutionary Computation, Proceedings Of EvoMUSART 2005},
pages = {428--436},
title = {{Open Problems in Evolutionary Music and Art}},
year = {2005}
}
@article{Zook2011,
abstract = {Play is a creative activity involving the construction, use, and modification of game frameworks. Developing computational agents capable of play with humans re- quires a formal categorization of the key aspects of play. We propose a theoretical framework to differenti- ate the knowledge, actions, and intentions employed by play agents. Play knowledge may be pre-conventional (lacking formal rules), conventional (composed of do- main-specific rules), or post-conventional (including both domain specific and out-of-domain rules). Actions may exploit, explore, generate, or modify play knowl- edge to create play experiences. These experiences may be pursued with ego-centric (self-oriented) or exo- centric (other-oriented) intentions. We illustrate this framework with examples from research on play and re- late this to existing creativity models.},
author = {Zook, Alexander E (Georgia Institute of Technology) and Riedl, Mark O (Georgie Institute of Technology) and Magerko, Brian S (Georgia Institute of Technology)},
file = {:home/memo/Mendeley/data/Zook, Riedl, Magerko - 2011 - Understanding Human Creativity for Computational Play.pdf:pdf},
isbn = {9786074774870 (ISBN)},
journal = {Proceedings of the Second International Conference on Computational Creativity},
pages = {42--47},
title = {{Understanding Human Creativity for Computational Play}},
year = {2011}
}
@article{Sudderth2008,
abstract = {We develop hierarchical, probabilistic models for objects, the parts$\backslash$ncomposing them, and the visual scenes surrounding them. Our approach$\backslash$ncouples topic models originally developed for text analysis with$\backslash$nspatial transformations, and thus consistently accounts for geometric$\backslash$nconstraints. By building integrated scene models, we may discover$\backslash$ncontextual relationships, and better exploit partially labeled training$\backslash$nimages. We first consider images of isolated objects, and show that$\backslash$nsharing parts among object categories improves detection accuracy$\backslash$nwhen learning from few examples. Turning to multiple object scenes,$\backslash$nwe propose nonparametric models which use Dirichlet processes to$\backslash$nautomatically learn the number of parts underlying each object category,$\backslash$nand objects composing each scene. The resulting transformed Dirichlet$\backslash$nprocess (TDP) leads to Monte Carlo algorithms which simultaneously$\backslash$nsegment and recognize objects in street and office scenes.},
author = {Sudderth, Erik B. and Torralba, Antonio and Freeman, William T. and Willsky, Alan S.},
doi = {10.1007/s11263-007-0069-5},
file = {:home/memo/Mendeley/data/Sudderth et al. - 2008 - Describing visual scenes using transformed objects and parts.pdf:pdf},
isbn = {076952334X},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Context,Dirichlet process,Graphical models,Hierarchical Dirichlet process,Object recognition,Scene analysis,Transformation},
number = {1-3},
pages = {291--330},
title = {{Describing visual scenes using transformed objects and parts}},
volume = {77},
year = {2008}
}
@article{Torralba2003,
abstract = {While navigating in an environment, a vision system has to be able to recognize where it is and what the main objects in the scene are. We present a context-based vision system for place and object recognition. The goal is to identify familiar locations (e.g., office 610, conference room 941, main street), to categorize new environments (office, corridor, street) and to use that information to provide contextual priors for object recognition (e.g., tables are more likely in an office than a street). We present a low-dimensional global image representation that provides relevant information for place recognition and categorization, and show how such contextual information introduces strong priors that simplify object recognition. We have trained the system to recognize over 60 locations (indoors and outdoors) and to suggest the presence and locations of more than 20 different object types. The algorithm has been integrated into a mobile system that provides realtime feedback to the user.},
author = {Torralba, a. and Murphy, K.P. and Freeman, W.T. and Rubin, M.a.},
doi = {10.1109/ICCV.2003.1238354},
file = {:home/memo/Mendeley/data/Torralba et al. - 2003 - Context-based vision system for place and object recognition.pdf:pdf},
isbn = {0-7695-1950-4},
issn = {0769519504},
journal = {Proceedings Ninth IEEE International Conference on Computer Vision},
number = {March},
title = {{Context-based vision system for place and object recognition}},
year = {2003}
}
@article{Davis2014,
author = {Davis, Nicholas and Popova, Yanna and Sysoev, Ivan and Hsiao, Chih-Pin and Zhang, Dingtian and Magerko, Brian},
file = {:home/memo/Mendeley/data/Davis et al. - 2014 - Building Artistic Computer Colleagues with an Enactive Model of Creativity.pdf:pdf},
number = {JANUARY},
title = {{Building Artistic Computer Colleagues with an Enactive Model of Creativity}},
year = {2014}
}
@article{Alonso2001,
abstract = {In recent years, multi-agent systems (MASs) have received increasing attention in the artificial intelligence community. Research in multi-agent systems involves the investigation of autonomous, rational and flexible behaviour of entities such as software programs or robots, and their interaction and coordination in such diverse areas as robotics (Kitano et al., 1997), information retrieval and management (Klusch, 1999), and simulation (Gilbert {\&} Conte, 1995). When designing agent systems, it is impossible to foresee all the potential situations an agent may encounter and specify an agent behaviour optimally in advance. Agents therefore have to learn from, and adapt to, their environment, especially in a multi-agent setting.},
author = {Alonso, E and D'Inverno, M and Kudenko, D and Luck, M and Noble, J},
doi = {10.1017/S0269888901000170},
file = {:home/memo/Mendeley/data/Alonso et al. - 2001 - Learning in multi-agent systems.pdf:pdf},
isbn = {0262232030},
issn = {0269-8889},
title = {{Learning in multi-agent systems}},
url = {http://dx.doi.org/10.1017/S0269888901000170},
year = {2001}
}
@article{Jacob2013,
author = {Jacob, M and Zook, a and Magerko, B},
file = {:home/memo/Mendeley/data/Jacob, Zook, Magerko - 2013 - Viewpoints AI Procedurally Representing and Reasoning about Gestures.pdf:pdf},
journal = {Proceedings of DiGRA},
keywords = {artificial intelligence,computational,gesture,procedural aesthetics,theatre,viewpoints},
pages = {15},
title = {{Viewpoints AI: Procedurally Representing and Reasoning about Gestures}},
year = {2013}
}
@article{Magerko2009,
abstract = {This paper presents preliminary findings from our empirical study of the cognition employed by performers in improvisational theatre. Our study has been conducted in a laboratory setting with local improvisers. Participants performed predesigned improv “games”, which were videotaped and shown to each individual participant for a retrospective protocol collection. The participants were then shown the video again as a group to elicit data on group dynamics, misunderstandings, etc. This paper presents our initial findings that we have built based on our initial analysis of the data and highlights details of interest.},
author = {Magerko, Brian and Manzoul, Waleed and Riedl, Mark and Baumer, Allan and Fuller, Daniel and Luther, Kurt and Pearce, Celia},
doi = {doi: 10.1145/1640233.1640253},
file = {:home/memo/Mendeley/data/Magerko et al. - 2009 - An Empirical Study of Cognition and Theatrical Improvisation.pdf:pdf},
isbn = {9781605584034},
journal = {Seventh ACM Conference on Creativity and Cognition},
number = {c},
pages = {117--126},
title = {{An Empirical Study of Cognition and Theatrical Improvisation}},
year = {2009}
}
@article{Eschrich2013,
author = {Eschrich, Brian},
doi = {10.1145/2460625.2460685},
file = {:home/memo/Mendeley/data/Eschrich - 2013 - Spatial illusions on tangibles.pdf:pdf},
isbn = {9781450318983},
journal = {Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction - TEI '13},
pages = {343--344},
title = {{Spatial illusions on tangibles}},
year = {2013}
}
@article{Ring1994,
abstract = {Continual learning$\backslash$n$\backslash$nis the constant development of complex behaviors with no nal end in$\backslash$n$\backslash$nmind. It is the process of learning ever more complicated skills by$\backslash$nbuilding on those skills al-$\backslash$n$\backslash$nready developed. In order for learning at one stage of development$\backslash$nto serve as the foundation$\backslash$n$\backslash$nfor later learning, a continual-learning agent should learn hierarchically.$\backslash$nCHILD, an agent$\backslash$n$\backslash$ncapable of$\backslash$n$\backslash$nContinual, Hierarchical, Incremental Learning$\backslash$n$\backslash$nand$\backslash$n$\backslash$nDevelopment$\backslash$n$\backslash$nis proposed,$\backslash$n$\backslash$ndescribed, tested, and evaluated in this dissertation. CHILD accumulates$\backslash$nuseful behaviors$\backslash$n$\backslash$nin reinforcement environments by using the$\backslash$n$\backslash$nTemporal Transition Hierarchies$\backslash$n$\backslash$nlearning algo-$\backslash$n$\backslash$nrithm, also derived in the dissertation. This constructive algorithm$\backslash$ngenerates a hierarchical,$\backslash$n$\backslash$nhigher-order neural network that can be used for predicting context-dependent$\backslash$ntemporal se-$\backslash$n$\backslash$nquences and can learn sequential-task benchmarks more than two orders$\backslash$nof magnitude faster$\backslash$n$\backslash$nthan competing neural-network systems. Consequently, CHILD can quickly$\backslash$nsolve compli-$\backslash$n$\backslash$ncated non-Markovian reinforcement-learning tasks and can then transfer$\backslash$nits skills to similar$\backslash$n$\backslash$nbut even more complicated tasks, learning these faster still. This$\backslash$ncontinual-learning ap-$\backslash$n$\backslash$nproach is made possible by the unique properties of Temporal Transition$\backslash$nHierarchies, which$\backslash$n$\backslash$nallow existing skills to be amended and augmented in precisely the$\backslash$nsame way that they were$\backslash$n$\backslash$nconstructed in the rst place.},
author = {Ring, M B},
file = {:home/memo/Mendeley/data/Ring - 1994 - Continual learning in reinforcement environments.pdf:pdf},
journal = {Psychology},
pages = {44},
title = {{Continual learning in reinforcement environments}},
volume = {1},
year = {1994}
}
@article{Luck2001,
author = {Luck, Michael and D'Inverno, Mark},
doi = {10.1093/comjnl/44.1.1},
file = {:home/memo/Mendeley/data/Luck, D'Inverno - 2001 - A conceptual framework for agent definition and development.pdf:pdf},
issn = {00104620},
journal = {Computer Journal},
number = {1},
pages = {1--20},
title = {{A conceptual framework for agent definition and development}},
volume = {44},
year = {2001}
}
@article{Newell1980,
author = {Newell, Allen},
doi = {10.1037/019640},
file = {:home/memo/Mendeley/data/Newell - 1980 - Principles of Artificial Intelligence.pdf:pdf},
journal = {PsycCRITIQUES},
number = {1},
title = {{Principles of Artificial Intelligence}},
volume = {26},
year = {1980}
}
@article{Magerko2004,
abstract = {We are creating an environment for investigating the role of advanced AI in interactive, story-based computer games. This environment is based on the Unreal Tournament (UT) game engine and the Soar AI engine. Unreal provides a 3D virtual environment, while Soar provides a flexible architecture for developing complex AI characters. This paper describes our progress to date, starting with our game, Haunt 2, which is designed so that complex AI characters will be critical to the success (or failure) of the game. It addresses design issues with constructing a plot for an interactive storytelling environment, creating synthetic characters for that environment, and using a story director agent to tell the story with those characters.},
author = {Magerko, Brian and Laird, John E. and Assanie, Mazin and Kerfoot, Alex and Stokes, Devvan},
file = {:home/memo/Mendeley/data/Magerko et al. - 2004 - AI characters and directors for interactive computer games.pdf:pdf},
isbn = {0-262-51183-5},
journal = {Proceedings of the Nineteenth National Conference on Artificial Intelligence, Sixteenth Conference on Innovative Applications of Artificial Intelligence},
keywords = {Copyright {\textcopyright} 2004 American Association for Artifici},
pages = {877--883},
title = {{AI characters and directors for interactive computer games}},
url = {http://dl.acm.org/citation.cfm?id=1597321.1597339},
year = {2004}
}
@article{Oliva2001,
abstract = {In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimen- sional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.},
author = {Oliva, Aude and Torralba, Antonio},
doi = {10.1023/A:1011139631724},
file = {:home/memo/Mendeley/data/Oliva, Torralba - 2001 - Modeling the shape of the scene A holistic representation of the spatial envelope.pdf:pdf},
isbn = {0920-5691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Energy spectrum,Natural images,Principal components,Scene recognition,Spatial layout},
number = {3},
pages = {145--175},
title = {{Modeling the shape of the scene: A holistic representation of the spatial envelope}},
volume = {42},
year = {2001}
}
@article{Magerko2003,
author = {Magerko, Brian and Laird, Je},
file = {:home/memo/Mendeley/data/Magerko, Laird - 2003 - Building an interactive drama architecture.pdf:pdf},
journal = {In the proceedings of First International Conference on Technologies for Interactive Digital Storytelling and Entertainment},
pages = {226--237},
title = {{Building an interactive drama architecture.}},
year = {2003}
}
@article{McCormack2012,
author = {McCormack, Jon and D'Inverno, Mark},
doi = {10.1007/978-3-642-31727-9},
file = {:home/memo/Mendeley/data/McCormack, d'Inverno - 2012 - Computers and Creativity The Road Ahead.pdf:pdf},
journal = {Computers and Creativity},
keywords = {*file-import-13-08-07},
pages = {421--424},
title = {{Computers and Creativity: The Road Ahead}},
url = {http://dx.doi.org/10.1007/978-3-642-31727-9},
year = {2012}
}
@article{DInverno2004,
abstract = {The Procedural Reasoning System (PRS) is the best established agent architecture currently available. It has been deployed in many major industrial applications, ranging from fault diagnosis on the space shuttle to air traffic management and business process control. The theory of PRS-like systems has also been widely studied: within the intelligent agents research community, the belief-desire-intention (BDI) model of practical reasoning that underpins PRS is arguably the dominant force in the theoretical foundations of rational agency. Despite the interest in PRS and BDI agents, no complete attempt has yet been made to precisely specify the behaviour of real PRS systems. This has led to the development of a range of systems that claim to conform to the PRS model, but which differ from it in many important respects. Our aim in this paper is to rectify this omission. We provide an abstract formal model of an idealised dMARS system (the most recent implementation of the PRS architecture), which precisely defines the key data structures present within the architecture and the operations that manipulate these structures. We focus in particular on dMARS plans, since these are the key tool for programming dMARS agents. The specification we present will enable other implementations of PRS to be easily developed, and will serve as a benchmark against which future architectural enhancements can be evaluated.},
author = {D'Inverno, Mark and Luck, Michael and Georgeff, M and Kinny, D and Wooldridge, M},
file = {:home/memo/Mendeley/data/d'Inverno et al. - 2004 - The dMARS Architechure A Specification of the Distributed Multi-Agent Reasoning System.pdf:pdf},
keywords = {agent architectures,bdi,formal specification,procedural reasoning system},
pages = {5--53},
title = {{The dMARS Architechure: A Specification of the Distributed Multi-Agent Reasoning System}},
url = {http://eprints.soton.ac.uk/260224/},
year = {2004}
}
@article{Franklin,
abstract = {The advent of software agents gave rise to much discussion of just what such an agent is, and of how they differ from programs in general. Here we propose a formal definition of an autonomous agent which clearly distinguishes a software agent from just any program. We also offer the beginnings of a natural kinds taxonomy of autonomous agents, and discuss possibilities for further classification. Finally, we discuss subagents and multiagent systems.},
author = {Franklin, Stan and Graesser, Art},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franklin, Graesser - Unknown - Is It an Agent , or Just a P r o g r a m A T a x o n o m y for A u t o n o m o u s Agents 1 Introductio.pdf:pdf},
title = {{Is It an Agent, or Just a Program? A Taxonomy for Autonomous Agents}}
}
@article{Gershman2009,
abstract = {... Edward Vul {\&} Joshua B. Tenenbaum Department of Brain and Cognitive Sciences Massachusetts ... posteriors of one scene variable conditioned on its neighbors (as in Gibbs sampling ). ... the classic findings of Gamma-distributed mode-switching times in bistable perception; the ...},
author = {Gershman, Sj and Vul, Edward and Tenenbaum, J},
doi = {10.1.1.189.1245},
file = {:home/memo/Mendeley/data/Gershman, Vul, Tenenbaum - 2009 - Perceptual multistability as Markov chain Monte Carlo inference.pdf:pdf},
isbn = {9781615679119},
journal = {Nips},
pages = {1--9},
title = {{Perceptual multistability as Markov chain Monte Carlo inference}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.189.1245{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{McCormack2007,
abstract = {This paper discusses the concept of an artificial ecosystem for use in machine-assisted creative discovery. Properties and processes from natural ecosystems are abstracted and applied to the design of creative systems, in a similar way that evolutionary computing methods use the metaphor of Darwinian evolution to solve problems in search and optimisation. The paper examines some appropriate mechanisms and metaphors when applying artificial ecosystems to problems in creative design. General properties and processes of evolutionary artificial ecosystems are presented as a basis for developing individual systems that automate the discovery of novelty without explicit teleological goals. The adaptation of species to fit their environment drives the creative solutions, so the role of the designer shifts to the design of environments. This allows a variety of creative solutions to emerge in simulation without the need for explicit or human-evaluated fitness measures, such as those used in interactive evolution. Two example creative ecosystems are described to highlight the effectiveness of the method presented.},
author = {McCormack, J},
doi = {10.1145/1276958.1277017},
file = {:home/memo/Mendeley/data/McCormack - 2007 - Artificial ecosystems for creative discovery.pdf:pdf},
isbn = {9781595936974},
journal = {Proceedings of the 9th annual conference on Genetic and Evolutionary Computation Conference},
keywords = {creativity,ecosystem theory},
pages = {301--307},
title = {{Artificial ecosystems for creative discovery}},
year = {2007}
}
@article{Goodman2008,
abstract = {This article proposes a new model of human concept learning that provides a rational analysis of learning feature-based concepts. This model is built upon Bayesian inference for a grammatically structured hypothesis space-a concept language of logical rules. This article compares the model predictions to human generalization judgments in several well-known category learning experiments, and finds good agreement for both average and individual participant generalizations. This article further investigates judgments for a broad set of 7-feature concepts-a more natural setting in several ways-and again finds that the model explains human performance.},
author = {Goodman, Noah D and Tenenbaum, Joshua B and Feldman, Jacob and Griffiths, Thomas L},
doi = {10.1080/03640210701802071},
file = {:home/memo/Mendeley/data/Goodman et al. - 2008 - A rational analysis of rule-based concept learning.pdf:pdf},
isbn = {0364-0213 (Print)$\backslash$r0364-0213 (Linking)},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {bayesian induction,categorization,concept learning,probabilistic grammar,rules},
number = {1},
pages = {108--154},
pmid = {21635333},
title = {{A rational analysis of rule-based concept learning.}},
volume = {32},
year = {2008}
}
@article{Beer1999,
abstract = {In systems composed of multiple autonomous agents, negotiation is a key form of interaction that enables groups of agents to arrive at a mutual agreement regarding some belief, goal or plan, for example. Particularly because the agents are autonomous and cannot be assumed to be benevolent, agents must influence others to convince them to act in certain ways, and negotiation is thus critical for managing such inter-agent dependencies. The process of negotiation may be of many different forms, such as auctions, protocols in the style of the contract net, and argumentation, but it is unclear just how sophisticated the agents or the protocols for interaction must be for successful negotiation in different contexts. All these issues were raised in the panel session on negotiation.},
author = {Beer, M. and D'Inverno, M. and Jennings, N. R. and Luck, M. and Preist, C. and Schroeder, M.},
doi = {10.1017/S0269888999003021},
file = {:home/memo/Mendeley/data/Beer et al. - 1999 - Negotiation in Multi-Agent Systems.pdf:pdf},
issn = {02698889},
pages = {1--6},
title = {{Negotiation in Multi-Agent Systems}},
url = {http://eprints.soton.ac.uk/253858/},
year = {1999}
}
@article{McCormack1998,
abstract = {Implicit surfaces obtained by convolution of multi-dimensional primitives with some potential function, are a generalisation of popular implicit surface models: blobs, metaballs and soft objects. These models differ in their choice of potential function but agree upon the use of underlying modelling primitives, namely, points. In this paper a method is described for modelling and rendering implicit surfaces built upon an expanded set of skeletal primitives: points, line segments, polygons, arcs and planes. An analytical solution to the convolution is described. This solution offers a more accurate and robust representation of the resultant implicit surface than previous methods. An algorithm for ray-tracing the surfaces formed through convolution of any combination of these primitives is also outlined.},
author = {McCormack, Jon and Sherstyuk, Andrei},
doi = {10.1111/1467-8659.00232},
file = {:home/memo/Mendeley/data/McCormack, Sherstyuk - 1998 - Creating and Rendering Convolution Surfaces.pdf:pdf},
issn = {0167-7055},
journal = {Computer Graphics Forum},
keywords = {convolution surfaces,geometric modelling,implicit surfaces,ray-tracing},
number = {2},
pages = {113--120},
title = {{Creating and Rendering Convolution Surfaces}},
url = {http://doi.wiley.com/10.1111/1467-8659.00232},
volume = {17},
year = {1998}
}
@article{Schmidhuber2006,
abstract = {Even in absence of external reward, babies and scientists and others explore their world. Using some sort of adaptive predictive world model, they improve their ability to answer questions such as: what happens if I do this or that? They lose interest in both the predictable things and those predicted to remain unpredictable despite some effort. One can design curious robots that do the same. The author's basic idea for doing so (1990, 1991): a reinforcement learning (RL) controller is rewarded for action sequences that improve the predictor. Here this idea is revisited in the context of recent results on optimal predictors and optimal RL machines. Several new variants of the basic principle are proposed. Finally it is pointed out how the fine arts can be formally understood as a consequence of the principle: given some subjective observer, great works of art and music yield observation histories exhibiting more novel, previously unknown compressibility / regularity / predictability (with respect to the observer's particular learning algorithm) than lesser works, thus deepening the observer's understanding of the world and what is possible in it.},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1080/09540090600768658},
file = {:home/memo/Mendeley/data/Schmidhuber - 2006 - Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts.pdf:pdf},
issn = {0954-0091},
journal = {Connection Science},
number = {2},
pages = {173--187},
title = {{Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts}},
volume = {18},
year = {2006}
}
@article{McCormack1996,
abstract = {L-Systems have traditionally been used as a popular method for the modelling of space- filling curves, biological systems and morphogenesis. In this paper, we adapt string re- writing grammars based on L-Systems into a system for music composition. Representation of pitch, duration and timbre are encoded as grammar symbols, upon which a series of re-writing rules are applied. Parametric extensions to the grammar allow the specification of continuous data for the purposes of modulation and control. Such continuous data is also under control of the grammar. Using non-deterministic grammars with context sensitivity allows the simulation of Nth-order Markov models with a more economical representation than transition matrices and greater flexibility than previous composition models based on finite state automata or Petri nets. Using symbols in the grammar to represent relationships between notes, (rather than absolute notes) in combination with a hierarchical grammar representation, permits the emergence of complex music compositions from a relatively simple grammars.},
author = {McCormack, Jon},
file = {:home/memo/Mendeley/data/McCormack - 1996 - Grammar based music composition.pdf:pdf},
journal = {Complex systems},
pages = {321--336},
title = {{Grammar based music composition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.8731{\&}rep=rep1{\&}type=pdf},
volume = {96},
year = {1996}
}
@article{McCormack1993,
abstract = {Evolution of Lindenmayer Systems (L-Systems) provides a powerful method for creating complex computer graphics and animations. This paper describes an interactive modelling system for computer graphics in which the user is able to “evolve” grammatical rules and surface equations. Starting from any initial L-System grammar the evolution proceeds via repeated random mutation and user selection. Sub-classes of the mutation process depend on the context of the current symbol or rule being mutated and include mutation of: parametric equations and expressions, growth functions, rules and productions. As the grammar allows importation of parametric surfaces, these surfaces can be mutated and selected as well. The mutated rules are then interpreted to create a three-dimensional, time-dependent model composed of parametric and polygonal geometry. L-System evolution allows with minimal knowledge of L-Systems to create complex, “life- like” images and animations that would be difficult and far more time-consuming to achieve by writing rules and equations explicitly. 1.},
author = {McCormack, J},
file = {:home/memo/Mendeley/data/McCormack - 1993 - Interactive evolution of L-system grammars for computer graphics modelling.pdf:pdf},
isbn = {978-9051991178},
journal = {Complex Systems: from biology to computation},
pages = {1--7},
title = {{Interactive evolution of L-system grammars for computer graphics modelling}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=BQUTF56EpAQC{\&}oi=fnd{\&}pg=PA118{\&}dq=Interactive+Evolution+of+L-System+Grammars+for+Computer+Graphics+Modelling{\&}ots=FhKpmSEtnm{\&}sig=ywzS-gyAHFDQ5jSWMATENvpEkKM},
year = {1993}
}
@article{Bown2009a,
abstract = {In this paper I discuss reasons for viewing human creativity more as a social process than as an individual act. $\backslash$n$\backslash$nThese reasons include the subjectivity of evaluation in attributing creativity, the potentially arbitrary relationship between individuals and creativity at the cultural level, the importance of the capacity for preserving cultural information over and above the capacity to innovate, the role of objects, institutions and interaction in sparking creativity, and the social constructedness of creative domains. $\backslash$n$\backslash$nI consider the consequences of this way of thinking for research into computational creativity. $\backslash$n$\backslash$nI argue that realising the goals of computational creativity depends on integrating research on creative agents with social technologies.},
author = {Bown, Oliver},
file = {:home/memo/Mendeley/data/Bown - 2009 - Against Individual Creativity.pdf:pdf},
journal = {Creativity},
pages = {1--16},
title = {{Against Individual Creativity}},
year = {2009}
}
@article{McCormack2009a,
abstract = {This chapter describes a novel type of artistic artificial life software environment. Agents that have the ability to make and listen to sound populate a synthetic world. An evolvable, rule-based classifier system drives agent behavior. Agents compete for limited resources in a virtual environment that is influenced by the presence and movement of people observing the system. Electronic sensors create a link between the real and virtual spaces, virtual agents evolve implicitly to try to maintain the interest of the human audience, whose presence provides them with life-sustaining food.},
author = {McCormack, Jon},
doi = {10.1007/978-1-84882-285-6_13},
file = {:home/memo/Mendeley/data/McCormack - 2009 - The evolution of sonic ecosystems.pdf:pdf},
isbn = {9781848822849},
journal = {Artificial Life Models in Software (Second Edition)},
pages = {393--414},
title = {{The evolution of sonic ecosystems}},
year = {2009}
}
@article{Kowaliw2012,
author = {Kowaliw, Taras and Dorin, Alan and McCormack, J},
file = {:home/memo/Mendeley/data/Kowaliw, Dorin, McCormack - 2012 - Promoting creative design in interactive evolutionary computation.pdf:pdf},
journal = {{\ldots} on Evolutionary Computation},
pages = {1--15},
title = {{Promoting creative design in interactive evolutionary computation}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Promoting+Creative+Design+in+Interactive+Evolutionary+Computation{\#}0},
year = {2012}
}
@article{Kowaliw2011,
abstract = {In this paper, we explore a generative art system designed to promote the creation of a diverse range of aesthetically pleasing images. We introduce our system, EvoEco, an agent-based pixel-level means of generating images based on artificial ecosystems. This art system is driven by interactive evolutionary computation, and further augmented using special measures to promote the diversity of the individuals. Following previous work, we explore a tractable definition of creativity and its addition to this interactive search. EvoEco was released online, and used by forty-one anonymous users to generate artwork. Here we present some of the discovered results.},
author = {Kowaliw, Taras and McCormack, Jon and Dorin, Alan},
doi = {10.1109/ALIFE.2011.5954645},
file = {:home/memo/Mendeley/data/Kowaliw, McCormack, Dorin - 2011 - An interactive electronic art system based on artificial ecosystemics.pdf:pdf},
isbn = {9781612840635},
issn = {2160-6374},
journal = {IEEE SSCI 2011 - Symposium Series on Computational Intelligence - IEEE ALIFE 2011: 2011 IEEE Symposium on Artificial Life},
keywords = {Interactive evolution,artificial ecosystem,computational creativity,electronic art,generative art},
pages = {162--169},
title = {{An interactive electronic art system based on artificial ecosystemics}},
year = {2011}
}
@article{Boden1998,
abstract = {Creativity is a fundamental feature of human intelligence, and a challenge for AI. AI techniques can be used to create new ideas in three ways: by producing novel combinations of familiar ideas; by exploring the potential of conceptual spaces; and by making transformations that enable the generation of previously impossible ideas. AI will have less difficulty in modelling the generation of new ideas than in automating their evaluation.},
author = {Boden, Margaret a.},
doi = {10.1016/S0004-3702(98)00055-1},
file = {:home/memo/Mendeley/data/Boden - 1998 - Creativity and artificial intelligence.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
number = {1-2},
pages = {347--356},
title = {{Creativity and artificial intelligence}},
volume = {103},
year = {1998}
}
@article{McCormack2001,
abstract = {This paper describes an Artificial Life system for music composition. An evolving ecology of sonic entities populate a virtual world and compete for limited resources. Part of their genetic representation permits the creatures to make and listen to sounds. Complex musical and sonic relationships can develop as the creatures use sound to aid in their survival and mating prospects.},
author = {McCormack, Jon},
doi = {10.1007/3-540-44811-X_13},
file = {:home/memo/Mendeley/data/McCormack - 2001 - Eden an evolutionary sonic ecosystem.pdf:pdf},
isbn = {3-540-42567-5},
journal = {Advances in Artificial Life},
number = {September},
pages = {133--142},
title = {{Eden: an evolutionary sonic ecosystem}},
volume = {2159},
year = {2001}
}
@article{Mccormack2001,
author = {Mccormack, Jon and Dorin, Alan},
doi = {10.1.1.16.6640},
file = {:home/memo/Mendeley/data/Mccormack, Dorin - 2001 - Art , Emergence , and the Computational Sublime.pdf:pdf},
isbn = {073262195X},
number = {December},
pages = {67--81},
title = {{Art , Emergence , and the Computational Sublime}},
year = {2001}
}
@article{Brown2009,
author = {Brown, Paul and Boden, M. and D'Inverno, M. and McCormack, J.},
file = {:home/memo/Mendeley/data/Brown et al. - 2009 - Autonomy, Signature and Creativity.pdf:pdf},
journal = {Computational Creativity: An Interdisciplinary Approach{\$}\backslash{\$}},
pages = {345--348},
title = {{Autonomy, Signature and Creativity}},
url = {http://drops.dagstuhl.de/opus/volltexte/2009/2204/},
volume = {348},
year = {2009}
}
@article{Pirsiavash2004,
abstract = {While recent advances in computer vision have provided reli-able methods to recognize actions in both images and videos, the problem of assessing how well people perform actions has been largely unexplored in computer vision. Since methods for assessing action quality have many real-world applications in healthcare, sports, and video retrieval, we be-lieve the computer vision community should begin to tackle this challeng-ing problem. To spur progress, we introduce a learning-based framework that takes steps towards assessing how well people perform actions in videos. Our approach works by training a regression model from spa-tiotemporal pose features to scores obtained from expert judges. More-over, our approach can provide interpretable feedback on how people can improve their action. We evaluate our method on a new Olympic sports dataset, and our experiments suggest our framework is able to rank the athletes more accurately than a non-expert human. While promising, our method is still a long way to rivaling the performance of expert judges, indicating that there is signiﬁcant opportunity in computer vision re-search to improve on this diﬃcult yet important task.},
author = {Pirsiavash, Hamed and Vondrick, Carl and Torralba, Antonio},
file = {:home/memo/Mendeley/data/Pirsiavash, Vondrick, Torralba - 2004 - Assessing the Quality of Actions.pdf:pdf},
title = {{Assessing the Quality of Actions}},
year = {2004}
}
@article{Tenenbaum2006,
abstract = {Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Tenenbaum, Joshua B. and Griffiths, Thomas L. and Kemp, Charles},
doi = {10.1016/j.tics.2006.05.009},
file = {:home/memo/Mendeley/data/Tenenbaum, Griffiths, Kemp - 2006 - Theory-based Bayesian models of inductive learning and reasoning.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {7},
pages = {309--318},
pmid = {16797219},
title = {{Theory-based Bayesian models of inductive learning and reasoning}},
volume = {10},
year = {2006}
}
@article{Griffiths2001,
abstract = {We argue that the apparent inconsistency between peo- ple's intuitions about chance and the normative predic- tions of probability theory, as expressed in judgments about randomness and coincidences, can be resolved by focussing on the evidence observations provide about the processes that generated them rather than their likelihood. This argument is supported by probabilistic modeling of sequence and number production, together with two ex- periments that examine judgments about coincidences.},
author = {Griffiths, Tl and Tenenbaum, Jb},
file = {:home/memo/Mendeley/data/Griffiths, Tenenbaum - 2001 - Randomness and coincidences Reconciling intuition and probability theory.pdf:pdf},
journal = {Proceedings of the 23rd annual conference of the cognitive science society},
pages = {370--375},
title = {{Randomness and coincidences: Reconciling intuition and probability theory}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=mJAclUVF8jIC{\&}oi=fnd{\&}pg=PA370{\&}dq=Randomness+and+Coincidences:+Reconciling+Intuition+and+Probability+Theory{\&}ots=eP-OaMQ5I8{\&}sig=ZUZCoOmoYawEcRTQ-LC58FiiP6Y},
year = {2001}
}
@article{Schorlemmer2011,
author = {Schorlemmer, Marco and Smaill, Alan and Kai-uwe, K and Kutz, Oliver and Colton, Simon and Cambouropoulos, Emilios and Pease, Alison},
file = {:home/memo/Mendeley/data/Schorlemmer et al. - 2011 - COINVENT Towards a Computational Concept Invention Theory.pdf:pdf},
title = {{COINVENT : Towards a Computational Concept Invention Theory}},
year = {2011}
}
@article{Mccormack,
author = {Mccormack, Jon},
file = {:home/memo/Mendeley/data/Mccormack - Unknown - Representation and Mimesis in Generative Art Creating Fifty Sisters.pdf:pdf},
keywords = {1m images of computer-synthesized,Generative Art, Representation, Mimesis, Artificia,abstract,algorithmically,artificial evolution and,artificial life,fifty 1m,fifty sisters is a,from computer code using,generative art,generative artwork commissioned for,grown,mimesis,museum in linz,plant-forms,representation,the ars electronica,the work consists of},
pages = {71--79},
title = {{Representation and Mimesis in Generative Art : Creating Fifty Sisters}}
}
@article{Tenenbaum2001,
abstract = {Shepard has argued that a universal law should govern generalization across different domains of perception and cognition, as well as across organisms from different species or even different planets. Starting with some basic assumptions about natural kinds, he derived an exponential decay function as the form of the universal generalization gradient, which accords strikingly well with a wide range of empirical data. However, his original formulation applied only to the ideal case of generalization from a single encountered stimulus to a single novel stimulus, and for stimuli that can be represented as points in a continuous metric psychological space. Here we recast Shepard's theory in a more general Bayesian framework and show how this naturally extends his approach to the more realistic situation of generalizing from multiple consequential stimuli with arbitrary representational structure. Our framework also subsumes a version of Tversky's set-theoretic model of similarity, which is conventionally thought of as the primary alternative to Shepard's continuous metric space model of similarity and generalization. This unification allows us not only to draw deep parallels between the set-theoretic and spatial approaches, but also to significantly advance the explanatory power of set-theoretic models.},
author = {Tenenbaum, J B and Griffiths, T L},
doi = {10.1017/S0140525X01000061},
file = {:home/memo/Mendeley/data/Tenenbaum, Griffiths - 2001 - Generalization, similarity, and Bayesian inference.pdf:pdf},
isbn = {0140-525X (Print)$\backslash$n0140-525X (Linking)},
issn = {0140-525X},
journal = {The Behavioral and brain sciences},
keywords = {additive clustering,bayesian inference,categorization,concept learning,contrast model,features,generalization,logical space,psycho-,similarity},
number = {4},
pages = {629--640; discussion 652--791},
pmid = {12048947},
title = {{Generalization, similarity, and Bayesian inference.}},
volume = {24},
year = {2001}
}
@article{Griffiths2007a,
abstract = {Processing language requires the retrieval of concepts from memory in response to an ongoing stream of information. This retrieval is facilitated if one can infer the gist of a sentence, conversation, or document and use that gist to predict related concepts and disambiguate words. This article analyzes the abstract computational problem underlying the extraction and use of gist, formulating this problem as a rational statistical inference. This leads to a novel approach to semantic representation in which word meanings are represented in terms of a set of probabilistic topics. The topic model performs well in predicting word association and the effects of semantic association and ambiguity on a variety of language-processing and memory tasks. It also provides a foundation for developing more richly structured statistical models of language, as the generative process assumed in the topic model can easily be extended to incorporate other kinds of semantic and syntactic structure.},
author = {Griffiths, Thomas L and Steyvers, Mark and Tenenbaum, Joshua B},
doi = {10.1037/0033-295X.114.2.211},
file = {:home/memo/Mendeley/data/Griffiths, Steyvers, Tenenbaum - 2007 - Topics in semantic representation.pdf:pdf},
isbn = {0033-295X (Print)$\backslash$r0033-295X (Linking)},
issn = {0033-295X},
journal = {Psychological review},
keywords = {bayesian models,compu-,probabilistic models,semantic memory,semantic representation},
number = {2},
pages = {211--244},
pmid = {17500626},
title = {{Topics in semantic representation.}},
volume = {114},
year = {2007}
}
@article{Pease2013,
abstract = {We investigate serendipity, or happy, accidental discover- ies, in CC, and propose computational concepts related to serendipity. These include a focus-shift, a breakdown of serendipitous discovery into prepared mind, serendipity trig- ger, bridge and result and three dimensions of serendipity: chance, sagacity and value. We propose a definition and stan- dards for computational serendipity and evaluate three cre- ative systems with respect to our standards. We argue that this is an important notion in creativity and, if carefully de- veloped and used with caution, could result in a valuable new discovery technique in CC.},
author = {Pease, Alison and Colton, Simon and Ramezani, Ramin and Charnley, John and Reed, Kate},
file = {:home/memo/Mendeley/data/Pease et al. - 2013 - A Discussion on Serendipity in Creative Systems.pdf:pdf},
isbn = {9781742103174},
journal = {Proceedings of the 4th International Conference on Computational Creativity},
pages = {64--71},
title = {{A Discussion on Serendipity in Creative Systems}},
url = {http://www.computationalcreativity.net/iccc2013/},
volume = {1000},
year = {2013}
}
@incollection{Tenenbaum,
author = {Tenenbaum, Joshua B and Kemp, Charles and Shafto, Patrick},
booktitle = {Inductive reasoning: Experimental, developmental and computational approaches},
file = {:home/memo/Mendeley/data/Tenenbaum, Kemp, Shafto - 2007 - Theory-based Bayesian models of inductive reasoning.pdf:pdf},
isbn = {9780521672443},
number = {1985},
pages = {167--204},
title = {{Theory-based Bayesian models of inductive reasoning}},
year = {2007}
}
@article{Cohen1973,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1973 - Parallel to perception some notes on the problem of machine-generated art.pdf:pdf},
journal = {Computer Studies},
pages = {1--10},
title = {{Parallel to perception: some notes on the problem of machine-generated art}},
url = {http://haroldcohen.com/aaron/publications/paralleltoperception.pdf},
year = {1973}
}
@article{Mccormack2014,
author = {Mccormack, Jon},
file = {:home/memo/Mendeley/data/Mccormack - 2014 - Balancing Act Variation and Utility in Evolutionary Art.pdf:pdf},
keywords = {aesthetics,artificial life,evolutionary art,genotype-},
pages = {26--37},
title = {{Balancing Act : Variation and Utility in Evolutionary Art}},
year = {2014}
}
@article{Mccormack2013,
author = {Mccormack, Jon},
file = {:home/memo/Mendeley/data/Mccormack - 2013 - Aesthetics , Art , Evolution.pdf:pdf},
keywords = {aesthetics,art theory,evolutionary art},
pages = {1--12},
title = {{Aesthetics , Art , Evolution}},
year = {2013}
}
@article{Cohen2010,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 2010 - Driving the Creative Machine.pdf:pdf},
journal = {Crossroads Lecture Series},
number = {September},
pages = {1--17},
title = {{Driving the Creative Machine}},
year = {2010}
}
@article{Pease2011,
abstract = {Computational Creativity is the AI subfield in which we study how to build computational models of creative thought in science and the arts. From an engineering perspective, it is desirable to have concrete measures for assessing the progress made from one version of a program to another, or for comparing and contrasting different software systems for the same creative task. We describe the Turing Test and versions of it which have been used in order to measure progress in Computational Creativity. We show that the versions proposed thus far lack the important aspect of interaction, without which much of the power of the Turing Test is lost. We argue that the Turing Test is largely inappropriate for the purposes of evaluation in Computational Creativity, since it attempts to homogenise creativity into a single (human) style, does not take into account the importance of background and contextual information for a creative act, encourages superficial, uninteresting advances in front-ends, and rewards creativity which adheres to a certain style over that which creates something which is genuinely novel. We further argue that although there may be some place for Turing-style tests for Computational Creativity at some point in the future, it is currently untenable to apply any defensible version of the Turing Test. As an alternative to Turing-style tests, we introduce two descriptive models for evaluating creative software, the FACE model which describes creative acts performed by software in terms of tuples of generative acts, and the IDEA model which describes how such creative acts can have an impact upon an ideal audience, given ideal information about background knowledge and the software development process. While these models require further study and elaboration, we believe that they can be usefully applied to current systems as well as guiding further development of creative systems.},
author = {Pease, a and Colton, S},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pease, Colton - 2011 - On impact and evaluation in computational creativity A discussion of the Turing test and an alternative proposal.pdf:pdf},
isbn = {9781908187031 (ISBN)},
journal = {AISB 2011: Computing and Philosophy},
pages = {15--22},
title = {{On impact and evaluation in computational creativity: A discussion of the Turing test and an alternative proposal}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863921254{\&}partnerID=40{\&}md5=d66940191c1907755d67b48d3c6267ae},
year = {2011}
}
@article{Baker2009,
author = {Baker, Chris L and Saxe, Rebecca R and Tenenbaum, Joshua B},
file = {:home/memo/Mendeley/data/Baker, Saxe, Tenenbaum - 2009 - Bayesian Theory of Mind Modeling Joint Belief-Desire Attribution.pdf:pdf},
journal = {Proceedings of the thirty-second annual conference of the cognitive science society},
keywords = {action un-,bayesian inference,derstanding,partially observable markov,social cognition,theory of mind},
number = {2006},
pages = {2469--2474},
title = {{Bayesian Theory of Mind : Modeling Joint Belief-Desire Attribution}},
volume = {1},
year = {2009}
}
@article{Cohen1974,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1974 - On purpose an enquiry into the possible roles of the computer in art.pdf:pdf},
journal = {Studio International},
title = {{On purpose: an enquiry into the possible roles of the computer in art}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:ON+PURPOSE+AN+ENQUIRY+INTO+THE+POSSIBLE+ROLES+OF+THE+COMPUTER+IN+ART{\#}0},
year = {1974}
}
@article{Baker2005,
author = {Baker, Chris and Saxe, Rebecca and Tenenbaum, Joshua B.},
file = {:home/memo/Mendeley/data/Baker, Saxe, Tenenbaum - 2005 - Bayesian models of human action understanding.pdf:pdf},
pages = {99--106},
title = {{Bayesian models of human action understanding}},
year = {2005}
}
@article{Bown2009,
abstract = {Throughout the short history of interactive digital music, there have been frequent calls for a new language of interaction that incorporates and acknowledges the unique capabilities of the computational medium. In this paper we suggest that a conceptualisation of possible modes of performance–time interaction can only be sensibly approached in light of the ways that computers alter the social–artistic interactions that are precursive to performance. This conceptualisation hinges upon a consideration of the changing roles of composition, performer and instrument in contemporary practice. We introduce the term behavioural object to refer to software that has the capacity to act as the musical and social focus of interaction in digital systems. Whilst formative, this term points to a new framework for understanding the role of software in musical culture. We discuss the potential for behavioural objects to contribute actively to musical culture through two types of agency: performative agency and memetic agency.},
author = {Bown, Oliver and Eldridge, Alice and McCormack, Jon},
doi = {10.1017/S1355771809000296},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bown, Eldridge, McCormack - 2009 - Understanding Interaction in Contemporary Digital Music from instruments to behavioural objects.pdf:pdf},
isbn = {1355771809000},
issn = {1355-7718},
journal = {Organised Sound},
number = {02},
pages = {188},
title = {{Understanding Interaction in Contemporary Digital Music: from instruments to behavioural objects}},
volume = {14},
year = {2009}
}
@article{Kowaliw2009,
author = {Kowaliw, Taras and Dorin, Alan and Mccormack, Jon},
file = {:home/memo/Mendeley/data/Kowaliw, Dorin, Mccormack - 2009 - An Empirical Exploration of a Definition of Creative Novelty for Generative Art.pdf:pdf},
pages = {1--10},
title = {{An Empirical Exploration of a Definition of Creative Novelty for Generative Art}},
year = {2009}
}
@article{Llano2014,
author = {Llano, Mt and Hepworth, Rose and Colton, Simon and Charnley, John and Gow, Jeremy},
file = {:home/memo/Mendeley/data/Llano et al. - 2014 - Automating Fictional Ideation using ConceptNet.pdf:pdf},
journal = {Proceedings of the 50th Anniversary Convention of the AISB},
title = {{Automating Fictional Ideation using ConceptNet}},
url = {http://ccg.doc.gold.ac.uk/papers/llano{\_}aisb14.pdf},
year = {2014}
}
@article{Cohen1976,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1976 - The material of symbols.pdf:pdf},
number = {August},
title = {{The material of symbols}},
year = {1976}
}
@article{Liu2005,
abstract = {We present motion magnification, a technique that acts like a microscope for visual motion. It can amplify subtle motions in a video sequence, allowing for visualization of deformations that would otherwise be invisible. To achieve motion magnification, we need to accurately measure visual motions, and group the pixels to be modified. After an initial image registration step, we measure motion by a robust analysis of feature point trajectories, and segment pixels based on similarity of position, color, and motion. A novel measure of motion similarity groups even very small motions according to correlation over time, which often relates to physical cause. An outlier mask marks observations not explained by our layered motion model, and those pixels are simply reproduced on the output from the original registered observations.The motion of any selected layer may be magnified by a user-specified amount; texture synthesis fills-in unseen "holes" revealed by the amplified motions. The resulting motion-magnified images can reveal or emphasize small motions in the original sequence, as we demonstrate with deformations in load-bearing structures, subtle motions or balancing corrections of people, and "rigid" structures bending under hand pressure.},
author = {Liu, Ce and Torralba, Antonio and Freeman, William T. and Durand, Fr{\'{e}}do and Adelson, Edward H.},
doi = {10.1145/1073204.1073223},
file = {:home/memo/Mendeley/data/Liu et al. - 2005 - Motion magnification.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {cessing,computer vision,motion processing,video pro-,video-based rendering},
number = {3},
pages = {519},
title = {{Motion magnification}},
volume = {24},
year = {2005}
}
@article{Llano2014a,
author = {Llano, Maria Teresa and Hepworth, Rose and Colton, Simon and Gow, Jeremy and Charnley, John and Granroth-wilding, Mark and Clark, Stephen},
file = {:home/memo/Mendeley/data/Llano et al. - 2014 - Baseline Methods for Automated Fictional Ideation.pdf:pdf},
journal = {Proceedings of the 5th International Conference on Computational Creativity},
title = {{Baseline Methods for Automated Fictional Ideation}},
year = {2014}
}
@article{Cohen1999,
author = {Cohen, H},
doi = {http://doi.acm.org/10.1145/317561.317564},
file = {:home/memo/Mendeley/data/Cohen - 1999 - A self-defining game for one player.pdf:pdf},
journal = {Creativity {\&} Cognition},
pages = {1--12},
title = {{A self-defining game for one player.}},
url = {http://aaronshome.com/aaron/publications/lboro.pdf},
year = {1999}
}
@article{McCormack2009,
abstract = {This paper advances new methods for ecosystemic approaches to evolutionary music and art. We explore the biological concept of the niche and its role in evolutionary dynamics, applying it to creative computational systems. Using the process of niche construction organisms are able to change and adapt their environment, and potentially that of other species. Constructed niches may become heritable environments for offspring, paralleling the way genes are passed from parent to child. In a creative ecosystem, niche construction can be used by agents to increase the diversity and heterogeneity of their output. We illustrate the usefulness of this technique by applying niche construction to line drawing and music composition.},
author = {McCormack, Jon and Bown, Oliver},
doi = {10.1007/978-3-642-01129-0_59},
file = {:home/memo/Mendeley/data/McCormack, Bown - 2009 - Life's what you make Niche construction and evolutionary art.pdf:pdf},
isbn = {3642011284},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {528--537},
title = {{Life's what you make: Niche construction and evolutionary art}},
volume = {5484 LNCS},
year = {2009}
}
@article{Cohen1988,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1988 - How To Draw Three People in a Botanical Garden.pdf:pdf},
journal = {Aaai},
title = {{How To Draw Three People in a Botanical Garden}},
url = {http://www.aaai.org/Papers/AAAI/1988/AAAI88-150.pdf},
year = {1988}
}
@article{Sundararajan2014,
author = {Sundararajan, Louise},
doi = {10.1002/jocb.44},
file = {:home/memo/Mendeley/data/Sundararajan - 2014 - Mind, Machine, and Creativity An Artist's Perspective.pdf:pdf},
issn = {00220175},
journal = {The Journal of Creative Behavior},
keywords = {about creativity in art,anthropomorphism,charles sanders peirce,cyborg,harold cohen,machine creativity,me to think more,no one has caused,than harold,the extended mind hypothesis},
number = {2},
pages = {136--151},
pmid = {25541564},
title = {{Mind, Machine, and Creativity: An Artist's Perspective}},
url = {http://doi.wiley.com/10.1002/jocb.44},
volume = {48},
year = {2014}
}
@article{Kowaliw2010,
abstract = {In this paper, we introduce a new image database, consisting of examples of artists' work. Successful classification of this database suggests the capacity to automatically recognize an artist's aesthetic style. We utilize the notion of Transform-based Evolvable Features as a means of evolving features on the space, these features are then evaluated through a standard classifier. We obtain recognition rates for our six artistic styles - relative to images by the other artists and images randomly downloaded from a search engine - of a mean true positive rate of 0.946 and a mean false positive rate of 0.017. Distance metrics designed to indicate the similarity between an arbitrary greyscale image and one of the artistic styles are created from the evolved features. These metrics are capable of ranking control images so that artist-drawn instances appear at the front of the list. We provide evidence that other images ranked as similar by the metric correspond to nai{\&}{\#}x0308;ve human notions of similarity as well, suggesting the distance metric could serve as a content-based aesthetic recommender.},
author = {Kowaliw, Taras and McCormack, Jon and Dorin, Alan},
doi = {10.1109/CEC.2010.5585975},
file = {:home/memo/Mendeley/data/Kowaliw, McCormack, Dorin - 2010 - Evolutionary automated recognition and characterization of an individual's artistic style.pdf:pdf},
isbn = {9781424469109},
journal = {2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010},
title = {{Evolutionary automated recognition and characterization of an individual's artistic style}},
year = {2010}
}
@article{Kemp,
author = {Kemp, Charles and Griffiths, Tom},
file = {:home/memo/Mendeley/data/Kemp, Griffiths - Unknown - Probabilistic models of cognition Exploring representations and inductive biases.pdf:pdf},
number = {510},
title = {{Probabilistic models of cognition: Exploring representations and inductive biases}}
}
@article{Kemp2010,
abstract = {Concept learning is challenging in part because the meanings of many concepts depend on their relationships to other concepts. Learning these concepts in isolation can be difficult, but we present a model that discovers entire systems of related concepts. These systems can be viewed as simple theories that specify the concepts that exist in a domain, and the laws or principles that relate these concepts. We apply our model to several real-world problems, including learning the structure of kinship systems and learning ontologies. We also compare its predictions to data collected in two behavioral experiments. Experiment 1 shows that our model helps to explain how simple theories are acquired and used for inductive inference. Experiment 2 suggests that our model provides a better account of theory discovery than a more traditional alternative that focuses on features rather than relations. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Kemp, Charles and Tenenbaum, Joshua B. and Niyogi, Sourabh and Griffiths, Thomas L.},
doi = {10.1016/j.cognition.2009.09.003},
file = {:home/memo/Mendeley/data/Kemp et al. - 2010 - A probabilistic model of theory formation.pdf:pdf},
isbn = {0010-0277 (Print)},
issn = {00100277},
journal = {Cognition},
keywords = {Bayesian modeling,Conceptual structure,Relational learning,Systems of concepts},
number = {2},
pages = {165--196},
pmid = {19892328},
publisher = {Elsevier B.V.},
title = {{A probabilistic model of theory formation}},
url = {http://dx.doi.org/10.1016/j.cognition.2009.09.003},
volume = {114},
year = {2010}
}
@article{McCormack2007a,
author = {McCormack, Jon},
doi = {10.1007/978-3-540-72877-1_19},
file = {:home/memo/Mendeley/data/McCormack - 2007 - Facing the Future Evolutionary Possibilities for Human-Machine Creativity.pdf:pdf},
journal = {The Art of Artificial Evolution: A Handbook on Evolutionary Art and Music},
pages = {417--451},
title = {{Facing the Future: Evolutionary Possibilities for Human-Machine Creativity}},
year = {2007}
}
@article{Cohen1994,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1994 - The Further Exploits of Aaron, Painter.pdf:pdf},
title = {{The Further Exploits of Aaron, Painter}},
year = {1994}
}
@article{Griffiths2007,
abstract = {People's reactions to coincidences are often cited as an illustration of the irrationality of human reasoning about chance. We argue that coincidences may be better understood in terms of rational statistical inference, based on their functional role in processes of causal discovery and theory revision. We present a formal definition of coincidences in the context of a Bayesian framework for causal induction: a coincidence is an event that provides support for an alternative to a currently favored causal theory, but not necessarily enough support to accept that alternative in light of its low prior probability. We test the qualitative and quantitative predictions of this account through a series of experiments that examine the transition from coincidence to evidence, the correspondence between the strength of coincidences and the statistical support for causal structure, and the relationship between causes and coincidences. Our results indicate that people can accurately assess the strength of coincidences, suggesting that irrational conclusions drawn from coincidences are the consequence of overestimation of the plausibility of novel causal forces. We discuss the implications of our account for understanding the role of coincidences in theory change. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Griffiths, Thomas L. and Tenenbaum, Joshua B.},
doi = {10.1016/j.cognition.2006.03.004},
file = {:home/memo/Mendeley/data/Griffiths, Tenenbaum - 2007 - From mere coincidences to meaningful discoveries.pdf:pdf},
isbn = {0010-0277 (Print)$\backslash$n0010-0277 (Linking)},
issn = {00100277},
journal = {Cognition},
keywords = {Bayesian models,Causal induction,Coincidences,Probabilistic reasoning,Theory change},
number = {2},
pages = {180--226},
pmid = {16678145},
title = {{From mere coincidences to meaningful discoveries}},
volume = {103},
year = {2007}
}
@article{Gopnik2007,
abstract = {... Bayesian networks , Bayesian learning and cognitive development . Alison Gopnik 1 ,; Joshua B. Tenenbaum 2. Article first published online: 17 APR 2007. ... How to Cite. Gopnik, A. and Tenenbaum, JB (2007), Bayesian networks , Bayesian learning and cognitive development . ...},
author = {Gopnik, Alison and Tenenbaum, Joshua B.},
doi = {10.1111/j.1467-7687.2007.00584.x},
file = {:home/memo/Mendeley/data/Gopnik, Tenenbaum - 2007 - Bayesian networks, Bayesian learning and cognitive development.pdf:pdf},
isbn = {1467-7687},
issn = {1363755X},
journal = {Developmental Science},
number = {3},
pages = {281--287},
pmid = {17444969},
title = {{Bayesian networks, Bayesian learning and cognitive development}},
volume = {10},
year = {2007}
}
@article{Gow2012,
abstract = {Computational analysis of player style has significant potential for video game design: it can provide insights into player behavior, as well as the means to dynamically adapt a game to each individual's style of play. To realize this potential, computational methods need to go beyond considerations of challenge and ability and account for aesthetic aspects of player style. We describe here a semiautomatic unsupervised learning approach to modeling player style using multiclass linear discriminant analysis (LDA). We argue that this approach is widely applicable for modeling player style in a wide range of games, including commercial applications, and illustrate it with two case studies: the first for a novel arcade game called Snakeotron, and the second for Rogue Trooper, a modern commercial third-person shooter video game.},
author = {Gow, Jeremy and Baumgarten, Robin and Cairns, Paul and Colton, Simon and Miller, Paul},
doi = {10.1109/TCIAIG.2012.2213600},
file = {:home/memo/Mendeley/data/Gow et al. - 2012 - Unsupervised modeling of player style with LDA.pdf:pdf},
isbn = {1943-068X VO  - 4},
issn = {1943068X},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
keywords = {Adaptive games,k-means clustering,linear discriminant analysis (LDA),log analysis,player style,player types,video games},
number = {3},
pages = {152--166},
title = {{Unsupervised modeling of player style with LDA}},
volume = {4},
year = {2012}
}
@article{Cohen,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - Unknown - Edinburgh Conference , Invited Talk March 99 .pdf:pdf},
pages = {1--17},
title = {{Edinburgh Conference , Invited Talk : March 99 .}}
}
@article{Bown2011,
author = {Bown, Oliver and McCormack, Jon},
doi = {10.1007/978-3-642-21314-4_32},
file = {:home/memo/Mendeley/data/Bown, McCormack - 2011 - Creative agency A clearer goal for artificial life in the arts.pdf:pdf},
isbn = {9783642213137},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 2},
pages = {254--261},
title = {{Creative agency: A clearer goal for artificial life in the arts}},
volume = {5778 LNAI},
year = {2011}
}
@article{Cook2014a,
author = {Cook, Michael and Colton, Simon},
file = {:home/memo/Mendeley/data/Cook, Colton - 2014 - Ludus Ex Machina Building A 3D Game Designer That Competes Alongside Humans.pdf:pdf},
journal = {Proceedings of the 5th International Conference on Computational Creativity},
title = {{Ludus Ex Machina: Building A 3D Game Designer That Competes Alongside Humans}},
year = {2014}
}
@article{Colton,
author = {Colton, Simon and Cook, Michael and Hepworth, Rose and Pease, Alison},
file = {:home/memo/Mendeley/data/Colton et al. - Unknown - On Acid Drops and Teardrops Observer Issues in Computational Creativity.pdf:pdf},
title = {{On Acid Drops and Teardrops : Observer Issues in Computational Creativity}}
}
@article{Colton2010,
abstract = {We have implemented a non-photorealistic rendering system which simulates$\backslash$nthe placement of paint/pencil/pastel strokes to produce representational$\backslash$nartworks from digital images. The system is able to record an image$\backslash$nof each paint stroke independent of the overall picture, in addition$\backslash$nto some details about each stroke. Working with sets of paint strokes$\backslash$nfrom paintings of different images, we investigate how to determine$\backslash$nwhich stroke from one picture most closely resembles a given stroke$\backslash$nfrom another picture. This enables the paint strokes from one picture$\backslash$nto be used to paint a different painting. This further enables the$\backslash$nanimation of one picture morphing into another, as the paint strokes$\backslash$nmove and rotate into new positions and orientations. Using a K-means$\backslash$nclustering approach, we can extract a set of representative strokes$\backslash$nfrom a series of paintings/drawings, and animate the same set of$\backslash$nstrokes moving around a picture in order to represent different scenes$\backslash$nat different times. We call such animations �paint dances�.We apply$\backslash$nthis technique to sets of portraits and we present the resulting$\backslash$npaint dances in an artistic context as video art. We describe here$\backslash$nthe various methods we experimented with in order to determine an$\backslash$noptimal stroke matching and extraction approach.},
author = {Colton, Simon},
doi = {http://dx.doi.org/10.2312/COMPAESTH/COMPAESTH10/067-074},
file = {:home/memo/Mendeley/data/Colton - 2010 - Stroke Matching for Paint Dances.pdf:pdf},
journal = {Computational Aesthetics 2010: Eurographics Workshop on Computational Aesthetics in Graphics, Visualization and Imaging (Victoria, British Columbia, Canada, May 28--30, 2009)},
pages = {67--74},
title = {{Stroke Matching for Paint Dances}},
year = {2010}
}
@article{Coltond,
author = {Colton, Simon and Ramezani, Ramin and Llano, Maria Teresa},
file = {:home/memo/Mendeley/data/Colton, Ramezani, Llano - Unknown - The HR3 Discovery System Design Decisions and Implementation Details.pdf:pdf},
title = {{The HR3 Discovery System : Design Decisions and Implementation Details}}
}
@article{Charnley2012,
author = {Charnley, John and Pease, Alison and Colton, Simon},
file = {:home/memo/Mendeley/data/Charnley, Pease, Colton - 2012 - On the notion of framing in computational creativity.pdf:pdf},
journal = {{\ldots} on Computational {\ldots}},
pages = {77--81},
title = {{On the notion of framing in computational creativity}},
url = {http://computationalcreativity.net/iccc2012/wp-content/uploads/2012/05/077-Charnley.pdf},
year = {2012}
}
@article{Colton2012,
abstract = {Notions relating to computational systems exhibiting creative behaviours have been explored since the very early days of computer science, and the field of Computational Creativity research has formed in the last dozen years to scientifically explore the potential of such systems. We describe this field via a working definition; a brief history of seminal work; an exploration of the main issues, technologies and ideas; and a look towards future directions. As a society, we are jealous of our creativity: creative people and their contributions to cultural progression are highly valued. Moreover, creative behaviour in people draws on a full set of intelligent abilities, so simulating such behaviour represents a serious technical challenge for Artificial Intelligence research. As such, we believe it is fair to characterise Computational Creativity as a frontier for AI research beyond all others—maybe, even, the final frontier.},
author = {Colton, Simon and Wiggins, Geraint a.},
doi = {10.3233/978-1-61499-098-7-21},
file = {:home/memo/Mendeley/data/Colton, Wiggins - 2012 - Computational creativity The final frontier.pdf:pdf},
isbn = {9781614990970},
issn = {09226389},
journal = {Frontiers in Artificial Intelligence and Applications},
pages = {21--26},
title = {{Computational creativity: The final frontier?}},
volume = {242},
year = {2012}
}
@article{Colton2012a,
author = {Colton, Simon},
doi = {10.1007/978-3-642-29142-5_4},
file = {:home/memo/Mendeley/data/Colton - 2012 - Evolving a library of artistic scene descriptors.pdf:pdf},
isbn = {9783642291418},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {35--47},
title = {{Evolving a library of artistic scene descriptors}},
volume = {7247 LNCS},
year = {2012}
}
@article{Charnley2014,
author = {Charnley, John and Colton, Simon and Llano, Mt},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Charnley, Colton, Llano - 2014 - The FloWr framework Automated flowchart construction, optimisation and alteration for creative systems.pdf:pdf},
journal = {Proceedings of the 5th International Conference on Computational Creativity},
title = {{The FloWr framework: Automated flowchart construction, optimisation and alteration for creative systems}},
url = {http://ccg.doc.gold.ac.uk/papers/charnley{\_}iccc2014.pdf},
year = {2014}
}
@article{Cook2014,
author = {Cook, Michael and Colton, Simon and Gow, Jeremy},
file = {:home/memo/Mendeley/data/Cook, Colton, Gow - 2014 - Automating Game Design In Three Dimensions.pdf:pdf},
journal = {AISB Symposium on AI and Games},
pages = {3--6},
title = {{Automating Game Design In Three Dimensions}},
year = {2014}
}
@article{Cohen1990,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1990 - Brother Giorgio's Kangaroo.pdf:pdf},
title = {{Brother Giorgio's Kangaroo}},
url = {http://www.kurzweilcyberart.com/aaron/pdf/brothergkanga.pdf},
year = {1990}
}
@article{Krzeczkowska2010,
author = {Cook, Michael and Colton, Simon},
file = {:home/memo/Mendeley/data/Cook, Colton - 2010 - Automated Collage Generation -- With Intent.pdf:pdf},
isbn = {9786074774870},
journal = {Proceedings of the International Conference on Computational Creativity},
keywords = {*file-import-13-08-05,*file-import-13-08-13,computational,creativity,iccc2010},
pages = {36--40},
title = {{Automated Collage Generation -- With Intent}},
url = {http://eden.dei.uc.pt/{~}amilcar/ftp/e-Proceedings{\_}ICCC-X.pdf},
year = {2010}
}
@article{Cohen1999a,
author = {Cohen, Harold},
file = {:home/memo/Mendeley/data/Cohen - 1999 - Colouring without seeing a problem in machine creativity.pdf:pdf},
journal = {AISB Quarterly},
number = {fig 2},
title = {{Colouring without seeing: a problem in machine creativity}},
url = {http://haroldcohen.com/aaron/publications/colouringwithoutseeing.pdf},
year = {1999}
}
@article{Coltong,
author = {Colton, Simon and Pease, Alison and Corneli, Joseph and Cook, Michael and Llano, Teresa},
file = {:home/memo/Mendeley/data/Colton et al. - Unknown - Assessing Progress in Building Autonomously Creative Systems.pdf:pdf},
title = {{Assessing Progress in Building Autonomously Creative Systems}}
}
@article{Perfors2011,
abstract = {We present an introduction to Bayesian inference as it is used in probabilistic models of cognitive development. Our goal is to provide an intuitive and accessible guide to the what, the how, and the why of the Bayesian approach: what sorts of problems and data the framework is most relevant for, and how and why it may be useful for developmentalists. We emphasize a qualitative understanding of Bayesian inference, but also include information about additional resources for those interested in the cognitive science applications, mathematical foundations, or machine learning details in more depth. In addition, we discuss some important interpretation issues that often arise when evaluating Bayesian models in cognitive science.},
author = {Perfors, a and Tenenbaum, J B and Griffiths, T L},
file = {:home/memo/Mendeley/data/Perfors, Tenenbaum, Griffiths - 2011 - A tutorial introduction to Bayesian models of cognitive development.pdf:pdf},
journal = {Cognition},
title = {{A tutorial introduction to Bayesian models of cognitive development}},
url = {papers2://publication/uuid/D5260FC9-8E83-46E1-8896-93306EDAAF50},
year = {2011}
}
@article{Goodman2008a,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.3255v2},
author = {Goodman, Noah D and Goodman, Noah D and Mansinghka, Vikash K and Mansinghka, Vikash K and Roy, Daniel M and Roy, Daniel M and Bonawitz, Keith and Bonawitz, Keith and Tenenbaum, Joshua B and Tenenbaum, Joshua B},
eprint = {arXiv:1206.3255v2},
file = {:home/memo/Mendeley/data/Goodman et al. - 2008 - Church a language for generative models.pdf:pdf},
journal = {Language},
pages = {220--229},
title = {{Church: a language for generative models}},
year = {2008}
}
@article{Tenenbaum1999,
author = {Tenenbaum, Joshua B and Richards, Whitman a and Schneider, Gerald E},
file = {:home/memo/Mendeley/data/Tenenbaum, Richards, Schneider - 1999 - A Bayesian Framework for Concept Learning by.pdf:pdf},
title = {{A Bayesian Framework for Concept Learning by}},
year = {1999}
}
@article{Griffiths2008,
author = {Griffiths, Thomas L and Kemp, Charles and Tenenbaum, Joshua B},
file = {:home/memo/Mendeley/data/Griffiths, Kemp, Tenenbaum - 2008 - Bayesian models of cognition.pdf:pdf},
title = {{Bayesian models of cognition}},
year = {2008}
}
@article{Goodman2011,
abstract = {The very early appearance of abstract knowledge is often taken as evidence for innateness. We explore the relative learning speeds of abstract and specific knowledge within a Bayesian framework and the role for innate structure. We focus on knowledge about causality, seen as a domain-general intuitive theory, and ask whether this knowledge can be learned from co-occurrence of events. We begin by phrasing the causal Bayes nets theory of causality and a range of alternatives in a logical language for relational theories. This allows us to explore simultaneous inductive learning of an abstract theory of causality and a causal model for each of several causal systems. We find that the correct theory of causality can be learned relatively quickly, often becoming available before specific causal theories have been learned--an effect we term the blessing of abstraction. We then explore the effect of providing a variety of auxiliary evidence and find that a collection of simple perceptual input analyzers can help to bootstrap abstract knowledge. Together, these results suggest that the most efficient route to causal knowledge may be to build in not an abstract notion of causality but a powerful inductive learning mechanism and a variety of perceptual supports. While these results are purely computational, they have implications for cognitive development, which we explore in the conclusion.},
author = {Goodman, Noah D and Ullman, Tomer D and Tenenbaum, Joshua B},
doi = {10.1037/a0021336},
file = {:home/memo/Mendeley/data/Goodman, Ullman, Tenenbaum - 2011 - Learning a theory of causality.pdf:pdf},
isbn = {0033-295X},
issn = {0033-295X},
journal = {Psychological review},
number = {1},
pages = {110--119},
pmid = {21244189},
title = {{Learning a theory of causality.}},
volume = {118},
year = {2011}
}
@article{Baumgarten2009,
author = {Baumgarten, Robin and Colton, Simon and Morris, Mark},
doi = {10.1155/2009/129075},
file = {:home/memo/Mendeley/data/Baumgarten, Colton, Morris - 2009 - Combining AI methods for learning bots in a real-time strategy game.pdf:pdf},
issn = {16877047},
journal = {International Journal of Computer Games Technology},
number = {1},
title = {{Combining AI methods for learning bots in a real-time strategy game}},
volume = {2009},
year = {2009}
}
@article{Dorin2012,
abstract = {In this article we argue that a framework for the description, analysis and comparison of generative artworks is needed. Existing ideas from kinetic art and other domains in which process description is prominent are shown to be inadequate. Therefore, we propose a new framework that meets this need and facilitates the long-term aim of constructing a comprehensive taxonomy of generative art. Our framework is divided into four major components: a description of a work's entities; its processes and their environmental interactions; and the outcomes experienced by the work's audience. We describe a set of diverse generative artworks in terms of our framework, demonstrating how it can be applied in practice to compare and contrast them.$\backslash$n$\backslash$n},
author = {Dorin, Alan and McCabe, Jonathan and McCormack, Jon and Monro, Gordon and Whitelaw, Mitchell},
doi = {10.1080/14626268.2012.709940},
file = {:home/memo/Mendeley/data/Dorin et al. - 2012 - A framework for understanding generative art.pdf:pdf},
isbn = {Digital Creativity, Vol. 23, No. 3-4, September–December 2012, pp. 239–259},
issn = {1462-6268},
journal = {Digital Creativity},
number = {June 2015},
pages = {239--259},
title = {{A framework for understanding generative art}},
url = {http://www.tandfonline.com/doi/abs/10.1080/14626268.2012.709940},
volume = {23},
year = {2012}
}
@article{Sutskever2009,
author = {Sutskever, Ilya and Salakhutdinov, R and Tenenbaum, Jb},
file = {:home/memo/Mendeley/data/Sutskever, Salakhutdinov, Tenenbaum - 2009 - Modelling Relational Data using Bayesian Clustered Tensor Factorization.pdf:pdf},
journal = {Nips},
pages = {1--8},
title = {{Modelling Relational Data using Bayesian Clustered Tensor Factorization.}},
url = {https://papers.nips.cc/paper/3863-modelling-relational-data-using-bayesian-clustered-tensor-factorization.pdf},
year = {2009}
}
@article{Bown2010,
author = {Bown, Oliver and McCormack, Jon},
doi = {10.1080/14626268.2011.550029},
file = {:home/memo/Mendeley/data/Bown, McCormack - 2010 - Taming nature tapping the creative potential of ecosystem models in the arts.pdf:pdf},
issn = {1462-6268},
journal = {Digital Creativity},
number = {4},
pages = {215--231},
title = {{Taming nature: tapping the creative potential of ecosystem models in the arts}},
volume = {21},
year = {2010}
}
@article{Griffiths2005,
abstract = {We present a framework for the rational analysis of elemental causal induction-learning about the existence of a relationship between a single cause and effect-based upon causal graphical models. This framework makes precise the distinction between causal structure and causal strength: The difference between asking whether a causal relationship exists and asking how strong that causal relationship might be. We show that two leading rational models of elemental causal induction, ??P and causal power, both estimate causal strength, and we introduce a new rational model, causal support, that assesses causal structure. Causal support predicts several key phenomena of causal induction that cannot be accounted for by other rational models, which we explore through a series of experiments. These phenomena include the complex interaction between ??P and the base-rate probability of the effect in the absence of the cause, sample size effects, inferences from incomplete contingency tables, and causal learning from rates. Causal support also provides a better account of a number of existing datasets than either ??P or causal power. ?? 2005 Elsevier Inc. All rights reserved.},
author = {Griffiths, Thomas L. and Tenenbaum, Joshua B.},
doi = {10.1016/j.cogpsych.2005.05.004},
file = {:home/memo/Mendeley/data/Griffiths, Tenenbaum - 2005 - Structure and strength in causal induction.pdf:pdf},
isbn = {0010-0285 U6 - ctx{\_}ver=Z39.88-2004{\&}ctx{\_}enc=info{\%}3Aofi{\%}2Fenc{\%}3AUTF-8{\&}rfr{\_}id=info:sid/summon.serialssolutions.com{\&}rft{\_}val{\_}fmt=info:ofi/fmt:kev:mtx:journal{\&}rft.genre=article{\&}rft.atitle=Structure+and+strength+in+causal+induction{\&}rft.jtitle=Cognitive+psycholog},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {Bayesian models,Causal induction,Causality,Computational modeling,Rational analysis},
number = {4},
pages = {334--384},
pmid = {16168981},
title = {{Structure and strength in causal induction}},
volume = {51},
year = {2005}
}
@article{Tenenbaum2011,
abstract = {In coming to understand the world-in learning concepts, acquiring language, and grasping causal relations-our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
author = {Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and Goodman, Noah D},
doi = {10.1126/science.1192788},
file = {:home/memo/Mendeley/data/Tenenbaum et al. - 2011 - How to grow a mind statistics, structure, and abstraction.pdf:pdf},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
number = {6022},
pages = {1279--1285},
pmid = {21393536},
title = {{How to grow a mind: statistics, structure, and abstraction.}},
volume = {331},
year = {2011}
}
@article{Battaglia2013,
abstract = {In a glance, we can perceive whether a stack of dishes will topple, a branch will support a child's weight, a grocery bag is poorly packed and liable to tear or crush its contents, or a tool is firmly attached to a table or free to be lifted. Such rapid physical inferences are central to how people interact with the world and with each other, yet their computational underpinnings are poorly understood. We propose a model based on an "intuitive physics engine," a cognitive mechanism similar to computer engines that simulate rich physics in video games and graphics, but that uses approximate, probabilistic simulations to make robust and fast inferences in complex natural scenes where crucial information is unobserved. This single model fits data from five distinct psychophysical tasks, captures several illusions and biases, and explains core aspects of human mental models and common-sense reasoning that are instrumental to how humans understand their everyday world.},
author = {Battaglia, Peter W and Hamrick, Jessica B and Tenenbaum, Joshua B},
doi = {10.1073/pnas.1306572110},
file = {:home/memo/Mendeley/data/Battaglia, Hamrick, Tenenbaum - 2013 - Simulation as an engine of physical scene understanding.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Bayes Theorem,Cognition,Cognition: physiology,Humans,Imagination,Imagination: physiology,Judgment,Judgment: physiology,Models, Psychological},
number = {45},
pages = {18327--32},
pmid = {24145417},
title = {{Simulation as an engine of physical scene understanding.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3831455{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110},
year = {2013}
}
@article{McCormack2014,
author = {McCormack, J and D'Inverno, M},
file = {:home/memo/Mendeley/data/McCormack, D'Inverno - 2014 - On the Future of Computers and Creativity.pdf:pdf},
title = {{On the Future of Computers and Creativity}},
url = {http://doc.gold.ac.uk/aisb50/AISB50-S04/AISB50-S4-McCormack-paper.pdf},
year = {2014}
}
@article{Vondrick2013,
abstract = {We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on ‘HOG goggles' and perceive the visual world as a HOG based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector's fail- ures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively sim- ilar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05461v1},
author = {Vondrick, Carl and Khosla, Aditya and Malisiewicz, Tomasz and Torralba, Antonio},
doi = {10.1109/ICCV.2013.8},
eprint = {arXiv:1502.05461v1},
file = {:home/memo/Mendeley/data/Vondrick et al. - 2013 - HOGgles Visualizing object detection features.pdf:pdf},
isbn = {9781479928392},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {hog,hoggles,object detection,visualization},
pages = {1--8},
title = {{HOGgles: Visualizing object detection features}},
year = {2013}
}
@article{Tilke2009,
abstract = {For many applications in graphics, design, and human computer interaction, it is essential to understand where humans look in a scene. Where eye tracking devices are not a viable option, models of saliency can be used to predict fixation locations. Most saliency approaches are based on bottom-up computation that does not consider top-down image semantics and often does not match actual eye movements. To address this problem, we collected eye tracking data of 15 viewers on 1003 images and use this database as training and testing examples to learn a model of saliency based on low, middle and high-level image features. This large database of eye tracking data is publicly available with this paper.},
author = {Tilke, Juddk and Ehinger, Krista and Durand, Fr{\'{e}}do and Torralba, Antonio},
doi = {10.1109/ICCV.2009.5459462},
file = {:home/memo/Mendeley/data/Tilke et al. - 2009 - Learning to predict where humans look.pdf:pdf},
isbn = {9781424444205},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2106--2113},
pmid = {5459462},
title = {{Learning to predict where humans look}},
year = {2009}
}
@article{McCormack2014a,
author = {McCormack, Jon and Bown, Oliver and Dorin, Alan and McCabe, Jonathan and Monro, Gordon and Whitelaw, Mitchell},
doi = {10.1162/LEON_a_00533},
file = {:home/memo/Mendeley/data/McCormack et al. - 2014 - Ten Questions Concerning Generative Computer Art.pdf:pdf},
issn = {0024-094X},
journal = {Leonardo},
number = {2},
pages = {135--141},
title = {{Ten Questions Concerning Generative Computer Art}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/LEON{\_}a{\_}00533},
volume = {47},
year = {2014}
}
@article{Isola2014,
abstract = {When glancing at a magazine, or browsing the Internet, we are continuously exposed to photographs. Despite this overflow of visual information, humans are extremely good at remembering thousands of pictures along with some of their visual details. But not all images are equal in memory. Some stick in our minds while others are quickly forgotten. In this paper we focus on the problem of predicting how memorable an image will be. We show that memorability is an intrinsic and stable property of an image that is shared across different viewers, and remains stable across delays. We introduce a database for which we have measured the probability that each picture will be recognized after a single view. We analyze a collection of image features, labels, and attributes that contribute to making an image memorable, and we train a predictor based on global image descriptors. We find that predicting image memorability is a task that can be addressed with current computer vision techniques. While making memorable images is a challenging task in visualization, photography, and education, this work is a first attempt to quantify this useful property of images.},
author = {Isola, Phillip and Xiao, Jianxiong and Parikh, Devi and Torralba, Antonio and Oliva, Aude},
doi = {10.1109/TPAMI.2013.200},
file = {:home/memo/Mendeley/data/Isola et al. - 2014 - What makes a photograph memorable.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Scene Analysis,Vision and Scene Understanding},
number = {7},
pages = {1469--1482},
pmid = {24127520},
title = {{What makes a photograph memorable?}},
volume = {36},
year = {2014}
}
@article{Bruneton2008,
author = {Bruneton, Eric and Neyret, Fabrice and Bruneton, Eric and Neyret, Fabrice and Atmospheric, Precomputed and Computer, Scattering},
file = {:home/memo/Mendeley/data/Bruneton et al. - 2008 - Precomputed Atmospheric Scattering To cite this version Precomputed Atmospheric Scattering.pdf:pdf},
title = {{Precomputed Atmospheric Scattering To cite this version : Precomputed Atmospheric Scattering}},
year = {2008}
}
@article{Xiao2014,
author = {Xiao, Jianxiong and Ehinger, Krista a. and Hays, James and Torralba, Antonio and Oliva, Aude},
doi = {10.1007/s11263-014-0748-y},
file = {:home/memo/Mendeley/data/Xiao et al. - 2014 - SUN Database Exploring a Large Collection of Scene Categories.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {descriptor,scene,scene and object,scene detection,scene recognition,scene typicality,visual},
title = {{SUN Database: Exploring a Large Collection of Scene Categories}},
url = {http://link.springer.com/10.1007/s11263-014-0748-y},
year = {2014}
}
@article{Westland2002,
author = {Westland, Stephen and Iovine, Laura and Bishop, John M},
doi = {10.1117/12.464656},
file = {:home/memo/Mendeley/data/Westland, Iovine, Bishop - 2002 - Kubelka-Munk or Neural Networks for Computer Colorant Formulation.pdf:pdf},
issn = {0277786X},
journal = {Networks},
keywords = {artificial neural networks,colour,colour recipe prediction,kubelka-munk theory},
pages = {745--748},
title = {{Kubelka-Munk or Neural Networks for Computer Colorant Formulation ?}},
volume = {4421},
year = {2002}
}
@article{Nasuto2009,
abstract = {An information processing paradigm in the brain is proposed, instantiated in an artificial neural network using biologically motivated temporal encoding. The network will locate within the external world stimulus, the target memory, defined by a specific pattern of micro-features. The proposed network is robust and efficient. Akin in operation to the swarm intelligence paradigm, stochastic diffusion search, it will find the best-fit to the memory with linear time complexity. Information multiplexing enables neurons to process knowledge as 'tokens' rather than 'types'. The network illustrates possible emergence of cognitive processing from low level interactions such as memory retrieval based on partial matching. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Nasuto, S. J. and Bishop, J. M. and {De Meyer}, K.},
doi = {10.1016/j.neucom.2008.03.019},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nasuto, Bishop, De Meyer - 2009 - Communicating neurons A connectionist spiking neuron implementation of stochastic diffusion search.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Global search,Selective attention,Spiking neural networks,Stochastic diffusion search,Swarm intelligence},
number = {4-6},
pages = {704--712},
title = {{Communicating neurons: A connectionist spiking neuron implementation of stochastic diffusion search}},
volume = {72},
year = {2009}
}
@article{Nasuto2008,
abstract = {A novel Swarm Intelligence method for best-fit search, Stochastic Diffusion Search, is presented capable of rapid location of the optimal solution in the search space. Population based search mechanisms employed by Swarm Intelligence methods can suffer lack of convergence resulting in ill defined stopping criteria and loss of the best solution. Conversely, as a result of its resource allocation mechanism, the solutions SDS discovers enjoy excellent stability.},
author = {Nasuto, Slawomir and Bishop, Mark},
doi = {10.1007/978-3-540-78987-1_11},
file = {:home/memo/Mendeley/data/Nasuto, Bishop - 2008 - Stabilizing swarm intelligence search via positive feedback resource allocation.pdf:pdf},
isbn = {9783540789864},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
pages = {115--123},
title = {{Stabilizing swarm intelligence search via positive feedback resource allocation}},
volume = {129},
year = {2008}
}
@article{Zhou2014a,
abstract = {With the success of new computational architectures for visual processing, such as convolutional neural networks (CNN) and access to image databases with millions of labeled examples (e.g., ImageNet, Places), the state of the art in computer vision is advancing rapidly. One important factor for continued progress is to understand the representations that are learned by the inner layers of these deep architectures. Here we show that object detectors emerge from training CNNs to perform scene classification. As scenes are composed of objects, the CNN for scene classifica-tion automatically discovers meaningful objects detectors, representative of the learned scene categories. With object detectors emerging as a result of learning to recognize scenes, our work demonstrates that the same network can perform both scene recognition and object localization in a single forward-pass, without ever having explicitly learned the notion of objects.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.6856v1},
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
eprint = {arXiv:1412.6856v1},
file = {:home/memo/Mendeley/data/Zhou et al. - 2014 - Object Detectors Emerge in Deep Scene Cnns.pdf:pdf},
title = {{Object Detectors Emerge in Deep Scene Cnns}},
year = {2014}
}
@article{Oliva,
author = {Oliva, a.},
file = {:home/memo/Mendeley/data/Oliva - Unknown - What makes an image memorable.pdf:pdf},
journal = {Cvcl.Mit.Edu},
number = {c},
title = {{What makes an image memorable?}},
url = {http://cvcl.mit.edu/memorableImages.html}
}
@article{DeMeyer2006,
author = {{De Meyer}, Kris and Nasuto, Slawomir J. and Bishop, Mark},
doi = {10.1007/978-3-540-34690-6_8},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Meyer, Nasuto, Bishop - 2006 - Stochastic diffusion search Partial function evaluation in swarm intelligence dynamic optimisation.pdf:pdf},
isbn = {3540346899},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
pages = {185--207},
title = {{Stochastic diffusion search: Partial function evaluation in swarm intelligence dynamic optimisation}},
volume = {31},
year = {2006}
}
@article{Owens2013,
abstract = {We present a data-driven method for building dense 3D reconstructions using a combination of recognition and multi-view cues. Our approach is based on the idea that there are image patches that are so distinctive that we can accurately estimate their latent 3D shapes solely using recognition. We call these patches shape anchors, and we use them as the basis of a multi-view reconstruction system that transfers dense, complex geometry between scenes. We "anchor" our 3D interpretation from these patches, using them to predict geometry for parts of the scene that are relatively ambiguous. The resulting algorithm produces dense reconstructions from stereo point clouds that are sparse and noisy, and we demonstrate it on a challenging dataset of real-world, indoor scenes.},
author = {Owens, Andrew and Xiao, Jianxiong and Torralba, Antonio and Freeman, William},
doi = {10.1109/ICCV.2013.461},
file = {:home/memo/Mendeley/data/Owens et al. - 2013 - Shape Anchors for Data-Driven Multi-view Reconstruction.pdf:pdf},
isbn = {978-1-4799-2840-8},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {33--40},
title = {{Shape Anchors for Data-Driven Multi-view Reconstruction}},
url = {http://www.cv-foundation.org/openaccess/content{\_}iccv{\_}2013/html/Owens{\_}Shape{\_}Anchors{\_}for{\_}2013{\_}ICCV{\_}paper.html},
year = {2013}
}
@article{Hidalgo-Sotelo2005,
abstract = {Attention allocation in visual search is known to be influenced by low-level image features, visual scene context and top down task constraints. Here, we investigate the role of Contextual priors in guiding visual search by monitoring eye movements as participants search very familiar scenes for a target object. The goal of the study is to identify which stage of the visual search benefits from contextual priors. Two groups of participants differed in the expectation of target presence associated with a scene. Stronger priors are established when a scene exemplar is always associated with the presence of the target than when the scene is periodically observed with and without the target. In both cases, overall search performance improves over repeated presentations of scenes. An analytic decomposition of the time course of the effect of contextual priors shows a time benefit to the exploration stage of search (scan time) and a decrease in gaze duration on the target. The strength of the contextual relationship modulates the magnitude of gaze duration gain, while the scan time gain constitutes one half of the overall search performance benefit regardless of the probability (50{\%} or 100{\%}) of target presence. These data are discussed in terms of the implications of contextdependent scene processing and its putative role in various stages of visual search.},
author = {Hidalgo-Sotelo, B. and Oliva, a. and Torralba, a.},
doi = {10.1109/CVPR.2005.470},
file = {:home/memo/Mendeley/data/Hidalgo-Sotelo, Oliva, Torralba - 2005 - Human Learning of Contextual Priors for Object Search Where does the time go.pdf:pdf},
isbn = {0-7695-2372-2},
issn = {1063-6919},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
title = {{Human Learning of Contextual Priors for Object Search: Where does the time go?}},
year = {2005}
}
@article{Myatt2004,
abstract = {An analysis of Stochastic Diffusion Search (SDS), a novel and efficient optimisation and search algorithm, is presented, resulting in a derivation of the minimum acceptable match resulting in a stable convergence within a noisy search space. The applicability of SDS can therefore be assessed for a given problem.},
author = {Myatt, D. R. and Bishop, J. M. and Nasuto, S. J.},
doi = {10.1049/el:20040096},
file = {:home/memo/Mendeley/data/Myatt, Bishop, Nasuto - 2004 - Minimum stable convergence criteria for stochastic diffusion search.pdf:pdf},
issn = {00135194},
pages = {2--8},
title = {{Minimum stable convergence criteria for stochastic diffusion search}},
url = {http://centaur.reading.ac.uk/15344/},
year = {2004}
}
@article{Nasuto1999,
author = {Nasuto, S.J. and Dautenhahn, K. and Bishop, J. M.},
file = {:home/memo/Mendeley/data/Nasuto, Dautenhahn, Bishop - 1999 - Communication as an Emergent Metaphor for Neuronal Operation.pdf:pdf},
title = {{Communication as an Emergent Metaphor for Neuronal Operation.}},
url = {http://hdl.handle.net/2299/1947},
year = {1999}
}
@article{Lim2014,
author = {Lim, Joseph J and Khosla, Aditya and Torralba, Antonio},
doi = {10.1007/978-3-319-10599-4_31},
file = {:home/memo/Mendeley/data/Lim, Khosla, Torralba - 2014 - FPM Fine Pose Parts-Based Model with 3D CAD Models.pdf:pdf},
isbn = {978-3-319-10598-7},
pages = {478--493},
title = {{FPM : Fine Pose Parts-Based Model with 3D CAD Models}},
year = {2014}
}
@article{Salakhutdinov2013,
abstract = {We introduce HD (or "Hierarchical-Deep") models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.},
author = {Salakhutdinov, Ruslan and Tenenbaum, Joshua B. and Torralba, Antonio},
doi = {10.1109/TPAMI.2012.269},
file = {:home/memo/Mendeley/data/Salakhutdinov, Tenenbaum, Torralba - 2013 - Learning with hierarchical-deep models.pdf:pdf},
isbn = {0162-8828 VO - 35},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Deep networks,deep Boltzmann machines,hierarchical Bayesian models,one-shot learning},
number = {8},
pages = {1958--1971},
pmid = {23787346},
title = {{Learning with hierarchical-deep models}},
volume = {35},
year = {2013}
}
@article{Nandakumar2011,
abstract = {How little do we need to perceive 3-D shape in monocular natural images? The shape-from-texture and shape-from-shading perspectives would motivate that 3-D perception vanishes once low-level cues are disrupted. Is this the case in human vision? Or can top-down influences salvage the percept? In this study we probe this question by employing a gauge-figure paradigm similar to that used by Koenderink et al (1992, Perception {\&} Psychophysics 52 487-496). Subjects were presented degraded natural images and instructed to make local assessments of slant and tilt at various locations thereby quantifying their internal 3-D percept. Analysis of subjects' responses reveals recognition to be a significant influence thereby allowing subjects to perceive 3-D shape at high levels of degradation. Specifically, we identify the 'medium-blur' condition, images approximately 32 pixels on a side, to be the limit for accurate 3-D shape perception. In addition, we find that degradation affects the perceived slant of point-estimates making images look flatter as degradation increases. A subsequent condition that eliminates texture and shading but preserves contour and recognition reveals how bottom-up and top-down cues can combine for accurate 3-D shape perception.},
author = {Nandakumar, Chetan and Torralba, Antonio and Malik, Jitendra},
doi = {10.1068/p6762},
file = {:home/memo/Mendeley/data/Nandakumar, Torralba, Malik - 2011 - How little do we need for 3-D shape perception.pdf:pdf},
issn = {03010066},
journal = {Perception},
number = {3},
pages = {257--271},
pmid = {21692418},
title = {{How little do we need for 3-D shape perception?}},
volume = {40},
year = {2011}
}
@article{Zhou2014,
author = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
file = {:home/memo/Mendeley/data/Zhou et al. - 2014 - Learning Deep Features for Scene Recognition using Places Database.pdf:pdf},
journal = {Nips},
title = {{Learning Deep Features for Scene Recognition using Places Database}},
year = {2014}
}
@article{Bishop1991,
abstract = {Conventional mechanisms for computer colorant formulation commonly employ the Kubelka-Munk theory to relate reflectance values to colorant concentrations. However, there are situations where this approach is not applicable and hence an alternative is desirable. One such method is to utilize artificial intelligence techniques to mimic the behavior of the professional colorist. The purpose of this paper is to describe recent research being carried out at Reading University, sponsored by Courtaulds Research, that utilizes collections of cellular automata, known as neural networks, in the problem of recipe prediction.},
author = {Bishop, J M and Bushnell, M J and Westland, S},
doi = {10.1002/col.5080160104},
file = {:home/memo/Mendeley/data/Bishop, Bushnell, Westland - 1991 - Application of Neural Networks To Computer Recipe Prediction.pdf:pdf},
isbn = {0361-2317},
issn = {03612317},
journal = {Color Research and Application},
number = {1},
pages = {3--9},
title = {{Application of Neural Networks To Computer Recipe Prediction}},
volume = {16},
year = {1991}
}
@article{Philipona2006,
abstract = {Psychophysical studies suggest that different colors have different perceptual status: red and blue for example are thought of as elementary sensations whereas yellowish green is not. The dominant account for such perceptual asymmetries attributes them to specificities of the neuronal representation of colors. Alternative accounts involve cultural or linguistic arguments. What these accounts have in common is the idea that there are no asymmetries in the physics of light and surfaces that could underlie the perceptual structure of colors, and this is why neuronal or cultural processes must be invoked as the essential underlying mechanisms that structure color perception. Here, we suggest a biological approach for surface reflection properties that takes into account only the information about light that is accessible to an organism given the photopigments it possesses, and we show that now asymmetries appear in the behavior of surfaces with respect to light. These asymmetries provide a classification of surface properties that turns out to be identical to the one observed in linguistic color categorization across numerous cultures, as pinned down by cross cultural studies. Further, we show that data from psychophysical studies about unique hues and hue cancellation are consistent with the viewpoint that stimuli reported by observers as special are those associated with this singularity-based categorization of surfaces under a standard illuminant. The approach predicts that unique blue and unique yellow should be aligned in chromatic space while unique red and unique green should not, a fact usually conjectured to result from nonlinearities in chromatic pathways.},
author = {Philipona, David L and Regan, J Kevin O},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Philipona, Regan - 2006 - Color naming, unique hues, and hue cancellation predicted from singularities in reflection properties.pdf:pdf},
journal = {Visual Neuroscience},
keywords = {color perception,hue cancellation,reflection properties,unique hues,world color survey},
number = {3-4},
pages = {331--339},
title = {{Color naming, unique hues, and hue cancellation predicted from singularities in reflection properties}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16961964},
volume = {23},
year = {2006}
}
@book{LaViolaJr2014,
author = {{LaViola Jr.}, Joseph J},
booktitle = {ACM SIGGRAPH 2014 Courses},
doi = {10.1145/2614028.2615424},
file = {:home/memo/Mendeley/data/LaViola Jr. - 2014 - An Introduction to 3D Gestural Interfaces.pdf:pdf},
isbn = {978-1-4503-2962-0},
pages = {25:1----25:42},
title = {{An Introduction to 3D Gestural Interfaces}},
url = {http://doi.acm.org/10.1145/2614028.2615424},
year = {2014}
}
@article{Ye2014,
abstract = {We present a system that allows the user to virtually try on new clothes. It uses a single commodity depth camera to capture the user in 3D. Both the pose and the shape of the user are estimated with a novel real-time template-based approach that performs tracking and shape adaptation jointly. The result is then used to drive realistic cloth simulation, in which the synthesized clothes are overlayed on the input image. The main challenge is to handle missing data and pose ambiguities due to the monocular setup, which captures less than 50 percent of the full body. Our solution is to incorporate automatic shape adaptation and novel constraints in pose tracking. The effectiveness of our system is demonstrated with a number of examples.},
author = {Ye, M and Yang, R},
doi = {10.1109/CVPR.2014.301},
file = {:home/memo/Mendeley/data/Ye, Yang - 2014 - Real-time Simultaneous Pose and Shape Estimation for Articulated Objects Using a Single Depth Camera.pdf:pdf},
isbn = {978-1-4799-5118-5},
journal = {Multi-Camera {\ldots}},
keywords = {-human motion capture,figure 1,mation,non-rigid surface defor-,our approach tracks both,pose estimation,pose of humans,results with three different,simultaneously,standard datasets are shown,the shape and the},
number = {January},
pages = {2353--2360},
title = {{Real-time Simultaneous Pose and Shape Estimation for Articulated Objects Using a Single Depth Camera}},
url = {http://vis.uky.edu/{~}gravity/Publications/2014/ArticulatedPoseShape{\_}CVPR14.pdf{\%}5Cnhttp://europepmc.org/abstract/MED/24650982{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=XA{\_}6o2dhTGEC{\&}oi=fnd{\&}pg=PA335{\&}dq=Real-Time+3D+Body+Pose+Estimation{\&}ots={\_}X-Zs47meG{\&}sig=},
year = {2014}
}
@article{Wei2012,
abstract = {We present a fast, automatic method for accurately capturing full-body motion data using a single depth camera. At the core of our system lies a realtime registration process that accurately reconstructs 3D human poses from single monocular depth images, even in the case of significant occlusions. The idea is to formulate the registration problem in a Maximum A Posteriori (MAP) framework and iteratively register a 3D articulated human body model with monocular depth cues via linear system solvers. We integrate depth data, silhouette information, full-body geometry, temporal pose priors, and occlusion reasoning into a unified MAP estimation framework. Our 3D tracking process, however, requires manual initialization and recovery from failures. We address this challenge by combining 3D tracking with 3D pose detection. This combination not only automates the whole process but also significantly improves the robustness and accuracy of the system. Our whole algorithm is highly parallel and is therefore easily implemented on a GPU. We demonstrate the power of our approach by capturing a wide range of human movements in real time and achieve state-of-the-art accuracy in our comparison against alternative systems such as Kinect [2012].},
author = {Wei, Xiaolin and Zhang, Peizhao and Chai, Jinxiang},
doi = {10.1145/2366145.2366207},
file = {:home/memo/Mendeley/data/Wei, Zhang, Chai - 2012 - Accurate realtime full-body motion capture using a single depth camera.pdf:pdf},
isbn = {0730-0301},
issn = {0730-0301},
journal = {ACM Trans. Graph.},
keywords = {3D pose detection,human motion tracking,motion capture,performance-based animation,vision-based motion modeling},
number = {6},
pages = {188:1----188:12},
title = {{Accurate realtime full-body motion capture using a single depth camera}},
url = {http://doi.acm.org/10.1145/2366145.2366207},
volume = {31},
year = {2012}
}
@article{Bickerman2010,
abstract = {We describe an unsupervised learning technique to facilitate automated creation of jazz melodic improvisation over chord sequences. Specifically we demonstrate training an artificial improvisation algorithm based on unsupervised learning using deep belief nets, a form of probabilistic neural network based on restricted Boltzmann machines. We present a musical encoding scheme and specifics of a learning and creational method. Our approach creates novel jazz licks, albeit not yet in real-time. The present work should be regarded as a feasibility study to determine whether such networks could be used at all. We do not claim superiority of this approach for pragmatically creating jazz.},
author = {Bickerman, Gregory and Bosley, Sam and Swire, Peter and Keller, Robert},
file = {:home/memo/Mendeley/data/Bickerman et al. - 2010 - Learning to Create Jazz Melodies using Deep Belief Nets.pdf:pdf},
isbn = {9789899600126},
journal = {International Conference on Computational Creativity (ICCC)},
keywords = {Improvisor,RBM-provisor,deep belief networks,jazz improvisation,melody generation,restricted boltzmann machine},
title = {{Learning to Create Jazz Melodies using Deep Belief Nets}},
url = {http://www.cs.hmc.edu/{~}keller/research/},
year = {2010}
}
@article{Denton,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.05751v1},
author = {Denton, Emily and Szlam, Arthur and Fergus, Rob},
eprint = {arXiv:1506.05751v1},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Denton, Szlam, Fergus - Unknown - Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks arXiv 1506 . 05751v1.pdf:pdf},
pages = {1--10},
title = {{Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks arXiv : 1506 . 05751v1 [ cs . CV ] 18 Jun 2015}}
}
@article{Tessendorf2004,
author = {Tessendorf, Jerry},
file = {:home/memo/Mendeley/data/Tessendorf - 2004 - Water Surfaces in Games.pdf:pdf},
journal = {Game Programming Gems 4},
title = {{Water Surfaces in Games}},
year = {2004}
}
@article{Browne2012,
abstract = {Monte Carlo Tree Search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarise the results from the key game and non-game domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
author = {Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
file = {:home/memo/Mendeley/data/Browne, n B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Step.pdf:pdf},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
keywords = {Artificial Intelligence (AI),Bandit-based methods,Computer Go,Game search,Monte Carlo Tree Search (MCTS),Upper Confidence Bounds (UCB),Upper Confidence Bounds for Trees (UCT)},
number = {1},
pages = {1--43},
title = {{A survey of monte carlo tree search methods}},
volume = {4},
year = {2012}
}
@article{Cohn2012,
abstract = {Computer vision and inertial measurement have made it possible for people to interact with computers using whole-body gestures. Although there has been rapid growth in the uses and applications of these systems, their ubiquity has been limited by the high cost of heavily instrumenting either the environment or the user. In this paper, we use the human body as an antenna for sensing whole-body gestures. Such an approach requires no instrumentation to the environment, and only minimal instrumentation to the user, and thus enables truly mobile applications. We show robust gesture recognition with an average accuracy of 93{\%} across 12 whole-body gestures, and promising results for robust location classification within a building. In addition, we demonstrate a real-time interactive system which allows a user to interact with a computer using whole-body gestures.},
author = {Cohn, Gabe and Morris, Daniel and Patel, Shwetak and Tan, Desney},
doi = {10.1145/2207676.2208330},
file = {:home/memo/Mendeley/data/Cohn et al. - 2012 - Humantenna Using the Body as an Antenna for Real-Time Whole-Body Interaction.pdf:pdf},
isbn = {9781450310154},
journal = {Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems - CHI '12},
keywords = {body as antenna,electrical noise,whole-body gestures},
pages = {1901--1910},
title = {{Humantenna: Using the Body as an Antenna for Real-Time Whole-Body Interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2207676.2208330},
year = {2012}
}
@article{Bourke2012,
author = {Bourke, Paul},
file = {:home/memo/Mendeley/data/Bourke - 2012 - Report on low latency video capture and display.pdf:pdf},
number = {September},
title = {{Report on low latency video capture and display}},
year = {2012}
}
@article{Tessendorf2001,
abstract = {These notes are intended to give computer graphics programmers and artists an introduction to methods of simulating, animating, and rendering ocean water environments. CG water has become a common tool in visual effects work at all levels of computer graphics},
author = {Tessendorf, Jerry},
file = {:home/memo/Mendeley/data/Tessendorf - 2001 - Simulating Ocean Water.pdf:pdf},
journal = {Environment},
pages = {1--19},
title = {{Simulating Ocean Water}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.131.5567{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {2001}
}
@article{Fellous2002,
abstract = {This article, we survey some issues about the nature of emotion, describe what is known about the neural basis of emotion, and consider some efforts that have been made to develop computer-based models of different aspects of emotion.},
author = {Fellous, Jean-marc and Armony, Jorge L and Ledoux, Joseph E},
doi = {10.1038/nature06992},
file = {:home/memo/Mendeley/data/Fellous, Armony, Ledoux - 2002 - Emotional Circuits and Computational Neuroscience.pdf:pdf},
isbn = {9780262011976},
issn = {14764687},
journal = {Neuroscience},
number = {7200},
pages = {1--8},
pmid = {18509338},
title = {{Emotional Circuits and Computational Neuroscience}},
url = {http://www.u.arizona.edu/{~}fellous/lab/pubs/emo2.pdf},
volume = {454},
year = {2002}
}
@article{Hadfield2014,
abstract = {In this paper, an algorithm is presented for estimating scene flow, which is a richer, 3D analog of optical flow. The approach operates orders of magnitude faster than alternative techniques and is well suited to further performance gains through parallelized implementation. The algorithm employs multiple hypotheses to deal with motion ambiguities, rather than the traditional smoothness constraints, removing oversmoothing errors and providing significant performance improvements on benchmark data, over the previous state of the art. The approach is flexible and capable of operating with any combination of appearance and/or depth sensors, in any setup, simultaneously estimating the structure and motion if necessary. Additionally, the algorithm propagates information over time to resolve ambiguities, rather than performing an isolated estimation at each frame, as in contemporary approaches. Approaches to smoothing the motion field without sacrificing the benefits of multiple hypotheses are explored, and a probabilistic approach to occlusion estimation is demonstrated, leading to 10 and 15 percent improved performance, respectively. Finally, a data-driven tracking approach is described, and used to estimate the 3D trajectories of hands during sign language, without the need to model complex appearance variations at each viewpoint.},
author = {Hadfield, Simon and Bowden, Richard},
doi = {10.1109/TPAMI.2013.162},
file = {:home/memo/Mendeley/data/Hadfield, Bowden - 2014 - Scene particles Unregularized particle-based scene flow estimation.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D,3D motion,3D tracking,Scene flow,bilateral filter,hand tracking,motion estimation,motion segmentation,occlusion,occlusion estimation,optical flow,particle,particle filter,probabilistic occlusion,scene particles,sign language,tracking},
number = {3},
pages = {564--576},
pmid = {24457511},
title = {{Scene particles: Unregularized particle-based scene flow estimation}},
volume = {36},
year = {2014}
}
@article{Zhao2014a,
author = {Zhao, Gangqiang and Thalmann, Daniel and Xiao, Yang},
file = {:home/memo/Mendeley/data/Zhao, Thalmann, Xiao - 2014 - Activity Recognition in Unconstrained RGB-D Video using 3D Trajectories.pdf:pdf},
isbn = {9781450332439},
keywords = {3d trajectories,activity recognition,figure 1,from hollywood 3d dataset,mbh,recognition pipeline with,rgb-d,the proposed rgb-d activity,the sample frames are},
pages = {12--15},
title = {{Activity Recognition in Unconstrained RGB-D Video using 3D Trajectories}},
year = {2014}
}
@article{Bera,
author = {Bera, Aniket},
file = {:home/memo/Mendeley/data/Bera - Unknown - Scene Flow Estimation from Stereo Video Source.pdf:pdf},
keywords = {disparity,head tracking,mobile 3d,optical,scene flow,stereo},
pages = {25--28},
title = {{Scene Flow Estimation from Stereo Video Source}}
}
@article{Vedula2005,
abstract = {Just as optical flow is the two-dimensional motion of points in an image, scene flow is the three-dimensional motion of points in the world. The fundamental difficulty with optical flow is that only the normal flow can be computed directly from the image measurements, without some form of smoothing or regularization. In this paper, we begin by showing that the same fundamental limitation applies to scene flow; however, many cameras are used to image the scene. There are then two choices when computing scene flow: 1) perform the regularization in the images or 2) perform the regularization on the surface of the object in the scene. In this paper, we choose to compute scene flow using regularization in the images. We describe three algorithms, the first two for computing scene flow from optical flows and the third for constraining scene tructure from the inconsistencies in multiple optical flows.},
author = {Vedula, Sundar and Baker, Simon and Rander, Peter and Collins, Robert and Kanade, Takeo},
doi = {10.1109/TPAMI.2005.63},
file = {:home/memo/Mendeley/data/Vedula et al. - 2005 - Three-dimensional scene flow.pdf:pdf},
isbn = {0-7695-0164-8},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Normal flow,Optical flow,Scene flow,The brightness constancy constraint,Three-dimensional dense nonrigid motion,Three-dimensional normal flow},
number = {3},
pages = {475--480},
pmid = {15747803},
title = {{Three-dimensional scene flow}},
volume = {27},
year = {2005}
}
@article{Quiroga2014,
abstract = {The scene flow describes the motion of each 3D point between two time steps. With the arrival of new depth sensors, as the Microsoft Kinect, it is now possible to compute scene flow with a single camera, with promising repercussion in a wide range of computer vision scenarios. We propose a novel method to compute a local scene flow by tracking in a Lucas-Kanade framework. Scene flow is estimated using a pair of aligned intensity and depth images but rather than computing a dense scene flow as in most previous methods, we get a set of 3D motion vectors by tracking surface patches. Assuming a 3D local rigidity of the scene, we propose a rigid translation flow model that allows solving directly for the scene flow by constraining the 3D motion field both in intensity and depth data. In our experimentation we achieve very encouraging results. Since this approach solves simultaneously for the 2D tracking and for the scene flow, it can be used for motion analysis in existing 2D tracking based methods or to define scene flow descriptors. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Quiroga, Julian and Devernay, Fr{\'{e}}d{\'{e}}ric and Crowley, James},
doi = {10.1016/j.jvcir.2013.03.018},
file = {:home/memo/Mendeley/data/Quiroga, Devernay, Crowley - 2014 - Local scene flow by tracking in intensity and depth.pdf:pdf},
isbn = {9781467316118},
issn = {10473203},
journal = {Journal of Visual Communication and Image Representation},
keywords = {3D motion estimation,Brightness consistency,Depth data,Image tracking,Image warping,Locally-rigid motion,Optical flow,Scene flow},
number = {1},
pages = {98--107},
title = {{Local scene flow by tracking in intensity and depth}},
volume = {25},
year = {2014}
}
@article{Ruttle2009,
abstract = {Scene flow is the motion of the surface points in the 3D world. For a camera, it is seen as a 2D optical flow in the image plane. Knowing the scene flow can be very useful as it gives an idea of the surface geometry of the objects in the scene and how those objects are moving. Four methods for calculating the scene flow given multiple optical flows have been explored and detailed in this paper along with the basic mathematics surrounding multi-view geometry. It was found that given multiple optical flows it is possible to estimate the scene flow to different levels of detail depending on the level of prior information present.},
author = {Ruttle, Jonathan and Manzke, Michael and Dahyot, Rozenn},
doi = {10.1109/IMVIP.2009.8},
file = {:home/memo/Mendeley/data/Ruttle, Manzke, Dahyot - 2009 - Estimating 3D scene flow from multiple 2D optical flows.pdf:pdf},
isbn = {9780769537962},
journal = {IMVIP 2009 - 2009 International Machine Vision and Image Processing Conference},
keywords = {3D scene geometry,Optical flow,Scene flow},
number = {1},
pages = {1--6},
title = {{Estimating 3D scene flow from multiple 2D optical flows}},
volume = {34},
year = {2009}
}
@article{Fanello2013,
author = {Fanello, Sr and Gori, I and Metta, Giorgio and Odone, F},
file = {:home/memo/Mendeley/data/Fanello et al. - 2013 - Keep it simple and sparse real-time action recognition.pdf:pdf},
issn = {15324435},
journal = {The Journal of Machine Learning {\ldots}},
keywords = {human,one-shot action learning,real-time action recognition,sparse representation},
pages = {2617--2640},
title = {{Keep it simple and sparse: real-time action recognition}},
url = {http://dl.acm.org/citation.cfm?id=2567745},
volume = {14},
year = {2013}
}
@article{Hadfield2011,
abstract = {The motion field of a scene can be used for object segmentation and to provide features for classification tasks like action recognition. Scene flow is the full 3D motion field of the scene, and is more difficult to estimate than it's 2D counterpart, optical flow. Current approaches use a smoothness cost for regularisation, which tends to over-smooth at object boundaries. This paper presents a novel formulation for scene flow estimation, a collection of moving points in 3D space, modelled using a particle filter that supports multiple hypotheses and does not oversmooth the motion field. In addition, this paper is the first to address scene flow estimation, while making use of modern depth sensors and monocular appearance images, rather than traditional multi-viewpoint rigs. The algorithm is applied to an existing scene flow dataset, where it achieves comparable results to approaches utilising multiple views, while taking a fraction of the time.},
author = {Hadfield, Simon and Bowden, Richard},
doi = {10.1109/ICCV.2011.6126509},
file = {:home/memo/Mendeley/data/Hadfield, Bowden - 2011 - Kinecting the dots Particle based scene flow from depth sensors.pdf:pdf},
isbn = {9781457711015},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2290--2295},
title = {{Kinecting the dots: Particle based scene flow from depth sensors}},
year = {2011}
}
@article{Devernay2006,
abstract = { Scene flow represents the 3-D motion of points in the scene, just as optical flow is related to their 2-D motion in the images. As opposed to classical methods which compute scene flow from optical flow, we propose to compute it by tracking 3-D points and surface elements (surfels) in a multi-camera setup (at least two cameras are needed). Two methods are proposed: in the first one, the translation of each 3-D point is found by matching the neighborhoods of its 2-D projections in each camera between two time steps; in the second one, the full pose of a surfel is recovered by matching the image of its projection with a texture template attached to the surfel, and visibility changes caused by occlusion or rotation of surfels are handled. Both methods detect lost or untrackable points and surfels. They were designed for real-time execution and can be used for fast extraction of scene flow from multi-camera sequences.},
author = {Devernay, Fr{\'{e}}d{\'{e}}ric and Mateus, Diana and Guilbert, Matthieu},
doi = {10.1109/CVPR.2006.194},
file = {:home/memo/Mendeley/data/Devernay, Mateus, Guilbert - 2006 - Multi-camera scene flow by tracking 3-D points and surfels.pdf:pdf},
isbn = {0769525970},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2203--2212},
title = {{Multi-camera scene flow by tracking 3-D points and surfels}},
volume = {2},
year = {2006}
}
@article{Munaro2013,
abstract = {Motion perception and classification are key elements exploited by humans for recognizing actions. The same principles can serve as a basis for building cognitive architectures which can recognize human actions, thus enhancing challenging applications such as human robot interaction, visual surveillance, content-based video analysis and motion capture. In this paper, we propose an autonomous system for real-time human action recognition based on 3D motion flow estimation. We exploit colored point cloud data acquired with a Microsoft Kinect and we summarize the motion information by means of a 3D grid-based descriptor. Finally, temporal sequences of descriptors are classified with the Nearest Neighbor technique. We also present a newly created public dataset for RGB-D human action recognition which contains 15 actions performed by 12 different people. Our overall system is tested on this dataset and on the dataset used in Ballin, Munaro, and Menegatti (2012), showing the effectiveness of the proposed approach in recognizing about 90{\%} of the actions. ?? 2013 Elsevier B.V.},
author = {Munaro, Matteo and Ballin, Gioia and Michieletto, Stefano and Menegatti, Emanuele},
doi = {10.1016/j.bica.2013.05.008},
file = {:home/memo/Mendeley/data/Munaro et al. - 2013 - 3D flow estimation for human action recognition from colored point clouds.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {3d motion flow,Action recognition,Colored point clouds,Ias-lab action dataset,Kinect,Rgb-d data},
pages = {42--51},
publisher = {Elsevier B.V.},
title = {{3D flow estimation for human action recognition from colored point clouds}},
url = {http://dx.doi.org/10.1016/j.bica.2013.05.008},
volume = {5},
year = {2013}
}
@article{Zhang2001,
abstract = {In this paper, novel algorithms computing dense 3D scene flow from multiview image sequences are described. A new hierarchical rule-based stereo matching algorithm is presented to estimate the initial disparity map. Different available constraints under a multiview camera setup are investigated and then utilized in the proposed motion estimation algorithms. We show two different formulations for 3D scene flow computation. One formulation assumes that initial disparity map is accurate while the other does not make this assumption. Image segmentation information is used to maintain the motion and depth discontinuities. Iterative implementations are used to successfully compute 3D scene flow and structure at every point in the reference image. Novel hard constraints are introduced in this paper to make the algorithms more accurate and robust. Promising experimental results are seen by applying our algorithms to real imagery.},
author = {Zhang, Ye and Kambhamettu, Chandra},
doi = {10.1109/CVPR.2001.991044},
file = {:home/memo/Mendeley/data/Zhang, Kambhamettu - 2001 - On 3D scene flow and structure estimation.pdf:pdf},
isbn = {0-7695-1272-0},
journal = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
pages = {II--778--II--785},
title = {{On 3D scene flow and structure estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=991044},
volume = {2},
year = {2001}
}
@article{Lenz2011,
abstract = {Modern driver assistance systems such as collision avoidance or intersection assistance need reliable information on the current environment. Extracting such information from camera-based systems is a complex and challenging task for inner city traffic scenarios. This paper presents an approach for object detection utilizing sparse scene flow. For consecutive stereo images taken from a moving vehicle, corresponding interest points are extracted. Thus, for every interest point, disparity and optical flow values are known and consequently, scene flow can be calculated. Adjacent interest points describing a similar scene flow are considered to belong to one rigid object. The proposed method does not rely on object classes and allows for a robust detection of dynamic objects in traffic scenes. Leading vehicles are continuously detected for several frames. Oncoming objects are detected within five frames after their appearance.},
author = {Lenz, Philip and Ziegler, Julius and Geiger, Andreas and Roser, Martin},
doi = {10.1109/IVS.2011.5940558},
file = {:home/memo/Mendeley/data/Lenz et al. - 2011 - Sparse scene flow segmentation for moving object detection in urban environments.pdf:pdf},
isbn = {9781457708909},
issn = {1931-0587},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
number = {Iv},
pages = {926--932},
pmid = {5940558},
title = {{Sparse scene flow segmentation for moving object detection in urban environments}},
year = {2011}
}
@article{Croft2015,
author = {Croft, John},
doi = {10.1017/S0040298214000989},
file = {:home/memo/Mendeley/data/Croft - 2015 - Composition Is Not Research.pdf:pdf},
isbn = {0040298214000},
issn = {0040-2982},
journal = {Tempo},
number = {272},
pages = {6--11},
title = {{Composition Is Not Research}},
url = {http://www.journals.cambridge.org/abstract{\_}S0040298214000989},
volume = {69},
year = {2015}
}
@inproceedings{Vlachos,
author = {Vlachos, Alex},
file = {:home/memo/Mendeley/data/Vlachos - Unknown - Advanced VR Rendering.pdf:pdf},
title = {{Advanced VR Rendering}}
}
@article{Nissen2005,
author = {Nissen, Steffen},
file = {:home/memo/Mendeley/data/Nissen - 2005 - Neural Networks Made Simple.pdf:pdf},
pages = {14--19},
title = {{Neural Networks Made Simple}},
year = {2005}
}
@article{Lees-Miller2013h,
author = {Lees-Miller, Dr John D.},
file = {:home/memo/Mendeley/data/Lees-Miller - 2013 - An Interactive Introduction to Latex Part 1(3).pdf:pdf},
title = {{An Interactive Introduction to Latex Part 1}},
year = {2013}
}
@article{Caramiaux2014,
author = {Caramiaux, Baptiste and Montecchio, Nicola and Tanaka, Atau and Bevilacqua, Fr{\'{e}}d{\'{e}}ric},
doi = {10.1145/2643204},
file = {:home/memo/Mendeley/data/Caramiaux et al. - 2014 - Adaptive Gesture Recognition with Variation Estimation for Interactive Systems.pdf:pdf},
issn = {2160-6455},
journal = {ACM Transactions on Interactive Intelligent Systems (TiiS) (In Press)},
number = {212},
title = {{Adaptive Gesture Recognition with Variation Estimation for Interactive Systems}},
volume = {V},
year = {2014}
}
@article{Blake2011,
author = {Blake, a},
file = {:home/memo/Mendeley/data/Blake - 2011 - Real-time human pose recognitiom in parts from single depth images.pdf:pdf},
journal = {��IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)��},
title = {{Real-time human pose recognitiom in parts from single depth images}},
year = {2011}
}
@article{Gillian2011DTW,
abstract = {This paper presents a novel algorithm that has been specif- ically designed for the recognition of multivariate tempo- ral musical gestures. The algorithm is based on Dynamic Time Warping and has been extended to classify any N- dimensional signal, automatically compute a classification threshold to reject any data that is not a valid gesture and be quickly trained with a low number of training examples. The algorithm is evaluated using a database of 10 temporal gestures performed by 10 participants achieving an average cross-validation result of 99{\%}.},
author = {Gillian, Nicholas and Knapp, Rb},
file = {:home/memo/Mendeley/data/Gillian, Knapp - 2011 - Recognition Of Multivariate Temporal Musical Gestures Using N-Dimensional Dynamic Time Warping.pdf:pdf},
issn = {2220-4806},
journal = {New Interfaces for Musical Expression},
keywords = {computer interaction,dynamic time warping,gesture recognition,multivariate temporal gestures,musician-},
pages = {337--342},
title = {{Recognition Of Multivariate Temporal Musical Gestures Using N-Dimensional Dynamic Time Warping}},
url = {http://www.nime2011.org/proceedings/papers/I02-Gillian.pdf},
year = {2011}
}
@article{Caramiaux2013,
abstract = {Gesture-based interaction is widespread in touch screen interfaces. The goal of this paper is to tap the richness of expressive variation in gesture to facilitate continuous interaction. We achieve this through novel techniques of adaptation and estimation of gesture characteristics. We describe two experiments. The first aims at understanding whether users can control certain gestural characteristics and if that control depends on gesture vocabulary. The second study uses a machine learning technique based on particle filtering to simultaneously recognize and measure variation in a gesture. With this technology, we create a gestural interface for a playful photo processing application. From these two studies, we show that 1) multiple characteristics can be varied independently in slower gestures (Study 1), and 2) users find gesture-only interaction less pragmatic but more stimulating than traditional menu-based systems (Study 2).},
author = {Caramiaux, Baptiste and Bevilacqua, Frederic and Tanaka, Atau},
doi = {10.1145/2468356.2468730},
file = {:home/memo/Mendeley/data/Caramiaux, Bevilacqua, Tanaka - 2013 - Beyond Recognition Using Gesture Variation for Continuous Interaction.pdf:pdf},
isbn = {9781450319522},
journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
keywords = {continuous interaction,gestural interaction,gesture recognition,motor control},
pages = {2109 -- 2118},
title = {{Beyond Recognition: Using Gesture Variation for Continuous Interaction}},
url = {http://dl.acm.org/citation.cfm?id=2468356.2468730},
year = {2013}
}
@article{Paradiso2014,
author = {Paradiso, Joseph A},
file = {:home/memo/Mendeley/data/Paradiso - 2014 - The Gesture Recognition Toolkit.pdf:pdf},
keywords = {c,classification,clustering,feature extraction,gesture recognition,gesture spotting,machine learning,open source,regression,signal processing},
pages = {3483--3487},
title = {{The Gesture Recognition Toolkit}},
volume = {15},
year = {2014}
}
@article{Fiebrink2010,
abstract = {A weekly seminar consisting of seven composers and one computer scientist was convened for the purpose of exploring questions surrounding how technology can support aspects of the computer music composition process. The composers were introduced to an existing interactive software system for creating new musical interfaces and compositions, which they used throughout the seminar. The group engaged in a user-centered design process to critically evaluate and improve this software. Through documentation of the experience and analysis of composers responses to a questionnaire following the seminar, we achieved a richer understanding of how technology can support composers modes of working and goals in the process of computer music interface design and composition. This work also resulted in an improved compositional software system and progress toward several new musical compositions and instruments.},
author = {Fiebrink, Rebecca and Trueman, Daniel and Britt, Cameron and Nagai, Michelle and Kaczmarek, Konrad and Early, Michael and Hege, Anne and Cook, Perry},
file = {:home/memo/Mendeley/data/Fiebrink et al. - 2010 - Toward Understanding Human-Computer Interaction in Composing the Instrument.pdf:pdf},
journal = {Proceedings of International Computer Music Conference},
pages = {135--142},
title = {{Toward Understanding Human-Computer Interaction in Composing the Instrument}},
year = {2010}
}
@article{Fiebrink2011,
abstract = {This thesis examines machine learning through the lens of human-computer interac- tion in order to address fundamental questions surrounding the application of machine learning to real-life problems, including: Can we make machine learning algorithms more usable and useful? Can we better understand the real-world consequences of algorithm choices and user interface designs for end-user machine learning? How can human interaction play a role in enabling users to efficiently create useful machine learning systems, in enabling successful application of algorithms by machine learning novices, and in ultimately making it possible in practice to apply machine learning to new problems? The scope of the research presented here is the application of supervised learning algorithms to contemporary computer music composition and performance. Com- puter music is a domain rich with computational problems requiring the modeling of complex phenomena, the construction of real-time interactive systems, and the sup- port of human creativity. Though varied, many of these problems may be addressed using machine learning techniques, including supervised learning in particular. This work endeavors to gain a deeper knowledge of the human factors surrounding the application of supervised learning to these types of problems, to make supervised learning algorithms more usable by musicians, and to study how supervised learning can function as a creative tool. This thesis presents a general-purpose software system for applying standard su- pervised learning algorithms in music and other real-time problem domains. This system, called the Wekinator, supports human interaction throughout the entire su- pervised learning process, including the generation of training examples and the ap- plication of trained models to real-time inputs. The Wekinator is published as a freely-available, open source software project, and several composers have already employed it in the creation of new musical instruments and compositions. This thesis also presents work utilizing the Wekinator to study human-computer interaction with supervised learning in computer music. Research is presented which includes a participatory design process with practicing composers, pedagogical use with non-expert users in an undergraduate classroom, a study of the design of a gesture recognition system for a sensor-augmented cello bow, and case studies with three composers who have used the system in completed artistic works. The primary contributions of this work include (1) a new software tool allowing real-time human interaction with supervised learning algorithms, which includes a novel playalong interaction for generating training data in real-time; (2) a demon- stration of the important roles that interactionencompassing both human-computer control and computer-human feedbackcan play in the development of supervised learning systems, and a greater understanding of the differences between interactive and conventional machine learning contexts; (3) a better understanding of the re- quirements and challenges in the analysis and design of algorithms and interfaces for interactive supervised learning in real-time and creative problem domains; (4) a clearer characterization of composers goals and priorities for interacting with com- puters in music composition and instrument design; and (5) a demonstration of the usefulness of interactive supervised learning as a creativity support tool. This work both empowers musicians to create new forms of art and contributes to a broader HCI perspective on machine learning practice.},
author = {Fiebrink, Rebecca Anne},
file = {:home/memo/Mendeley/data/Fiebrink - 2011 - Real-time Human Interaction with Supervised Learning Algorithms for Music Composition and Performance.pdf:pdf},
journal = {Imagine},
number = {January},
pages = {376},
title = {{Real-time Human Interaction with Supervised Learning Algorithms for Music Composition and Performance}},
url = {http://www.cs.princeton.edu/{~}fiebrink/drop/thesis/thesis{\_}kbow{\_}conclusions.pdf},
year = {2011}
}
@article{Fiebrink2009,
abstract = {Supervised learning methods have long been used to allow musical interface designers to generate new mappings by example. We propose a method for harnessing machine learning algorithms within a radically interactive paradigm, in which the designer may repeatedly generate examples, train a learner, evaluate outcomes, and modify parameters in real-time within a single software environment. We describe our meta-instrument, the Wekinator, which allows a user to engage in on-the-fly learning using arbitrary control modalities and sound synthesis environments. We provide details regarding the system implementation and discuss our experiences using the Wekinator for experimentation and performance.},
author = {Fiebrink, R. and Trueman, D. and Cook, P.R.},
file = {:home/memo/Mendeley/data/Fiebrink, Trueman, Cook - 2009 - A metainstrument for interactive, on-the-fly machine learning.pdf:pdf},
journal = {Proc. NIME},
keywords = {and he does it,any code,audience,in front of an,joe does all of,live,machine learning,mapping,minutes,on stage during a,performance,this in a few,tools,without writing},
pages = {3},
title = {{A metainstrument for interactive, on-the-fly machine learning}},
url = {http://www.cs.dartmouth.edu/{~}cs104/BodyPartRecognition.pdf{\%}5Cnhttp://www.cs.princeton.edu/{~}fiebrink/publications/FiebrinkTruemanCook{\_}NIME2009.pdf},
volume = {2},
year = {2009}
}
@article{Gillian2012,
author = {Gillian, Nicholas and Nicolls, Sarah},
file = {:home/memo/Mendeley/data/Gillian, Nicolls - 2012 - A Gesturally Controlled Improvisation System for Piano.pdf:pdf},
journal = {Proceedings of the 2012 International Conference on Live Interfaces: Performance, Art, Music (LiPAM), Leeds, UK},
number = {3},
title = {{A Gesturally Controlled Improvisation System for Piano}},
year = {2012}
}
@article{Gillian2014,
author = {Gillian, Nicholas and Pfenninger, Sara and Russell, Spencer and Paradiso, Joseph a.},
doi = {10.1145/2611009.2611032},
file = {:home/memo/Mendeley/data/Gillian et al. - 2014 - Gestures Everywhere A Multimodal Sensor Fusion and Analysis Framework for Pervasive Displays.pdf:pdf},
isbn = {9781450329521},
journal = {Proceedings of The International Symposium on Pervasive Displays - PerDis '14},
pages = {98--103},
title = {{Gestures Everywhere: A Multimodal Sensor Fusion and Analysis Framework for Pervasive Displays}},
url = {http://dl.acm.org/citation.cfm?id=2611009.2611032{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2611009.2611032},
year = {2014}
}
@article{Fiebrink2009a,
abstract = {We describe our tool for interactively creating musical controller mappings using a ” play-along” paradigm, in which a user pretends to play along with a musical score in real-time using an arbitrary input control modality. As the user ” performs,” a supervised machine learning system builds a training dataset from the user's gestures and the synthesis engine's current parameters. After one or more training stages, the algorithm learns a mapping from user inputs to synthesis parameters. Control is transferred to the user, who can then control the synthesis in real-time.},
author = {Fiebrink, Rebecca and Cook, Perry R and Trueman, Dan},
file = {:home/memo/Mendeley/data/Fiebrink, Cook, Trueman - 2009 - Play-Along Mapping of Musical Controllers.pdf:pdf},
isbn = {9780971319271},
journal = {Icmc 2009},
pages = {61--64},
title = {{Play-Along Mapping of Musical Controllers}},
year = {2009}
}
@article{Gillian2011gestures,
abstract = {ABSTRACT This paper presents a novel machine learning algorithm that has been specifically developed for the classification of semiotic musical gestures . We demonstrate how our algorithm, called the Adaptive Naıve Bayes Classifier, can be quickly trained with ...},
author = {Gillian, N and Knapp, R B and Al, Et},
file = {:home/memo/Mendeley/data/Gillian, Knapp, Al - 2011 - An adaptive classification algorithm for semiotic musical gestures.pdf:pdf},
journal = {the 8th Sound and Music {\ldots}},
title = {{An adaptive classification algorithm for semiotic musical gestures}},
url = {http://www.nickgillian.com/papers/Gillian{\_}ANBC.pdf{\%}5Cnpapers2://publication/uuid/AC1D7C1C-1459-4C46-A6A5-0C790EC3181A},
year = {2011}
}
@article{Baraff2001b,
author = {Baraff, David},
file = {:home/memo/Mendeley/data/Baraff - 2001 - Physically Based Modeling Rigid Body Simulation Rigid Body Simulation.pdf:pdf},
title = {{Physically Based Modeling Rigid Body Simulation Rigid Body Simulation}},
year = {2001}
}
@article{Engelhardt2011d,
abstract = {Previous research has shown that media violence exposure can cause desensitization to violence, which in theory can increase aggression. However, no study to date has demonstrated this association. In the present experiment, participants played a violent or nonviolent video game, viewed violent and nonviolent photos while their brain activity was measured, and then gave an ostensible opponent unpleasant noise blasts. Participants low in previous exposure to video game violence who played a violent (relative to a nonviolent) game showed a reduction in the P3 component of the event-related brain potential (ERP) to violent images (indicating physiological desensitization), and this brain response mediated the effect of video game content on subsequent aggressive behavior. These data provide the first experimental evidence linking violence desensitization with increased aggression, and show that a neural marker of this process can at least partially account for the causal link between violent game exposure and aggression. {\textcopyright} 2011 Elsevier Inc.},
author = {Engelhardt, Christopher R. and Bartholow, Bruce D. and Kerr, Geoffrey T. and Bushman, Brad J.},
doi = {10.1016/j.jesp.2011.03.027},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Engelhardt et al. - 2011 - This is your brain on violent video games Neural desensitization to violence predicts increased aggression fo.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Aggression,Desensitization,Event-related potentials,Media violence,Violent video games},
month = {sep},
number = {5},
pages = {1033--1036},
title = {{This is your brain on violent video games: Neural desensitization to violence predicts increased aggression following violent video game exposure}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103111000928},
volume = {47},
year = {2011}
}
@article{Butterfield2011,
abstract = {This is one of two papers about emergence, reduction and supervenience. It expounds these notions and analyses the general relations between them. The companion paper analyses the situation in physics, especially limiting relations between physical theories. I shall take emergence as behaviour that is novel and robust relative to some comparison class. I shall take reduction as deduction using appropriate auxiliary definitions. And I shall take supervenience as a weakening of reduction, viz. to allow infinitely long definitions. The overall claim of this paper will be that emergence is logically independent both of reduction and of supervenience. In particular, one can have emergence with reduction, as well as without it; and emergence without supervenience, as well as with it. Of the subsidiary claims, the four main ones (each shared with some other authors) are: (i): I defend the traditional Nagelian conception of reduction (Section 3); (ii): I deny that the multiple realizability argument causes trouble for reductions, or "reductionism" (Section 4); (iii): I stress the collapse of supervenience into deduction via Beth's theorem (Section 5.1); (iv): I adapt some examples already in the literature to show supervenience without emergence and vice versa (Section 5.2).},
archivePrefix = {arXiv},
arxivId = {1106.0704},
author = {Butterfield, J.},
doi = {10.1007/s10701-011-9549-0},
eprint = {1106.0704},
file = {:home/memo/Mendeley/data/Butterfield - 2011 - Emergence, Reduction and Supervenience A Varied Landscape.pdf:pdf},
isbn = {0015-9018},
issn = {00159018},
journal = {Foundations of Physics},
keywords = {Beth's theorem,Definitional extension,Emergence,Multiple realisability,Nagel,Reduction,Supervenience},
number = {ii},
pages = {920--959},
title = {{Emergence, Reduction and Supervenience: A Varied Landscape}},
volume = {41},
year = {2011}
}
@article{Harnad1994,
author = {Bishop, Mark},
file = {:home/memo/Mendeley/data/Bishop - 1994 - A view inside the Chinese room Mark Bishop.pdf:pdf},
journal = {Brain},
title = {{A view inside the Chinese room Mark Bishop}},
year = {1994}
}
@article{Bishop2002,
author = {Bishop, Mark},
file = {:home/memo/Mendeley/data/Bishop - 2002 - Can Computers Feel.pdf:pdf},
journal = {Consciousness {\&} Cognition},
pages = {642--652},
title = {{Can Computers Feel?}},
volume = {11},
year = {2002}
}
@article{Bishop2009,
abstract = {The journal of Cognitive Computation is defined in part by the notion that biologically inspired computational accounts are at the heart of cognitive processes in both natural and artificial systems. Many studies of various important aspects of cognition (memory, observational learning, decision making, reward prediction learning, attention control, etc.) have been made by modelling the various experimental results using ever-more sophisticated computer programs. In this manner progressive inroads have been made into gaining a better understanding of the many components of cognition. Concomitantly in both science and science fiction the hope is periodically re-ignited that a man-made system can be engineered to be fully cognitive and conscious purely in virtue of its execution of an appropriate computer program. However, whilst the usefulness of the computational metaphor in many areas of psychology and neuroscience is clear, it has not gone unchallenged and in this article I will review a group of philosophical arguments that suggest either such unequivocal optimism in computationalism is misplaced�computation is neither necessary nor sufficient for cognition�or panpsychism (the belief that the physical universe is fundamentally composed of elements each of which is conscious) is true. I conclude by highlighting an alternative metaphor for cognitive processes based on communication and interaction.},
author = {Bishop, Mark},
doi = {10.1007/s12559-009-9019-6},
file = {:home/memo/Mendeley/data/Bishop - 2009 - A cognitive computation fallacy Cognition, computations and panpsychism.pdf:pdf},
issn = {18669956},
journal = {Cognitive Computation},
keywords = {Computationalism,Machine consciousness,Panpsychism},
pages = {221--233},
title = {{A cognitive computation fallacy? Cognition, computations and panpsychism}},
volume = {1},
year = {2009}
}
@article{Hameroff2014,
abstract = {The nature of consciousness, the mechanism by which it occurs in the brain, and its ultimate place in the universe are unknown. We proposed in the mid 1990's that consciousness depends on biologically 'orchestrated' coherent quantum processes in collections of microtubules within brain neurons, that these quantum processes correlate with, and regulate, neuronal synaptic and membrane activity, and that the continuous Schr??dinger evolution of each such process terminates in accordance with the specific Di??si-Penrose (DP) scheme of 'objective reduction' ('OR') of the quantum state. This orchestrated OR activity ('Orch OR') is taken to result in moments of conscious awareness and/or choice. The DP form of OR is related to the fundamentals of quantum mechanics and space-time geometry, so Orch OR suggests that there is a connection between the brain's biomolecular processes and the basic structure of the universe. Here we review Orch OR in light of criticisms and developments in quantum biology, neuroscience, physics and cosmology. We also introduce a novel suggestion of 'beat frequencies' of faster microtubule vibrations as a possible source of the observed electro-encephalographic ('EEG') correlates of consciousness. We conclude that consciousness plays an intrinsic role in the universe. ?? 2013 Elsevier B.V.},
author = {Hameroff, Stuart and Penrose, Roger},
doi = {10.1016/j.plrev.2013.08.002},
file = {:home/memo/Mendeley/data/Hameroff, Penrose - 2014 - Consciousness in the universe A review of the 'Orch OR' theory.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
number = {1},
pages = {39--78},
pmid = {24070914},
publisher = {Elsevier B.V.},
title = {{Consciousness in the universe: A review of the 'Orch OR' theory}},
url = {http://dx.doi.org/10.1016/j.plrev.2013.08.002},
volume = {11},
year = {2014}
}
@article{Grinde2012,
author = {Grinde, Bj{\o}rn},
doi = {10.1007/s13752-012-0061-3},
file = {:home/memo/Mendeley/data/Grinde - 2012 - The Evolutionary Rationale for Consciousness.pdf:pdf},
issn = {1555-5542},
journal = {Biological Theory},
keywords = {amniotes {\'{a}} consciousness {\'{a}},emotions {\'{a}},evolution {\'{a}} mood modules,{\'{a}} self-awareness},
pages = {227--236},
title = {{The Evolutionary Rationale for Consciousness}},
url = {http://link.springer.com/10.1007/s13752-012-0061-3},
volume = {7},
year = {2012}
}
@misc{Beckermann1992,
author = {Beckermann, Ansgar},
booktitle = {{\{}E{\}}mergence or reduction?},
file = {:home/memo/Mendeley/data/Beckermann - 1992 - {\{}S{\}}upervenience, {\{}E{\}}mergence, and {\{}R{\}}eduction.pdf:pdf},
isbn = {3110128802},
keywords = {Philosophie;Philosophie des Geistes;Emergenztheori},
pages = {94--118},
title = {{{\{}S{\}}upervenience, {\{}E{\}}mergence, and {\{}R{\}}eduction}},
year = {1992}
}
@article{Howell2009,
abstract = {A purely metaphysical formulation of physicalism is surprisingly elusive. One popular slogan is, 'There is nothing over and above the physical'. Problems with this arise on two fronts. First, it is difficult to explain what makes a property 'physical' without appealing to the methodology of physics or to particular ways in which properties are known. This obviously introduces epistemic features into the core of a metaphysical issue. Second, it is difficult to cash out 'over-and-aboveness' in a way that is rigorous, metaphysically pure and extensionally apt for the purposes of the debate. In this paper I will touch on the first problem, but I wish to focus on the second. In particular, I will focus on the claim that supervenience theses cannot define physicalism because they allow classical emergentist dualism through the physicalist door [Horgan 1993; Kim 1998; Wilson 2005]. I will argue that when the relevant supervenience thesis is metaphysical, emergentism is excluded. Against recent arguments to the contrary, I maintain that this is the case even given necessitarianism about natural laws [Wilson 2005]. I will argue that a necessitarian with emergentist sympathies will be forced either into a type of quasi-panpsychism, where our basic physical properties contain the illicit seeds of mentality at their core, or she will be forced to admit that emergence laws are not necessary after all. Either way, the combination of necessitarianism and emergentism does not provide a counterexample to supervenience physicalism.},
author = {Howell, Robert},
doi = {10.1080/00048400802215398},
file = {:home/memo/Mendeley/data/Howell - 2009 - Emergentism and supervenience physicalism.pdf:pdf},
issn = {0004-8402},
journal = {Australasian Journal of Philosophy},
number = {1993},
pages = {83--98},
title = {{Emergentism and supervenience physicalism}},
volume = {87},
year = {2009}
}
@article{Review1940,
abstract = {The Imitation Game. I PROPOSE to consider the question, Can machines think This should begin with definitions of the meaning of the tTms machine and' think '. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words machine' and' think are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, Can machines think is to be sought in a statistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words. The new form of the problem can be described in terms of a game which we call the imitation game '. It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either X is A and Y is B or X is B and Y is A'. The interrogator is allowed to put questions to A and B thus: C : Will X please tell me the length of his or her hair Now suppose X is actually A, then A must answer. It is A's 28 3 Downloaded from http://mind.oxfordjournals.org/ by guest on February 6, 2012 434 A. M. TURING : object in the game to try and cause C to make the wrong identification. His answer might therefore be My hair is shingled, and the longest strands are about nine inches long.' In order that tones of voice may not help the interrogator the answers should be written, or better still, typewritten. The ideal arrangement is to have a teleprinter communicating between the two rooms. Alternatively the question and answers can be repeated by an intermediary. The object of the game for the third player (B) is to help the interrogator. The best strategy for her is probably to give truthful answers. She can add such things as I am the woman, don't listen to him t to her answers, but it will avail nothing as the man can make mmilar remarks. We now ask the question, What will happen when a machine takes the part of A in this game Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman These questions replace our original,' Can machines think},
author = {Review, A Quarterly},
doi = {10.1038/145662c0},
file = {:home/memo/Mendeley/data/Review - 1940 - Psychology and Philosophy.pdf:pdf},
isbn = {9781402085819},
issn = {0028-0836},
journal = {Nature},
number = {236},
pages = {662--662},
pmid = {18684640},
title = {{Psychology and Philosophy}},
volume = {145},
year = {1940}
}
@article{Schroedinger1944,
abstract = {Based on lectures delivered under the auspices of the Institute [for Advanced Studies] at Trinity College, Dublin, in February 1943.},
author = {Schroedinger, Erwin},
file = {:home/memo/Mendeley/data/Schroedinger - 1944 - What is life.pdf:pdf},
isbn = {0-521-42708-8},
pages = {91},
title = {{What is life?}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=VwsRNzrcCf4C{\&}oi=fnd{\&}pg=PR7{\&}dq=What+Is+Life?{\&}ots=5HABBa0tNY{\&}sig=9ZP7tNSDLTPRTojov{\_}VQxV2evxs},
year = {1944}
}
@article{Seager,
author = {Seager, William},
file = {:home/memo/Mendeley/data/Seager - Unknown - Supervenience and Emergence.pdf:pdf},
pages = {1--39},
title = {{Supervenience and Emergence}}
}
@article{Chen2012,
author = {Chen, Cw and Hu, Mc and Cheng, Wh},
doi = {10.1145/2393347.2396433},
file = {:home/memo/Mendeley/data/Chen, Hu, Cheng - 2012 - Action tutor real-time exemplar-based sequential movement assessment with kinect sensor.pdf:pdf},
isbn = {9781450310895},
journal = {Proceedings of the 20th {\ldots}},
pages = {1263--1264},
title = {{Action tutor: real-time exemplar-based sequential movement assessment with kinect sensor}},
year = {2012}
}
@article{Wu2014,
author = {Wu, Jiaxiang},
file = {:home/memo/Mendeley/data/Wu - 2014 - Bayesian Co-Boosting for Multi-modal Gesture Recognition.pdf:pdf},
keywords = {bayesian co-boosting,feature selection,gesture recognition,hidden markov model,modal fusion,multi-},
pages = {3013--3036},
title = {{Bayesian Co-Boosting for Multi-modal Gesture Recognition}},
volume = {15},
year = {2014}
}
@article{Scherer2003,
abstract = {The current state of research on emotion effects on voice and speech is reviewed and issues for future research efforts are discussed. In particular, it is suggested to use the Brunswikian lens model as a base for research on the vocal communication of emotion. This approach allows one to model the complete process, including both encoding (expression), transmission, and decoding (impression) of vocal emotion communication. Special emphasis is placed on the conceptualization and operationalization of the major elements of the model (i.e., the speaker's emotional state, the listener's attribution, and the mediating acoustic cues). In addition, the advantages and disadvantages of research paradigms for the induction or observation of emotional expression in voice and speech and the experimental manipulation of vocal cues are discussed, using pertinent examples drawn from past and present research.},
author = {Scherer, K},
doi = {10.1016/S0167-6393(02)00084-5},
file = {:home/memo/Mendeley/data/Scherer - 2003 - Vocal communication of emotion A review of research paradigms.pdf:pdf},
isbn = {0167-6393},
issn = {01676393},
journal = {Speech Communication},
pages = {227--256},
title = {{Vocal communication of emotion: A review of research paradigms}},
volume = {40},
year = {2003}
}
@article{Fawcett2006,
abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Fawcett, Tom},
doi = {10.1016/j.patrec.2005.10.010},
file = {:home/memo/Mendeley/data/Fawcett - 2006 - An introduction to ROC analysis.pdf:pdf},
isbn = {226},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
pages = {861--874},
title = {{An introduction to ROC analysis}},
volume = {27},
year = {2006}
}
@article{Marquardt2012,
abstract = {Abstract We propose the Super Mirror , a Kinect -based system that combines the functionality of studio mirrors and prescriptive images to provide the user with instructional feedback in real-time. In this study, we developed a working prototype of this system, which records ... $\backslash$n},
author = {Marquardt, Z and Beira, J and Em, N and Paiva, I and Kox, S},
doi = {10.1145/2212776.2223682},
file = {:home/memo/Mendeley/data/Marquardt et al. - 2012 - Super Mirror a kinect interface for ballet dancers.pdf:pdf},
isbn = {9781450310161},
journal = {Proceedings of CHI 2012 Extended Abstracts},
pages = {1619--1624},
title = {{Super Mirror: a kinect interface for ballet dancers}},
url = {http://dl.acm.org/citation.cfm?id=2223682{\%}5Cnpapers://c80d98e4-9a96-4487-8d06-8e1acc780d86/Paper/p4942},
year = {2012}
}
@article{Krauss2002,
abstract = {Communication occurs when signals carry information-bearing messages between a source (or sender) and a destination (or receiver). Although all species communicate, human communication is notable for its precision and flexibility, a consequence of the uniquely human ability to use language. Language endows human communication system with the properties of semanticity, generativity, and displacement, allowing people to formulate an unlimited number of meaningful novel messages that are not tied to the immediate present. At a fundamental level verbal messages convey meanings the speaker has encoded into the words of an utterance, but a listener who has understood the utterance has gone beyond the literal meaning of the words and grasped the particular sense in which the speaker intended them to be understood. In order to do so, communicators must make their coparticipants' perspectives part of the process of formulating and interpreting messages. Thus any communicative exchange is implicitly a joint or collective activity in which meaning emerges from the participants' collaborative efforts.},
author = {Krauss, Robert M},
file = {:home/memo/Mendeley/data/Krauss - 2002 - The Psychology of Verbal Communication.pdf:pdf},
isbn = {9780080430768},
journal = {International Encyclopedia of the Social and Behavioral Sciences},
pages = {1--13},
title = {{The Psychology of Verbal Communication}},
year = {2002}
}
@article{Zhao2014,
author = {Zhao, X I N and Li, X U E and Pang, Chaoyi and Sheng, Quan Z and Wang, S E N and Ye, M A O},
file = {:home/memo/Mendeley/data/Zhao et al. - 2014 - Structured Streaming Skeleton – A New Feature for Online Human Gesture Recognition.pdf:pdf},
number = {1},
title = {{Structured Streaming Skeleton – A New Feature for Online Human Gesture Recognition}},
volume = {11},
year = {2014}
}
@article{Ang2002,
abstract = {We investigate the use of prosody for the detection of frustration and annoyance in natural human-computer dialog. In addition to prosodic features, we examine the contribution of language model information and speaking "style". Results show that a prosodic model can predict whether an utterance is neutral versus "annoyed or frustrated" with an accuracy on par with that of human interlabeler agreement. Accuracy increases when discriminating only "frustrated" from other utterances, and when using only those utterances on which labelers originally agreed. Furthermore, prosodic model accuracy degrades only slightly when using recognized versus true words. Language model features, even if based on true words, are relatively poor predictors of frustration. Finally, we find that hyperarticulation is not a good predictor of emotion; the two phenomena often occur independently.},
author = {Ang, Jeremy and Dhillon, Rajdip and Krupski, Ashley and Shriberg, Elizabeth and Stolcke, Andreas},
file = {:home/memo/Mendeley/data/Ang et al. - 2002 - Prosody-based automatic detection of annoyance and frustration in human-computer dialog.pdf:pdf},
journal = {ICSLP 2002 - {\{}I{\}}nterspeech 2002. Proceedings of the 7th International Conference on Spoken Language Processing},
keywords = {Sistemes de di{\`{a}}leg;Variaci{\'{o}};Emocions;Fon{\`{e}}tica;Pros},
number = {June},
pages = {2037--2040},
title = {{Prosody-based automatic detection of annoyance and frustration in human-computer dialog}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.4027},
year = {2002}
}
@article{Lin2012,
author = {Lin, Shih-Yao and Shie, Chuen-Kai and Chen, Shen-Chi and Hung, Yi-Ping},
doi = {10.1145/2393347.2393360},
file = {:home/memo/Mendeley/data/Lin et al. - 2012 - Action recognition for human-marionette interaction.pdf:pdf},
isbn = {9781450310895},
journal = {Proceedings of the 20th ACM international conference on Multimedia - MM '12},
pages = {39},
title = {{Action recognition for human-marionette interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2393347.2393360},
year = {2012}
}
@article{Zhao2013,
author = {Zhao, Xin and Li, Xue and Pang, Chaoyi and Zhu, Xiaofeng and Sheng, Quan Z.},
doi = {10.1145/2502081.2502103},
file = {:home/memo/Mendeley/data/Zhao et al. - 2013 - Online human gesture recognition from motion data streams.pdf:pdf},
isbn = {9781450324045},
journal = {Proceedings of the 21st ACM international conference on Multimedia - MM '13},
keywords = {depth camera,feature extraction,gesture recognition},
pages = {23--32},
title = {{Online human gesture recognition from motion data streams}},
url = {http://dl.acm.org/citation.cfm?id=2502081.2502103},
year = {2013}
}
@article{Bevilacqua2009,
abstract = {We present a HMM based system for real-time gesture analysis. The system outputs continuously parameters relative to the gesture time progression and its likelihood. These parameters are computed by comparing the performed gesture with stored reference gestures. The method relies on a detailed modeling of multidimensional temporal curves. Compared to standard HMM systems, the learning procedure is simplified using prior knowledge allowing the system to use a single example for each class. Several applications have been developed using this system in the context of music education, music and dance performances and interactive installation. Typically, the estimation of the time progression allows for the synchronization of physical gestures to sound files by time stretching/compressing audio buffers or videos.},
author = {Bevilacqua, Fr{\'{e}}d{\'{e}}ric and Zamborlin, Bruno and Sypniewski, Anthony and Schnell, Norbert and Gu{\'{e}}dy, Fabrice and Rasamimanana, Nicolas},
doi = {10.1007/978-3-642-12553-9_7},
file = {:home/memo/Mendeley/data/Bevilacqua et al. - 2009 - Continuous realtime gesture following and recognition.pdf:pdf},
isbn = {3642125522},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Gesture following,Gesture recognition,Hidden Markov Model,Interactive systems,Music},
pages = {73--84},
title = {{Continuous realtime gesture following and recognition}},
volume = {5934 LNAI},
year = {2009}
}
@article{ElKaliouby2005,
abstract = { This paper presents a system for inferring complex mental states from video of facial expressions and head gestures in real-time. The system is based on a multi-level dynamic Bayesian network classifier which models complex mental states as a number of interacting facial and head displays, identified from component-based facial features. Experimental results for 6 mental states groups- agreement, concentrating, disagreement, interested, thinking and unsure are reported. Real-time performance, unobtrusiveness and lack of preprocessing make our system particularly suitable for user-independent human computer interaction.},
author = {{El Kaliouby}, Rana and Robinson, Peter},
doi = {10.1007/0-387-27890-7_11},
file = {:home/memo/Mendeley/data/El Kaliouby, Robinson - 2005 - Real-time inference of complex mental states from facial expressions and head gestures.pdf:pdf},
isbn = {0387276971},
issn = {1063-6919},
journal = {Real-Time Vision for Human-Computer Interaction},
pages = {181--200},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
year = {2005}
}
@article{Morency2007,
author = {Morency, Louis-Philippe and Morency, Louis-Philippe and Quattoni, Ariadna and Quattoni, Ariadna and Darrell, Trevor and Darrell, Trevor},
file = {:home/memo/Mendeley/data/Morency et al. - 2007 - Latent-Dynamic Discrimiative Models for Continuous Gesture Recognition.pdf:pdf},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
title = {{Latent-Dynamic Discrimiative Models for Continuous Gesture Recognition}},
year = {2007}
}
@article{Schedel2011,
abstract = {In this paper we discuss how the band 000000Swan uses machine learning to parse complex sensor data and create intricate artistic systems for live performance. Using the Wekinator software for interactive machine learning, we have created discrete and continuous models for controlling audio and visual environments using human gestures sensed by a commercially-available sensor bow and the Microsoft Kinect. In particular, we have employed machine learning to quickly and easily prototype complex relationships between performer gesture and performative outcome.},
author = {Schedel, Margaret and Fiebrink, Rebecca and Perry, Phoenix},
file = {:home/memo/Mendeley/data/Schedel, Fiebrink, Perry - 2011 - Wekinating 000000Swan Using Machine Learning to Create and Control Complex Artistic Systems.pdf:pdf},
issn = {2220-4806},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
number = {June},
pages = {453--456},
title = {{Wekinating 000000Swan : Using Machine Learning to Create and Control Complex Artistic Systems}},
url = {http://www.nime2011.org/proceedings/papers/M10-Schedel.pdf},
year = {2011}
}
@article{Science1991,
author = {Science, Computer},
file = {:home/memo/Mendeley/data/Science - 1991 - The Experimental Study of Machine Learning.pdf:pdf},
title = {{The Experimental Study of Machine Learning}},
year = {1991}
}
@inproceedings{Quilez2008,
author = {Quilez, Inigo},
booktitle = {NVSCENE},
file = {:home/memo/Mendeley/data/Quilez - 2008 - Rendering Worlds with Two Triangles with raytracing on the GPU in 4096 bytes.pdf:pdf},
title = {{Rendering Worlds with Two Triangles with raytracing on the GPU in 4096 bytes}},
year = {2008}
}
@article{Quadro,
author = {Quadro, Nvidia},
file = {:home/memo/Mendeley/data/Quadro - Unknown - Technical Brief Features and Benefits.pdf:pdf},
title = {{Technical Brief Features and Benefits}}
}
@article{Stam,
author = {Stam, Jos},
file = {:home/memo/Mendeley/data/Stam - Unknown - Real-Time Fluid Dynamics for Games.pdf:pdf},
title = {{Real-Time Fluid Dynamics for Games}}
}
@article{Szegedy,
author = {Szegedy, Christian and Goodfellow, Ian and Bruna, Joan and Fergus, Rob},
file = {:home/memo/Mendeley/data/Szegedy et al. - Unknown - Intriguing properties of neural networks.pdf:pdf},
pages = {1--9},
title = {{Intriguing properties of neural networks}}
}
@article{Sorensen2010,
author = {Sorensen, Andrew and Gardner, Henry},
file = {:home/memo/Mendeley/data/Sorensen, Gardner - 2010 - Programming With Time Cyber-physical programming with Impromptu.pdf:pdf},
title = {{Programming With Time Cyber-physical programming with Impromptu}},
year = {2010}
}
@article{Hinton,
author = {Hinton, G E and Krizhevsky, A and Wang, S D},
file = {:home/memo/Mendeley/data/Hinton, Krizhevsky, Wang - Unknown - Transforming Auto-encoders.pdf:pdf},
keywords = {auto-encoder,invariance,shape representation},
title = {{Transforming Auto-encoders}}
}
@article{Kingma2014,
author = {Kingma, Diederik P and Welling, Max and Group, Machine Learning},
file = {:home/memo/Mendeley/data/Kingma, Welling, Group - 2014 - Efficient Gradient-Based Inference through Transformations between Bayes Nets and Neural Nets.pdf:pdf},
title = {{Efficient Gradient-Based Inference through Transformations between Bayes Nets and Neural Nets}},
year = {2014}
}
@article{Alain,
author = {Alain, Guillaume and Yosinski, Jason},
file = {:home/memo/Mendeley/data/Alain, Yosinski - Unknown - Deep Generative Stochastic Networks Trainable by Backprop.pdf:pdf},
title = {{Deep Generative Stochastic Networks Trainable by Backprop}}
}
@article{Salakhutdinov,
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
file = {:home/memo/Mendeley/data/Salakhutdinov, Hinton - Unknown - A Better Way to Pretrain Deep Boltzmann Machines.pdf:pdf},
number = {3},
pages = {1--9},
title = {{A Better Way to Pretrain Deep Boltzmann Machines}}
}
@article{Salakhutdinov2009,
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
file = {:home/memo/Mendeley/data/Salakhutdinov, Hinton - 2009 - Deep Boltzmann Machines.pdf:pdf},
number = {2},
title = {{Deep Boltzmann Machines}},
year = {2009}
}
@article{Bullock2005,
author = {Bullock, Theodore H and Bennett, Michael V L and Johnston, Daniel and Josephson, Robert and Marder, Eve and Fields, R Douglas},
file = {:home/memo/Mendeley/data/Bullock et al. - 2005 - The Neuron Doctrine , Redux.pdf:pdf},
number = {November},
pages = {791--793},
title = {{The Neuron Doctrine , Redux}},
volume = {310},
year = {2005}
}
@article{Salakhutdinov2012,
abstract = {We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent statistics are estimated using a variational approximation that tends to focus on a single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer pretraining phase that initializes the weights sensibly. The pretraining also allows the variational inference to be initialized sensibly with a single bottom-up pass. We present results on the MNIST and NORB data sets showing that deep Boltzmann machines learn very good generative models of handwritten digits and 3D objects. We also show that the features discovered by deep Boltzmann machines are a very effective way to initialize the hidden layers of feedforward neural nets, which are then discriminatively fine-tuned.},
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
doi = {10.1162/NECO_a_00311},
file = {:home/memo/Mendeley/data/Salakhutdinov, Hinton - 2012 - An efficient learning procedure for deep Boltzmann machines.pdf:pdf},
issn = {1530-888X},
journal = {Neural computation},
month = {aug},
number = {8},
pages = {1967--2006},
pmid = {22509963},
title = {{An efficient learning procedure for deep Boltzmann machines.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22509963},
volume = {24},
year = {2012}
}
@article{Perov,
archivePrefix = {arXiv},
arxivId = {arXiv:1407.2646v1},
author = {Perov, Yura and Wood, Frank},
eprint = {arXiv:1407.2646v1},
file = {:home/memo/Mendeley/data/Perov, Wood - Unknown - Learning Probabilistic Programs.pdf:pdf},
pages = {1--11},
title = {{Learning Probabilistic Programs}}
}
@article{Stollenga2014,
archivePrefix = {arXiv},
arxivId = {1407.3068},
author = {Stollenga, Marijn and Masci, Jonathan and Gomez, Faustino and Schmidhuber, J{\"{u}}rgen},
eprint = {1407.3068},
file = {:home/memo/Mendeley/data/Stollenga et al. - 2014 - Deep Networks with Internal Selective Attention through Feedback Connections.pdf:pdf},
month = {jul},
pages = {1--13},
title = {{Deep Networks with Internal Selective Attention through Feedback Connections}},
url = {http://arxiv.org/abs/1407.3068v2},
year = {2014}
}
@article{Rezende2014,
abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
archivePrefix = {arXiv},
arxivId = {1401.4082},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
eprint = {1401.4082},
file = {:home/memo/Mendeley/data/Rezende, Mohamed, Wierstra - 2014 - Stochastic Backpropagation and Approximate Inference in Deep Generative Models.pdf:pdf},
month = {jan},
title = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
url = {http://arxiv.org/abs/1401.4082},
year = {2014}
}
@article{Szegedy2013,
abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.   First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.   Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.},
archivePrefix = {arXiv},
arxivId = {1312.6199},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
eprint = {1312.6199},
file = {:home/memo/Mendeley/data/Szegedy et al. - 2013 - Intriguing properties of neural networks.pdf:pdf},
month = {dec},
pages = {1--10},
title = {{Intriguing properties of neural networks}},
url = {http://arxiv.org/abs/1312.6199},
year = {2013}
}
@article{Cook,
author = {Cook, Michael and Colton, Simon and Gow, Jeremy},
file = {:home/memo/Mendeley/data/Cook, Colton, Gow - Unknown - Initial Results From Co-operative Co-evolution for Automated Platformer Design.pdf:pdf},
keywords = {automated game design,co-operative co-evolution,procedural generation},
title = {{Initial Results From Co-operative Co-evolution for Automated Platformer Design}}
}
@article{Coltonc,
author = {Colton, Simon and Gow, Jeremy and Torres, Pedro and Cairns, Paul},
file = {:home/memo/Mendeley/data/Colton et al. - Unknown - Experiments in Objet Trouv ´ e Browsing.pdf:pdf},
title = {{Experiments in Objet Trouv ´ e Browsing}}
}
@article{Cavallo2013,
author = {Cavallo, Flaminia and Pease, Alison and Gow, Jeremy and Colton, Simon},
file = {:home/memo/Mendeley/data/Cavallo et al. - 2013 - Using Theory Formation Techniques for the Invention of Fictional Concepts.pdf:pdf},
pages = {176--183},
title = {{Using Theory Formation Techniques for the Invention of Fictional Concepts}},
year = {2013}
}
@misc{Lee2004,
abstract = {We introduce a personality inventory designed to measure six major dimensions of personality derived from lexical studies of personality structure. The HEXACO Personality Inventory (HEXACO-PI) consists of 24 facet-level personality trait scales that define the six personality factors named Honesty-Humility (H), Emotionality (E), Extraversion (X), Agreeableness (A), Conscientiousness (C), and Openness to Experience (O). In this validation study involving a sample of over 400 respondents, all HEXACO-PI scales showed high internal consistency reliabilities, conformed to the hypothesized six-factor structure, and showed adequate convergent validities with external variables. The HEXACO factor space, and the rotations of factors within that space, are discussed with reference to J.S. Wiggins' work on the circumplex. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract).},
author = {Lee, Kibeom and Ashton, Michael C.},
booktitle = {Multivariate Behavioral Research},
doi = {10.1207/s15327906mbr3902_8},
isbn = {0027-3171},
issn = {0027-3171},
pages = {329--358},
title = {{Psychometric Properties of the HEXACO Personality Inventory}},
volume = {39},
year = {2004}
}
@book{Cairns2008,
author = {Cairns, Paul and Cox, Anna L.},
publisher = {Cambridge University Press},
title = {{Research Methods for Human-Computer Interaction}},
year = {2008}
}
@article{Mori1970,
abstract = {There are mathematical functions of the form y= f (x) for which the value of y increases (or decreases) continuously with the value of x. For example, as the effort x increases, income y increases, or as a car's accelerator is pressed, the car moves faster. This kind of ... $\backslash$n},
author = {Mori, M},
doi = {10.1162/pres.16.4.337},
issn = {02721716},
journal = {Energy},
pages = {33--35},
title = {{The Uncanny Valley}},
url = {http://www.movingimages.info/digitalmedia/wp-content/uploads/2010/06/MorUnc.pdf{\%}5Cnpapers2://publication/uuid/D1D33515-2241-479C-8578-232DEF7BF003},
volume = {7},
year = {1970}
}
@article{Hennix2003,
author = {Hennix, M and Hugoson, P and Johansson, G},
file = {:home/memo/Mendeley/data/Hennix, Hugoson, Johansson - 2003 - Rag doll physics.pdf:pdf},
title = {{Rag doll physics}},
url = {http://staffwww.itn.liu.se/{~}gunjo/papers/ragdoll{\_}physics.pdf},
year = {2003}
}
@article{Strauss1990,
abstract = {Strausss, A., J. Corbin (1990) Basics of qualitative research: grounded theory procedures and techniques. London: Sage},
author = {Strauss, A and Corbin, J},
isbn = {978-1-4129-0644-9},
journal = {Qualitative Sociology},
keywords = {London,Qualitative Research,Research,grounded theory},
title = {{Basics of qualitative research: grounded theory procedure and techniques}},
volume = {13},
year = {1990}
}
@article{Strauss1994,
abstract = {THE purpose of this chapter is to give an overview of the origins, purposes, uses, and contributions of grounded theory methodology. We will not address the methodology's suggested procedures or much of the logic lying behind them, as these have been ...},
author = {Strauss, Anselm and Corbin, Juliet},
doi = {10.1007/BF00988593},
isbn = {0803946791},
journal = {Handbook of qualitative research},
keywords = {grounded theory},
pages = {273--285},
title = {{Grounded theory methodology}},
url = {http://cms.educ.ttu.edu/uploadedFiles/personnel-folder/lee-duemer/epsy-5382/documents/Grounded theory methodology.pdf{\%}22 onmousedown={\%}22return scife{\_}clk(this.href,'gga','gga','2')},
year = {1994}
}
@article{Gentile2003,
abstract = {(from the chapter) This chapter explores whether video games may have similar effects to the effects of other entertainment media. The term video game is used to describe games played on video game consoles (e.g., PlayStation), on computers, or on hand-held video game devices (e.g., GameBoy). (PsycINFO Database Record (c) 2009 APA, all rights reserved)},
author = {Gentile, D.A. and Anderson, C.A.},
isbn = {0-275-97956-3 hardcover},
issn = {0022-023X},
journal = {Media violence and children},
pages = {131--152},
pmid = {481860},
title = {{Violent video games: The newest media violence hazard}},
year = {2003}
}
@misc{Kirsh2003,
abstract = {Recent acts of extreme violence involving teens and associated links to violent video games have led to an increased interest in video game violence. Research suggests that violent video games influence aggressive behavior, aggressive affect, aggressive cognition, and physiological arousal. Anderson and Bushman [Annu. Rev. Psychol. 53 (2002) 27.] have posited a General Aggression Model (GAM) to explain the mechanism behind the link between violent video games and aggressive behavior. However, the influence of violent video games as a function of developmental changes across adolescence has yet to be addressed. The purpose of this review is to integrate the GAM with developmental changes that occur across adolescence. ?? 2002 Elsevier Science Ltd. All rights reserved.},
author = {Kirsh, Steven J.},
booktitle = {Aggression and Violent Behavior},
doi = {10.1016/S1359-1789(02)00056-3},
isbn = {1359-1789},
issn = {13591789},
keywords = {Adolescence,Risk factors,Video games},
pages = {377--389},
title = {{The effects of violent video games on adolescents: The overlooked influence of development}},
volume = {8},
year = {2003}
}
@article{Anderson2010,
abstract = {Meta-analytic procedures were used to test the effects of violent video games on aggressive behavior, aggressive cognition, aggressive affect, physiological arousal, empathy/desensitization, and prosocial behavior. Unique features of this meta-analytic review include (a) more restrictive methodological quality inclusion criteria than in past meta-analyses; (b) cross-cultural comparisons; (c) longitudinal studies for all outcomes except physiological arousal; (d) conservative statistical controls; (e) multiple moderator analyses; and (f) sensitivity analyses. Social-cognitive models and cultural differences between Japan and Western countries were used to generate theory-based predictions. Meta-analyses yielded significant effects for all 6 outcome variables. The pattern of results for different outcomes and research designs (experimental, cross-sectional, longitudinal) fit theoretical predictions well. The evidence strongly suggests that exposure to violent video games is a causal risk factor for increased aggressive behavior, aggressive cognition, and aggressive affect and for decreased empathy and prosocial behavior. Moderator analyses revealed significant research design effects, weak evidence of cultural differences in susceptibility and type of measurement effects, and no evidence of sex differences in susceptibility. Results of various sensitivity analyses revealed these effects to be robust, with little evidence of selection (publication) bias.},
author = {Anderson, Craig A and Shibuya, Akiko and Ihori, Nobuko and Swing, Edward L and Bushman, Brad J and Sakamoto, Akira and Rothstein, Hannah R and Saleem, Muniba},
doi = {10.1037/a0018251},
isbn = {1939-1455 (Electronic); 0033-2909 (Print)},
issn = {0033-2909},
journal = {Psychological bulletin},
pages = {151--173},
pmid = {20192553},
title = {{Violent video game effects on aggression, empathy, and prosocial behavior in eastern and western countries: a meta-analytic review.}},
volume = {136},
year = {2010}
}
@article{Anderson2001,
abstract = {Research on exposure to television and movie violence suggests that playing violent video games will increase aggressive behavior. A metaanalytic review of the video-game research literature reveals that violent video games increase aggressive behavior in children and young adults. Experimental and nonexperimental studies with males and females in laboratory and field settings support this conclusion. Analyses also reveal that exposure to violent video games increases physiological arousal and aggression-related thoughts and feelings. Playing violent video games also decreases prosocial behavior.},
archivePrefix = {arXiv},
arxivId = {117},
author = {Anderson, C A and Bushman, B J},
doi = {10.1111/1467-9280.00366},
eprint = {117},
isbn = {1467-9280 (Electronic); 0956-7976 (Print)},
issn = {0956-7976},
journal = {Psychological science : a journal of the American Psychological Society / APS},
pages = {353--359},
pmid = {11554666},
title = {{Effects of violent video games on aggressive behavior, aggressive cognition, aggressive affect, physiological arousal, and prosocial behavior: a meta-analytic review of the scientific literature.}},
volume = {12},
year = {2001}
}
@article{Manfredi2014,
abstract = {The goal of the present study was to shed some light on a particular kind of humour, called slapstick, by measuring brain bioelectrical activity during the perception of funny vs. non-funny pictures involving misfortunate circumstances. According to our hypothesis, the element mostly providing a comic feature in a misfortunate situation is the facial expression of the victims: the observer׳s reaction will usually be laughing only if the victims will show a funny bewilderment face and not a painful or anger expression. Several coloured photographs depicting people involved in misfortunate situations were presented to 30 Italian healthy volunteers, while their EEG was recorded. Three different situations were considered: people showing a painful or an angry expression (Affective); people showing a bewilderment expression and, so, a comic look (Comic); people engaged in similar misfortunate situations but with no face visible (No Face). Results showed that the mean amplitude of both the posterior N170 and anterior N220 components was much larger in amplitude to comic pictures, than the other stimuli. This early response could be considered the first identification of a comic element and evidence of the compelling and automatic response that usually characterizes people amused reaction during a misfortune. In addition, we observed a larger P300 amplitude in response to comic than affective pictures, probably reflecting a more conscious processing of the comic element. Finally, no face pictures elicited an anteriorly distributed N400, which might reflect the effort to comprehend the nature of the situation displayed without any affective facial information, and a late positivity, possibly indexing a re-analysis processing of the unintelligible misfortunate situation (comic or unhappy) depicted in the No Face stimuli. These data support the hypothesis that the facial expression of the victims acts as a specific trigger for the amused feeling that observers usually experience when someone falls down. Overall, the data indicate the existence of a neural circuit that is capable of recognize and appreciate the comic element of a misfortunate situation in a group of young adults.},
author = {Manfredi, Mirella and Adorni, Roberta and Proverbio, Alice},
doi = {10.1016/j.neuropsychologia.2014.06.029},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Manfredi, Adorni, Proverbio - 2014 - Why do we laugh at misfortunes An electrophysiological exploration of comic situation processing.pdf:pdf},
issn = {1873-3514},
journal = {Neuropsychologia},
keywords = {ERPs,Emotion,Facial expression,Humour,Misfortune},
month = {aug},
pages = {324--34},
pmid = {25014163},
publisher = {Elsevier},
title = {{Why do we laugh at misfortunes? An electrophysiological exploration of comic situation processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25014163},
volume = {61},
year = {2014}
}
@article{Savage2004,
author = {Savage, Joanne},
doi = {10.1016/j.avb.2003.10.001},
file = {:home/memo/Mendeley/data/Savage - 2004 - Does viewing violent media really cause criminal violence A methodological review.pdf:pdf},
issn = {13591789},
journal = {Aggression and Violent Behavior},
keywords = {media violence,television violence,violent crime},
month = {nov},
number = {1},
pages = {99--128},
title = {{Does viewing violent media really cause criminal violence? A methodological review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1359178903000855},
volume = {10},
year = {2004}
}
@article{Chraif2011,
author = {Chraif, Mihaela and Aniţei, Mihai},
doi = {10.1016/j.sbspro.2011.10.091},
file = {:home/memo/Mendeley/data/Chraif, Aniţei - 2011 - The Physiological Effects of Cartoons Blood Scenes on the Youngsters in Romania.pdf:pdf},
isbn = {0407688110},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {1,40s,and many others,comedy scenes,grew up and mature,gsr response,heart rate response,popey the saylor man,scenes,since the,slapstik scenes,tens of generations have,the coloured and spectacular,theoretical framework,tom and jerry,tv entertains us with,violent cartoons with blood,with,woody woodspeker show,world of cartoons},
month = {jan},
pages = {465--470},
title = {{The Physiological Effects of Cartoons Blood Scenes on the Youngsters in Romania}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042811019161},
volume = {30},
year = {2011}
}
@article{Kirsh2006,
author = {Kirsh, Steven J.},
doi = {10.1016/j.avb.2005.10.002},
file = {:home/memo/Mendeley/data/Kirsh - 2006 - Cartoon violence and aggression in youth.pdf:pdf},
issn = {13591789},
journal = {Aggression and Violent Behavior},
keywords = {aggressive behavior,cartoon violence,youth},
month = {nov},
number = {6},
pages = {547--557},
title = {{Cartoon violence and aggression in youth}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1359178905000698},
volume = {11},
year = {2006}
}
@article{Bandura1963,
author = {Bandura, Albert and Ross, Dorothea and Ross, Sheila a.},
doi = {10.1037/h0048687},
file = {:home/memo/Mendeley/data/Bandura, Ross, Ross - 1963 - Imitation of film-mediated aggressive models.pdf:pdf},
issn = {0096-851X},
journal = {The Journal of Abnormal and Social Psychology},
number = {1},
pages = {3--11},
title = {{Imitation of film-mediated aggressive models.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0048687},
volume = {66},
year = {1963}
}
@article{Hertzmann2011,
author = {Hertzmann, Aaron and Zordan, Victor},
doi = {10.1109/MCG.2011.61},
file = {:home/memo/Mendeley/data/Hertzmann, Zordan - 2011 - Physics-Based Characters.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
month = {jul},
number = {4},
pages = {20--21},
title = {{Physics-Based Characters}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5934838},
volume = {31},
year = {2011}
}
@article{Mulley2007,
author = {Mulley, Gabe and Bittarelli, Matt},
file = {:home/memo/Mendeley/data/Mulley, Bittarelli - 2007 - Ragdoll Physics.pdf:pdf},
journal = {New York},
title = {{Ragdoll Physics}},
url = {http://www.cs.rpi.edu/{~}cutler/classes/advancedgraphics/S07/final{\_}projects/mulley{\_}bittarelli.pdf},
year = {2007}
}
@article{Jakobsen2001,
author = {Jakobsen, Thomas},
file = {:home/memo/Mendeley/data/Jakobsen - 2001 - Advanced character physics.pdf:pdf},
journal = {Game Developers Conference},
pages = {1--16},
title = {{Advanced character physics}},
url = {http://www.pagines.ma1.upc.edu/{~}susin/files/AdvancedCharacterPhysics.pdf},
year = {2001}
}
@article{Cairns2014a,
address = {New York, New York, USA},
author = {Cairns, Paul and Li, Jing and Wang, Wendy and Nordin, a. Imran},
doi = {10.1145/2556288.2557345},
file = {:home/memo/Mendeley/data/Cairns et al. - 2014 - The influence of controllers on immersion in mobile games.pdf:pdf},
isbn = {9781450324731},
journal = {Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14},
pages = {371--380},
publisher = {ACM Press},
title = {{The influence of controllers on immersion in mobile games}},
url = {http://dl.acm.org/citation.cfm?doid=2556288.2557345},
year = {2014}
}
@article{Chapter2008,
author = {Chapter, Book},
file = {:home/memo/Mendeley/data/Chapter - 2008 - A qualititative approach to HCI research Book Chapter A qualitative approach to HCI research.pdf:pdf},
isbn = {9780521870122},
title = {{A qualititative approach to HCI research Book Chapter A qualitative approach to HCI research}},
year = {2008}
}
@article{Seah1904,
author = {Seah, May-li and Place, Alfred and Cairns, Paul},
file = {:home/memo/Mendeley/data/Seah, Place, Cairns - 1904 - From I mmersion to A ddiction in V ideogames.pdf:pdf},
keywords = {1,addiction,and game-,commonly used by gamers,engagement,immersion,immersion and addiction,immersion is a term,videogames},
pages = {55--63},
title = {{From I mmersion to A ddiction in V ideogames}},
year = {1904}
}
@article{Cheng2005,
address = {New York, New York, USA},
author = {Cheng, Kevin and Cairns, Paul a.},
doi = {10.1145/1056808.1056894},
file = {:home/memo/Mendeley/data/Cheng, Cairns - 2005 - Behaviour, realism and immersion in games.pdf:pdf},
isbn = {1595930027},
journal = {CHI '05 extended abstracts on Human factors in computing systems - CHI '05},
pages = {1272},
publisher = {ACM Press},
title = {{Behaviour, realism and immersion in games}},
url = {http://portal.acm.org/citation.cfm?doid=1056808.1056894},
year = {2005}
}
@article{Thimbleby2001,
author = {Thimbleby, Harold and Cairns, Paul and Jones, Matt},
doi = {10.1145/376929.376941},
file = {:home/memo/Mendeley/data/Thimbleby, Cairns, Jones - 2001 - Usability analysis with Markov models.pdf:pdf},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
month = {jun},
number = {2},
pages = {99--132},
title = {{Usability analysis with Markov models}},
url = {http://portal.acm.org/citation.cfm?doid=376929.376941},
volume = {8},
year = {2001}
}
@article{Jennett2008,
author = {Jennett, Charlene and Cox, Anna L. and Cairns, Paul and Dhoparee, Samira and Epps, Andrew and Tijs, Tim and Walton, Alison},
doi = {10.1016/j.ijhcs.2008.04.004},
file = {:home/memo/Mendeley/data/Jennett et al. - 2008 - Measuring and defining the experience of immersion in games.pdf:pdf},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {affect,eye tracking,games,immersion,pace},
month = {sep},
number = {9},
pages = {641--661},
title = {{Measuring and defining the experience of immersion in games}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581908000499},
volume = {66},
year = {2008}
}
@article{Brown2004,
address = {New York, New York, USA},
author = {Brown, Emily and Cairns, Paul},
doi = {10.1145/985921.986048},
file = {:home/memo/Mendeley/data/Brown, Cairns - 2004 - A grounded investigation of game immersion.pdf:pdf},
isbn = {1581137036},
journal = {Extended abstracts of the 2004 conference on Human factors and computing systems - CHI '04},
pages = {1297},
publisher = {ACM Press},
title = {{A grounded investigation of game immersion}},
url = {http://portal.acm.org/citation.cfm?doid=985921.986048},
year = {2004}
}
@article{Andersen2011,
author = {Andersen, Erik and Liu, YE and Snider, Richard},
file = {:home/memo/Mendeley/data/Andersen, Liu, Snider - 2011 - Placing a value on aesthetics in online casual games.pdf:pdf},
isbn = {9781450302678},
journal = {Proceedings of the {\ldots}},
pages = {1275--1278},
title = {{Placing a value on aesthetics in online casual games}},
url = {http://dl.acm.org/citation.cfm?id=1979131},
year = {2011}
}
@article{Klimmt2007,
abstract = {This article explores video game enjoyment originated by games' key characteristic, interactivity. An online experiment (N=500) tested experiences of effectance (perceived influence on the game world) and of being in control as mechanisms that link interactivity to enjoyment. A video game was manipulated to either allow normal play, reduce perceived effectance, or reduce perceived control. Enjoyment ratings suggest that effectance is an important factor in video game enjoyment but that the relationship between control of the game situation and enjoyment is more complex.},
author = {Klimmt, Christoph and Hartmann, Tilo and Frey, Andreas},
doi = {10.1089/cpb.2007.9942},
file = {:home/memo/Mendeley/data/Klimmt, Hartmann, Frey - 2007 - Effectance and control as determinants of video game enjoyment.pdf:pdf},
issn = {1094-9313},
journal = {Cyberpsychology {\&} behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},
keywords = {Adolescent,Adult,Aged,Consumer Satisfaction,Happiness,Humans,Middle Aged,Play and Playthings,User-Computer Interface,Video Games},
month = {dec},
number = {6},
pages = {845--7},
pmid = {18085976},
title = {{Effectance and control as determinants of video game enjoyment.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18085976},
volume = {10},
year = {2007}
}
@article{Ivory2009,
author = {Ivory, JD and Williams, Dmitri},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ivory, Williams - 2009 - Good clean fun A content analysis of profanity in video games and its prevalence across game systems and rating.pdf:pdf},
journal = {CyberPsychology {\&} {\ldots}},
number = {4},
title = {{Good clean fun? A content analysis of profanity in video games and its prevalence across game systems and ratings}},
url = {http://online.liebertpub.com/doi/abs/10.1089/cpb.2008.0337},
volume = {12},
year = {2009}
}
@article{Cairns2014,
author = {Cairns, Paul},
file = {:home/memo/Mendeley/data/Cairns - 2014 - Experimental Methods in Human-Computer Interaction.pdf:pdf},
title = {{Experimental Methods in Human-Computer Interaction}},
year = {2014}
}
@article{Cheung2011,
author = {Cheung, Gifford and Huang, J},
file = {:home/memo/Mendeley/data/Cheung, Huang - 2011 - Starcraft from the stands understanding the game spectator.pdf:pdf},
isbn = {9781450302678},
journal = {Proceedings of the SIGCHI Conference on Human {\ldots}},
pages = {763--772},
title = {{Starcraft from the stands: understanding the game spectator}},
url = {http://dl.acm.org/citation.cfm?id=1979053},
year = {2011}
}
@article{Grierson2013,
author = {Grierson, Mick and Kiefer, Chris},
file = {:home/memo/Mendeley/data/Grierson, Kiefer - 2013 - NoiseBear a wireless malleable multiparametric controller for.pdf:pdf},
isbn = {9781450319522},
title = {{NoiseBear: a wireless malleable multiparametric controller for}},
year = {2013}
}
@article{Chapman1930,
author = {Chapman, Dominik},
file = {:home/memo/Mendeley/data/Chapman - 1930 - N-gon Waves – Audio Applications of the Geometry of Regular Polygons in the Time Domain.pdf:pdf},
title = {{N-gon Waves – Audio Applications of the Geometry of Regular Polygons in the Time Domain}},
year = {1930}
}
@phdthesis{Grierson2005,
author = {Grierson, MS},
file = {:home/memo/Mendeley/data/Grierson - 2005 - Audiovisual composition.pdf:pdf},
pages = {1--145},
title = {{Audiovisual composition}},
url = {http://www.strangeloop.co.uk/Dr. M.Grierson - Audiovisual Composition Thesis.pdf},
year = {2005}
}
@article{Grierson2009,
author = {Grierson, Mick and Grierson, M},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grierson, Grierson - 2009 - PLUNDERMATICS REAL-TIME INTERACTIVE MEDIA SEGMENTATION FOR AUDIOVISUAL ANALYSIS , COMPOSITION AND PERFORMAN.pdf:pdf},
pages = {276--284},
title = {{PLUNDERMATICS : REAL-TIME INTERACTIVE MEDIA SEGMENTATION FOR AUDIOVISUAL ANALYSIS , COMPOSITION AND PERFORMANCE}},
year = {2009}
}
@misc{Grierson2010,
author = {Grierson, Mick},
file = {:home/memo/Mendeley/data/Grierson - 2010 - Maximillian A cross platform C Audio Synthesis Library for artists learning to program.pdf:pdf},
title = {{Maximillian: A cross platform C++ Audio Synthesis Library for artists learning to program}},
year = {2010}
}
@article{Grierson2007,
author = {Grierson, Mick},
file = {:home/memo/Mendeley/data/Grierson - 2007 - Noisescape an interactive 3D audiovisual multi-user composition environment.pdf:pdf},
journal = {The World as Virtual Environment, Trans-Media- {\ldots}},
pages = {2--5},
title = {{Noisescape: an interactive 3D audiovisual multi-user composition environment}},
url = {http://doc.gold.ac.uk/{~}mus02mg/wp-content/uploads/drm-grierson-icmc-submissioncr4page-2007.pdf},
year = {2007}
}
@article{Grierson2008,
author = {Grierson, M},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grierson - 2008 - Composing with brainwaves minimal trial P300b recognition as an indication of subjective preference for the control of.pdf:pdf},
journal = {Proceedings of International Cryogenic Materials {\ldots}},
title = {{Composing with brainwaves: minimal trial P300b recognition as an indication of subjective preference for the control of a musical instrument}},
url = {http://classes.berklee.edu/mbierylo/ICMC08/defevent/papers/cr1450.pdf},
year = {2008}
}
@article{Dickey2006,
author = {Dickey, Michele D.},
doi = {10.1111/j.1467-8535.2006.00561.x},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dickey - 2006 - Girl gamers the controversy of girl games and the relevance of female-oriented game design for instructional design.pdf:pdf},
issn = {00071013},
journal = {British Journal of Educational Technology},
month = {sep},
number = {5},
pages = {785--793},
title = {{Girl gamers: the controversy of girl games and the relevance of female-oriented game design for instructional design}},
url = {http://doi.wiley.com/10.1111/j.1467-8535.2006.00561.x},
volume = {37},
year = {2006}
}
@article{Breuer2014,
author = {Breuer, Johannes and Festl, Ruth and Quandt, Thorsten},
doi = {10.1080/08824096.2014.907146},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breuer, Festl, Quandt - 2014 - Aggression and Preference for First-Person Shooter and Action Games Data From a Large-Scale Survey of Ger.pdf:pdf},
issn = {0882-4096},
journal = {Communication Research Reports},
month = {apr},
number = {2},
pages = {183--196},
title = {{Aggression and Preference for First-Person Shooter and Action Games: Data From a Large-Scale Survey of German Gamers Aged 14 and Above}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08824096.2014.907146},
volume = {31},
year = {2014}
}
@phdthesis{Kirk2014,
author = {Kirk, JF},
file = {:home/memo/Mendeley/data/Kirk - 2014 - Blaming Halo The Effects of Violent Video Games and What Should Be Done about Them.pdf:pdf},
title = {{Blaming Halo: The Effects of Violent Video Games and What Should Be Done about Them}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:No+Title{\#}0 http://digitalcommons.liberty.edu/honors/460/},
year = {2014}
}
@phdthesis{Plante2014,
author = {Plante, C},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Plante - 2014 - Getting into the Game The Precursors of Immersion into Violent Video Games and the Effect of Immersion on Post-Game Aggr.pdf:pdf},
title = {{Getting into the Game: The Precursors of Immersion into Violent Video Games and the Effect of Immersion on Post-Game Aggression}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:No+Title{\#}0 https://uwspace.uwaterloo.ca/handle/10012/8681},
year = {2014}
}
@article{Doyle2014,
author = {Doyle, Amanda},
file = {:home/memo/Mendeley/data/Doyle - 2014 - Violent video games, empathy and indirect aggression Is there an association.pdf:pdf},
number = {March},
title = {{Violent video games, empathy and indirect aggression; Is there an association?}},
year = {2014}
}
@article{Tamamiya2014,
abstract = {The current study examined the long-term effects of video game violence on aggressiveness and facial expression recognition using multiple measures. In Experiment 1, participants unfamiliar with video games were randomly assigned to play a violent or nonviolent video game for four weeks. Before and after the game play interval, event-related potentials (ERP) evoked by facial expressions were recorded, and aggressiveness was measured with a questionnaire. Results showed that playing a violent video game delayed peak latency of a positive component of the ERP evoked by angry faces and increased aggressiveness among male participants. Experiment 2 included a 3-month follow-up assessment. Results showed preservation of delayed neural activity, while levels of aggressiveness diminished to some extent. These findings highlight differential aspects regarding the long-term effects of playing a violent video game: more enduring for facial expression recognition and short-lived for aggressiveness.},
author = {Tamamiya, Yoshiyuki and Matsuda, Goh and Hiraki, Kazuo},
file = {:home/memo/Mendeley/data/Tamamiya, Matsuda, Hiraki - 2014 - Relationship between Video Game Violence and Long-Term Neuropsychological Outcomes.pdf:pdf},
keywords = {Violent Media, Facial Expression Recognition, Aggr,aggression,erp,event-related potential,facial expression recognition,violent media},
number = {September},
pages = {1477--1487},
title = {{Relationship between Video Game Violence and Long-Term Neuropsychological Outcomes}},
year = {2014}
}
@article{Landau2014,
author = {Landau, LD},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Landau - 2014 - Violent video games, mass shootings, and the supreme Court Lessons for the legal community in the wake of recent free sp.pdf:pdf},
journal = {Zhurnal Eksperimental'noi i Teoreticheskoi Fiziki},
keywords = {17,2014 by the regents,586,all rights,california,electronic,issn 1933 - 4192,issn 1933 - 4206,new criminal law review,number 4,of the university of,pps 553,stetson university,supreme court,video games,violence,vol},
number = {4},
pages = {553--586},
title = {{Violent video games, mass shootings, and the supreme Court: Lessons for the legal community in the wake of recent free speech cases and mass shootings}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:No+Title{\#}0},
volume = {17},
year = {2014}
}
@article{Gentile2004,
abstract = {Video games have become one of the favorite activities of American children. A growing body of research is linking violent video game play to aggressive cognitions, attitudes, and behaviors. The first goal of this study was to document the video games habits of adolescents and the level of parental monitoring of adolescent video game use. The second goal was to examine associations among violent video game exposure, hostility, arguments with teachers, school grades, and physical fights. In addition, path analyses were conducted to test mediational pathways from video game habits to outcomes. Six hundred and seven 8th- and 9th-grade students from four schools participated. Adolescents who expose themselves to greater amounts of video game violence were more hostile, reported getting into arguments with teachers more frequently, were more likely to be involved in physical fights, and performed more poorly in school. Mediational pathways were found such that hostility mediated the relationship between violent video game exposure and outcomes. Results are interpreted within and support the framework of the General Aggression Model. ?? 2003 The Association for Professionals in Services for Adolescents. Published by Elsevier Ltd. All rights reserved.},
author = {Gentile, Douglas A. and Lynch, Paul J. and Linder, Jennifer Ruh and Walsh, David A.},
doi = {10.1016/j.adolescence.2003.10.002},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gentile et al. - 2004 - The effects of violent video game habits on adolescent hostility, aggressive behaviors, and school performance.pdf:pdf},
isbn = {0140-1971},
issn = {01401971},
journal = {Journal of Adolescence},
keywords = {Aggression,Media violence,Video games},
pages = {5--22},
pmid = {15013257},
title = {{The effects of violent video game habits on adolescent hostility, aggressive behaviors, and school performance}},
volume = {27},
year = {2004}
}
@misc{Funk2004,
abstract = {It is believed that repeated exposure to real-life and to entertainment violence may alter cognitive, affective, and behavioral processes, possibly leading to desensitization. The goal of the present study was to determine if there are relationships between real-life and media violence exposure and desensitization as reflected in related characteristics. One hundred fifty fourth and fifth graders completed measures of real-life violence exposure, media violence exposure, empathy, and attitudes towards violence. Regression analyses indicated that only exposure to video game violence was associated with (lower) empathy. Both video game and movie violence exposure were associated with stronger proviolence attitudes. The active nature of playing video games, intense engagement, and the tendency to be translated into fantasy play may explain negative impact, though causality was not investigated in the present design. The samples' relatively low exposure to real-life violence may have limited the identification of relationships. Although difficult to quantify, desensitization to violence should be further studied using related characteristics as in the present study. Individual differences and causal relationships should also be examined. ?? 2003 The Association for Professionals in Services for Adolescents. Published by Elsevier Ltd. All rights reserved.},
author = {Funk, Jeanne B. and Baldacci, Heidi Bechtoldt and Pasold, Tracie and Baumgardner, Jennifer},
booktitle = {Journal of Adolescence},
doi = {10.1016/j.adolescence.2003.10.005},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Funk et al. - 2004 - Violence exposure in real-life, video games, television, movies, and the internet Is there desensitization.pdf:pdf},
isbn = {0140-1971 (Print) 0140-1971 (Linking)},
issn = {01401971},
pages = {23--39},
pmid = {15013258},
title = {{Violence exposure in real-life, video games, television, movies, and the internet: Is there desensitization?}},
volume = {27},
year = {2004}
}
@article{Dill1998,
abstract = {The popularity of video games, especially violent video games, has reached phenomenal proportions. The theoretical line of reasoning that hypothesizes a causal relationship between violent video-game play and aggression draws on the very large literature on media violence effects. Additionally, there are theoretical reasons to believe that video game effects should be stronger than movie or television violence effects. This paper outlines what is known about the relationship between violent video-game playing and aggression. The available literature on virtual reality effects on aggression is discussed as well. The preponderance of the evidence from the existing literature suggests that exposure to video-game violence increases aggressive behavior and other aggression-related phenomena. However, the paucity of empirical data, coupled with a variety of methodological problems and inconsistencies in these data, clearly demonstrate the need for additional research. (C) 1998 Elsevier Science Ltd.},
author = {Dill, K E and Dill, J C},
doi = {Doi 10.1016/S1359-1789(97)00001-3},
file = {:home/memo/Mendeley/data/Dill, Dill - 1998 - Video game violence A review of the empirical literature.pdf:pdf},
isbn = {1359-1789},
issn = {1359-1789},
journal = {Aggression and Violent Behavior},
keywords = {adolescents,aggression,aggressive-behavior,chemotherapy,children,computer games,distraction,performance,personality,playing violent,thoughts,video games,violence,virtual reality},
pages = {407--428},
title = {{Video game violence: A review of the empirical literature}},
volume = {3},
year = {1998}
}
@article{Ferguson2011,
abstract = {The potential influence of violent video games on youth violence remains an issue of concern for psychologists, policymakers and the general public. Although several prospective studies of video game violence effects have been conducted, none have employed well validated measures of youth violence, nor considered video game violence effects in context with other influences on youth violence such as family environment, peer delinquency, and depressive symptoms. The current study builds upon previous research in a sample of 302 (52.3{\%} female) mostly Hispanic youth. Results indicated that current levels of depressive symptoms were a strong predictor of serious aggression and violence across most outcome measures. Depressive symptoms also interacted with antisocial traits so that antisocial individuals with depressive symptoms were most inclined toward youth violence. Neither video game violence exposure, nor television violence exposure, were prospective predictors of serious acts of youth aggression or violence. These results are put into the context of criminological data on serious acts of violence among youth.},
author = {Ferguson, Christopher J.},
doi = {10.1007/s10964-010-9610-x},
file = {:home/memo/Mendeley/data/Ferguson - 2011 - Video Games and Youth Violence A Prospective Analysis in Adolescents.pdf:pdf},
isbn = {1096401096},
issn = {00472891},
journal = {Journal of Youth and Adolescence},
keywords = {Adolescence,Aggression,Computer games,Mass media,Violence},
pages = {377--391},
pmid = {21161351},
title = {{Video Games and Youth Violence: A Prospective Analysis in Adolescents}},
volume = {40},
year = {2011}
}
@article{Bartholow2005,
abstract = {Research has shown that exposure to violent video games causes increases in aggression, but the mechanisms of this effect have remained elusive. Also, potential differences in short-term and long-term exposure are not well understood. An initial correlational study shows that video game violence exposure (VVE) is positively correlated with self-reports of aggressive behavior and that this relation is robust to controlling for multiple aspects of personality. A lab experiment showed that individuals low in VVE behave more aggressively after playing a violent video game than after a nonviolent game but that those high in VVE display relatively high levels of aggression regardless of game content. Mediational analyses show that trait hostility, empathy, and hostile perceptions partially account for the VVE effect on aggression. These findings suggest that repeated exposure to video game violence increases aggressive behavior in part via changes in cognitive and personality factors associated with desensitization.},
author = {Bartholow, Bruce D and Sestir, Marc A and Davis, Edward B},
doi = {10.1177/0146167205277205},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bartholow, Sestir, Davis - 2005 - Correlates and consequences of exposure to video game violence hostile personality, empathy, and aggre.pdf:pdf},
isbn = {0146-1672},
issn = {0146-1672},
journal = {Personality and social psychology bulletin},
pages = {1573--1586},
pmid = {16207775},
title = {{Correlates and consequences of exposure to video game violence: hostile personality, empathy, and aggressive behavior.}},
volume = {31},
year = {2005}
}
@misc{Adachi2011,
abstract = {Objective: This study is the first to our knowledge to isolate the effect of video game violence and competetiveness on aggressive behavior. Method: In Piolot Study I, a violen and nonviolent video game were matches on competetiveness, difficulty, and pace of action, and the effect of each game on aggressive behaviorwas then compared using an unambiguous measure of aggressive behavior (i.e. the Hot Sauce Paradigm) in Experiment I. In Piolt Study II, competetiveness was isolated by matching games on difficulty and pace of action, and systematically controlling for violence. The effect of video game competetiveness on aggressive behavior was then examined in Experiment II. Results: We found that video game violence was not sufficient to elevate aggressive behavior when compared with a nonviolent video game, and that more competeive games produced greater levels of aggressive behavior, irrespective of the amount of violence in the games. Conclusions: It appears that competetition, not violence, may be the video game characteristic that has the greatest influence on aggressive behavior. Future research is needed to explore the mechanism through which video game conpetetitiveness influences aggressive behavior, as well as whether this relation holds in the long-term.},
author = {Adachi, Paul J. C. and Willoughby, Teena},
booktitle = {Psychology of Violence},
doi = {10.1037/a0024908},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adachi, Willoughby - 2011 - The effect of video game competition and violence on aggressive behavior Which characteristic has the greate.pdf:pdf},
isbn = {2152-0828},
issn = {2152-0828},
pages = {259--274},
title = {{The effect of video game competition and violence on aggressive behavior: Which characteristic has the greatest influence?}},
volume = {1},
year = {2011}
}
@article{Bartholow2006,
abstract = {Numerous studies have shown that exposure to media violence increases aggression, though the mechanisms of this effect have remained elusive. One theory posits that repeated exposure to media violence desensitizes viewers to real world violence, increasing aggression by blunting aversive reactions to violence and removing normal inhibitions against aggression. Theoretically, violence desensitization should be reflected in the amplitude of the P300 component of the event-related brain potential (ERP), which has been associated with activation of the aversive motivational system. In the current study, violent images elicited reduced P300 amplitudes among violent, as compared to nonviolent video game players. Additionally, this reduced brain response predicted increased aggressive behavior in a later task. Moreover, these effects held after controlling for individual differences in trait aggressiveness. These data are the first to link media violence exposure and aggressive behavior to brain processes hypothetically associated with desensitization. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
author = {Bartholow, Bruce D. and Bushman, Brad J. and Sestir, Marc A.},
doi = {10.1016/j.jesp.2005.08.006},
file = {:home/memo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bartholow, Bushman, Sestir - 2006 - Chronic violent video game exposure and desensitization to violence Behavioral and event-related bra.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Aggression,Brain,Desensitization,Event-related potential ERP,Habituation,P300,Video games,Violent media},
pages = {532--539},
title = {{Chronic violent video game exposure and desensitization to violence: Behavioral and event-related brain potential data}},
volume = {42},
year = {2006}
}
@article{Funk2003,
abstract = {Relationships between short- and long-term exposure to violent video games and desensitization, as measured through components of moral evaluation, were examined. Sixty-six children aged 5-12 years old completed questionnaires assessing video game experience and preferences and empathy and attitudes toward violence. The children played a violent or nonviolent video game and then responded to vignettes about everyday occurrences. Vignette responses were coded for aggression and empathy. Preexisting empathy and attitudes towards violence were positively related to the corresponding vignette scores. Long-term exposure to violent video games contributed to lower empathy vignette scores. Playing a violent versus a nonviolent game did not affect vignette responses. Results suggest that long-term exposure to violent video games may be associated with desensitization as reflected in lower empathy, although the direction of causality remains unclear. ?? 2003 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {137},
author = {Funk, Jeanne B. and Buchman, Debra D. and Jenks, Jennifer and Bechtoldt, Heidi},
doi = {10.1016/S0193-3973(03)00073-X},
eprint = {137},
file = {:home/memo/Mendeley/data/Funk et al. - 2003 - Playing violent video games, desensitization, and moral evaluation in children.pdf:pdf},
isbn = {0193-3973},
issn = {01933973},
journal = {Journal of Applied Developmental Psychology},
keywords = {Children,Desensitization,Moral development,Video games,Violence},
pages = {413--436},
title = {{Playing violent video games, desensitization, and moral evaluation in children}},
volume = {24},
year = {2003}
}
@misc{Anderson2004,
abstract = {This article presents a brief overview of existing research on the effects of exposure to violent video games. An updated meta-analysis reveals that exposure to violent video games is significantly linked to increases in aggressive behaviour, aggressive cognition, aggressive affect, and cardiovascular arousal, and to decreases in helping behaviour. Experimental studies reveal this linkage to be causal. Correlational studies reveal a linkage to serious, real-world types of aggression. Methodologically weaker studies yielded smaller effect sizes than methodologically stronger studies, suggesting that previous meta-analytic studies of violent video games underestimate the true magnitude of observed deleterious effects on behaviour, cognition, and affect. ?? 2003 The Association for Professionals in Services for Adolescents. Published by Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {504},
author = {Anderson, Craig A.},
booktitle = {Journal of Adolescence},
doi = {10.1016/j.adolescence.2003.10.009},
eprint = {504},
file = {:home/memo/Mendeley/data/Anderson - 2004 - An update on the effects of playing violent video games.pdf:pdf},
isbn = {0140-1971},
issn = {01401971},
pages = {113--122},
pmid = {15013264},
title = {{An update on the effects of playing violent video games}},
volume = {27},
year = {2004}
}
@article{Mandler1992,
author = {Mandler, Jean M.},
doi = {10.1037//0033-295X.99.4.587},
file = {:home/memo/Mendeley/data/Mandler - 1992 - How to build a baby II. Conceptual primitives.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
number = {4},
pages = {587--604},
title = {{How to build a baby: II. Conceptual primitives.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.99.4.587},
volume = {99},
year = {1992}
}
@misc{Spector2012,
abstract = {Paper sobre a forma como a google faz investiga{\c{c}}{\~{a}}o. Uma investiga{\c{c}}{\~{a}}o que {\'{e}} muito pr{\'{o}}xima da engenharia em que a maioria dos investigadores alterna com engenheiros e que come{\c{c}}am a desenvolver c{\'{o}}digo desde o dia 0 para testarem a aplica{\c{c}}{\~{a}}o com dados reais de utilizadores. Preferem testar e implementar tudo e s{\'{o}} depois lan{\c{c}}arem papers. Tornam a investiga{\c{c}}{\~{a}}o o mais pr{\'{a}}tica poss{\'{i}}vel para colocarem produto o mais depressa possivel no mercado. Suportam ainda actividades de investiga{\c{c}}{\~{a}}o isoladas que resultam em coisas como o google translator e health...},
author = {Spector, Alfred and Norvig, Peter and Petrov, Slav},
booktitle = {Communications of the ACM},
doi = {10.1145/2209249.2209262},
issn = {00010782},
pages = {34},
title = {{Google's hybrid approach to research}},
volume = {55},
year = {2012}
}
@article{Witkin,
author = {Witkin, Andrew},
file = {:home/memo/Mendeley/data/Brinks - 2011 - Physically-Based Modeling.pdf:pdf},
pages = {1--6},
title = {{Physically Based Modeling}}
}
@article{Baraff2001,
author = {Baraff, David},
file = {:home/memo/Mendeley/data/Witkin - 2001 - Particle Systems.pdf:pdf},
journal = {SIGGRAPH 2001 Course Notes},
pages = {1--39},
title = {{Collision and Contact}},
year = {2001}
}
@article{Coltona,
author = {Colton, Simon},
file = {:home/memo/Mendeley/data/Colton - Unknown - Seven Catchy Phrases for Computational Creativity Research A Position Paper.pdf:pdf},
title = {{Seven Catchy Phrases for Computational Creativity Research A Position Paper}}
}
@inproceedings{Witkin2001c,
author = {Witkin, Andrew},
file = {:home/memo/Mendeley/data/Witkin - 2001 - Particle Systems.pdf:pdf},
pages = {1--26},
publisher = {Siggraph},
title = {{Particle Systems}},
year = {2001}
}
@inproceedings{Witkin2001n,
author = {Witkin, Andrew},
file = {:home/memo/Mendeley/data/Witkin - 2001 - Differential Equation Basics.pdf:pdf},
pages = {1--13},
publisher = {Siggraph},
title = {{Differential Equation Basics}},
year = {2001}
}
@inproceedings{Kass2001,
author = {Kass, Michael},
file = {:home/memo/Mendeley/data/Kass - 2001 - Cloth and Fur Energy Functions.pdf:pdf},
pages = {1--18},
publisher = {Siggraph},
title = {{Cloth and Fur Energy Functions}},
year = {2001}
}
@inproceedings{Baraff2001a,
author = {Baraff, David},
file = {:home/memo/Mendeley/data/Baraff - 2001 - Implicit Methods.pdf:pdf},
keywords = {Pixar},
pages = {1--25},
publisher = {Siggraph},
title = {{Implicit Methods}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Impl{\#}3},
year = {2001}
}
@article{Malik2003,
author = {Malik, By Shahzad},
file = {:home/memo/Mendeley/data/Malik - 2003 - Real-time Hand Tracking and Finger Tracking for Interaction CSC2503F Project Report.pdf:pdf},
title = {{Real-time Hand Tracking and Finger Tracking for Interaction CSC2503F Project Report}},
year = {2003}
}
@article{Silva,
author = {Silva, Cl{\'{a}}udio T and Bernardon, Fabio F},
file = {:home/memo/Mendeley/data/Silva, Bernardon - Unknown - A Survey of GPU-Based Volume Rendering of Unstructured Grids Abstract.pdf:pdf},
pages = {1--22},
title = {{A Survey of GPU-Based Volume Rendering of Unstructured Grids Abstract :}}
}
@article{Clavet2005a,
address = {New York, New York, USA},
author = {Clavet, Simon and Beaudoin, Philippe and Poulin, Pierre},
doi = {10.1145/1073368.1073400},
file = {:home/memo/Mendeley/data/Clavet, Beaudoin, Poulin - 2005 - Particle-based viscoelastic fluid simulation.pdf:pdf},
isbn = {176952270X},
journal = {Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation - SCA '05},
pages = {219},
publisher = {ACM Press},
title = {{Particle-based viscoelastic fluid simulation}},
url = {http://portal.acm.org/citation.cfm?doid=1073368.1073400},
year = {2005}
}
@article{Timonen2010,
author = {Timonen, Ville and Westerholm, Jan},
doi = {10.1111/j.1467-8659.2009.01642.x},
file = {:home/memo/Mendeley/data/Timonen, Westerholm - 2010 - Scalable Height Field Self-Shadowing.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
month = {may},
number = {2},
pages = {723--731},
title = {{Scalable Height Field Self-Shadowing}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2009.01642.x},
volume = {29},
year = {2010}
}
@article{Whitehill,
author = {Whitehill, Jacob and Littlewort, Gwen and Fasel, Ian and Bartlett, Marian and Movellan, Javier},
file = {:home/memo/Mendeley/data/Whitehill et al. - Unknown - Developing a Practical Smile Detector.pdf:pdf},
pages = {1--19},
title = {{Developing a Practical Smile Detector}}
}
@article{Brinks2011,
author = {Brinks, C},
file = {:home/memo/Mendeley/data/Brinks - 2011 - Physically-Based Modeling.pdf:pdf},
pages = {1--6},
title = {{Physically-Based Modeling}},
url = {http://scholarworks.gvsu.edu/honorsprojects/82/?utm{\_}source=scholarworks.gvsu.edu{\%}252Fhonorsprojects{\%}252F82{\&}utm{\_}medium=PDF{\&}utm{\_}campaign=PDFCoverPages},
year = {2011}
}
@article{Stuart2010e,
address = {New York, New York, USA},
author = {Stuart, Jeff a. and Chen, Cheng-Kai and Ma, Kwan-Liu and Owens, John D.},
doi = {10.1145/1851476.1851597},
file = {:home/memo/Mendeley/data/Stuart et al. - 2010 - Multi-GPU volume rendering using MapReduce.pdf:pdf},
isbn = {9781605589428},
journal = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing - HPDC '10},
keywords = {gpu,mapreduce,volume rendering},
pages = {841},
publisher = {ACM Press},
title = {{Multi-GPU volume rendering using MapReduce}},
url = {http://portal.acm.org/citation.cfm?doid=1851476.1851597},
year = {2010}
}
@article{Timonen2013,
author = {Timonen, Ville},
doi = {10.1111/cgf.12155},
file = {:home/memo/Mendeley/data/Timonen - 2013 - Line-Sweep Ambient Obscurance.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
month = {jul},
number = {4},
pages = {97--105},
title = {{Line-Sweep Ambient Obscurance}},
url = {http://doi.wiley.com/10.1111/cgf.12155},
volume = {32},
year = {2013}
}
@article{Cortical2011,
author = {Cortical, H T M and Algorithms, Learning},
file = {:home/memo/Mendeley/data/Cortical, Algorithms - 2011 - HTM Cortical Learning Algorithms.pdf:pdf},
pages = {1--68},
title = {{HTM Cortical Learning Algorithms}},
year = {2011}
}
@article{Friedman2014a,
author = {Friedman, Ken},
file = {:home/memo/Mendeley/data/Friedman - 2014 - Doctorate in Design Prelude to a Multilogue.pdf:pdf},
title = {{Doctorate in Design : Prelude to a Multilogue}},
year = {2014}
}
@article{Friedman,
author = {Friedman, Ken},
file = {:home/memo/Mendeley/data/Friedman - Unknown - AHRC Practice-Led Research Review Summary Statements.pdf:pdf},
title = {{AHRC Practice-Led Research Review : Summary Statements}}
}
@article{Green2008,
author = {Green, Simon},
file = {:home/memo/Mendeley/data/Green - 2008 - Particle based Fluid Simulation.pdf:pdf},
number = {February},
title = {{Particle based Fluid Simulation}},
year = {2008}
}
@article{Ghoniem2013,
address = {New York, New York, USA},
author = {Ghoniem, Ashraf and Museth, Ken},
doi = {10.1145/2504459.2504502},
file = {:home/memo/Mendeley/data/Ghoniem, Museth - 2013 - Hair growth by means of sparse volumetric modeling and advection.pdf:pdf},
isbn = {9781450323444},
journal = {ACM SIGGRAPH 2013 Talks on - SIGGRAPH '13},
pages = {1},
publisher = {ACM Press},
title = {{Hair growth by means of sparse volumetric modeling and advection}},
url = {http://dl.acm.org/citation.cfm?doid=2504459.2504502},
volume = {3},
year = {2013}
}
@article{Teschner,
author = {Teschner, M and Kimmerle, S and Heidelberger, B and Zachmann, G and Raghupathi, L and Fuhrmann, A},
file = {:home/memo/Mendeley/data/Teschner et al. - Unknown - Collision Detection for Deformable Objects.pdf:pdf},
number = {x},
title = {{Collision Detection for Deformable Objects}},
volume = {xx}
}
@article{Coltonb,
author = {Colton, Simon},
file = {:home/memo/Mendeley/data/Colton - Unknown - Automatic Invention of Fitness Functions with Application to Scene Generation.pdf:pdf},
title = {{Automatic Invention of Fitness Functions with Application to Scene Generation}}
}
@article{Colton2008,
author = {Colton, Simon},
file = {:home/memo/Mendeley/data/Colton - 2008 - Creativity Versus the Perception of Creativity in Computational Systems.pdf:pdf},
number = {Colton 2002},
title = {{Creativity Versus the Perception of Creativity in Computational Systems}},
year = {2008}
}
@article{Adams2013,
author = {Adams, Ron},
file = {:home/memo/Mendeley/data/Adams - 2013 - Demystify Your Thesis.pdf:pdf},
number = {May},
title = {{Demystify Your Thesis}},
year = {2013}
}
